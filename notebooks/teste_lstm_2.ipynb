{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from deltalake import DeltaTable\n",
    "\n",
    "class StockLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(StockLSTM, self).__init__()\n",
    "        self.encoder = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.decoder = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        _, (hidden, cell) = self.encoder(x)\n",
    "        \n",
    "        # Decoder\n",
    "        outputs, _ = self.decoder(hidden)\n",
    "        outputs = self.fc(outputs[:, -1, :])\n",
    "        return outputs\n",
    "\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, data, seq_length):\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.seq_length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.data[idx:idx+self.seq_length]\n",
    "        target = self.data[idx+self.seq_length]\n",
    "        return sequence, target\n",
    "\n",
    "def prepare_data(df, window_size):\n",
    "    # Ensure 'ds' is in datetime format\n",
    "    df['ds'] = pd.to_datetime(df['ds'])\n",
    "    \n",
    "    # Sort by datetime\n",
    "    df = df.sort_values('ds')\n",
    "    \n",
    "    # Prepare sequences\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    for i in range(len(df) - window_size):\n",
    "        sequence = df.iloc[i:i+window_size]['y'].values\n",
    "        target = df.iloc[i+window_size]['y']\n",
    "        sequences.append(sequence)\n",
    "        targets.append(target)\n",
    "    \n",
    "    return sequences, targets\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_sequences, batch_targets in train_loader:\n",
    "            batch_sequences, batch_targets = batch_sequences.to(\"cuda\"), batch_targets.to(\"cuda\").unsqueeze(-1)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_sequences)\n",
    "            loss = criterion(outputs, batch_targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    df = DeltaTable(\"../deltalake\").to_pandas()  # Replace \"your_table_name\" with actual table name\n",
    "        \n",
    "    # Prepare data\n",
    "    window_size = 77  # As per best_config\n",
    "    sequences, targets = prepare_data(df, window_size)\n",
    "\n",
    "    # Normalize data\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_sequences = scaler.fit_transform(sequences)\n",
    "    scaled_targets = scaler.fit_transform([[target] for target in targets])\n",
    "\n",
    "    # Create dataset and dataloader\n",
    "    dataset = StockDataset(scaled_sequences, window_size)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, len(dataset)-train_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Initialize model\n",
    "    input_size = 77  # As per best_config\n",
    "    hidden_size = 300  # As per best_config\n",
    "    num_layers = 1   # As per best_config\n",
    "    output_size = 1  # For predicting single value\n",
    "\n",
    "    model = StockLSTM(input_size, hidden_size, num_layers, output_size).to(\"cuda\")\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.008279309926218455)  # As per best_config\n",
    "\n",
    "    # Train model\n",
    "    num_epochs = 10000  # As per best_config\n",
    "\n",
    "    train_model(model, train_loader, criterion, optimizer, num_epochs)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_sequences, batch_targets in val_loader:\n",
    "            batch_sequences, batch_targets = batch_sequences.to(\"cuda\"), batch_targets.to(\"cuda\").unsqueeze(-1)\n",
    "            outputs = model(batch_sequences)\n",
    "            loss = criterion(outputs, batch_targets)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    print(f\"Validation Loss: {val_loss / len(val_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))\n",
    "# sys.path.insert(0, project_root)\n",
    "\n",
    "if os.path.basename(os.getcwd()) == \"notebooks\":  \n",
    "    os.chdir(\"..\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from deltalake import DeltaTable\n",
    "from src.utils import WMAPE\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import psutil\n",
    "import platform\n",
    "import socket\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "class StockLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(StockLSTM, self).__init__()\n",
    "        self.encoder = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.decoder = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        _, (hidden, cell) = self.encoder(x)\n",
    "        \n",
    "        # Decoder\n",
    "        outputs, _ = self.decoder(hidden)\n",
    "        outputs = self.fc(outputs[:, -1, :])\n",
    "        return outputs\n",
    "\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, data, seq_length):\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.seq_length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.data[idx:idx+self.seq_length]\n",
    "        target = self.data[idx+self.seq_length]\n",
    "        return sequence, target\n",
    "\n",
    "def prepare_data(df, window_size):\n",
    "    # Ensure 'ds' is in datetime format\n",
    "    df['ds'] = pd.to_datetime(df['ds'])\n",
    "    \n",
    "    # Sort by datetime\n",
    "    df = df.sort_values('ds')\n",
    "    \n",
    "    # Prepare sequences\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    for i in range(len(df) - window_size):\n",
    "        sequence = df.iloc[i:i+window_size]['y'].values\n",
    "        target = df.iloc[i+window_size]['y']\n",
    "        sequences.append(sequence)\n",
    "        targets.append(target)\n",
    "    \n",
    "    return sequences, targets\n",
    "\n",
    "def log_system_info():\n",
    "    mlflow.log_param(\"system\", platform.system())\n",
    "    mlflow.log_param(\"release\", platform.release())\n",
    "    mlflow.log_param(\"version\", platform.version())\n",
    "    mlflow.log_param(\"processor\", platform.processor())\n",
    "    mlflow.log_param(\"cpu_count\", psutil.cpu_count())\n",
    "    mlflow.log_param(\"memory_gb\", psutil.virtual_memory().total / (1024 ** 3))\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for batch_sequences, batch_targets in train_loader:\n",
    "            batch_sequences, batch_targets = batch_sequences.to(\"cuda\"), batch_targets.to(\"cuda\").unsqueeze(-1)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_sequences)\n",
    "            loss = criterion(outputs, batch_targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "        mlflow.log_metric(\"train_loss\", avg_loss, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.enable_system_metrics_logging()\n",
    "mlflow.set_experiment(\"stock_lstm_experiment\")\n",
    "\n",
    "df = DeltaTable(\"deltalake\").to_pandas() \n",
    "    \n",
    "\n",
    "window_size = 77  # trocar pra ler o best_config\n",
    "sequences, targets = prepare_data(df, window_size)\n",
    "\n",
    "# Normalize data\n",
    "scaler = MinMaxScaler()\n",
    "scaled_sequences = scaler.fit_transform(sequences)\n",
    "scaled_targets = scaler.fit_transform([[target] for target in targets])\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = StockDataset(scaled_sequences, window_size)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, len(dataset)-train_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Initialize model\n",
    "input_size = 77  # trocar pra ler o best_config\n",
    "hidden_size = 300  # trocar pra ler o best_config\n",
    "num_layers = 1   # trocar pra ler o best_config\n",
    "learning_rate = 0.008279309926218455  # trocar pra ler o best_config\n",
    "batch_size = 32  # trocar pra ler o best_config\n",
    "output_size = 1  # For predicting single value\n",
    "\n",
    "\n",
    "model = StockLSTM(input_size, hidden_size, num_layers, output_size).to(\"cuda\")\n",
    "criterion = WMAPE() #nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  # trocar pra ler o best_config\n",
    "\n",
    "# Train model\n",
    "num_epochs = 15 #10000  # trocar pra ler o best_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/31 18:45:18 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 1.0053\n",
      "Epoch [2/5], Loss: 1.0021\n",
      "Epoch [3/5], Loss: 1.0014\n",
      "Epoch [4/5], Loss: 1.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/31 18:47:17 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2024/12/31 18:47:17 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Loss: 1.0006\n",
      "ðŸƒ View run gaudy-jay-324 at: http://127.0.0.1:5000/#/experiments/2/runs/71fa8e68a47945f1b3a4f7957dc98fc6\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/2\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    log_system_info()\n",
    "    \n",
    "    # Log model parameters\n",
    "    mlflow.log_param(\"input_size\", input_size)\n",
    "    mlflow.log_param(\"hidden_size\", hidden_size)\n",
    "    mlflow.log_param(\"num_layers\", num_layers)\n",
    "    mlflow.log_param(\"output_size\", output_size)\n",
    "    mlflow.log_param(\"num_epochs\", num_epochs)\n",
    "    mlflow.log_param(\"batch_size\", batch_size)\n",
    "    mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "\n",
    "    train_model(model, train_loader, criterion, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/31 18:47:57 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n",
      "2024/12/31 18:48:04 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2024/12/31 18:48:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.0005\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "mlflow.pytorch.log_model(model, \"stock_lstm_model\")\n",
    "\n",
    "# Evaluate on validation set\n",
    "model.eval()\n",
    "val_loss = 0\n",
    "predictions = []\n",
    "actuals = []\n",
    "with torch.no_grad():\n",
    "    for batch_sequences, batch_targets in val_loader:\n",
    "        batch_sequences, batch_targets = batch_sequences.to(\"cuda\"), batch_targets.to(\"cuda\").unsqueeze(-1)\n",
    "        outputs = model(batch_sequences)\n",
    "        loss = criterion(outputs, batch_targets)\n",
    "        val_loss += loss.item()\n",
    "        predictions.extend(outputs.cpu().numpy())\n",
    "        actuals.extend(batch_targets.cpu().numpy())\n",
    "\n",
    "avg_val_loss = val_loss / len(val_loader)\n",
    "print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "mlflow.log_metric(\"val_loss\", avg_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17793"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(actuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "557"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "predictions = np.stack(predictions)\n",
    "actuals = np.stack(actuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17793"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actuals.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Per-column arrays must each be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(predictions)\n\u001b[1;32m      3\u001b[0m actuals \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(actuals)\n\u001b[0;32m----> 5\u001b[0m predictions_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mds\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mds\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPredicted\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m actuals_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mds\u001b[39m\u001b[38;5;124m\"\u001b[39m: df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mds\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(actuals):],\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mActual\u001b[39m\u001b[38;5;124m\"\u001b[39m: actuals\n\u001b[1;32m     13\u001b[0m })\n",
      "File \u001b[0;32m~/Documents/mle-tech-challenge-4/.venv/lib/python3.11/site-packages/pandas/core/frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    774\u001b[0m     )\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m~/Documents/mle-tech-challenge-4/.venv/lib/python3.11/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/mle-tech-challenge-4/.venv/lib/python3.11/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/Documents/mle-tech-challenge-4/.venv/lib/python3.11/site-packages/pandas/core/internals/construction.py:664\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    662\u001b[0m         raw_lengths\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(val))\n\u001b[1;32m    663\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m val\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 664\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_lengths:\n\u001b[1;32m    667\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf using all scalar values, you must pass an index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Per-column arrays must each be 1-dimensional"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "predictions_df = pd.DataFrame({\n",
    "    \"ds\": df[\"ds\"].iloc[-len(predictions):],\n",
    "    \"Predicted\": predictions\n",
    "})\n",
    "\n",
    "actuals_df = pd.DataFrame({\n",
    "    \"ds\": df[\"ds\"].iloc[-len(actuals):],\n",
    "    \"Actual\": actuals\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "no numeric data to plot",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 11\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ax_i, unique_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mABEV3\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBBAS3\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m      5\u001b[0m     plot_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(\n\u001b[1;32m      6\u001b[0m         [\n\u001b[1;32m      7\u001b[0m             actuals_df\u001b[38;5;241m.\u001b[39mloc[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munique_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m unique_id]\u001b[38;5;241m.\u001b[39mtail(\u001b[38;5;241m30\u001b[39m),\n\u001b[1;32m      8\u001b[0m             predictions_df\u001b[38;5;241m.\u001b[39mloc[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munique_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m unique_id],\n\u001b[1;32m      9\u001b[0m         ]\n\u001b[1;32m     10\u001b[0m     )\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m     \u001b[43mplot_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mActual\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPredicted\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43max\u001b[49m\u001b[43m[\u001b[49m\u001b[43max_i\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinewidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munique_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m plot_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreports/forecast_plot_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mdate()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m plt\u001b[38;5;241m.\u001b[39msavefig(plot_path)\n",
      "File \u001b[0;32m~/Documents/mle-tech-challenge-4/.venv/lib/python3.11/site-packages/pandas/plotting/_core.py:1030\u001b[0m, in \u001b[0;36mPlotAccessor.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1027\u001b[0m             label_name \u001b[38;5;241m=\u001b[39m label_kw \u001b[38;5;129;01mor\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   1028\u001b[0m             data\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m label_name\n\u001b[0;32m-> 1030\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mplot_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/mle-tech-challenge-4/.venv/lib/python3.11/site-packages/pandas/plotting/_matplotlib/__init__.py:71\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(data, kind, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124max\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(ax, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft_ax\u001b[39m\u001b[38;5;124m\"\u001b[39m, ax)\n\u001b[1;32m     70\u001b[0m plot_obj \u001b[38;5;241m=\u001b[39m PLOT_CLASSES[kind](data, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 71\u001b[0m \u001b[43mplot_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m plot_obj\u001b[38;5;241m.\u001b[39mdraw()\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m plot_obj\u001b[38;5;241m.\u001b[39mresult\n",
      "File \u001b[0;32m~/Documents/mle-tech-challenge-4/.venv/lib/python3.11/site-packages/pandas/plotting/_matplotlib/core.py:499\u001b[0m, in \u001b[0;36mMPLPlot.generate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_plot_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m     fig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfig\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_plot(fig)\n",
      "File \u001b[0;32m~/Documents/mle-tech-challenge-4/.venv/lib/python3.11/site-packages/pandas/plotting/_matplotlib/core.py:698\u001b[0m, in \u001b[0;36mMPLPlot._compute_plot_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;66;03m# no non-numeric frames or series allowed\u001b[39;00m\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_empty:\n\u001b[0;32m--> 698\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno numeric data to plot\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m numeric_data\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_convert_to_ndarray)\n",
      "\u001b[0;31mTypeError\u001b[0m: no numeric data to plot"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1333.33x750 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot and save the figure\n",
    "fig, ax = plt.subplots(2, 1, figsize=(1280 / 96, 720 / 96))\n",
    "fig.tight_layout(pad=7.0)\n",
    "for ax_i, unique_id in enumerate([\"ABEV3\", \"BBAS3\"]):\n",
    "    plot_df = pd.concat(\n",
    "        [\n",
    "            actuals_df.loc[df[\"unique_id\"] == unique_id].tail(30),\n",
    "            predictions_df.loc[df[\"unique_id\"] == unique_id],\n",
    "        ]\n",
    "    ).set_index(\"ds\")\n",
    "    plot_df[[\"Actual\", \"Predicted\"]].plot(ax=ax[ax_i], linewidth=2, title=unique_id)\n",
    "\n",
    "plot_path = f\"reports/forecast_plot_{datetime.datetime.now().date()}.png\"\n",
    "plt.savefig(plot_path)\n",
    "mlflow.log_artifact(plot_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
