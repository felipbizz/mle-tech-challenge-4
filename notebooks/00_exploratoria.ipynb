{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.path.basename(os.getcwd()) == \"notebooks\":\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "import pandas as pd\n",
    "from deltalake import DeltaTable\n",
    "from src.utils import WMAPE, wmape\n",
    "\n",
    "df = DeltaTable(\"deltalake\").to_pandas()\n",
    "df = df.sort_values(by=[\"unique_id\", \"ds\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89117, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPO_FILTRO_PARA_TESTE = \"2018-01-01\"\n",
    "\n",
    "df = df.loc[df[\"ds\"] > TEMPO_FILTRO_PARA_TESTE]\n",
    "\n",
    "FILTRA_IDS = df[\"unique_id\"].unique()[:2]\n",
    "\n",
    "df = df[df[\"unique_id\"].isin(FILTRA_IDS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3468, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.loc[df[\"ds\"] < \"2024-09-01\"]\n",
    "valid = df.loc[(df[\"ds\"] >= \"2024-09-01\") & (df[\"ds\"] < \"2024-12-20\")]\n",
    "h = valid[\"ds\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.auto import AutoLSTM\n",
    "\n",
    "models = [AutoLSTM(h=h, num_samples=30, loss=WMAPE())]\n",
    "\n",
    "model = NeuralForecast(models=models, freq=\"D\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21min 33.3s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=2692)\u001b[0m /home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=2692)\u001b[0m Seed set to 5\n",
      "\u001b[36m(_train_tune pid=2692)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=2692)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=2692)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=2692)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(_train_tune pid=2692)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_train_tune pid=2692)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=2692)\u001b[0m   | Name            | Type          | Params | Mode \n",
      "\u001b[36m(_train_tune pid=2692)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=2692)\u001b[0m 0 | loss            | WMAPE         | 0      | train\n",
      "\u001b[36m(_train_tune pid=2692)\u001b[0m 1 | padder          | ConstantPad1d | 0      | train\n",
      "\u001b[36m(_train_tune pid=2692)\u001b[0m 2 | scaler          | TemporalNorm  | 0      | train\n",
      "\u001b[36m(_train_tune pid=2692)\u001b[0m 3 | hist_encoder    | LSTM          | 122 K  | train\n",
      "\u001b[36m(_train_tune pid=2692)\u001b[0m 4 | context_adapter | Linear        | 388 K  | train\n",
      "\u001b[36m(_train_tune pid=2692)\u001b[0m 5 | mlp_decoder     | MLP           | 26.6 K | train\n",
      "\u001b[36m(_train_tune pid=2692)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=2692)\u001b[0m 537 K     Trainable params\n",
      "\u001b[36m(_train_tune pid=2692)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=2692)\u001b[0m 537 K     Total params\n",
      "\u001b[36m(_train_tune pid=2692)\u001b[0m 2.150     Total estimated model params size (MB)\n",
      "\u001b[36m(_train_tune pid=2692)\u001b[0m 11        Modules in train mode\n",
      "\u001b[36m(_train_tune pid=2692)\u001b[0m 0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]\n",
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]        \n",
      "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.981, train_loss_epoch=0.981]        \n",
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997]        \n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00, 49.42it/s, v_num=0, train_loss_step=0.974, train_loss_epoch=0.977]\n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00, 47.56it/s, v_num=0, train_loss_step=0.974, train_loss_epoch=0.974]\n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00, 75.29it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030]\n",
      "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]        \n",
      "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.876, train_loss_epoch=0.876]        \n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00, 85.26it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995]\n",
      "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.918, train_loss_epoch=0.918]        \n",
      "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.853, train_loss_epoch=0.853]        \n",
      "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.726, train_loss_epoch=0.726]        \n",
      "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.715, train_loss_epoch=0.715]        \n",
      "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.667, train_loss_epoch=0.667]        \n",
      "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.966, train_loss_epoch=0.966]        \n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00, 85.67it/s, v_num=0, train_loss_step=0.966, train_loss_epoch=0.966]\n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00, 86.12it/s, v_num=0, train_loss_step=0.848, train_loss_epoch=0.848]\n",
      "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.665, train_loss_epoch=0.665]        \n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00, 63.65it/s, v_num=0, train_loss_step=0.665, train_loss_epoch=0.665]\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 81.01it/s, v_num=0, train_loss_step=0.835, train_loss_epoch=0.835]\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00, 49.48it/s, v_num=0, train_loss_step=0.783, train_loss_epoch=0.773]\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00, 47.51it/s, v_num=0, train_loss_step=0.783, train_loss_epoch=0.783]\n",
      "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.783, train_loss_epoch=0.783]        \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 60.39it/s, v_num=0, train_loss_step=0.684, train_loss_epoch=0.669]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=2692)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 40.02it/s]\u001b[A\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00, 40.36it/s, v_num=0, train_loss_step=0.698, train_loss_epoch=0.636, valid_loss=0.193]\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00, 27.62it/s, v_num=0, train_loss_step=0.698, train_loss_epoch=0.698, valid_loss=0.193]\n",
      "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.698, train_loss_epoch=0.698, valid_loss=0.193]        \n",
      "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.673, train_loss_epoch=0.673, valid_loss=0.193]        \n",
      "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.909, train_loss_epoch=0.909, valid_loss=0.193]        \n",
      "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.660, train_loss_epoch=0.660, valid_loss=0.193]        \n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 48.98it/s, v_num=0, train_loss_step=0.584, train_loss_epoch=0.584, valid_loss=0.193]\n",
      "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.584, train_loss_epoch=0.584, valid_loss=0.193]        \n",
      "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.957, train_loss_epoch=0.957, valid_loss=0.193]        \n",
      "Epoch 126: 100%|██████████| 1/1 [00:00<00:00, 89.54it/s, v_num=0, train_loss_step=0.702, train_loss_epoch=0.702, valid_loss=0.193]\n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00, 45.88it/s, v_num=0, train_loss_step=0.832, train_loss_epoch=0.832, valid_loss=0.193]\n",
      "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.832, train_loss_epoch=0.832, valid_loss=0.193]        \n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00, 70.57it/s, v_num=0, train_loss_step=0.583, train_loss_epoch=0.583, valid_loss=0.193]\n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00, 50.71it/s, v_num=0, train_loss_step=0.681, train_loss_epoch=0.681, valid_loss=0.193]\n",
      "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.672, train_loss_epoch=0.672, valid_loss=0.193]        \n",
      "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.938, train_loss_epoch=0.938, valid_loss=0.193]        \n",
      "Epoch 150: 100%|██████████| 1/1 [00:00<00:00, 91.63it/s, v_num=0, train_loss_step=0.656, train_loss_epoch=0.656, valid_loss=0.193]\n",
      "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.883, train_loss_epoch=0.883, valid_loss=0.193]        \n",
      "Epoch 155: 100%|██████████| 1/1 [00:00<00:00, 68.29it/s, v_num=0, train_loss_step=0.883, train_loss_epoch=0.883, valid_loss=0.193]\n",
      "Epoch 160: 100%|██████████| 1/1 [00:00<00:00, 71.12it/s, v_num=0, train_loss_step=0.867, train_loss_epoch=0.867, valid_loss=0.193]\n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00, 77.82it/s, v_num=0, train_loss_step=0.754, train_loss_epoch=0.754, valid_loss=0.193]\n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00, 54.21it/s, v_num=0, train_loss_step=0.784, train_loss_epoch=0.784, valid_loss=0.193]\n",
      "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.784, train_loss_epoch=0.784, valid_loss=0.193]        \n",
      "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.907, train_loss_epoch=0.907, valid_loss=0.193]        \n",
      "Epoch 175: 100%|██████████| 1/1 [00:00<00:00, 77.56it/s, v_num=0, train_loss_step=0.735, train_loss_epoch=0.735, valid_loss=0.193]\n",
      "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.649, train_loss_epoch=0.649, valid_loss=0.193]        \n",
      "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.767, train_loss_epoch=0.767, valid_loss=0.193]        \n",
      "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.735, train_loss_epoch=0.735, valid_loss=0.193]        \n",
      "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.398, train_loss_epoch=0.398, valid_loss=0.193]        \n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 63.07it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.723, valid_loss=0.193]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=2692)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 40.65it/s]\u001b[A\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00, 59.13it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.0506]\n",
      "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.0506]        \n",
      "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.619, train_loss_epoch=0.619, valid_loss=0.0506]        \n",
      "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.667, train_loss_epoch=0.667, valid_loss=0.0506]        \n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00, 81.90it/s, v_num=0, train_loss_step=0.667, train_loss_epoch=0.667, valid_loss=0.0506]\n",
      "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.0506]        \n",
      "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.655, train_loss_epoch=0.655, valid_loss=0.0506]        \n",
      "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.447, train_loss_epoch=0.447, valid_loss=0.0506]        \n",
      "Epoch 231: 100%|██████████| 1/1 [00:00<00:00, 80.26it/s, v_num=0, train_loss_step=0.447, train_loss_epoch=0.447, valid_loss=0.0506]\n",
      "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.699, train_loss_epoch=0.699, valid_loss=0.0506]        \n",
      "Epoch 241: 100%|██████████| 1/1 [00:00<00:00, 75.03it/s, v_num=0, train_loss_step=0.741, train_loss_epoch=0.741, valid_loss=0.0506]\n",
      "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.412, train_loss_epoch=0.412, valid_loss=0.0506]        \n",
      "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.662, train_loss_epoch=0.662, valid_loss=0.0506]        \n",
      "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.408, train_loss_epoch=0.408, valid_loss=0.0506]        \n",
      "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.663, train_loss_epoch=0.663, valid_loss=0.0506]        \n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00, 83.01it/s, v_num=0, train_loss_step=0.663, train_loss_epoch=0.663, valid_loss=0.0506]\n",
      "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.677, train_loss_epoch=0.677, valid_loss=0.0506]        \n",
      "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.776, train_loss_epoch=0.776, valid_loss=0.0506]        \n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00, 62.56it/s, v_num=0, train_loss_step=0.672, train_loss_epoch=0.627, valid_loss=0.0506]\n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00, 59.71it/s, v_num=0, train_loss_step=0.672, train_loss_epoch=0.672, valid_loss=0.0506]\n",
      "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.672, train_loss_epoch=0.672, valid_loss=0.0506]        \n",
      "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.672, train_loss_epoch=0.672, valid_loss=0.0506]\n",
      "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.628, train_loss_epoch=0.628, valid_loss=0.0506]        \n",
      "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.625, train_loss_epoch=0.625, valid_loss=0.0506]        \n",
      "Epoch 292: 100%|██████████| 1/1 [00:00<00:00, 74.95it/s, v_num=0, train_loss_step=0.645, train_loss_epoch=0.645, valid_loss=0.0506]\n",
      "Epoch 292: 100%|██████████| 1/1 [00:00<00:00, 55.48it/s, v_num=0, train_loss_step=0.647, train_loss_epoch=0.645, valid_loss=0.0506]\n",
      "Epoch 292: 100%|██████████| 1/1 [00:00<00:00, 53.41it/s, v_num=0, train_loss_step=0.647, train_loss_epoch=0.647, valid_loss=0.0506]\n",
      "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.647, train_loss_epoch=0.647, valid_loss=0.0506]        \n",
      "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.686, train_loss_epoch=0.686, valid_loss=0.0506]        \n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 58.40it/s, v_num=0, train_loss_step=0.674, train_loss_epoch=0.479, valid_loss=0.0506]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 37.86it/s]\u001b[A\n",
      "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=0.0618]        \n",
      "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.615, train_loss_epoch=0.615, valid_loss=0.0618]        \n",
      "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.689, train_loss_epoch=0.689, valid_loss=0.0618]        \n",
      "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.677, train_loss_epoch=0.677, valid_loss=0.0618]        \n",
      "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.662, train_loss_epoch=0.662, valid_loss=0.0618]        \n",
      "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.653, train_loss_epoch=0.653, valid_loss=0.0618]        \n",
      "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0618]        \n",
      "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.963, train_loss_epoch=0.963, valid_loss=0.0618]        \n",
      "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=0.0618]        \n",
      "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.802, train_loss_epoch=0.802, valid_loss=0.0618]        \n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00, 76.37it/s, v_num=0, train_loss_step=0.671, train_loss_epoch=0.671, valid_loss=0.0618]\n",
      "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.591, train_loss_epoch=0.591, valid_loss=0.0618]        \n",
      "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.640, train_loss_epoch=0.640, valid_loss=0.0618]        \n",
      "Epoch 367: 100%|██████████| 1/1 [00:00<00:00, 79.74it/s, v_num=0, train_loss_step=0.790, train_loss_epoch=0.790, valid_loss=0.0618]\n",
      "Epoch 372: 100%|██████████| 1/1 [00:00<00:00, 76.23it/s, v_num=0, train_loss_step=0.630, train_loss_epoch=0.630, valid_loss=0.0618]\n",
      "Epoch 372: 100%|██████████| 1/1 [00:00<00:00, 53.42it/s, v_num=0, train_loss_step=0.670, train_loss_epoch=0.670, valid_loss=0.0618]\n",
      "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471, valid_loss=0.0618]        \n",
      "Epoch 383: 100%|██████████| 1/1 [00:00<00:00, 80.78it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=0.0618]\n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00, 56.54it/s, v_num=0, train_loss_step=0.692, train_loss_epoch=0.747, valid_loss=0.0618]\n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00, 53.98it/s, v_num=0, train_loss_step=0.692, train_loss_epoch=0.692, valid_loss=0.0618]\n",
      "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.692, train_loss_epoch=0.692, valid_loss=0.0618]        \n",
      "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.669, train_loss_epoch=0.669, valid_loss=0.0618]        \n",
      "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.0618]        \n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 55.26it/s, v_num=0, train_loss_step=0.688, train_loss_epoch=1.010, valid_loss=0.0618]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 38.86it/s]\u001b[A\n",
      "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.866, train_loss_epoch=0.866, valid_loss=0.0942]        \n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00, 45.55it/s, v_num=0, train_loss_step=0.588, train_loss_epoch=0.649, valid_loss=0.0942]\n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00, 42.39it/s, v_num=0, train_loss_step=0.588, train_loss_epoch=0.588, valid_loss=0.0942]\n",
      "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.588, train_loss_epoch=0.588, valid_loss=0.0942]        \n",
      "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.677, train_loss_epoch=0.677, valid_loss=0.0942]        \n",
      "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.649, train_loss_epoch=0.649, valid_loss=0.0942]        \n",
      "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.772, train_loss_epoch=0.772, valid_loss=0.0942]        \n",
      "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.724, train_loss_epoch=0.724, valid_loss=0.0942]        \n",
      "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.946, train_loss_epoch=0.946, valid_loss=0.0942]        \n",
      "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.642, train_loss_epoch=0.642, valid_loss=0.0942]        \n",
      "Epoch 440: 100%|██████████| 1/1 [00:00<00:00, 87.70it/s, v_num=0, train_loss_step=0.662, train_loss_epoch=0.662, valid_loss=0.0942]\n",
      "Epoch 445: 100%|██████████| 1/1 [00:00<00:00, 60.27it/s, v_num=0, train_loss_step=0.715, train_loss_epoch=0.687, valid_loss=0.0942]\n",
      "Epoch 445: 100%|██████████| 1/1 [00:00<00:00, 57.06it/s, v_num=0, train_loss_step=0.715, train_loss_epoch=0.715, valid_loss=0.0942]\n",
      "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.715, train_loss_epoch=0.715, valid_loss=0.0942]        \n",
      "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.734, train_loss_epoch=0.734, valid_loss=0.0942]        \n",
      "Epoch 456: 100%|██████████| 1/1 [00:00<00:00, 73.62it/s, v_num=0, train_loss_step=0.654, train_loss_epoch=0.654, valid_loss=0.0942]\n",
      "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0942]        \n",
      "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.665, train_loss_epoch=0.665, valid_loss=0.0942]        \n",
      "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=0.0942]        \n",
      "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.960, train_loss_epoch=0.960, valid_loss=0.0942]        \n",
      "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.883, train_loss_epoch=0.883, valid_loss=0.0942]        \n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00, 41.37it/s, v_num=0, train_loss_step=0.813, train_loss_epoch=0.813, valid_loss=0.0942]\n",
      "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.813, train_loss_epoch=0.813, valid_loss=0.0942]        \n",
      "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.598, train_loss_epoch=0.598, valid_loss=0.0942]        \n",
      "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.824, train_loss_epoch=0.824, valid_loss=0.0942]        \n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 53.54it/s, v_num=0, train_loss_step=0.604, train_loss_epoch=0.792, valid_loss=0.0942]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 37.02it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=2692)\u001b[0m \n",
      "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=0.0466]        \n",
      "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.694, train_loss_epoch=0.694, valid_loss=0.0466]        \n",
      "Epoch 507: 100%|██████████| 1/1 [00:00<00:00, 35.88it/s, v_num=0, train_loss_step=0.694, train_loss_epoch=0.694, valid_loss=0.0466]\n",
      "Epoch 507: 100%|██████████| 1/1 [00:00<00:00, 30.24it/s, v_num=0, train_loss_step=0.827, train_loss_epoch=0.694, valid_loss=0.0466]\n",
      "Epoch 507: 100%|██████████| 1/1 [00:00<00:00, 28.52it/s, v_num=0, train_loss_step=0.827, train_loss_epoch=0.827, valid_loss=0.0466]\n",
      "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.827, train_loss_epoch=0.827, valid_loss=0.0466]        \n",
      "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.860, train_loss_epoch=0.860, valid_loss=0.0466]        \n",
      "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.657, train_loss_epoch=0.657, valid_loss=0.0466]        \n",
      "Epoch 522: 100%|██████████| 1/1 [00:00<00:00, 64.11it/s, v_num=0, train_loss_step=0.450, train_loss_epoch=0.450, valid_loss=0.0466]\n",
      "Epoch 527: 100%|██████████| 1/1 [00:00<00:00, 74.03it/s, v_num=0, train_loss_step=0.867, train_loss_epoch=0.867, valid_loss=0.0466]\n",
      "Epoch 527: 100%|██████████| 1/1 [00:00<00:00, 53.03it/s, v_num=0, train_loss_step=0.714, train_loss_epoch=0.714, valid_loss=0.0466]\n",
      "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.714, train_loss_epoch=0.714, valid_loss=0.0466]        \n",
      "Epoch 532: 100%|██████████| 1/1 [00:00<00:00, 70.35it/s, v_num=0, train_loss_step=0.718, train_loss_epoch=0.718, valid_loss=0.0466]\n",
      "Epoch 532: 100%|██████████| 1/1 [00:00<00:00, 54.60it/s, v_num=0, train_loss_step=0.830, train_loss_epoch=0.718, valid_loss=0.0466]\n",
      "Epoch 532: 100%|██████████| 1/1 [00:00<00:00, 49.40it/s, v_num=0, train_loss_step=0.830, train_loss_epoch=0.830, valid_loss=0.0466]\n",
      "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.830, train_loss_epoch=0.830, valid_loss=0.0466]        \n",
      "Epoch 537: 100%|██████████| 1/1 [00:00<00:00, 49.97it/s, v_num=0, train_loss_step=0.940, train_loss_epoch=0.940, valid_loss=0.0466]\n",
      "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.940, train_loss_epoch=0.940, valid_loss=0.0466]        \n",
      "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.629, train_loss_epoch=0.629, valid_loss=0.0466]        \n",
      "Epoch 547: 100%|██████████| 1/1 [00:00<00:00, 74.83it/s, v_num=0, train_loss_step=0.672, train_loss_epoch=0.672, valid_loss=0.0466]\n",
      "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.918, train_loss_epoch=0.918, valid_loss=0.0466]        \n",
      "Epoch 557: 100%|██████████| 1/1 [00:00<00:00, 92.93it/s, v_num=0, train_loss_step=0.614, train_loss_epoch=0.614, valid_loss=0.0466]\n",
      "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.906, train_loss_epoch=0.906, valid_loss=0.0466]        \n",
      "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.656, train_loss_epoch=0.656, valid_loss=0.0466]        \n",
      "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.679, train_loss_epoch=0.679, valid_loss=0.0466]        \n",
      "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.572, valid_loss=0.0466]        \n",
      "Epoch 582: 100%|██████████| 1/1 [00:00<00:00, 72.50it/s, v_num=0, train_loss_step=0.869, train_loss_epoch=0.869, valid_loss=0.0466]\n",
      "Epoch 582: 100%|██████████| 1/1 [00:00<00:00, 53.38it/s, v_num=0, train_loss_step=0.670, train_loss_epoch=0.869, valid_loss=0.0466]\n",
      "Epoch 582: 100%|██████████| 1/1 [00:00<00:00, 50.41it/s, v_num=0, train_loss_step=0.670, train_loss_epoch=0.670, valid_loss=0.0466]\n",
      "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.670, train_loss_epoch=0.670, valid_loss=0.0466]        \n",
      "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=0.0466]        \n",
      "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.0466]        \n",
      "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0466]        \n",
      "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 56.75it/s, v_num=0, train_loss_step=0.624, train_loss_epoch=1.010, valid_loss=0.0466]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 34.48it/s]\u001b[A\n",
      "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.900, train_loss_epoch=0.900, valid_loss=0.0378]        \n",
      "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.699, train_loss_epoch=0.699, valid_loss=0.0378]        \n",
      "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.654, train_loss_epoch=0.654, valid_loss=0.0378]        \n",
      "Epoch 613: 100%|██████████| 1/1 [00:00<00:00, 57.68it/s, v_num=0, train_loss_step=0.619, train_loss_epoch=0.619, valid_loss=0.0378]\n",
      "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.619, train_loss_epoch=0.619, valid_loss=0.0378]        \n",
      "Epoch 618: 100%|██████████| 1/1 [00:00<00:00, 48.58it/s, v_num=0, train_loss_step=0.704, train_loss_epoch=0.704, valid_loss=0.0378]\n",
      "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.704, train_loss_epoch=0.704, valid_loss=0.0378]        \n",
      "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.683, train_loss_epoch=0.683, valid_loss=0.0378]        \n",
      "Epoch 629: 100%|██████████| 1/1 [00:00<00:00, 72.49it/s, v_num=0, train_loss_step=0.657, train_loss_epoch=0.657, valid_loss=0.0378]\n",
      "Epoch 629: 100%|██████████| 1/1 [00:00<00:00, 54.02it/s, v_num=0, train_loss_step=0.695, train_loss_epoch=0.695, valid_loss=0.0378]\n",
      "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.686, train_loss_epoch=0.686, valid_loss=0.0378]        \n",
      "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.694, train_loss_epoch=0.694, valid_loss=0.0378]        \n",
      "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0378]        \n",
      "Epoch 644: 100%|██████████| 1/1 [00:00<00:00, 94.71it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0378]\n",
      "Epoch 649: 100%|██████████| 1/1 [00:00<00:00, 75.73it/s, v_num=0, train_loss_step=0.863, train_loss_epoch=0.863, valid_loss=0.0378]\n",
      "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.790, train_loss_epoch=0.790, valid_loss=0.0378]        \n",
      "Epoch 654: 100%|██████████| 1/1 [00:00<00:00, 64.85it/s, v_num=0, train_loss_step=0.790, train_loss_epoch=0.790, valid_loss=0.0378]\n",
      "Epoch 658: 100%|██████████| 1/1 [00:00<00:00, 68.02it/s, v_num=0, train_loss_step=0.868, train_loss_epoch=0.868, valid_loss=0.0378]\n",
      "Epoch 663: 100%|██████████| 1/1 [00:00<00:00, 83.70it/s, v_num=0, train_loss_step=0.630, train_loss_epoch=0.630, valid_loss=0.0378]\n",
      "Epoch 663: 100%|██████████| 1/1 [00:00<00:00, 57.01it/s, v_num=0, train_loss_step=0.733, train_loss_epoch=0.733, valid_loss=0.0378]\n",
      "Epoch 668: 100%|██████████| 1/1 [00:00<00:00, 60.01it/s, v_num=0, train_loss_step=0.660, train_loss_epoch=0.660, valid_loss=0.0378]\n",
      "Epoch 668: 100%|██████████| 1/1 [00:00<00:00, 49.88it/s, v_num=0, train_loss_step=0.683, train_loss_epoch=0.660, valid_loss=0.0378]\n",
      "Epoch 668: 100%|██████████| 1/1 [00:00<00:00, 47.81it/s, v_num=0, train_loss_step=0.683, train_loss_epoch=0.683, valid_loss=0.0378]\n",
      "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.647, train_loss_epoch=0.647, valid_loss=0.0378]        \n",
      "Epoch 678: 100%|██████████| 1/1 [00:00<00:00, 45.88it/s, v_num=0, train_loss_step=0.634, train_loss_epoch=0.634, valid_loss=0.0378]\n",
      "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.634, train_loss_epoch=0.634, valid_loss=0.0378]        \n",
      "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.610, train_loss_epoch=0.610, valid_loss=0.0378]        \n",
      "Epoch 689: 100%|██████████| 1/1 [00:00<00:00, 76.03it/s, v_num=0, train_loss_step=0.630, train_loss_epoch=0.630, valid_loss=0.0378]\n",
      "Epoch 694: 100%|██████████| 1/1 [00:00<00:00, 53.68it/s, v_num=0, train_loss_step=0.927, train_loss_epoch=0.927, valid_loss=0.0378]\n",
      "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.927, train_loss_epoch=0.927, valid_loss=0.0378]        \n",
      "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 56.86it/s, v_num=0, train_loss_step=0.600, train_loss_epoch=0.722, valid_loss=0.0378]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=2692)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 38.53it/s]\u001b[A\n",
      "Epoch 703: 100%|██████████| 1/1 [00:00<00:00, 62.18it/s, v_num=0, train_loss_step=0.739, train_loss_epoch=0.753, valid_loss=0.106] \n",
      "Epoch 703: 100%|██████████| 1/1 [00:00<00:00, 60.52it/s, v_num=0, train_loss_step=0.739, train_loss_epoch=0.739, valid_loss=0.106]\n",
      "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.739, train_loss_epoch=0.739, valid_loss=0.106]        \n",
      "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.854, train_loss_epoch=0.854, valid_loss=0.106]        \n",
      "Epoch 714: 100%|██████████| 1/1 [00:00<00:00, 78.73it/s, v_num=0, train_loss_step=0.842, train_loss_epoch=0.842, valid_loss=0.106]\n",
      "Epoch 719: 100%|██████████| 1/1 [00:00<00:00, 54.14it/s, v_num=0, train_loss_step=0.614, train_loss_epoch=0.614, valid_loss=0.106]\n",
      "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.614, train_loss_epoch=0.614, valid_loss=0.106]        \n",
      "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=0.106]        \n",
      "Epoch 730: 100%|██████████| 1/1 [00:00<00:00, 79.83it/s, v_num=0, train_loss_step=0.737, train_loss_epoch=0.737, valid_loss=0.106]\n",
      "Epoch 730: 100%|██████████| 1/1 [00:00<00:00, 56.42it/s, v_num=0, train_loss_step=0.696, train_loss_epoch=0.696, valid_loss=0.106]\n",
      "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.696, train_loss_epoch=0.696, valid_loss=0.106]        \n",
      "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.709, train_loss_epoch=0.709, valid_loss=0.106]        \n",
      "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.849, train_loss_epoch=0.849, valid_loss=0.106]        \n",
      "Epoch 746: 100%|██████████| 1/1 [00:00<00:00, 89.89it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=0.106]\n",
      "Epoch 746: 100%|██████████| 1/1 [00:00<00:00, 62.21it/s, v_num=0, train_loss_step=0.699, train_loss_epoch=0.325, valid_loss=0.106]\n",
      "Epoch 746: 100%|██████████| 1/1 [00:00<00:00, 59.71it/s, v_num=0, train_loss_step=0.699, train_loss_epoch=0.699, valid_loss=0.106]\n",
      "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.699, train_loss_epoch=0.699, valid_loss=0.106]        \n",
      "Epoch 751: 100%|██████████| 1/1 [00:00<00:00, 49.29it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=0.106]\n",
      "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=0.106]        \n",
      "Epoch 756: 100%|██████████| 1/1 [00:00<00:00, 63.04it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.670, valid_loss=0.106]\n",
      "Epoch 756: 100%|██████████| 1/1 [00:00<00:00, 61.26it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.106]\n",
      "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.106]        \n",
      "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.106]        \n",
      "Epoch 766: 100%|██████████| 1/1 [00:00<00:00, 77.31it/s, v_num=0, train_loss_step=0.679, train_loss_epoch=0.679, valid_loss=0.106]\n",
      "Epoch 766: 100%|██████████| 1/1 [00:00<00:00, 54.90it/s, v_num=0, train_loss_step=0.645, train_loss_epoch=0.645, valid_loss=0.106]\n",
      "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.645, train_loss_epoch=0.645, valid_loss=0.106]        \n",
      "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.739, train_loss_epoch=0.739, valid_loss=0.106]        \n",
      "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.697, train_loss_epoch=0.697, valid_loss=0.106]        \n",
      "Epoch 781:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.705, train_loss_epoch=0.705, valid_loss=0.106]        \n",
      "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.664, train_loss_epoch=0.664, valid_loss=0.106]        \n",
      "Epoch 786: 100%|██████████| 1/1 [00:00<00:00, 78.71it/s, v_num=0, train_loss_step=0.664, train_loss_epoch=0.664, valid_loss=0.106]\n",
      "Epoch 790: 100%|██████████| 1/1 [00:00<00:00, 42.49it/s, v_num=0, train_loss_step=0.578, train_loss_epoch=0.578, valid_loss=0.106]\n",
      "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.578, train_loss_epoch=0.578, valid_loss=0.106]        \n",
      "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.815, train_loss_epoch=0.815, valid_loss=0.106]        \n",
      "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 62.32it/s, v_num=0, train_loss_step=0.766, train_loss_epoch=0.497, valid_loss=0.106]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 37.78it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=2692)\u001b[0m \n",
      "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.671, train_loss_epoch=0.671, valid_loss=0.0458]        \n",
      "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.801, train_loss_epoch=0.801, valid_loss=0.0458]        \n",
      "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.698, train_loss_epoch=0.698, valid_loss=0.0458]        \n",
      "Epoch 819:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.661, train_loss_epoch=0.661, valid_loss=0.0458]        \n",
      "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0458]        \n",
      "Epoch 829: 100%|██████████| 1/1 [00:00<00:00, 66.25it/s, v_num=0, train_loss_step=0.686, train_loss_epoch=0.686, valid_loss=0.0458]\n",
      "Epoch 829: 100%|██████████| 1/1 [00:00<00:00, 54.27it/s, v_num=0, train_loss_step=0.749, train_loss_epoch=0.686, valid_loss=0.0458]\n",
      "Epoch 829: 100%|██████████| 1/1 [00:00<00:00, 51.30it/s, v_num=0, train_loss_step=0.749, train_loss_epoch=0.749, valid_loss=0.0458]\n",
      "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.749, train_loss_epoch=0.749, valid_loss=0.0458]        \n",
      "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.623, train_loss_epoch=0.623, valid_loss=0.0458]        \n",
      "Epoch 840: 100%|██████████| 1/1 [00:00<00:00, 81.55it/s, v_num=0, train_loss_step=0.690, train_loss_epoch=0.690, valid_loss=0.0458]\n",
      "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=0.0458]        \n",
      "Epoch 851: 100%|██████████| 1/1 [00:00<00:00, 79.70it/s, v_num=0, train_loss_step=0.680, train_loss_epoch=0.680, valid_loss=0.0458]\n",
      "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.0458]        \n",
      "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.636, train_loss_epoch=0.636, valid_loss=0.0458]        \n",
      "Epoch 862: 100%|██████████| 1/1 [00:00<00:00, 88.61it/s, v_num=0, train_loss_step=0.636, train_loss_epoch=0.636, valid_loss=0.0458]\n",
      "Epoch 868:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.631, train_loss_epoch=0.631, valid_loss=0.0458]        \n",
      "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.613, train_loss_epoch=0.613, valid_loss=0.0458]        \n",
      "Epoch 878: 100%|██████████| 1/1 [00:00<00:00, 74.29it/s, v_num=0, train_loss_step=0.985, train_loss_epoch=0.985, valid_loss=0.0458]\n",
      "Epoch 878: 100%|██████████| 1/1 [00:00<00:00, 51.32it/s, v_num=0, train_loss_step=0.662, train_loss_epoch=0.662, valid_loss=0.0458]\n",
      "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569, valid_loss=0.0458]        \n",
      "Epoch 889: 100%|██████████| 1/1 [00:00<00:00, 92.34it/s, v_num=0, train_loss_step=0.781, train_loss_epoch=0.781, valid_loss=0.0458]\n",
      "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.741, train_loss_epoch=0.741, valid_loss=0.0458]        \n",
      "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 59.85it/s, v_num=0, train_loss_step=0.615, train_loss_epoch=0.858, valid_loss=0.0458]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=2692)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 38.52it/s]\u001b[A\n",
      "Epoch 902: 100%|██████████| 1/1 [00:00<00:00, 66.48it/s, v_num=0, train_loss_step=0.624, train_loss_epoch=0.624, valid_loss=0.0714]\n",
      "Epoch 908:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.976, train_loss_epoch=0.976, valid_loss=0.0714]        \n",
      "Epoch 913:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.699, train_loss_epoch=0.699, valid_loss=0.0714]        \n",
      "Epoch 918:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.760, train_loss_epoch=0.760, valid_loss=0.0714]        \n",
      "Epoch 922: 100%|██████████| 1/1 [00:00<00:00, 49.16it/s, v_num=0, train_loss_step=0.761, train_loss_epoch=0.761, valid_loss=0.0714]\n",
      "Epoch 923:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.761, train_loss_epoch=0.761, valid_loss=0.0714]        \n",
      "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.745, train_loss_epoch=0.745, valid_loss=0.0714]        \n",
      "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.597, train_loss_epoch=0.597, valid_loss=0.0714]        \n",
      "Epoch 938: 100%|██████████| 1/1 [00:00<00:00, 96.10it/s, v_num=0, train_loss_step=0.695, train_loss_epoch=0.695, valid_loss=0.0714]\n",
      "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.971, train_loss_epoch=0.971, valid_loss=0.0714]        \n",
      "Epoch 949:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.915, train_loss_epoch=0.915, valid_loss=0.0714]        \n",
      "Epoch 954:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.400, train_loss_epoch=0.400, valid_loss=0.0714]        \n",
      "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.635, train_loss_epoch=0.635, valid_loss=0.0714]        \n",
      "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.650, train_loss_epoch=0.650, valid_loss=0.0714]        \n",
      "Epoch 968: 100%|██████████| 1/1 [00:00<00:00, 73.25it/s, v_num=0, train_loss_step=0.924, train_loss_epoch=0.924, valid_loss=0.0714]\n",
      "Epoch 973: 100%|██████████| 1/1 [00:00<00:00, 55.76it/s, v_num=0, train_loss_step=0.740, train_loss_epoch=0.740, valid_loss=0.0714]\n",
      "Epoch 974:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.740, train_loss_epoch=0.740, valid_loss=0.0714]        \n",
      "Epoch 979:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.732, train_loss_epoch=0.732, valid_loss=0.0714]        \n",
      "Epoch 984:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.676, train_loss_epoch=0.676, valid_loss=0.0714]        \n",
      "Epoch 988: 100%|██████████| 1/1 [00:00<00:00, 67.23it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.415, valid_loss=0.0714]\n",
      "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.795, train_loss_epoch=0.795, valid_loss=0.0714]        \n",
      "Epoch 998: 100%|██████████| 1/1 [00:00<00:00, 84.64it/s, v_num=0, train_loss_step=0.767, train_loss_epoch=0.767, valid_loss=0.0714]\n",
      "Epoch 998: 100%|██████████| 1/1 [00:00<00:00, 58.62it/s, v_num=0, train_loss_step=0.654, train_loss_epoch=0.654, valid_loss=0.0714]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=2692)\u001b[0m `Trainer.fit` stopped: `max_steps=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 56.01it/s, v_num=0, train_loss_step=0.704, train_loss_epoch=0.654, valid_loss=0.0714]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 38.77it/s]\u001b[A\n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 17.26it/s, v_num=0, train_loss_step=0.704, train_loss_epoch=0.704, valid_loss=0.0623]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=2878)\u001b[0m /home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=2878)\u001b[0m Seed set to 2\n",
      "\u001b[36m(_train_tune pid=2878)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=2878)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=2878)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=2878)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(_train_tune pid=2878)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_train_tune pid=2878)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=2878)\u001b[0m   | Name            | Type          | Params | Mode \n",
      "\u001b[36m(_train_tune pid=2878)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=2878)\u001b[0m 0 | loss            | WMAPE         | 0      | train\n",
      "\u001b[36m(_train_tune pid=2878)\u001b[0m 1 | padder          | ConstantPad1d | 0      | train\n",
      "\u001b[36m(_train_tune pid=2878)\u001b[0m 2 | scaler          | TemporalNorm  | 0      | train\n",
      "\u001b[36m(_train_tune pid=2878)\u001b[0m 3 | hist_encoder    | LSTM          | 1.1 M  | train\n",
      "\u001b[36m(_train_tune pid=2878)\u001b[0m 4 | context_adapter | Linear        | 115 K  | train\n",
      "\u001b[36m(_train_tune pid=2878)\u001b[0m 5 | mlp_decoder     | MLP           | 3.6 K  | train\n",
      "\u001b[36m(_train_tune pid=2878)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=2878)\u001b[0m 1.2 M     Trainable params\n",
      "\u001b[36m(_train_tune pid=2878)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=2878)\u001b[0m 1.2 M     Total params\n",
      "\u001b[36m(_train_tune pid=2878)\u001b[0m 4.822     Total estimated model params size (MB)\n",
      "\u001b[36m(_train_tune pid=2878)\u001b[0m 11        Modules in train mode\n",
      "\u001b[36m(_train_tune pid=2878)\u001b[0m 0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998]        \n",
      "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993]        \n",
      "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.971, train_loss_epoch=0.971]        \n",
      "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.907, train_loss_epoch=0.907]        \n",
      "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.839, train_loss_epoch=0.839]        \n",
      "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.800, train_loss_epoch=0.800]        \n",
      "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.777, train_loss_epoch=0.777]        \n",
      "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.750, train_loss_epoch=0.750]        \n",
      "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.702, train_loss_epoch=0.702]       \n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=0, train_loss_step=0.702, train_loss_epoch=0.702]\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00,  5.39it/s, v_num=0, train_loss_step=0.678, train_loss_epoch=0.678]\n",
      "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.678, train_loss_epoch=0.678]        \n",
      "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.659, train_loss_epoch=0.659]        \n",
      "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.633, train_loss_epoch=0.633]        \n",
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.615, train_loss_epoch=0.615]        \n",
      "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.618, train_loss_epoch=0.618]        \n",
      "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.602, train_loss_epoch=0.602]        \n",
      "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.607, train_loss_epoch=0.607]        \n",
      "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.592, train_loss_epoch=0.592]        \n",
      "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.585, train_loss_epoch=0.585]        \n",
      "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.580, train_loss_epoch=0.580]        \n",
      "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.585, train_loss_epoch=0.585]        \n",
      "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582]        \n",
      "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.579, train_loss_epoch=0.579]        \n",
      "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574]        \n",
      "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.577, train_loss_epoch=0.577]        \n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00,  5.71it/s, v_num=0, train_loss_step=0.577, train_loss_epoch=0.577]\n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.572]\n",
      "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.572]        \n",
      "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.572]        \n",
      "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569]        \n",
      "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.572]        \n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.572]\n",
      "Epoch 29: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569]\n",
      "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569]        \n",
      "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569]        \n",
      "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567]        \n",
      "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567]        \n",
      "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.566, train_loss_epoch=0.566]        \n",
      "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565]        \n",
      "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563]        \n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00,  3.94it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563]\n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00,  3.93it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563]\n",
      "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563]        \n",
      "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563]        \n",
      "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562]        \n",
      "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560]        \n",
      "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559]        \n",
      "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556]        \n",
      "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.570, train_loss_epoch=0.570]        \n",
      "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574]        \n",
      "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560]        \n",
      "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565]        \n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00,  5.44it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565]\n",
      "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568]        \n",
      "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554]        \n",
      "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563]        \n",
      "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555]        \n",
      "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567]        \n",
      "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567]        \n",
      "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.575, train_loss_epoch=0.575]        \n",
      "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.579, train_loss_epoch=0.579]        \n",
      "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574]        \n",
      "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567]        \n",
      "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567]        \n",
      "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564]        \n",
      "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557]        \n",
      "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562]        \n",
      "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561]        \n",
      "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559]        \n",
      "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563]        \n",
      "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559]        \n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00,  5.79it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559]\n",
      "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555]        \n",
      "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556]        \n",
      "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553]        \n",
      "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551]        \n",
      "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550]        \n",
      "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545]        \n",
      "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.572]        \n",
      "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568]        \n",
      "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551]        \n",
      "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557]        \n",
      "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553]        \n",
      "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554]        \n",
      "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550]        \n",
      "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543]        \n",
      "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548]        \n",
      "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547]        \n",
      "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567]        \n",
      "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.572]        \n",
      "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568]        \n",
      "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550]        \n",
      "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565]        \n",
      "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569]        \n",
      "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561]        \n",
      "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.570, train_loss_epoch=0.570]        \n",
      "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.572]        \n",
      "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562]        \n",
      "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549]        \n",
      "Epoch 91: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549]\n",
      "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547]        \n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548]\n",
      "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548]        \n",
      "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547]        \n",
      "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549]        \n",
      "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545]        \n",
      "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538]        \n",
      "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538]        \n",
      "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538]        \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=2878)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  9.80it/s]\u001b[A\n",
      "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.0487]       \n",
      "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0487]        \n",
      "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=0.0487]        \n",
      "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=0.0487]        \n",
      "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.0487]        \n",
      "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.0487]        \n",
      "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0487]        \n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=0.0487]\n",
      "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=0.0487]        \n",
      "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.0487]        \n",
      "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0487]        \n",
      "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.0487]        \n",
      "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.0487]        \n",
      "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.0487]        \n",
      "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0487]        \n",
      "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=0.0487]        \n",
      "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0487]        \n",
      "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0487]        \n",
      "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0487]        \n",
      "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0487]        \n",
      "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0487]        \n",
      "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0487]        \n",
      "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0487]        \n",
      "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0487]        \n",
      "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0487]        \n",
      "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0487]        \n",
      "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0487]        \n",
      "Epoch 125: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.510, valid_loss=0.0487]\n",
      "Epoch 125: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0487]\n",
      "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0487]        \n",
      "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0487]        \n",
      "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0487]        \n",
      "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0487]        \n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00,  4.32it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0487]\n",
      "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0487]        \n",
      "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0487]        \n",
      "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0487]        \n",
      "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0487]        \n",
      "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0487]        \n",
      "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0487]        \n",
      "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0487]        \n",
      "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0487]        \n",
      "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0487]        \n",
      "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0487]        \n",
      "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0487]        \n",
      "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0487]        \n",
      "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0487]        \n",
      "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0487]        \n",
      "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0487]        \n",
      "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0487]        \n",
      "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0487]        \n",
      "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0487]        \n",
      "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0487]        \n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00,  5.73it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0487]\n",
      "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0487]        \n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0487]\n",
      "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0487]        \n",
      "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0487]        \n",
      "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0487]        \n",
      "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0487]        \n",
      "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0487]        \n",
      "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0487]        \n",
      "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0487]        \n",
      "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0487]        \n",
      "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0487]        \n",
      "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0487]        \n",
      "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0487]        \n",
      "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0487]        \n",
      "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0487]        \n",
      "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0487]        \n",
      "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0487]        \n",
      "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0487]        \n",
      "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0487]        \n",
      "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0487]        \n",
      "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0487]        \n",
      "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0487]        \n",
      "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0487]        \n",
      "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0487]        \n",
      "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0487]        \n",
      "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0487]        \n",
      "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0487]        \n",
      "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0487]        \n",
      "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0487]        \n",
      "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0487]        \n",
      "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0487]        \n",
      "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0487]        \n",
      "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0487]        \n",
      "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0487]        \n",
      "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0487]        \n",
      "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0487]        \n",
      "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0487]        \n",
      "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0487]        \n",
      "Epoch 185: 100%|██████████| 1/1 [00:00<00:00,  5.88it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0487]\n",
      "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0487]        \n",
      "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0487]        \n",
      "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0487]        \n",
      "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0487]        \n",
      "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0487]        \n",
      "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0487]        \n",
      "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0487]        \n",
      "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.0487]        \n",
      "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471, valid_loss=0.0487]        \n",
      "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473, valid_loss=0.0487]        \n",
      "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471, valid_loss=0.0487]        \n",
      "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=0.0487]        \n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00,  6.03it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=0.0487]\n",
      "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.0487]        \n",
      "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=0.0487]        \n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s, v_num=0, train_loss_step=0.451, train_loss_epoch=0.462, valid_loss=0.0487]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=2878)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 10.68it/s]\u001b[A\n",
      "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.451, train_loss_epoch=0.451, valid_loss=0.0361]        \n",
      "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455, valid_loss=0.0361]        \n",
      "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452, valid_loss=0.0361]        \n",
      "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0361]        \n",
      "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.0361]        \n",
      "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=0.0361]        \n",
      "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=0.0361]        \n",
      "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.459, train_loss_epoch=0.459, valid_loss=0.0361]        \n",
      "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=0.0361]        \n",
      "Epoch 208: 100%|██████████| 1/1 [00:00<00:00,  4.78it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=0.0361]\n",
      "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=0.0361]        \n",
      "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452, valid_loss=0.0361]        \n",
      "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=0.0361]        \n",
      "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.468, valid_loss=0.0361]        \n",
      "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.457, train_loss_epoch=0.457, valid_loss=0.0361]        \n",
      "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.456, train_loss_epoch=0.456, valid_loss=0.0361]        \n",
      "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=0.0361]        \n",
      "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455, valid_loss=0.0361]        \n",
      "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.458, train_loss_epoch=0.458, valid_loss=0.0361]        \n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00,  5.83it/s, v_num=0, train_loss_step=0.458, train_loss_epoch=0.458, valid_loss=0.0361]\n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00,  5.69it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.458, valid_loss=0.0361]\n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00,  5.67it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455, valid_loss=0.0361]\n",
      "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455, valid_loss=0.0361]        \n",
      "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0361]        \n",
      "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0361]        \n",
      "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.0361]        \n",
      "Epoch 221: 100%|██████████| 1/1 [00:00<00:00,  5.69it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0361]\n",
      "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0361]        \n",
      "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0361]        \n",
      "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0361]        \n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00,  5.75it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0361]\n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.512, valid_loss=0.0361]\n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00,  5.52it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0361]\n",
      "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0361]        \n",
      "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0361]\n",
      "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0361]        \n",
      "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0361]        \n",
      "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0361]        \n",
      "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0361]        \n",
      "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0361]        \n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00,  5.20it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0361]\n",
      "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0361]        \n",
      "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.475, train_loss_epoch=0.475, valid_loss=0.0361]        \n",
      "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471, valid_loss=0.0361]        \n",
      "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473, valid_loss=0.0361]        \n",
      "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.0361]        \n",
      "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=0.0361]        \n",
      "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.465, valid_loss=0.0361]        \n",
      "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=0.0361]        \n",
      "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.0361]        \n",
      "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=0.0361]        \n",
      "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=0.0361]        \n",
      "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.457, train_loss_epoch=0.457, valid_loss=0.0361]        \n",
      "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.456, train_loss_epoch=0.456, valid_loss=0.0361]        \n",
      "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.461, train_loss_epoch=0.461, valid_loss=0.0361]        \n",
      "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0361]        \n",
      "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0361]        \n",
      "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0361]        \n",
      "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0361]        \n",
      "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0361]        \n",
      "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0361]        \n",
      "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0361]        \n",
      "Epoch 251: 100%|██████████| 1/1 [00:00<00:00,  5.23it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0361]\n",
      "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0361]        \n",
      "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=0.0361]        \n",
      "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0361]        \n",
      "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0361]        \n",
      "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573, valid_loss=0.0361]        \n",
      "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0361]        \n",
      "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0361]        \n",
      "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0361]        \n",
      "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0361]        \n",
      "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0361]        \n",
      "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0361]        \n",
      "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0361]        \n",
      "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0361]        \n",
      "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0361]        \n",
      "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0361]        \n",
      "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0361]        \n",
      "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0361]        \n",
      "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0361]        \n",
      "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0361]        \n",
      "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0361]        \n",
      "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0361]        \n",
      "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0361]        \n",
      "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0361]        \n",
      "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0361]        \n",
      "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0361]        \n",
      "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0361]        \n",
      "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0361]        \n",
      "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0361]        \n",
      "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0361]        \n",
      "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0361]        \n",
      "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0361]        \n",
      "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0361]        \n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00,  5.21it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0361]\n",
      "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0361]        \n",
      "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0361]        \n",
      "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0361]        \n",
      "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0361]        \n",
      "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0361]        \n",
      "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0361]        \n",
      "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0361]        \n",
      "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0361]        \n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00,  5.80it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0361]\n",
      "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0361]        \n",
      "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0361]        \n",
      "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0361]        \n",
      "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0361]        \n",
      "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0361]        \n",
      "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0361]        \n",
      "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0361]        \n",
      "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0361]        \n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.505, valid_loss=0.0361]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=2878)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  9.12it/s]\u001b[A\n",
      "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0324]        \n",
      "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0324]        \n",
      "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0324]        \n",
      "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0324]        \n",
      "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0324]        \n",
      "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0324]        \n",
      "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0324]        \n",
      "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0324]        \n",
      "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0324]        \n",
      "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0324]        \n",
      "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473, valid_loss=0.0324]        \n",
      "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473, valid_loss=0.0324]        \n",
      "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=0.0324]        \n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00,  5.52it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=0.0324]\n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00,  5.41it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=0.0324]\n",
      "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=0.0324]        \n",
      "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.465, valid_loss=0.0324]        \n",
      "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.0324]        \n",
      "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0324]        \n",
      "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0324]        \n",
      "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0324]        \n",
      "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0324]        \n",
      "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473, valid_loss=0.0324]        \n",
      "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.468, valid_loss=0.0324]        \n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.468, valid_loss=0.0324]\n",
      "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=0.0324]        \n",
      "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.0324]        \n",
      "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.0324]        \n",
      "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=0.0324]        \n",
      "Epoch 325: 100%|██████████| 1/1 [00:00<00:00,  4.98it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=0.0324]\n",
      "Epoch 325: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=0, train_loss_step=0.457, train_loss_epoch=0.460, valid_loss=0.0324]\n",
      "Epoch 325: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=0, train_loss_step=0.457, train_loss_epoch=0.457, valid_loss=0.0324]\n",
      "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.457, train_loss_epoch=0.457, valid_loss=0.0324]        \n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00,  4.91it/s, v_num=0, train_loss_step=0.454, train_loss_epoch=0.454, valid_loss=0.0324]\n",
      "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.454, train_loss_epoch=0.454, valid_loss=0.0324]        \n",
      "Epoch 327: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=0, train_loss_step=0.454, train_loss_epoch=0.454, valid_loss=0.0324]\n",
      "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452, valid_loss=0.0324]        \n",
      "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.449, train_loss_epoch=0.449, valid_loss=0.0324]        \n",
      "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.447, train_loss_epoch=0.447, valid_loss=0.0324]        \n",
      "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.449, train_loss_epoch=0.449, valid_loss=0.0324]        \n",
      "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.437, train_loss_epoch=0.437, valid_loss=0.0324]        \n",
      "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.447, train_loss_epoch=0.447, valid_loss=0.0324]        \n",
      "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=0.0324]        \n",
      "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571, valid_loss=0.0324]        \n",
      "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573, valid_loss=0.0324]        \n",
      "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0324]        \n",
      "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.628, train_loss_epoch=0.628, valid_loss=0.0324]        \n",
      "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.629, train_loss_epoch=0.629, valid_loss=0.0324]        \n",
      "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.572, valid_loss=0.0324]        \n",
      "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.566, train_loss_epoch=0.566, valid_loss=0.0324]        \n",
      "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567, valid_loss=0.0324]        \n",
      "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.0324]        \n",
      "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=0.0324]        \n",
      "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.0324]        \n",
      "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0324]        \n",
      "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0324]        \n",
      "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573, valid_loss=0.0324]        \n",
      "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.583, train_loss_epoch=0.583, valid_loss=0.0324]        \n",
      "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569, valid_loss=0.0324]        \n",
      "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0324]        \n",
      "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0324]        \n",
      "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0324]        \n",
      "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0324]        \n",
      "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569, valid_loss=0.0324]        \n",
      "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0324]        \n",
      "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0324]        \n",
      "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0324]        \n",
      "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=0.0324]        \n",
      "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=0.0324]        \n",
      "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.0324]        \n",
      "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0324]        \n",
      "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0324]        \n",
      "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0324]        \n",
      "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0324]        \n",
      "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0324]        \n",
      "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0324]        \n",
      "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0324]        \n",
      "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0324]        \n",
      "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0324]        \n",
      "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0324]        \n",
      "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0324]        \n",
      "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0324]        \n",
      "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0324]        \n",
      "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0324]        \n",
      "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0324]        \n",
      "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0324]        \n",
      "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0324]        \n",
      "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0324]        \n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0324]\n",
      "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0324]        \n",
      "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0324]        \n",
      "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0324]        \n",
      "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0324]        \n",
      "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0324]        \n",
      "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0324]        \n",
      "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0324]        \n",
      "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0324]        \n",
      "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0324]        \n",
      "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0324]        \n",
      "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0324]        \n",
      "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0324]        \n",
      "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0324]        \n",
      "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0324]        \n",
      "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0324]        \n",
      "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0324]        \n",
      "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0324]        \n",
      "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0324]        \n",
      "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0324]        \n",
      "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0324]        \n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.502, valid_loss=0.0324]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=2878)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 10.95it/s]\u001b[A\n",
      "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=0.0711]        \n",
      "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0711]        \n",
      "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0711]        \n",
      "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0711]        \n",
      "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0711]        \n",
      "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0711]        \n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00,  5.63it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0711]\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00,  5.53it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.497, valid_loss=0.0711]\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00,  5.52it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0711]\n",
      "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0711]        \n",
      "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0711]        \n",
      "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0711]        \n",
      "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.585, train_loss_epoch=0.585, valid_loss=0.0711]        \n",
      "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.603, train_loss_epoch=0.603, valid_loss=0.0711]        \n",
      "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.596, train_loss_epoch=0.596, valid_loss=0.0711]        \n",
      "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.593, train_loss_epoch=0.593, valid_loss=0.0711]        \n",
      "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.580, train_loss_epoch=0.580, valid_loss=0.0711]        \n",
      "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.570, train_loss_epoch=0.570, valid_loss=0.0711]        \n",
      "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567, valid_loss=0.0711]        \n",
      "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567, valid_loss=0.0711]        \n",
      "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=0.0711]        \n",
      "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=0.0711]        \n",
      "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=0.0711]        \n",
      "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0711]        \n",
      "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0711]        \n",
      "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0711]        \n",
      "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0711]        \n",
      "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0711]        \n",
      "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0711]        \n",
      "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0711]        \n",
      "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0711]        \n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00,  5.74it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0711]\n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.515, valid_loss=0.0711]\n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0711]\n",
      "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0711]        \n",
      "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0711]        \n",
      "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0711]        \n",
      "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0711]        \n",
      "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0711]        \n",
      "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0711]        \n",
      "Epoch 433: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.498, valid_loss=0.0711]\n",
      "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0711]        \n",
      "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0711]        \n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.492, valid_loss=0.0711]\n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0711]\n",
      "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0711]        \n",
      "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0711]        \n",
      "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0711]        \n",
      "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0711]        \n",
      "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0711]        \n",
      "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0711]        \n",
      "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0711]        \n",
      "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0711]        \n",
      "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0711]        \n",
      "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0711]        \n",
      "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471, valid_loss=0.0711]        \n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00,  5.37it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471, valid_loss=0.0711]\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00,  5.21it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.471, valid_loss=0.0711]\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.0711]\n",
      "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.0711]        \n",
      "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0711]        \n",
      "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0711]        \n",
      "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0711]        \n",
      "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0711]        \n",
      "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0711]        \n",
      "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.0711]        \n",
      "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0711]        \n",
      "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0711]        \n",
      "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0711]        \n",
      "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0711]        \n",
      "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.475, train_loss_epoch=0.475, valid_loss=0.0711]        \n",
      "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.0711]        \n",
      "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=0.0711]        \n",
      "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=0.0711]        \n",
      "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471, valid_loss=0.0711]        \n",
      "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.474, train_loss_epoch=0.474, valid_loss=0.0711]        \n",
      "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0711]        \n",
      "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0711]        \n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0711]\n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.491, valid_loss=0.0711]\n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00,  5.45it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0711]\n",
      "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0711]        \n",
      "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0711]        \n",
      "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0711]        \n",
      "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0711]        \n",
      "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0711]        \n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00,  5.86it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0711]\n",
      "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0711]        \n",
      "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.475, train_loss_epoch=0.475, valid_loss=0.0711]        \n",
      "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.474, train_loss_epoch=0.474, valid_loss=0.0711]        \n",
      "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.468, valid_loss=0.0711]        \n",
      "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=0.0711]        \n",
      "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.0711]        \n",
      "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.465, valid_loss=0.0711]        \n",
      "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.0711]        \n",
      "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=0.0711]        \n",
      "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=0.0711]        \n",
      "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=0.0711]        \n",
      "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.458, train_loss_epoch=0.458, valid_loss=0.0711]        \n",
      "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.456, train_loss_epoch=0.456, valid_loss=0.0711]        \n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00,  5.39it/s, v_num=0, train_loss_step=0.459, train_loss_epoch=0.459, valid_loss=0.0711]\n",
      "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.459, train_loss_epoch=0.459, valid_loss=0.0711]        \n",
      "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0711]        \n",
      "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0711]        \n",
      "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0711]        \n",
      "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0711]        \n",
      "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0711]        \n",
      "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0711]        \n",
      "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0711]        \n",
      "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0711]        \n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0711]\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00,  5.41it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0711]\n",
      "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0711]        \n",
      "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0711]        \n",
      "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0711]        \n",
      "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0711]        \n",
      "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.475, train_loss_epoch=0.475, valid_loss=0.0711]        \n",
      "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.468, valid_loss=0.0711]        \n",
      "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=0.0711]        \n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  5.34it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=0.0711]\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.466, valid_loss=0.0711]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=2878)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 10.31it/s]\u001b[A\n",
      "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=0.0454]        \n",
      "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.0454]        \n",
      "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=0.0454]        \n",
      "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=0.0454]        \n",
      "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.465, valid_loss=0.0454]        \n",
      "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.459, train_loss_epoch=0.459, valid_loss=0.0454]        \n",
      "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.468, valid_loss=0.0454]        \n",
      "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=0.0454]        \n",
      "Epoch 507: 100%|██████████| 1/1 [00:00<00:00,  5.94it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=0.0454]\n",
      "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.456, train_loss_epoch=0.456, valid_loss=0.0454]        \n",
      "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.474, train_loss_epoch=0.474, valid_loss=0.0454]        \n",
      "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=0.0454]        \n",
      "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=0.0454]        \n",
      "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.458, train_loss_epoch=0.458, valid_loss=0.0454]        \n",
      "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452, valid_loss=0.0454]        \n",
      "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=0.0454]        \n",
      "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.449, train_loss_epoch=0.449, valid_loss=0.0454]        \n",
      "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.448, valid_loss=0.0454]        \n",
      "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.444, train_loss_epoch=0.444, valid_loss=0.0454]        \n",
      "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.435, train_loss_epoch=0.435, valid_loss=0.0454]        \n",
      "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.436, train_loss_epoch=0.436, valid_loss=0.0454]        \n",
      "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.433, train_loss_epoch=0.433, valid_loss=0.0454]        \n",
      "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.430, train_loss_epoch=0.430, valid_loss=0.0454]        \n",
      "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=0.0454]        \n",
      "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.424, train_loss_epoch=0.424, valid_loss=0.0454]        \n",
      "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.423, train_loss_epoch=0.423, valid_loss=0.0454]        \n",
      "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=0.0454]        \n",
      "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452, valid_loss=0.0454]        \n",
      "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.435, train_loss_epoch=0.435, valid_loss=0.0454]        \n",
      "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.443, train_loss_epoch=0.443, valid_loss=0.0454]        \n",
      "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.429, train_loss_epoch=0.429, valid_loss=0.0454]        \n",
      "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.429, train_loss_epoch=0.429, valid_loss=0.0454]        \n",
      "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.431, train_loss_epoch=0.431, valid_loss=0.0454]        \n",
      "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.423, train_loss_epoch=0.423, valid_loss=0.0454]        \n",
      "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.420, train_loss_epoch=0.420, valid_loss=0.0454]        \n",
      "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.420, train_loss_epoch=0.420, valid_loss=0.0454]        \n",
      "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.415, valid_loss=0.0454]        \n",
      "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.418, train_loss_epoch=0.418, valid_loss=0.0454]        \n",
      "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.416, valid_loss=0.0454]        \n",
      "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.411, train_loss_epoch=0.411, valid_loss=0.0454]        \n",
      "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.410, train_loss_epoch=0.410, valid_loss=0.0454]        \n",
      "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=0.0454]        \n",
      "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.403, train_loss_epoch=0.403, valid_loss=0.0454]        \n",
      "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.402, train_loss_epoch=0.402, valid_loss=0.0454]        \n",
      "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.407, train_loss_epoch=0.407, valid_loss=0.0454]        \n",
      "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396, valid_loss=0.0454]        \n",
      "Epoch 544: 100%|██████████| 1/1 [00:00<00:00,  4.35it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396, valid_loss=0.0454]\n",
      "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.399, train_loss_epoch=0.399, valid_loss=0.0454]        \n",
      "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=0.0454]        \n",
      "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.392, train_loss_epoch=0.392, valid_loss=0.0454]        \n",
      "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.391, train_loss_epoch=0.391, valid_loss=0.0454]        \n",
      "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.387, train_loss_epoch=0.387, valid_loss=0.0454]        \n",
      "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.386, train_loss_epoch=0.386, valid_loss=0.0454]        \n",
      "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.382, train_loss_epoch=0.382, valid_loss=0.0454]        \n",
      "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.382, train_loss_epoch=0.382, valid_loss=0.0454]        \n",
      "Epoch 552: 100%|██████████| 1/1 [00:00<00:00,  5.46it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379, valid_loss=0.0454]\n",
      "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379, valid_loss=0.0454]        \n",
      "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=0.0454]        \n",
      "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.370, train_loss_epoch=0.370, valid_loss=0.0454]        \n",
      "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.374, train_loss_epoch=0.374, valid_loss=0.0454]        \n",
      "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=0.0454]        \n",
      "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.435, train_loss_epoch=0.435, valid_loss=0.0454]        \n",
      "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.424, train_loss_epoch=0.424, valid_loss=0.0454]        \n",
      "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.414, train_loss_epoch=0.414, valid_loss=0.0454]        \n",
      "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.422, train_loss_epoch=0.422, valid_loss=0.0454]        \n",
      "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.424, train_loss_epoch=0.424, valid_loss=0.0454]        \n",
      "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.410, train_loss_epoch=0.410, valid_loss=0.0454]        \n",
      "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.409, train_loss_epoch=0.409, valid_loss=0.0454]        \n",
      "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.409, train_loss_epoch=0.409, valid_loss=0.0454]        \n",
      "Epoch 565: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=0, train_loss_step=0.399, train_loss_epoch=0.399, valid_loss=0.0454]\n",
      "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.399, train_loss_epoch=0.399, valid_loss=0.0454]        \n",
      "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.397, train_loss_epoch=0.397, valid_loss=0.0454]        \n",
      "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.393, train_loss_epoch=0.393, valid_loss=0.0454]        \n",
      "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.389, valid_loss=0.0454]        \n",
      "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.387, train_loss_epoch=0.387, valid_loss=0.0454]        \n",
      "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.383, train_loss_epoch=0.383, valid_loss=0.0454]        \n",
      "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=0.0454]        \n",
      "Epoch 572: 100%|██████████| 1/1 [00:00<00:00,  5.72it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=0.0454]\n",
      "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.376, train_loss_epoch=0.376, valid_loss=0.0454]        \n",
      "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.373, train_loss_epoch=0.373, valid_loss=0.0454]        \n",
      "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.371, train_loss_epoch=0.371, valid_loss=0.0454]        \n",
      "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369, valid_loss=0.0454]        \n",
      "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361, valid_loss=0.0454]        \n",
      "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=0.0454]        \n",
      "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.359, train_loss_epoch=0.359, valid_loss=0.0454]        \n",
      "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=0.0454]        \n",
      "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.358, train_loss_epoch=0.358, valid_loss=0.0454]        \n",
      "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379, valid_loss=0.0454]        \n",
      "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.384, train_loss_epoch=0.384, valid_loss=0.0454]        \n",
      "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.373, train_loss_epoch=0.373, valid_loss=0.0454]        \n",
      "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369, valid_loss=0.0454]        \n",
      "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.370, train_loss_epoch=0.370, valid_loss=0.0454]        \n",
      "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.368, train_loss_epoch=0.368, valid_loss=0.0454]        \n",
      "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365, valid_loss=0.0454]        \n",
      "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363, valid_loss=0.0454]        \n",
      "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.358, train_loss_epoch=0.358, valid_loss=0.0454]        \n",
      "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=0.0454]        \n",
      "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=0.0454]        \n",
      "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.345, train_loss_epoch=0.345, valid_loss=0.0454]        \n",
      "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.340, train_loss_epoch=0.340, valid_loss=0.0454]        \n",
      "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336, valid_loss=0.0454]        \n",
      "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=0.0454]        \n",
      "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=0.0454]        \n",
      "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=0.0454]        \n",
      "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.344, train_loss_epoch=0.344, valid_loss=0.0454]        \n",
      "Epoch 599: 100%|██████████| 1/1 [00:00<00:00,  5.29it/s, v_num=0, train_loss_step=0.421, train_loss_epoch=0.344, valid_loss=0.0454]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=2878)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 11.14it/s]\u001b[A\n",
      "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.421, train_loss_epoch=0.421, valid_loss=0.0322]        \n",
      "Epoch 600: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.434, train_loss_epoch=0.434, valid_loss=0.0322]\n",
      "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.434, train_loss_epoch=0.434, valid_loss=0.0322]        \n",
      "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.420, train_loss_epoch=0.420, valid_loss=0.0322]        \n",
      "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.411, train_loss_epoch=0.411, valid_loss=0.0322]        \n",
      "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.423, train_loss_epoch=0.423, valid_loss=0.0322]        \n",
      "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.416, valid_loss=0.0322]        \n",
      "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.423, train_loss_epoch=0.423, valid_loss=0.0322]        \n",
      "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.414, train_loss_epoch=0.414, valid_loss=0.0322]        \n",
      "Epoch 607: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.416, valid_loss=0.0322]\n",
      "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.416, valid_loss=0.0322]        \n",
      "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.404, train_loss_epoch=0.404, valid_loss=0.0322]        \n",
      "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.403, train_loss_epoch=0.403, valid_loss=0.0322]        \n",
      "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.398, train_loss_epoch=0.398, valid_loss=0.0322]        \n",
      "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.387, train_loss_epoch=0.387, valid_loss=0.0322]        \n",
      "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.386, train_loss_epoch=0.386, valid_loss=0.0322]        \n",
      "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.383, train_loss_epoch=0.383, valid_loss=0.0322]        \n",
      "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396, valid_loss=0.0322]        \n",
      "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=0.0322]        \n",
      "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.392, train_loss_epoch=0.392, valid_loss=0.0322]        \n",
      "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=0.0322]        \n",
      "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.417, train_loss_epoch=0.417, valid_loss=0.0322]        \n",
      "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.414, train_loss_epoch=0.414, valid_loss=0.0322]        \n",
      "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.412, train_loss_epoch=0.412, valid_loss=0.0322]        \n",
      "Epoch 622:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.406, train_loss_epoch=0.406, valid_loss=0.0322]        \n",
      "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=0.0322]        \n",
      "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.413, train_loss_epoch=0.413, valid_loss=0.0322]        \n",
      "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.400, train_loss_epoch=0.400, valid_loss=0.0322]        \n",
      "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.393, train_loss_epoch=0.393, valid_loss=0.0322]        \n",
      "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.389, valid_loss=0.0322]        \n",
      "Epoch 628:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.401, train_loss_epoch=0.401, valid_loss=0.0322]        \n",
      "Epoch 628: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.401, valid_loss=0.0322]\n",
      "Epoch 628: 100%|██████████| 1/1 [00:00<00:00,  5.51it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=0.0322]\n",
      "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=0.0322]        \n",
      "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.381, train_loss_epoch=0.381, valid_loss=0.0322]        \n",
      "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.375, train_loss_epoch=0.375, valid_loss=0.0322]        \n",
      "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.362, train_loss_epoch=0.362, valid_loss=0.0322]        \n",
      "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363, valid_loss=0.0322]        \n",
      "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.359, train_loss_epoch=0.359, valid_loss=0.0322]        \n",
      "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354, valid_loss=0.0322]        \n",
      "Epoch 635: 100%|██████████| 1/1 [00:00<00:00,  5.44it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.354, valid_loss=0.0322]\n",
      "Epoch 635: 100%|██████████| 1/1 [00:00<00:00,  5.42it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.372, valid_loss=0.0322]\n",
      "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.372, valid_loss=0.0322]        \n",
      "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.362, train_loss_epoch=0.362, valid_loss=0.0322]        \n",
      "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361, valid_loss=0.0322]        \n",
      "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=0.0322]        \n",
      "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346, valid_loss=0.0322]        \n",
      "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=0.0322]        \n",
      "Epoch 641: 100%|██████████| 1/1 [00:00<00:00,  4.32it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=0.0322]\n",
      "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335, valid_loss=0.0322]        \n",
      "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=0.0322]        \n",
      "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=0.0322]        \n",
      "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=0.0322]        \n",
      "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=0.0322]        \n",
      "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.340, train_loss_epoch=0.340, valid_loss=0.0322]        \n",
      "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.344, train_loss_epoch=0.344, valid_loss=0.0322]        \n",
      "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.340, train_loss_epoch=0.340, valid_loss=0.0322]        \n",
      "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335, valid_loss=0.0322]        \n",
      "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=0.0322]        \n",
      "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=0.0322]        \n",
      "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=0.0322]        \n",
      "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=0.0322]        \n",
      "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=0.0322]        \n",
      "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=0.0322]        \n",
      "Epoch 657:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=0.0322]        \n",
      "Epoch 657: 100%|██████████| 1/1 [00:00<00:00,  5.64it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=0.0322]\n",
      "Epoch 657: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.322, valid_loss=0.0322]\n",
      "Epoch 657: 100%|██████████| 1/1 [00:00<00:00,  5.46it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=0.0322]\n",
      "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=0.0322]        \n",
      "Epoch 658: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=0.0322]\n",
      "Epoch 658: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.316, valid_loss=0.0322]\n",
      "Epoch 658: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=0.0322]\n",
      "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=0.0322]        \n",
      "Epoch 659: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=0.0322]\n",
      "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=0.0322]        \n",
      "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=0.0322]        \n",
      "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=0.0322]        \n",
      "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.312, train_loss_epoch=0.312, valid_loss=0.0322]        \n",
      "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=0.0322]        \n",
      "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=0.0322]        \n",
      "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=0.0322]        \n",
      "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=0.0322]        \n",
      "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.300, valid_loss=0.0322]        \n",
      "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=0.0322]        \n",
      "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=0.0322]        \n",
      "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=0.0322]        \n",
      "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=0.0322]        \n",
      "Epoch 672: 100%|██████████| 1/1 [00:00<00:00,  5.71it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=0.0322]\n",
      "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.289, valid_loss=0.0322]        \n",
      "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.289, valid_loss=0.0322]        \n",
      "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=0.0322]        \n",
      "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.305, train_loss_epoch=0.305, valid_loss=0.0322]        \n",
      "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.300, valid_loss=0.0322]        \n",
      "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=0.0322]        \n",
      "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295, valid_loss=0.0322]        \n",
      "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=0.0322]        \n",
      "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=0.0322]        \n",
      "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=0.0322]        \n",
      "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.286, valid_loss=0.0322]        \n",
      "Epoch 683: 100%|██████████| 1/1 [00:00<00:00,  5.44it/s, v_num=0, train_loss_step=0.281, train_loss_epoch=0.281, valid_loss=0.0322]\n",
      "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.281, train_loss_epoch=0.281, valid_loss=0.0322]        \n",
      "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.278, train_loss_epoch=0.278, valid_loss=0.0322]        \n",
      "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.279, train_loss_epoch=0.279, valid_loss=0.0322]        \n",
      "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.280, train_loss_epoch=0.280, valid_loss=0.0322]        \n",
      "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.275, valid_loss=0.0322]        \n",
      "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=0.0322]        \n",
      "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=0.0322]        \n",
      "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.275, valid_loss=0.0322]        \n",
      "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.268, train_loss_epoch=0.268, valid_loss=0.0322]        \n",
      "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.272, train_loss_epoch=0.272, valid_loss=0.0322]        \n",
      "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276, valid_loss=0.0322]        \n",
      "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=0.0322]        \n",
      "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.268, train_loss_epoch=0.268, valid_loss=0.0322]        \n",
      "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=0.0322]        \n",
      "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.288, train_loss_epoch=0.288, valid_loss=0.0322]        \n",
      "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.269, train_loss_epoch=0.269, valid_loss=0.0322]        \n",
      "Epoch 699: 100%|██████████| 1/1 [00:00<00:00,  5.65it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.269, valid_loss=0.0322]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=2878)\u001b[0m \n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=2878)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 11.23it/s]\u001b[A\n",
      "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=0.0441]        \n",
      "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.280, train_loss_epoch=0.280, valid_loss=0.0441]        \n",
      "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.275, valid_loss=0.0441]        \n",
      "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.271, train_loss_epoch=0.271, valid_loss=0.0441]        \n",
      "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.265, train_loss_epoch=0.265, valid_loss=0.0441]        \n",
      "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.260, train_loss_epoch=0.260, valid_loss=0.0441]        \n",
      "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=0.0441]        \n",
      "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=0.0441]        \n",
      "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=0.0441]        \n",
      "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.253, train_loss_epoch=0.253, valid_loss=0.0441]        \n",
      "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.250, train_loss_epoch=0.250, valid_loss=0.0441]        \n",
      "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.251, train_loss_epoch=0.251, valid_loss=0.0441]        \n",
      "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.246, train_loss_epoch=0.246, valid_loss=0.0441]        \n",
      "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=0.0441]        \n",
      "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=0.0441]        \n",
      "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=0.0441]        \n",
      "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.239, valid_loss=0.0441]        \n",
      "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.235, train_loss_epoch=0.235, valid_loss=0.0441]        \n",
      "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.236, train_loss_epoch=0.236, valid_loss=0.0441]        \n",
      "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.233, train_loss_epoch=0.233, valid_loss=0.0441]        \n",
      "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.233, train_loss_epoch=0.233, valid_loss=0.0441]        \n",
      "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.229, train_loss_epoch=0.229, valid_loss=0.0441]        \n",
      "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.228, train_loss_epoch=0.228, valid_loss=0.0441]        \n",
      "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.224, train_loss_epoch=0.224, valid_loss=0.0441]        \n",
      "Epoch 724:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.237, train_loss_epoch=0.237, valid_loss=0.0441]        \n",
      "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.236, train_loss_epoch=0.236, valid_loss=0.0441]        \n",
      "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.284, valid_loss=0.0441]        \n",
      "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=0.0441]        \n",
      "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=0.0441]        \n",
      "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=0.0441]        \n",
      "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=0.0441]        \n",
      "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=0.0441]        \n",
      "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=0.0441]        \n",
      "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=0.0441]        \n",
      "Epoch 733: 100%|██████████| 1/1 [00:00<00:00,  5.29it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=0.0441]\n",
      "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=0.0441]        \n",
      "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=0.0441]        \n",
      "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.288, train_loss_epoch=0.288, valid_loss=0.0441]        \n",
      "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.282, valid_loss=0.0441]        \n",
      "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=0.0441]        \n",
      "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.275, valid_loss=0.0441]        \n",
      "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.272, train_loss_epoch=0.272, valid_loss=0.0441]        \n",
      "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.266, train_loss_epoch=0.266, valid_loss=0.0441]        \n",
      "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=0.0441]        \n",
      "Epoch 742: 100%|██████████| 1/1 [00:00<00:00,  5.65it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=0.0441]\n",
      "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=0.0441]        \n",
      "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.257, valid_loss=0.0441]        \n",
      "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.254, train_loss_epoch=0.254, valid_loss=0.0441]        \n",
      "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=0.0441]        \n",
      "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=0.0441]        \n",
      "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.254, train_loss_epoch=0.254, valid_loss=0.0441]        \n",
      "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.266, train_loss_epoch=0.266, valid_loss=0.0441]        \n",
      "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.257, valid_loss=0.0441]        \n",
      "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.247, train_loss_epoch=0.247, valid_loss=0.0441]        \n",
      "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.250, train_loss_epoch=0.250, valid_loss=0.0441]        \n",
      "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.248, train_loss_epoch=0.248, valid_loss=0.0441]        \n",
      "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.246, train_loss_epoch=0.246, valid_loss=0.0441]        \n",
      "Epoch 754: 100%|██████████| 1/1 [00:00<00:00,  3.66it/s, v_num=0, train_loss_step=0.247, train_loss_epoch=0.246, valid_loss=0.0441]\n",
      "Epoch 754: 100%|██████████| 1/1 [00:00<00:00,  3.64it/s, v_num=0, train_loss_step=0.247, train_loss_epoch=0.247, valid_loss=0.0441]\n",
      "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.247, train_loss_epoch=0.247, valid_loss=0.0441]        \n",
      "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.241, train_loss_epoch=0.241, valid_loss=0.0441]        \n",
      "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.239, valid_loss=0.0441]        \n",
      "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.236, train_loss_epoch=0.236, valid_loss=0.0441]        \n",
      "Epoch 758: 100%|██████████| 1/1 [00:00<00:00,  3.50it/s, v_num=0, train_loss_step=0.237, train_loss_epoch=0.237, valid_loss=0.0441]\n",
      "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.237, train_loss_epoch=0.237, valid_loss=0.0441]        \n",
      "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.233, train_loss_epoch=0.233, valid_loss=0.0441]        \n",
      "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.230, train_loss_epoch=0.230, valid_loss=0.0441]        \n",
      "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.229, train_loss_epoch=0.229, valid_loss=0.0441]        \n",
      "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.228, train_loss_epoch=0.228, valid_loss=0.0441]        \n",
      "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.226, train_loss_epoch=0.226, valid_loss=0.0441]        \n",
      "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.223, valid_loss=0.0441]        \n",
      "Epoch 766:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.222, train_loss_epoch=0.222, valid_loss=0.0441]        \n",
      "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.221, train_loss_epoch=0.221, valid_loss=0.0441]        \n",
      "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.223, valid_loss=0.0441]        \n",
      "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.221, train_loss_epoch=0.221, valid_loss=0.0441]        \n",
      "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217, valid_loss=0.0441]        \n",
      "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216, valid_loss=0.0441]        \n",
      "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216, valid_loss=0.0441]        \n",
      "Epoch 773:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=0.0441]        \n",
      "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=0.0441]        \n",
      "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=0.0441]        \n",
      "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.207, valid_loss=0.0441]        \n",
      "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=0.0441]        \n",
      "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.210, train_loss_epoch=0.210, valid_loss=0.0441]        \n",
      "Epoch 779:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=0.0441]        \n",
      "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=0.0441]        \n",
      "Epoch 781:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206, valid_loss=0.0441]        \n",
      "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=0.0441]        \n",
      "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206, valid_loss=0.0441]        \n",
      "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=0.0441]        \n",
      "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=0.0441]        \n",
      "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=0.0441]        \n",
      "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.198, valid_loss=0.0441]        \n",
      "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=0.0441]        \n",
      "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=0.0441]        \n",
      "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=0.0441]        \n",
      "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196, valid_loss=0.0441]        \n",
      "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196, valid_loss=0.0441]        \n",
      "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=0.0441]        \n",
      "Epoch 794:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=0.0441]        \n",
      "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=0.0441]        \n",
      "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=0.0441]        \n",
      "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=0.0441]        \n",
      "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=0.0441]        \n",
      "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190, valid_loss=0.0441]        \n",
      "Epoch 799: 100%|██████████| 1/1 [00:00<00:00,  3.94it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.190, valid_loss=0.0441]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=2878)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s]\u001b[A\n",
      "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=0.0388]        \n",
      "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.200, train_loss_epoch=0.200, valid_loss=0.0388]        \n",
      "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196, valid_loss=0.0388]        \n",
      "Epoch 803:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=0.0388]        \n",
      "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.198, valid_loss=0.0388]        \n",
      "Epoch 805:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=0.0388]        \n",
      "Epoch 806:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=0.0388]        \n",
      "Epoch 806: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=0.0388]\n",
      "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196, valid_loss=0.0388]        \n",
      "Epoch 808:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=0.0388]        \n",
      "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=0.0388]        \n",
      "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193, valid_loss=0.0388]        \n",
      "Epoch 811:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.187, train_loss_epoch=0.187, valid_loss=0.0388]        \n",
      "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=0.0388]        \n",
      "Epoch 812: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=0.0388]\n",
      "Epoch 813:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=0.0388]        \n",
      "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=0.0388]        \n",
      "Epoch 815:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=0.0388]        \n",
      "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=0.0388]        \n",
      "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.183, train_loss_epoch=0.183, valid_loss=0.0388]        \n",
      "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=0.0388]        \n",
      "Epoch 819:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.180, train_loss_epoch=0.180, valid_loss=0.0388]        \n",
      "Epoch 819: 100%|██████████| 1/1 [00:00<00:00,  3.67it/s, v_num=0, train_loss_step=0.180, train_loss_epoch=0.180, valid_loss=0.0388]\n",
      "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.183, train_loss_epoch=0.183, valid_loss=0.0388]        \n",
      "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=0.0388]        \n",
      "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.179, train_loss_epoch=0.179, valid_loss=0.0388]        \n",
      "Epoch 823:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.187, train_loss_epoch=0.187, valid_loss=0.0388]        \n",
      "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.183, train_loss_epoch=0.183, valid_loss=0.0388]        \n",
      "Epoch 825:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.181, train_loss_epoch=0.181, valid_loss=0.0388]        \n",
      "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=0.0388]        \n",
      "Epoch 827:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.179, train_loss_epoch=0.179, valid_loss=0.0388]        \n",
      "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=0.0388]        \n",
      "Epoch 829:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=0.0388]        \n",
      "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=0.0388]        \n",
      "Epoch 831:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=0.0388]        \n",
      "Epoch 831: 100%|██████████| 1/1 [00:00<00:00,  4.74it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=0.0388]\n",
      "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=0.0388]        \n",
      "Epoch 833:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.176, train_loss_epoch=0.176, valid_loss=0.0388]        \n",
      "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.174, valid_loss=0.0388]        \n",
      "Epoch 834: 100%|██████████| 1/1 [00:00<00:00,  3.24it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.174, valid_loss=0.0388]\n",
      "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.175, train_loss_epoch=0.175, valid_loss=0.0388]        \n",
      "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=0.0388]        \n",
      "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.174, valid_loss=0.0388]        \n",
      "Epoch 838:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=0.0388]        \n",
      "Epoch 838: 100%|██████████| 1/1 [00:00<00:00,  5.74it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=0.0388]\n",
      "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.172, train_loss_epoch=0.172, valid_loss=0.0388]        \n",
      "Epoch 839: 100%|██████████| 1/1 [00:00<00:00,  5.00it/s, v_num=0, train_loss_step=0.172, train_loss_epoch=0.172, valid_loss=0.0388]\n",
      "Epoch 840:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.172, train_loss_epoch=0.172, valid_loss=0.0388]        \n",
      "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=0.0388]        \n",
      "Epoch 842:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=0.0388]        \n",
      "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=0.0388]        \n",
      "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=0.0388]        \n",
      "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=0.0388]        \n",
      "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=0.0388]        \n",
      "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=0.0388]        \n",
      "Epoch 848:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=0.0388]        \n",
      "Epoch 849:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=0.0388]        \n",
      "Epoch 850:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=0.0388]        \n",
      "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=0.0388]        \n",
      "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=0.0388]        \n",
      "Epoch 853:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.170, valid_loss=0.0388]        \n",
      "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.170, valid_loss=0.0388]        \n",
      "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=0.0388]        \n",
      "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=0.0388]        \n",
      "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=0.0388]        \n",
      "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=0.0388]        \n",
      "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=0.0388]        \n",
      "Epoch 860:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=0.0388]        \n",
      "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=0.0388]        \n",
      "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=0.0388]        \n",
      "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.164, train_loss_epoch=0.164, valid_loss=0.0388]        \n",
      "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=0.0388]        \n",
      "Epoch 865:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=0.0388]        \n",
      "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=0.0388]        \n",
      "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=0.0388]        \n",
      "Epoch 867: 100%|██████████| 1/1 [00:00<00:00,  3.62it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=0.0388]\n",
      "Epoch 867: 100%|██████████| 1/1 [00:00<00:00,  3.55it/s, v_num=0, train_loss_step=0.164, train_loss_epoch=0.164, valid_loss=0.0388]\n",
      "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.164, train_loss_epoch=0.164, valid_loss=0.0388]        \n",
      "Epoch 868:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.164, train_loss_epoch=0.164, valid_loss=0.0388]\n",
      "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.164, train_loss_epoch=0.164, valid_loss=0.0388]        \n",
      "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=0.0388]        \n",
      "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=0.0388]        \n",
      "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=0.0388]        \n",
      "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=0.0388]        \n",
      "Epoch 873: 100%|██████████| 1/1 [00:00<00:00,  5.41it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=0.0388]\n",
      "Epoch 873: 100%|██████████| 1/1 [00:00<00:00,  5.24it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=0.0388]\n",
      "Epoch 874:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=0.0388]        \n",
      "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=0.0388]        \n",
      "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.164, train_loss_epoch=0.164, valid_loss=0.0388]        \n",
      "Epoch 877:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.161, train_loss_epoch=0.161, valid_loss=0.0388]        \n",
      "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=0.0388]        \n",
      "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.161, train_loss_epoch=0.161, valid_loss=0.0388]        \n",
      "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.161, train_loss_epoch=0.161, valid_loss=0.0388]        \n",
      "Epoch 881:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.164, train_loss_epoch=0.164, valid_loss=0.0388]        \n",
      "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.161, train_loss_epoch=0.161, valid_loss=0.0388]        \n",
      "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=0.0388]        \n",
      "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.160, train_loss_epoch=0.160, valid_loss=0.0388]        \n",
      "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.158, train_loss_epoch=0.158, valid_loss=0.0388]        \n",
      "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.160, train_loss_epoch=0.160, valid_loss=0.0388]        \n",
      "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.158, train_loss_epoch=0.158, valid_loss=0.0388]        \n",
      "Epoch 888:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.158, train_loss_epoch=0.158, valid_loss=0.0388]        \n",
      "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.157, train_loss_epoch=0.157, valid_loss=0.0388]        \n",
      "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.155, train_loss_epoch=0.155, valid_loss=0.0388]        \n",
      "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.157, train_loss_epoch=0.157, valid_loss=0.0388]        \n",
      "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.155, train_loss_epoch=0.155, valid_loss=0.0388]        \n",
      "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.156, train_loss_epoch=0.156, valid_loss=0.0388]        \n",
      "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.155, train_loss_epoch=0.155, valid_loss=0.0388]        \n",
      "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.155, train_loss_epoch=0.155, valid_loss=0.0388]        \n",
      "Epoch 896:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.159, train_loss_epoch=0.159, valid_loss=0.0388]        \n",
      "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.174, valid_loss=0.0388]        \n",
      "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=0.0388]        \n",
      "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.159, train_loss_epoch=0.159, valid_loss=0.0388]        \n",
      "Epoch 899: 100%|██████████| 1/1 [00:00<00:00,  4.64it/s, v_num=0, train_loss_step=0.158, train_loss_epoch=0.159, valid_loss=0.0388]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=2878)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s]\u001b[A\n",
      "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.158, train_loss_epoch=0.158, valid_loss=0.0392]        \n",
      "Epoch 901:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.161, train_loss_epoch=0.161, valid_loss=0.0392]        \n",
      "Epoch 902:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.161, train_loss_epoch=0.161, valid_loss=0.0392]        \n",
      "Epoch 903:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.158, train_loss_epoch=0.158, valid_loss=0.0392]        \n",
      "Epoch 903: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s, v_num=0, train_loss_step=0.158, train_loss_epoch=0.158, valid_loss=0.0392]\n",
      "Epoch 904:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.155, train_loss_epoch=0.155, valid_loss=0.0392]        \n",
      "Epoch 905:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.156, train_loss_epoch=0.156, valid_loss=0.0392]        \n",
      "Epoch 906:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.155, train_loss_epoch=0.155, valid_loss=0.0392]        \n",
      "Epoch 907:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.155, train_loss_epoch=0.155, valid_loss=0.0392]        \n",
      "Epoch 908:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.154, train_loss_epoch=0.154, valid_loss=0.0392]        \n",
      "Epoch 909:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.152, train_loss_epoch=0.152, valid_loss=0.0392]        \n",
      "Epoch 910:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.154, train_loss_epoch=0.154, valid_loss=0.0392]        \n",
      "Epoch 911:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.153, train_loss_epoch=0.153, valid_loss=0.0392]        \n",
      "Epoch 912:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.151, train_loss_epoch=0.151, valid_loss=0.0392]        \n",
      "Epoch 912: 100%|██████████| 1/1 [00:00<00:00,  5.67it/s, v_num=0, train_loss_step=0.151, train_loss_epoch=0.151, valid_loss=0.0392]\n",
      "Epoch 912: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=0, train_loss_step=0.151, train_loss_epoch=0.151, valid_loss=0.0392]\n",
      "Epoch 912: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=0, train_loss_step=0.151, train_loss_epoch=0.151, valid_loss=0.0392]\n",
      "Epoch 913:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.151, train_loss_epoch=0.151, valid_loss=0.0392]        \n",
      "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.151, train_loss_epoch=0.151, valid_loss=0.0392]        \n",
      "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.149, train_loss_epoch=0.149, valid_loss=0.0392]        \n",
      "Epoch 916:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.149, train_loss_epoch=0.149, valid_loss=0.0392]        \n",
      "Epoch 917:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.150, train_loss_epoch=0.150, valid_loss=0.0392]        \n",
      "Epoch 918:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.148, train_loss_epoch=0.148, valid_loss=0.0392]        \n",
      "Epoch 918: 100%|██████████| 1/1 [00:00<00:00,  4.59it/s, v_num=0, train_loss_step=0.150, train_loss_epoch=0.150, valid_loss=0.0392]\n",
      "Epoch 919:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.150, train_loss_epoch=0.150, valid_loss=0.0392]        \n",
      "Epoch 920:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.152, train_loss_epoch=0.152, valid_loss=0.0392]        \n",
      "Epoch 921:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.148, train_loss_epoch=0.148, valid_loss=0.0392]        \n",
      "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.152, train_loss_epoch=0.152, valid_loss=0.0392]        \n",
      "Epoch 923:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.152, train_loss_epoch=0.152, valid_loss=0.0392]        \n",
      "Epoch 924:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.150, train_loss_epoch=0.150, valid_loss=0.0392]        \n",
      "Epoch 925:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.149, train_loss_epoch=0.149, valid_loss=0.0392]        \n",
      "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.149, train_loss_epoch=0.149, valid_loss=0.0392]        \n",
      "Epoch 927:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.146, train_loss_epoch=0.146, valid_loss=0.0392]        \n",
      "Epoch 927: 100%|██████████| 1/1 [00:00<00:00,  4.05it/s, v_num=0, train_loss_step=0.150, train_loss_epoch=0.150, valid_loss=0.0392]\n",
      "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.150, train_loss_epoch=0.150, valid_loss=0.0392]        \n",
      "Epoch 929:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.147, train_loss_epoch=0.147, valid_loss=0.0392]        \n",
      "Epoch 930:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.149, train_loss_epoch=0.149, valid_loss=0.0392]        \n",
      "Epoch 931:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.148, train_loss_epoch=0.148, valid_loss=0.0392]        \n",
      "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.148, train_loss_epoch=0.148, valid_loss=0.0392]        \n",
      "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.151, train_loss_epoch=0.151, valid_loss=0.0392]        \n",
      "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.247, train_loss_epoch=0.247, valid_loss=0.0392]        \n",
      "Epoch 935:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.414, train_loss_epoch=0.414, valid_loss=0.0392]        \n",
      "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0392]        \n",
      "Epoch 936: 100%|██████████| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0392]\n",
      "Epoch 937:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.456, train_loss_epoch=0.456, valid_loss=0.0392]        \n",
      "Epoch 938:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455, valid_loss=0.0392]        \n",
      "Epoch 939:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.443, train_loss_epoch=0.443, valid_loss=0.0392]        \n",
      "Epoch 939: 100%|██████████| 1/1 [00:00<00:00,  4.03it/s, v_num=0, train_loss_step=0.443, train_loss_epoch=0.443, valid_loss=0.0392]\n",
      "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.416, valid_loss=0.0392]        \n",
      "Epoch 941:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.401, train_loss_epoch=0.401, valid_loss=0.0392]        \n",
      "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.394, train_loss_epoch=0.394, valid_loss=0.0392]        \n",
      "Epoch 943:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.394, train_loss_epoch=0.394, valid_loss=0.0392]        \n",
      "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.376, train_loss_epoch=0.376, valid_loss=0.0392]        \n",
      "Epoch 945:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.368, train_loss_epoch=0.368, valid_loss=0.0392]        \n",
      "Epoch 945: 100%|██████████| 1/1 [00:00<00:00,  4.54it/s, v_num=0, train_loss_step=0.368, train_loss_epoch=0.368, valid_loss=0.0392]\n",
      "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369, valid_loss=0.0392]        \n",
      "Epoch 947:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363, valid_loss=0.0392]        \n",
      "Epoch 947: 100%|██████████| 1/1 [00:00<00:00,  4.00it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363, valid_loss=0.0392]\n",
      "Epoch 948:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=0.0392]        \n",
      "Epoch 949:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=0.0392]        \n",
      "Epoch 949: 100%|██████████| 1/1 [00:00<00:00,  4.23it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=0.0392]\n",
      "Epoch 950:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=0.0392]        \n",
      "Epoch 951:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=0.0392]        \n",
      "Epoch 951: 100%|██████████| 1/1 [00:00<00:00,  3.91it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=0.0392]\n",
      "Epoch 952:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=0.0392]        \n",
      "Epoch 953:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=0.0392]        \n",
      "Epoch 953: 100%|██████████| 1/1 [00:00<00:00,  4.05it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=0.0392]\n",
      "Epoch 954:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=0.0392]        \n",
      "Epoch 955:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=0.0392]        \n",
      "Epoch 955: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=0.0392]\n",
      "Epoch 956:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.312, train_loss_epoch=0.312, valid_loss=0.0392]        \n",
      "Epoch 957:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=0.0392]        \n",
      "Epoch 958:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.305, train_loss_epoch=0.305, valid_loss=0.0392]        \n",
      "Epoch 958: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=0, train_loss_step=0.305, train_loss_epoch=0.305, valid_loss=0.0392]\n",
      "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=0.0392]        \n",
      "Epoch 960:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=0.0392]        \n",
      "Epoch 961:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=0.0392]        \n",
      "Epoch 962:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.278, train_loss_epoch=0.278, valid_loss=0.0392]        \n",
      "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.275, valid_loss=0.0392]        \n",
      "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.273, train_loss_epoch=0.273, valid_loss=0.0392]        \n",
      "Epoch 965:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.267, train_loss_epoch=0.267, valid_loss=0.0392]        \n",
      "Epoch 965: 100%|██████████| 1/1 [00:00<00:00,  4.67it/s, v_num=0, train_loss_step=0.267, train_loss_epoch=0.267, valid_loss=0.0392]\n",
      "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.265, train_loss_epoch=0.265, valid_loss=0.0392]        \n",
      "Epoch 967:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259, valid_loss=0.0392]        \n",
      "Epoch 968:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=0.0392]        \n",
      "Epoch 969:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=0.0392]        \n",
      "Epoch 970:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=0.0392]        \n",
      "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336, valid_loss=0.0392]        \n",
      "Epoch 972:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=0.0392]        \n",
      "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=0.0392]        \n",
      "Epoch 974:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354, valid_loss=0.0392]        \n",
      "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=0.0392]        \n",
      "Epoch 976:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=0.0392]        \n",
      "Epoch 977:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=0.0392]        \n",
      "Epoch 978:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.342, train_loss_epoch=0.342, valid_loss=0.0392]        \n",
      "Epoch 979:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332, valid_loss=0.0392]        \n",
      "Epoch 980:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351, valid_loss=0.0392]        \n",
      "Epoch 981:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=0.0392]        \n",
      "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=0.0392]        \n",
      "Epoch 983:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=0.0392]        \n",
      "Epoch 983: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=0.0392]\n",
      "Epoch 984:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=0.0392]        \n",
      "Epoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.312, train_loss_epoch=0.312, valid_loss=0.0392]        \n",
      "Epoch 986:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=0.0392]        \n",
      "Epoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.305, train_loss_epoch=0.305, valid_loss=0.0392]        \n",
      "Epoch 987: 100%|██████████| 1/1 [00:00<00:00,  4.41it/s, v_num=0, train_loss_step=0.305, train_loss_epoch=0.305, valid_loss=0.0392]\n",
      "Epoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=0.0392]        \n",
      "Epoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=0.0392]        \n",
      "Epoch 989: 100%|██████████| 1/1 [00:00<00:00,  4.19it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=0.0392]\n",
      "Epoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.286, valid_loss=0.0392]        \n",
      "Epoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.278, train_loss_epoch=0.278, valid_loss=0.0392]        \n",
      "Epoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.269, train_loss_epoch=0.269, valid_loss=0.0392]        \n",
      "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.266, train_loss_epoch=0.266, valid_loss=0.0392]        \n",
      "Epoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=0.0392]        \n",
      "Epoch 994: 100%|██████████| 1/1 [00:00<00:00,  4.19it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=0.0392]\n",
      "Epoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.256, train_loss_epoch=0.256, valid_loss=0.0392]        \n",
      "Epoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.254, train_loss_epoch=0.254, valid_loss=0.0392]        \n",
      "Epoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=0.0392]        \n",
      "Epoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.251, train_loss_epoch=0.251, valid_loss=0.0392]        \n",
      "Epoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.245, valid_loss=0.0392]        \n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00,  3.73it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.245, valid_loss=0.0392]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=2878)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s]\u001b[A\n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00,  2.45it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.245, valid_loss=0.0344]\n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00,  2.43it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=0.0344]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=2878)\u001b[0m `Trainer.fit` stopped: `max_steps=1000` reached.\n",
      "\u001b[36m(_train_tune pid=3619)\u001b[0m /home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=3619)\u001b[0m Seed set to 3\n",
      "\u001b[36m(_train_tune pid=3619)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=3619)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=3619)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=3619)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(_train_tune pid=3619)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_train_tune pid=3619)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=3619)\u001b[0m   | Name            | Type          | Params | Mode \n",
      "\u001b[36m(_train_tune pid=3619)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=3619)\u001b[0m 0 | loss            | WMAPE         | 0      | train\n",
      "\u001b[36m(_train_tune pid=3619)\u001b[0m 1 | padder          | ConstantPad1d | 0      | train\n",
      "\u001b[36m(_train_tune pid=3619)\u001b[0m 2 | scaler          | TemporalNorm  | 0      | train\n",
      "\u001b[36m(_train_tune pid=3619)\u001b[0m 3 | hist_encoder    | LSTM          | 1.8 M  | train\n",
      "\u001b[36m(_train_tune pid=3619)\u001b[0m 4 | context_adapter | Linear        | 1.2 M  | train\n",
      "\u001b[36m(_train_tune pid=3619)\u001b[0m 5 | mlp_decoder     | MLP           | 13.3 K | train\n",
      "\u001b[36m(_train_tune pid=3619)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=3619)\u001b[0m 3.0 M     Trainable params\n",
      "\u001b[36m(_train_tune pid=3619)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=3619)\u001b[0m 3.0 M     Total params\n",
      "\u001b[36m(_train_tune pid=3619)\u001b[0m 11.922    Total estimated model params size (MB)\n",
      "\u001b[36m(_train_tune pid=3619)\u001b[0m 11        Modules in train mode\n",
      "\u001b[36m(_train_tune pid=3619)\u001b[0m 0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 16.11it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994]\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=0.994]\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 14.81it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]\n",
      "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]        \n",
      "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.991]        \n",
      "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992]        \n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 11.57it/s, v_num=0, train_loss_step=0.967, train_loss_epoch=0.967]\n",
      "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.967, train_loss_epoch=0.967]        \n",
      "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.949, train_loss_epoch=0.949]       \n",
      "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=0.914]        \n",
      "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.856, train_loss_epoch=0.856]        \n",
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.717, train_loss_epoch=0.717]        \n",
      "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.700, train_loss_epoch=0.700]        \n",
      "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650]        \n",
      "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.708, train_loss_epoch=0.708]        \n",
      "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.700, train_loss_epoch=0.700]        \n",
      "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.897, train_loss_epoch=0.897]        \n",
      "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.801, train_loss_epoch=0.801]        \n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00, 16.83it/s, v_num=0, train_loss_step=0.854, train_loss_epoch=0.854]\n",
      "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.907, train_loss_epoch=0.907]        \n",
      "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.897, train_loss_epoch=0.897]        \n",
      "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.928, train_loss_epoch=0.928]        \n",
      "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.913, train_loss_epoch=0.913]        \n",
      "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.832, train_loss_epoch=0.832]        \n",
      "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.907, train_loss_epoch=0.907]        \n",
      "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.821, train_loss_epoch=0.821]        \n",
      "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.827, train_loss_epoch=0.827]        \n",
      "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.878, train_loss_epoch=0.878]        \n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00, 17.76it/s, v_num=0, train_loss_step=0.928, train_loss_epoch=0.928]\n",
      "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.670, train_loss_epoch=0.670]        \n",
      "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.660, train_loss_epoch=0.660]        \n",
      "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.659, train_loss_epoch=0.659]        \n",
      "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.659, train_loss_epoch=0.659]        \n",
      "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030]        \n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=0, train_loss_step=0.817, train_loss_epoch=0.940]\n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s, v_num=0, train_loss_step=0.817, train_loss_epoch=0.817]\n",
      "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.817, train_loss_epoch=0.817]        \n",
      "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.802, train_loss_epoch=0.802]        \n",
      "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.825, train_loss_epoch=0.825]        \n",
      "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.941, train_loss_epoch=0.941]        \n",
      "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.849, train_loss_epoch=0.849]        \n",
      "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.880, train_loss_epoch=0.880]        \n",
      "Epoch 55: 100%|██████████| 1/1 [00:00<00:00, 13.52it/s, v_num=0, train_loss_step=0.818, train_loss_epoch=0.818]\n",
      "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.845, train_loss_epoch=0.845]        \n",
      "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.761, train_loss_epoch=0.761]        \n",
      "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.734, train_loss_epoch=0.734]        \n",
      "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.760, train_loss_epoch=0.760]        \n",
      "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.706, train_loss_epoch=0.706]        \n",
      "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.650, train_loss_epoch=0.650]        \n",
      "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.921, train_loss_epoch=0.921]        \n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00, 15.74it/s, v_num=0, train_loss_step=0.595, train_loss_epoch=0.595]\n",
      "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.595, train_loss_epoch=0.595]        \n",
      "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984]        \n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00, 16.19it/s, v_num=0, train_loss_step=0.599, train_loss_epoch=0.599]\n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00, 15.86it/s, v_num=0, train_loss_step=0.820, train_loss_epoch=0.820]\n",
      "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.819, train_loss_epoch=0.819]        \n",
      "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.752, train_loss_epoch=0.752]        \n",
      "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.684, train_loss_epoch=0.684]        \n",
      "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.856, train_loss_epoch=0.856]        \n",
      "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.818, train_loss_epoch=0.818]        \n",
      "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.734, train_loss_epoch=0.734]        \n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00, 21.03it/s, v_num=0, train_loss_step=0.838, train_loss_epoch=0.838]\n",
      "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557]        \n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00, 20.89it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557]\n",
      "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.612, train_loss_epoch=0.612]        \n",
      "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.669, train_loss_epoch=0.669]        \n",
      "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.675, train_loss_epoch=0.675]        \n",
      "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.900, train_loss_epoch=0.900]        \n",
      "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.900, train_loss_epoch=0.900]        \n",
      "Epoch 93: 100%|██████████| 1/1 [00:00<00:00, 17.54it/s, v_num=0, train_loss_step=0.670, train_loss_epoch=0.670]\n",
      "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.607, train_loss_epoch=0.607]        \n",
      "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.642, train_loss_epoch=0.642]        \n",
      "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536]        \n",
      "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.714, train_loss_epoch=0.714]        \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=0, train_loss_step=0.410, train_loss_epoch=0.714]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=3619)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  5.38it/s]\u001b[A\n",
      "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.410, train_loss_epoch=0.410, valid_loss=0.0523]       \n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00, 15.57it/s, v_num=0, train_loss_step=0.847, train_loss_epoch=0.847, valid_loss=0.0523]\n",
      "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.589, train_loss_epoch=0.589, valid_loss=0.0523]        \n",
      "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.654, train_loss_epoch=0.654, valid_loss=0.0523]        \n",
      "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.701, train_loss_epoch=0.701, valid_loss=0.0523]        \n",
      "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.895, train_loss_epoch=0.895, valid_loss=0.0523]        \n",
      "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.696, train_loss_epoch=0.696, valid_loss=0.0523]        \n",
      "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.675, train_loss_epoch=0.675, valid_loss=0.0523]        \n",
      "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.977, train_loss_epoch=0.977, valid_loss=0.0523]        \n",
      "Epoch 111: 100%|██████████| 1/1 [00:00<00:00, 13.47it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0523]\n",
      "Epoch 111: 100%|██████████| 1/1 [00:00<00:00, 12.00it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0523]\n",
      "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0523]        \n",
      "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0523]\n",
      "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.789, train_loss_epoch=0.789, valid_loss=0.0523]        \n",
      "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.749, train_loss_epoch=0.749, valid_loss=0.0523]        \n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00, 14.78it/s, v_num=0, train_loss_step=0.634, train_loss_epoch=0.634, valid_loss=0.0523]\n",
      "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.594, train_loss_epoch=0.594, valid_loss=0.0523]        \n",
      "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.741, train_loss_epoch=0.741, valid_loss=0.0523]        \n",
      "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.735, train_loss_epoch=0.735, valid_loss=0.0523]        \n",
      "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.955, train_loss_epoch=0.955, valid_loss=0.0523]        \n",
      "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.671, train_loss_epoch=0.671, valid_loss=0.0523]        \n",
      "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.748, train_loss_epoch=0.748, valid_loss=0.0523]        \n",
      "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.697, train_loss_epoch=0.697, valid_loss=0.0523]        \n",
      "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.721, train_loss_epoch=0.721, valid_loss=0.0523]        \n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00, 17.56it/s, v_num=0, train_loss_step=0.693, train_loss_epoch=0.693, valid_loss=0.0523]\n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s, v_num=0, train_loss_step=0.699, train_loss_epoch=0.693, valid_loss=0.0523]\n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=0, train_loss_step=0.699, train_loss_epoch=0.699, valid_loss=0.0523]\n",
      "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.699, train_loss_epoch=0.699, valid_loss=0.0523]        \n",
      "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.828, train_loss_epoch=0.828, valid_loss=0.0523]        \n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00, 16.51it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=0.0523]\n",
      "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.690, train_loss_epoch=0.690, valid_loss=0.0523]        \n",
      "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.930, train_loss_epoch=0.930, valid_loss=0.0523]        \n",
      "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.641, train_loss_epoch=0.641, valid_loss=0.0523]        \n",
      "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.642, train_loss_epoch=0.642, valid_loss=0.0523]        \n",
      "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.795, train_loss_epoch=0.795, valid_loss=0.0523]        \n",
      "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.629, train_loss_epoch=0.629, valid_loss=0.0523]        \n",
      "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.730, train_loss_epoch=0.730, valid_loss=0.0523]        \n",
      "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.608, train_loss_epoch=0.608, valid_loss=0.0523]        \n",
      "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.638, train_loss_epoch=0.638, valid_loss=0.0523]        \n",
      "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.658, train_loss_epoch=0.658, valid_loss=0.0523]        \n",
      "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.676, train_loss_epoch=0.676, valid_loss=0.0523]        \n",
      "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.572, valid_loss=0.0523]        \n",
      "Epoch 146: 100%|██████████| 1/1 [00:00<00:00, 12.10it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.572, valid_loss=0.0523]\n",
      "Epoch 146: 100%|██████████| 1/1 [00:00<00:00, 11.86it/s, v_num=0, train_loss_step=0.821, train_loss_epoch=0.821, valid_loss=0.0523]\n",
      "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.630, train_loss_epoch=0.630, valid_loss=0.0523]        \n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 16.60it/s, v_num=0, train_loss_step=0.590, train_loss_epoch=0.590, valid_loss=0.0523]\n",
      "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.761, train_loss_epoch=0.761, valid_loss=0.0523]        \n",
      "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.703, train_loss_epoch=0.703, valid_loss=0.0523]        \n",
      "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.771, train_loss_epoch=0.771, valid_loss=0.0523]        \n",
      "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.626, train_loss_epoch=0.626, valid_loss=0.0523]        \n",
      "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.798, train_loss_epoch=0.798, valid_loss=0.0523]        \n",
      "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.615, train_loss_epoch=0.615, valid_loss=0.0523]        \n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00, 16.44it/s, v_num=0, train_loss_step=0.650, train_loss_epoch=0.650, valid_loss=0.0523]\n",
      "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.843, train_loss_epoch=0.843, valid_loss=0.0523]        \n",
      "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.766, train_loss_epoch=0.766, valid_loss=0.0523]        \n",
      "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.625, train_loss_epoch=0.625, valid_loss=0.0523]        \n",
      "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.768, train_loss_epoch=0.768, valid_loss=0.0523]        \n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00, 14.02it/s, v_num=0, train_loss_step=0.767, train_loss_epoch=0.767, valid_loss=0.0523]\n",
      "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.708, train_loss_epoch=0.708, valid_loss=0.0523]        \n",
      "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.581, train_loss_epoch=0.581, valid_loss=0.0523]        \n",
      "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.602, train_loss_epoch=0.602, valid_loss=0.0523]        \n",
      "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.0523]        \n",
      "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.603, train_loss_epoch=0.603, valid_loss=0.0523]        \n",
      "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.951, train_loss_epoch=0.951, valid_loss=0.0523]        \n",
      "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.617, train_loss_epoch=0.617, valid_loss=0.0523]        \n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00, 13.03it/s, v_num=0, train_loss_step=0.724, train_loss_epoch=0.707, valid_loss=0.0523]\n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00, 12.91it/s, v_num=0, train_loss_step=0.724, train_loss_epoch=0.724, valid_loss=0.0523]\n",
      "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.724, train_loss_epoch=0.724, valid_loss=0.0523]        \n",
      "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.756, train_loss_epoch=0.756, valid_loss=0.0523]        \n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00, 16.19it/s, v_num=0, train_loss_step=0.791, train_loss_epoch=0.791, valid_loss=0.0523]\n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00, 14.81it/s, v_num=0, train_loss_step=0.718, train_loss_epoch=0.791, valid_loss=0.0523]\n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=0, train_loss_step=0.718, train_loss_epoch=0.718, valid_loss=0.0523]\n",
      "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.718, train_loss_epoch=0.718, valid_loss=0.0523]        \n",
      "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.801, train_loss_epoch=0.801, valid_loss=0.0523]        \n",
      "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.590, train_loss_epoch=0.590, valid_loss=0.0523]        \n",
      "Epoch 184: 100%|██████████| 1/1 [00:00<00:00, 13.58it/s, v_num=0, train_loss_step=0.667, train_loss_epoch=0.667, valid_loss=0.0523]\n",
      "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.940, train_loss_epoch=0.940, valid_loss=0.0523]        \n",
      "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0523]        \n",
      "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.675, train_loss_epoch=0.675, valid_loss=0.0523]        \n",
      "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.872, train_loss_epoch=0.872, valid_loss=0.0523]        \n",
      "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.715, train_loss_epoch=0.715, valid_loss=0.0523]        \n",
      "Epoch 192: 100%|██████████| 1/1 [00:00<00:00, 16.91it/s, v_num=0, train_loss_step=0.641, train_loss_epoch=0.641, valid_loss=0.0523]\n",
      "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.674, train_loss_epoch=0.674, valid_loss=0.0523]        \n",
      "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.756, train_loss_epoch=0.756, valid_loss=0.0523]        \n",
      "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.967, train_loss_epoch=0.967, valid_loss=0.0523]        \n",
      "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.701, train_loss_epoch=0.701, valid_loss=0.0523]        \n",
      "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.414, train_loss_epoch=0.414, valid_loss=0.0523]        \n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 14.15it/s, v_num=0, train_loss_step=0.665, train_loss_epoch=0.414, valid_loss=0.0523]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=3619)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s]\u001b[A\n",
      "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.668, train_loss_epoch=0.668, valid_loss=0.063]         \n",
      "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.579, train_loss_epoch=0.579, valid_loss=0.063]        \n",
      "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.774, train_loss_epoch=0.774, valid_loss=0.063]        \n",
      "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.700, train_loss_epoch=0.700, valid_loss=0.063]        \n",
      "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.639, train_loss_epoch=0.639, valid_loss=0.063]        \n",
      "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.626, train_loss_epoch=0.626, valid_loss=0.063]        \n",
      "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.063]        \n",
      "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.609, train_loss_epoch=0.609, valid_loss=0.063]        \n",
      "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.658, train_loss_epoch=0.658, valid_loss=0.063]        \n",
      "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.651, train_loss_epoch=0.651, valid_loss=0.063]        \n",
      "Epoch 214: 100%|██████████| 1/1 [00:00<00:00, 14.81it/s, v_num=0, train_loss_step=0.610, train_loss_epoch=0.610, valid_loss=0.063]\n",
      "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.881, train_loss_epoch=0.881, valid_loss=0.063]        \n",
      "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.645, train_loss_epoch=0.645, valid_loss=0.063]        \n",
      "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.671, train_loss_epoch=0.671, valid_loss=0.063]        \n",
      "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.669, train_loss_epoch=0.669, valid_loss=0.063]        \n",
      "Epoch 221: 100%|██████████| 1/1 [00:00<00:00, 15.57it/s, v_num=0, train_loss_step=0.659, train_loss_epoch=0.659, valid_loss=0.063]\n",
      "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.618, train_loss_epoch=0.618, valid_loss=0.063]        \n",
      "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.641, train_loss_epoch=0.641, valid_loss=0.063]        \n",
      "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.662, train_loss_epoch=0.662, valid_loss=0.063]        \n",
      "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.668, train_loss_epoch=0.668, valid_loss=0.063]        \n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00, 18.12it/s, v_num=0, train_loss_step=0.668, train_loss_epoch=0.668, valid_loss=0.063]\n",
      "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.752, train_loss_epoch=0.752, valid_loss=0.063]        \n",
      "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.800, train_loss_epoch=0.800, valid_loss=0.063]        \n",
      "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.702, train_loss_epoch=0.702, valid_loss=0.063]        \n",
      "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.685, train_loss_epoch=0.685, valid_loss=0.063]        \n",
      "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.693, train_loss_epoch=0.693, valid_loss=0.063]        \n",
      "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.650, train_loss_epoch=0.650, valid_loss=0.063]        \n",
      "Epoch 237: 100%|██████████| 1/1 [00:00<00:00, 16.28it/s, v_num=0, train_loss_step=0.816, train_loss_epoch=0.816, valid_loss=0.063]\n",
      "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.604, train_loss_epoch=0.604, valid_loss=0.063]        \n",
      "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.673, train_loss_epoch=0.673, valid_loss=0.063]        \n",
      "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.741, train_loss_epoch=0.741, valid_loss=0.063]        \n",
      "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.664, train_loss_epoch=0.664, valid_loss=0.063]        \n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00, 16.93it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.063]\n",
      "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.850, train_loss_epoch=0.850, valid_loss=0.063]        \n",
      "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.592, train_loss_epoch=0.592, valid_loss=0.063]        \n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00, 16.01it/s, v_num=0, train_loss_step=0.592, train_loss_epoch=0.592, valid_loss=0.063]\n",
      "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.621, train_loss_epoch=0.621, valid_loss=0.063]        \n",
      "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.754, train_loss_epoch=0.754, valid_loss=0.063]        \n",
      "Epoch 250: 100%|██████████| 1/1 [00:00<00:00, 16.86it/s, v_num=0, train_loss_step=0.754, train_loss_epoch=0.754, valid_loss=0.063]\n",
      "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.932, train_loss_epoch=0.932, valid_loss=0.063]        \n",
      "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.063]        \n",
      "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.747, train_loss_epoch=0.747, valid_loss=0.063]        \n",
      "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.732, train_loss_epoch=0.732, valid_loss=0.063]        \n",
      "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.929, train_loss_epoch=0.929, valid_loss=0.063]        \n",
      "Epoch 258: 100%|██████████| 1/1 [00:00<00:00, 16.34it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.415, valid_loss=0.063]\n",
      "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.686, train_loss_epoch=0.686, valid_loss=0.063]        \n",
      "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569, valid_loss=0.063]        \n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00, 13.15it/s, v_num=0, train_loss_step=0.849, train_loss_epoch=0.849, valid_loss=0.063]\n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00, 12.90it/s, v_num=0, train_loss_step=0.621, train_loss_epoch=0.621, valid_loss=0.063]\n",
      "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.621, train_loss_epoch=0.621, valid_loss=0.063]        \n",
      "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.753, train_loss_epoch=0.753, valid_loss=0.063]        \n",
      "Epoch 265: 100%|██████████| 1/1 [00:00<00:00, 19.28it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=0.063]\n",
      "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.615, train_loss_epoch=0.615, valid_loss=0.063]        \n",
      "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=0.063]        \n",
      "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.758, train_loss_epoch=0.758, valid_loss=0.063]        \n",
      "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.667, train_loss_epoch=0.667, valid_loss=0.063]        \n",
      "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.610, train_loss_epoch=0.610, valid_loss=0.063]        \n",
      "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.406, train_loss_epoch=0.406, valid_loss=0.063]        \n",
      "Epoch 275: 100%|██████████| 1/1 [00:00<00:00, 18.35it/s, v_num=0, train_loss_step=0.637, train_loss_epoch=0.637, valid_loss=0.063]\n",
      "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.788, train_loss_epoch=0.788, valid_loss=0.063]        \n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00, 18.58it/s, v_num=0, train_loss_step=0.754, train_loss_epoch=0.754, valid_loss=0.063]\n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00, 15.66it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.754, valid_loss=0.063]\n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00, 15.51it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.063]\n",
      "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.063]        \n",
      "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=0.063]        \n",
      "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.824, train_loss_epoch=0.824, valid_loss=0.063]        \n",
      "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.860, train_loss_epoch=0.860, valid_loss=0.063]        \n",
      "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.449, train_loss_epoch=0.449, valid_loss=0.063]        \n",
      "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.722, train_loss_epoch=0.722, valid_loss=0.063]        \n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00, 12.02it/s, v_num=0, train_loss_step=0.722, train_loss_epoch=0.722, valid_loss=0.063]\n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00, 11.86it/s, v_num=0, train_loss_step=0.716, train_loss_epoch=0.722, valid_loss=0.063]\n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00, 11.75it/s, v_num=0, train_loss_step=0.716, train_loss_epoch=0.716, valid_loss=0.063]\n",
      "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.716, train_loss_epoch=0.716, valid_loss=0.063]        \n",
      "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.973, train_loss_epoch=0.973, valid_loss=0.063]        \n",
      "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.373, train_loss_epoch=0.373, valid_loss=0.063]        \n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=0, train_loss_step=0.812, train_loss_epoch=0.668, valid_loss=0.063]\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00, 14.54it/s, v_num=0, train_loss_step=0.812, train_loss_epoch=0.812, valid_loss=0.063]\n",
      "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.812, train_loss_epoch=0.812, valid_loss=0.063]        \n",
      "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.678, train_loss_epoch=0.678, valid_loss=0.063]        \n",
      "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.794, train_loss_epoch=0.794, valid_loss=0.063]        \n",
      "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332, valid_loss=0.063]        \n",
      "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.653, train_loss_epoch=0.653, valid_loss=0.063]        \n",
      "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.655, train_loss_epoch=0.655, valid_loss=0.063]        \n",
      "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.063]        \n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 14.63it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.063]\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 13.31it/s, v_num=0, train_loss_step=0.715, train_loss_epoch=0.513, valid_loss=0.063]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=3619)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s]\u001b[A\n",
      "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.715, train_loss_epoch=0.715, valid_loss=0.0388]        \n",
      "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.847, train_loss_epoch=0.847, valid_loss=0.0388]        \n",
      "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.800, train_loss_epoch=0.800, valid_loss=0.0388]        \n",
      "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.671, train_loss_epoch=0.671, valid_loss=0.0388]        \n",
      "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.681, train_loss_epoch=0.681, valid_loss=0.0388]        \n",
      "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.668, train_loss_epoch=0.668, valid_loss=0.0388]        \n",
      "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.633, train_loss_epoch=0.633, valid_loss=0.0388]        \n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00, 17.20it/s, v_num=0, train_loss_step=0.667, train_loss_epoch=0.667, valid_loss=0.0388]\n",
      "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.701, train_loss_epoch=0.701, valid_loss=0.0388]        \n",
      "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.601, train_loss_epoch=0.601, valid_loss=0.0388]        \n",
      "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.776, train_loss_epoch=0.776, valid_loss=0.0388]        \n",
      "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.725, train_loss_epoch=0.725, valid_loss=0.0388]        \n",
      "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.677, train_loss_epoch=0.677, valid_loss=0.0388]        \n",
      "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.613, train_loss_epoch=0.613, valid_loss=0.0388]        \n",
      "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0388]        \n",
      "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.595, train_loss_epoch=0.595, valid_loss=0.0388]        \n",
      "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.762, train_loss_epoch=0.762, valid_loss=0.0388]        \n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00, 14.46it/s, v_num=0, train_loss_step=0.680, train_loss_epoch=0.680, valid_loss=0.0388]\n",
      "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.760, train_loss_epoch=0.760, valid_loss=0.0388]        \n",
      "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.613, train_loss_epoch=0.613, valid_loss=0.0388]        \n",
      "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.931, train_loss_epoch=0.931, valid_loss=0.0388]        \n",
      "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.786, train_loss_epoch=0.786, valid_loss=0.0388]        \n",
      "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.606, train_loss_epoch=0.606, valid_loss=0.0388]        \n",
      "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.924, train_loss_epoch=0.924, valid_loss=0.0388]        \n",
      "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.0388]        \n",
      "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.688, train_loss_epoch=0.688, valid_loss=0.0388]        \n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s, v_num=0, train_loss_step=0.909, train_loss_epoch=0.909, valid_loss=0.0388]\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00, 14.63it/s, v_num=0, train_loss_step=0.649, train_loss_epoch=0.649, valid_loss=0.0388]\n",
      "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.649, train_loss_epoch=0.649, valid_loss=0.0388]        \n",
      "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.794, train_loss_epoch=0.794, valid_loss=0.0388]        \n",
      "Epoch 339: 100%|██████████| 1/1 [00:00<00:00, 16.09it/s, v_num=0, train_loss_step=0.668, train_loss_epoch=0.668, valid_loss=0.0388]\n",
      "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.646, train_loss_epoch=0.646, valid_loss=0.0388]        \n",
      "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.607, train_loss_epoch=0.607, valid_loss=0.0388]        \n",
      "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.840, train_loss_epoch=0.840, valid_loss=0.0388]        \n",
      "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.639, train_loss_epoch=0.639, valid_loss=0.0388]        \n",
      "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.742, train_loss_epoch=0.742, valid_loss=0.0388]        \n",
      "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.654, train_loss_epoch=0.654, valid_loss=0.0388]        \n",
      "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.657, train_loss_epoch=0.657, valid_loss=0.0388]        \n",
      "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.644, train_loss_epoch=0.644, valid_loss=0.0388]        \n",
      "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.638, train_loss_epoch=0.638, valid_loss=0.0388]        \n",
      "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.410, train_loss_epoch=0.410, valid_loss=0.0388]        \n",
      "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.868, train_loss_epoch=0.868, valid_loss=0.0388]        \n",
      "Epoch 356: 100%|██████████| 1/1 [00:00<00:00, 14.44it/s, v_num=0, train_loss_step=0.666, train_loss_epoch=0.666, valid_loss=0.0388]\n",
      "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.762, train_loss_epoch=0.762, valid_loss=0.0388]        \n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 18.22it/s, v_num=0, train_loss_step=0.638, train_loss_epoch=0.638, valid_loss=0.0388]\n",
      "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.385, train_loss_epoch=0.385, valid_loss=0.0388]        \n",
      "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.646, train_loss_epoch=0.646, valid_loss=0.0388]        \n",
      "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.755, train_loss_epoch=0.755, valid_loss=0.0388]        \n",
      "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.607, train_loss_epoch=0.607, valid_loss=0.0388]        \n",
      "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.607, train_loss_epoch=0.607, valid_loss=0.0388]        \n",
      "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.649, train_loss_epoch=0.649, valid_loss=0.0388]        \n",
      "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=0.0388]        \n",
      "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.705, train_loss_epoch=0.705, valid_loss=0.0388]        \n",
      "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0388]        \n",
      "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.642, train_loss_epoch=0.642, valid_loss=0.0388]        \n",
      "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.854, train_loss_epoch=0.854, valid_loss=0.0388]        \n",
      "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.575, train_loss_epoch=0.575, valid_loss=0.0388]        \n",
      "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.658, train_loss_epoch=0.658, valid_loss=0.0388]        \n",
      "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.648, train_loss_epoch=0.648, valid_loss=0.0388]        \n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00, 15.48it/s, v_num=0, train_loss_step=0.693, train_loss_epoch=0.693, valid_loss=0.0388]\n",
      "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.693, train_loss_epoch=0.693, valid_loss=0.0388]        \n",
      "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.633, train_loss_epoch=0.633, valid_loss=0.0388]        \n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00, 18.52it/s, v_num=0, train_loss_step=0.811, train_loss_epoch=0.811, valid_loss=0.0388]\n",
      "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.605, train_loss_epoch=0.605, valid_loss=0.0388]        \n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00, 15.81it/s, v_num=0, train_loss_step=0.610, train_loss_epoch=0.610, valid_loss=0.0388]\n",
      "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.671, train_loss_epoch=0.671, valid_loss=0.0388]        \n",
      "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.0388]        \n",
      "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361, valid_loss=0.0388]        \n",
      "Epoch 393: 100%|██████████| 1/1 [00:00<00:00, 17.07it/s, v_num=0, train_loss_step=0.681, train_loss_epoch=0.681, valid_loss=0.0388]\n",
      "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.733, train_loss_epoch=0.733, valid_loss=0.0388]        \n",
      "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.834, train_loss_epoch=0.834, valid_loss=0.0388]        \n",
      "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.364, train_loss_epoch=0.364, valid_loss=0.0388]        \n",
      "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.632, train_loss_epoch=0.632, valid_loss=0.0388]        \n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s, v_num=0, train_loss_step=0.624, train_loss_epoch=0.632, valid_loss=0.0388]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=3619)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  6.04it/s]\u001b[A\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00, 16.64it/s, v_num=0, train_loss_step=0.624, train_loss_epoch=0.624, valid_loss=0.141] \n",
      "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.626, train_loss_epoch=0.626, valid_loss=0.141]        \n",
      "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.837, train_loss_epoch=0.837, valid_loss=0.141]        \n",
      "Epoch 404: 100%|██████████| 1/1 [00:00<00:00, 13.28it/s, v_num=0, train_loss_step=0.731, train_loss_epoch=0.731, valid_loss=0.141]\n",
      "Epoch 404: 100%|██████████| 1/1 [00:00<00:00, 13.09it/s, v_num=0, train_loss_step=0.754, train_loss_epoch=0.731, valid_loss=0.141]\n",
      "Epoch 404: 100%|██████████| 1/1 [00:00<00:00, 13.01it/s, v_num=0, train_loss_step=0.754, train_loss_epoch=0.754, valid_loss=0.141]\n",
      "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.754, train_loss_epoch=0.754, valid_loss=0.141]        \n",
      "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.676, train_loss_epoch=0.676, valid_loss=0.141]        \n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00, 18.14it/s, v_num=0, train_loss_step=0.722, train_loss_epoch=0.722, valid_loss=0.141]\n",
      "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.873, train_loss_epoch=0.873, valid_loss=0.141]        \n",
      "Epoch 410: 100%|██████████| 1/1 [00:00<00:00, 16.77it/s, v_num=0, train_loss_step=0.584, train_loss_epoch=0.584, valid_loss=0.141]\n",
      "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.729, train_loss_epoch=0.729, valid_loss=0.141]        \n",
      "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.656, train_loss_epoch=0.656, valid_loss=0.141]        \n",
      "Epoch 414: 100%|██████████| 1/1 [00:00<00:00, 18.46it/s, v_num=0, train_loss_step=0.926, train_loss_epoch=0.926, valid_loss=0.141]\n",
      "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.638, train_loss_epoch=0.638, valid_loss=0.141]        \n",
      "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.639, train_loss_epoch=0.639, valid_loss=0.141]        \n",
      "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.945, valid_loss=0.141]        \n",
      "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.727, train_loss_epoch=0.727, valid_loss=0.141]        \n",
      "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.612, train_loss_epoch=0.612, valid_loss=0.141]        \n",
      "Epoch 422: 100%|██████████| 1/1 [00:00<00:00, 15.68it/s, v_num=0, train_loss_step=0.632, train_loss_epoch=0.632, valid_loss=0.141]\n",
      "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.602, train_loss_epoch=0.602, valid_loss=0.141]        \n",
      "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.674, train_loss_epoch=0.674, valid_loss=0.141]        \n",
      "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.613, train_loss_epoch=0.613, valid_loss=0.141]        \n",
      "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.956, train_loss_epoch=0.956, valid_loss=0.141]        \n",
      "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.141]        \n",
      "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.664, train_loss_epoch=0.664, valid_loss=0.141]        \n",
      "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.602, train_loss_epoch=0.602, valid_loss=0.141]        \n",
      "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.661, train_loss_epoch=0.661, valid_loss=0.141]        \n",
      "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.752, train_loss_epoch=0.752, valid_loss=0.141]        \n",
      "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.725, train_loss_epoch=0.725, valid_loss=0.141]        \n",
      "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.611, train_loss_epoch=0.611, valid_loss=0.141]        \n",
      "Epoch 439: 100%|██████████| 1/1 [00:00<00:00, 14.24it/s, v_num=0, train_loss_step=0.627, train_loss_epoch=0.627, valid_loss=0.141]\n",
      "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.703, train_loss_epoch=0.703, valid_loss=0.141]        \n",
      "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.433, train_loss_epoch=0.433, valid_loss=0.141]        \n",
      "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.853, train_loss_epoch=0.853, valid_loss=0.141]        \n",
      "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.141]        \n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00, 15.35it/s, v_num=0, train_loss_step=0.701, train_loss_epoch=0.701, valid_loss=0.141]\n",
      "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.674, train_loss_epoch=0.674, valid_loss=0.141]        \n",
      "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.770, train_loss_epoch=0.770, valid_loss=0.141]        \n",
      "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.759, train_loss_epoch=0.759, valid_loss=0.141]        \n",
      "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.623, train_loss_epoch=0.623, valid_loss=0.141]        \n",
      "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.720, train_loss_epoch=0.720, valid_loss=0.141]        \n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, v_num=0, train_loss_step=0.628, train_loss_epoch=0.969, valid_loss=0.141]\n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=0, train_loss_step=0.628, train_loss_epoch=0.628, valid_loss=0.141]\n",
      "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.628, train_loss_epoch=0.628, valid_loss=0.141]        \n",
      "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.595, train_loss_epoch=0.595, valid_loss=0.141]        \n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00, 14.61it/s, v_num=0, train_loss_step=0.593, train_loss_epoch=0.647, valid_loss=0.141]\n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s, v_num=0, train_loss_step=0.593, train_loss_epoch=0.593, valid_loss=0.141]\n",
      "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.593, train_loss_epoch=0.593, valid_loss=0.141]        \n",
      "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.589, train_loss_epoch=0.589, valid_loss=0.141]        \n",
      "Epoch 460: 100%|██████████| 1/1 [00:00<00:00, 17.47it/s, v_num=0, train_loss_step=0.852, train_loss_epoch=0.852, valid_loss=0.141]\n",
      "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.609, train_loss_epoch=0.609, valid_loss=0.141]        \n",
      "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.622, train_loss_epoch=0.622, valid_loss=0.141]        \n",
      "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.957, train_loss_epoch=0.957, valid_loss=0.141]        \n",
      "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.834, train_loss_epoch=0.834, valid_loss=0.141]        \n",
      "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.638, train_loss_epoch=0.638, valid_loss=0.141]        \n",
      "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.768, train_loss_epoch=0.768, valid_loss=0.141]        \n",
      "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.632, train_loss_epoch=0.632, valid_loss=0.141]        \n",
      "Epoch 471: 100%|██████████| 1/1 [00:00<00:00, 13.52it/s, v_num=0, train_loss_step=0.635, train_loss_epoch=0.635, valid_loss=0.141]\n",
      "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.630, train_loss_epoch=0.630, valid_loss=0.141]        \n",
      "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.617, train_loss_epoch=0.617, valid_loss=0.141]        \n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00, 11.62it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.141]\n",
      "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.141]        \n",
      "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.621, train_loss_epoch=0.621, valid_loss=0.141]        \n",
      "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.617, train_loss_epoch=0.617, valid_loss=0.141]        \n",
      "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.638, train_loss_epoch=0.638, valid_loss=0.141]        \n",
      "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.374, train_loss_epoch=0.374, valid_loss=0.141]        \n",
      "Epoch 481: 100%|██████████| 1/1 [00:00<00:00, 15.27it/s, v_num=0, train_loss_step=0.374, train_loss_epoch=0.374, valid_loss=0.141]\n",
      "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.141]        \n",
      "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.587, train_loss_epoch=0.587, valid_loss=0.141]        \n",
      "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.635, train_loss_epoch=0.635, valid_loss=0.141]        \n",
      "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.638, train_loss_epoch=0.638, valid_loss=0.141]        \n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00, 15.72it/s, v_num=0, train_loss_step=0.638, train_loss_epoch=0.638, valid_loss=0.141]\n",
      "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=0.141]        \n",
      "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.797, train_loss_epoch=0.797, valid_loss=0.141]        \n",
      "Epoch 491: 100%|██████████| 1/1 [00:00<00:00, 15.88it/s, v_num=0, train_loss_step=0.735, train_loss_epoch=0.735, valid_loss=0.141]\n",
      "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.598, train_loss_epoch=0.598, valid_loss=0.141]        \n",
      "Epoch 494: 100%|██████████| 1/1 [00:00<00:00, 15.55it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.141]\n",
      "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.141]        \n",
      "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.817, train_loss_epoch=0.817, valid_loss=0.141]        \n",
      "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.698, train_loss_epoch=0.698, valid_loss=0.141]        \n",
      "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.141]        \n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 16.24it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.550, valid_loss=0.141]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=3619)\u001b[0m `Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=3619)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  5.65it/s]\u001b[A\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  3.98it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0825]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=3824)\u001b[0m /home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=3824)\u001b[0m Seed set to 10\n",
      "\u001b[36m(_train_tune pid=3824)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=3824)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=3824)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=3824)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(_train_tune pid=3824)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_train_tune pid=3824)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=3824)\u001b[0m   | Name            | Type          | Params | Mode \n",
      "\u001b[36m(_train_tune pid=3824)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=3824)\u001b[0m 0 | loss            | WMAPE         | 0      | train\n",
      "\u001b[36m(_train_tune pid=3824)\u001b[0m 1 | padder          | ConstantPad1d | 0      | train\n",
      "\u001b[36m(_train_tune pid=3824)\u001b[0m 2 | scaler          | TemporalNorm  | 0      | train\n",
      "\u001b[36m(_train_tune pid=3824)\u001b[0m 3 | hist_encoder    | LSTM          | 31.0 K | train\n",
      "\u001b[36m(_train_tune pid=3824)\u001b[0m 4 | context_adapter | Linear        | 196 K  | train\n",
      "\u001b[36m(_train_tune pid=3824)\u001b[0m 5 | mlp_decoder     | MLP           | 3.3 K  | train\n",
      "\u001b[36m(_train_tune pid=3824)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=3824)\u001b[0m 230 K     Trainable params\n",
      "\u001b[36m(_train_tune pid=3824)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=3824)\u001b[0m 230 K     Total params\n",
      "\u001b[36m(_train_tune pid=3824)\u001b[0m 0.923     Total estimated model params size (MB)\n",
      "\u001b[36m(_train_tune pid=3824)\u001b[0m 11        Modules in train mode\n",
      "\u001b[36m(_train_tune pid=3824)\u001b[0m 0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]\n",
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]\n",
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]        \n",
      "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]         \n",
      "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.900, train_loss_epoch=0.900]         \n",
      "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.688, train_loss_epoch=0.688]         \n",
      "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.690, train_loss_epoch=0.690]         \n",
      "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.808, train_loss_epoch=0.808]         \n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00, 104.27it/s, v_num=0, train_loss_step=0.794, train_loss_epoch=0.808]\n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00, 97.42it/s, v_num=0, train_loss_step=0.794, train_loss_epoch=0.794] \n",
      "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.794, train_loss_epoch=0.794]        \n",
      "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.676, train_loss_epoch=0.676]         \n",
      "Epoch 57: 100%|██████████| 1/1 [00:00<00:00, 113.54it/s, v_num=0, train_loss_step=0.617, train_loss_epoch=0.617]\n",
      "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.617, train_loss_epoch=0.617]         \n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00, 109.04it/s, v_num=0, train_loss_step=0.762, train_loss_epoch=0.762]\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00, 100.38it/s, v_num=0, train_loss_step=0.707, train_loss_epoch=0.707]\n",
      "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.707, train_loss_epoch=0.707]         \n",
      "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.633, train_loss_epoch=0.633]         \n",
      "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.742, train_loss_epoch=0.742]         \n",
      "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.727, train_loss_epoch=0.727]         \n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00, 110.41it/s, v_num=0, train_loss_step=0.672, train_loss_epoch=0.672]\n",
      "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.672, train_loss_epoch=0.672]         \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 118.94it/s, v_num=0, train_loss_step=0.649, train_loss_epoch=0.670]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 91.34it/s]\u001b[A\n",
      "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.905, train_loss_epoch=0.905, valid_loss=0.0749]         \n",
      "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.776, train_loss_epoch=0.776, valid_loss=0.0749]         \n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00, 84.37it/s, v_num=0, train_loss_step=0.687, train_loss_epoch=0.775, valid_loss=0.0749] \n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00, 81.34it/s, v_num=0, train_loss_step=0.687, train_loss_epoch=0.687, valid_loss=0.0749]\n",
      "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.687, train_loss_epoch=0.687, valid_loss=0.0749]        \n",
      "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.619, train_loss_epoch=0.619, valid_loss=0.0749]         \n",
      "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.0749]         \n",
      "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.701, train_loss_epoch=0.701, valid_loss=0.0749]         \n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00, 113.61it/s, v_num=0, train_loss_step=0.670, train_loss_epoch=0.701, valid_loss=0.0749]\n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00, 106.68it/s, v_num=0, train_loss_step=0.670, train_loss_epoch=0.670, valid_loss=0.0749]\n",
      "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.670, train_loss_epoch=0.670, valid_loss=0.0749]         \n",
      "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.677, train_loss_epoch=0.677, valid_loss=0.0749]         \n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00, 85.04it/s, v_num=0, train_loss_step=0.677, train_loss_epoch=0.677, valid_loss=0.0749]\n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00, 75.94it/s, v_num=0, train_loss_step=0.893, train_loss_epoch=0.893, valid_loss=0.0749]\n",
      "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.649, train_loss_epoch=0.649, valid_loss=0.0749]         \n",
      "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.669, train_loss_epoch=0.669, valid_loss=0.0749]         \n",
      "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.643, train_loss_epoch=0.643, valid_loss=0.0749]         \n",
      "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.618, train_loss_epoch=0.618, valid_loss=0.0749]         \n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 110.70it/s, v_num=0, train_loss_step=0.706, train_loss_epoch=0.618, valid_loss=0.0749]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 93.34it/s]\u001b[A\n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00, 116.42it/s, v_num=0, train_loss_step=0.637, train_loss_epoch=0.654, valid_loss=0.0544]\n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00, 108.38it/s, v_num=0, train_loss_step=0.637, train_loss_epoch=0.637, valid_loss=0.0544]\n",
      "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.637, train_loss_epoch=0.637, valid_loss=0.0544]         \n",
      "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.769, train_loss_epoch=0.769, valid_loss=0.0544]         \n",
      "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.626, train_loss_epoch=0.626, valid_loss=0.0544]         \n",
      "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.981, train_loss_epoch=0.981, valid_loss=0.0544]         \n",
      "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.705, train_loss_epoch=0.705, valid_loss=0.0544]         \n",
      "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.368, train_loss_epoch=0.368, valid_loss=0.0544]         \n",
      "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.0544]         \n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00, 113.57it/s, v_num=0, train_loss_step=0.602, train_loss_epoch=0.538, valid_loss=0.0544]\n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00, 107.78it/s, v_num=0, train_loss_step=0.602, train_loss_epoch=0.602, valid_loss=0.0544]\n",
      "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.602, train_loss_epoch=0.602, valid_loss=0.0544]         \n",
      "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.758, train_loss_epoch=0.758, valid_loss=0.0544]         \n",
      "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.670, train_loss_epoch=0.670, valid_loss=0.0544]         \n",
      "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.670, train_loss_epoch=0.670, valid_loss=0.0544]\n",
      "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.830, train_loss_epoch=0.830, valid_loss=0.0544]         \n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 117.09it/s, v_num=0, train_loss_step=0.764, train_loss_epoch=0.670, valid_loss=0.0544]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 100.59it/s]\u001b[A\n",
      "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.639, train_loss_epoch=0.639, valid_loss=0.0671]         \n",
      "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.856, train_loss_epoch=0.856, valid_loss=0.0671]         \n",
      "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.735, train_loss_epoch=0.735, valid_loss=0.0671]         \n",
      "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.833, train_loss_epoch=0.833, valid_loss=0.0671]         \n",
      "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.842, train_loss_epoch=0.842, valid_loss=0.0671]         \n",
      "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.609, train_loss_epoch=0.609, valid_loss=0.0671]         \n",
      "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.820, train_loss_epoch=0.820, valid_loss=0.0671]         \n",
      "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.875, train_loss_epoch=0.875, valid_loss=0.0671]         \n",
      "Epoch 363: 100%|██████████| 1/1 [00:00<00:00, 103.96it/s, v_num=0, train_loss_step=0.956, train_loss_epoch=0.875, valid_loss=0.0671]\n",
      "Epoch 363: 100%|██████████| 1/1 [00:00<00:00, 76.62it/s, v_num=0, train_loss_step=0.956, train_loss_epoch=0.956, valid_loss=0.0671] \n",
      "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571, valid_loss=0.0671]         \n",
      "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.613, train_loss_epoch=0.613, valid_loss=0.0671]         \n",
      "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.701, train_loss_epoch=0.701, valid_loss=0.0671]         \n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 108.06it/s, v_num=0, train_loss_step=0.645, train_loss_epoch=0.758, valid_loss=0.0671]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 85.09it/s]\u001b[A\n",
      "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.645, train_loss_epoch=0.645, valid_loss=0.0618]         \n",
      "Epoch 410: 100%|██████████| 1/1 [00:00<00:00, 132.67it/s, v_num=0, train_loss_step=0.580, train_loss_epoch=0.659, valid_loss=0.0618]\n",
      "Epoch 410: 100%|██████████| 1/1 [00:00<00:00, 121.04it/s, v_num=0, train_loss_step=0.580, train_loss_epoch=0.580, valid_loss=0.0618]\n",
      "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.580, train_loss_epoch=0.580, valid_loss=0.0618]         \n",
      "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.635, train_loss_epoch=0.635, valid_loss=0.0618]         \n",
      "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.659, train_loss_epoch=0.659, valid_loss=0.0618]         \n",
      "Epoch 441: 100%|██████████| 1/1 [00:00<00:00, 118.05it/s, v_num=0, train_loss_step=0.634, train_loss_epoch=0.634, valid_loss=0.0618]\n",
      "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.634, train_loss_epoch=0.634, valid_loss=0.0618]         \n",
      "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.697, train_loss_epoch=0.697, valid_loss=0.0618]         \n",
      "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.823, train_loss_epoch=0.823, valid_loss=0.0618]         \n",
      "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.664, train_loss_epoch=0.664, valid_loss=0.0618]         \n",
      "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.423, train_loss_epoch=0.423, valid_loss=0.0618]         \n",
      "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.731, train_loss_epoch=0.731, valid_loss=0.0618]         \n",
      "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.632, train_loss_epoch=0.632, valid_loss=0.0618]         \n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 73.37it/s, v_num=0, train_loss_step=0.910, train_loss_epoch=0.558, valid_loss=0.0618]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=3824)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 65.11it/s]\u001b[A\n",
      "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.809, train_loss_epoch=0.809, valid_loss=0.0504]         \n",
      "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.674, train_loss_epoch=0.674, valid_loss=0.0504]         \n",
      "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.876, train_loss_epoch=0.876, valid_loss=0.0504]         \n",
      "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.691, train_loss_epoch=0.691, valid_loss=0.0504]         \n",
      "Epoch 537: 100%|██████████| 1/1 [00:00<00:00, 116.24it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471, valid_loss=0.0504]\n",
      "Epoch 537: 100%|██████████| 1/1 [00:00<00:00, 95.12it/s, v_num=0, train_loss_step=0.684, train_loss_epoch=0.684, valid_loss=0.0504] \n",
      "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.684, train_loss_epoch=0.684, valid_loss=0.0504]        \n",
      "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.640, train_loss_epoch=0.640, valid_loss=0.0504]         \n",
      "Epoch 553: 100%|██████████| 1/1 [00:00<00:00, 81.58it/s, v_num=0, train_loss_step=0.731, train_loss_epoch=0.731, valid_loss=0.0504] \n",
      "Epoch 553: 100%|██████████| 1/1 [00:00<00:00, 73.45it/s, v_num=0, train_loss_step=0.922, train_loss_epoch=0.922, valid_loss=0.0504]\n",
      "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.922, train_loss_epoch=0.922, valid_loss=0.0504]        \n",
      "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.911, train_loss_epoch=0.911, valid_loss=0.0504]         \n",
      "Epoch 569: 100%|██████████| 1/1 [00:00<00:00, 74.50it/s, v_num=0, train_loss_step=0.724, train_loss_epoch=0.724, valid_loss=0.0504] \n",
      "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.724, train_loss_epoch=0.724, valid_loss=0.0504]        \n",
      "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.639, train_loss_epoch=0.639, valid_loss=0.0504]         \n",
      "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.629, train_loss_epoch=0.629, valid_loss=0.0504]         \n",
      "Epoch 584: 100%|██████████| 1/1 [00:00<00:00, 108.28it/s, v_num=0, train_loss_step=0.629, train_loss_epoch=0.629, valid_loss=0.0504]\n",
      "Epoch 590: 100%|██████████| 1/1 [00:00<00:00, 69.02it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0504] \n",
      "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.660, train_loss_epoch=0.660, valid_loss=0.0504]         \n",
      "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 72.65it/s, v_num=0, train_loss_step=0.708, train_loss_epoch=0.475, valid_loss=0.0504]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 53.20it/s]\u001b[A\n",
      "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.642, train_loss_epoch=0.642, valid_loss=0.0651]         \n",
      "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.633, train_loss_epoch=0.633, valid_loss=0.0651]         \n",
      "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.648, train_loss_epoch=0.648, valid_loss=0.0651]         \n",
      "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.700, train_loss_epoch=0.700, valid_loss=0.0651]         \n",
      "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.609, train_loss_epoch=0.609, valid_loss=0.0651]         \n",
      "Epoch 638: 100%|██████████| 1/1 [00:00<00:00, 84.16it/s, v_num=0, train_loss_step=0.663, train_loss_epoch=0.663, valid_loss=0.0651] \n",
      "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.663, train_loss_epoch=0.663, valid_loss=0.0651]        \n",
      "Epoch 646: 100%|██████████| 1/1 [00:00<00:00, 94.98it/s, v_num=0, train_loss_step=0.743, train_loss_epoch=0.743, valid_loss=0.0651] \n",
      "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.743, train_loss_epoch=0.743, valid_loss=0.0651]        \n",
      "Epoch 654: 100%|██████████| 1/1 [00:00<00:00, 101.54it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0651]\n",
      "Epoch 654: 100%|██████████| 1/1 [00:00<00:00, 87.74it/s, v_num=0, train_loss_step=0.630, train_loss_epoch=0.630, valid_loss=0.0651] \n",
      "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.655, train_loss_epoch=0.655, valid_loss=0.0651]         \n",
      "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.671, train_loss_epoch=0.671, valid_loss=0.0651]         \n",
      "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.669, train_loss_epoch=0.669, valid_loss=0.0651]         \n",
      "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.625, train_loss_epoch=0.625, valid_loss=0.0651]         \n",
      "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.759, train_loss_epoch=0.759, valid_loss=0.0651]         \n",
      "Epoch 690: 100%|██████████| 1/1 [00:00<00:00, 110.53it/s, v_num=0, train_loss_step=0.759, train_loss_epoch=0.759, valid_loss=0.0651]\n",
      "Epoch 690: 100%|██████████| 1/1 [00:00<00:00, 90.57it/s, v_num=0, train_loss_step=0.388, train_loss_epoch=0.388, valid_loss=0.0651] \n",
      "Epoch 698: 100%|██████████| 1/1 [00:00<00:00, 97.44it/s, v_num=0, train_loss_step=0.837, train_loss_epoch=0.837, valid_loss=0.0651] \n",
      "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.837, train_loss_epoch=0.837, valid_loss=0.0651]        \n",
      "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 80.49it/s, v_num=0, train_loss_step=0.795, train_loss_epoch=0.837, valid_loss=0.0651]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 66.77it/s]\u001b[A\n",
      "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.630, train_loss_epoch=0.630, valid_loss=0.0422]         \n",
      "Epoch 713: 100%|██████████| 1/1 [00:00<00:00, 107.30it/s, v_num=0, train_loss_step=0.660, train_loss_epoch=0.660, valid_loss=0.0422]\n",
      "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.711, train_loss_epoch=0.711, valid_loss=0.0422]         \n",
      "Epoch 720: 100%|██████████| 1/1 [00:00<00:00, 77.12it/s, v_num=0, train_loss_step=0.588, train_loss_epoch=0.711, valid_loss=0.0422]\n",
      "Epoch 720: 100%|██████████| 1/1 [00:00<00:00, 73.27it/s, v_num=0, train_loss_step=0.588, train_loss_epoch=0.588, valid_loss=0.0422]\n",
      "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.588, train_loss_epoch=0.588, valid_loss=0.0422]        \n",
      "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.711, train_loss_epoch=0.711, valid_loss=0.0422]        \n",
      "Epoch 733: 100%|██████████| 1/1 [00:00<00:00, 78.79it/s, v_num=0, train_loss_step=0.766, train_loss_epoch=0.766, valid_loss=0.0422] \n",
      "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.766, train_loss_epoch=0.766, valid_loss=0.0422]        \n",
      "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.0422]         \n",
      "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.447, train_loss_epoch=0.447, valid_loss=0.0422]         \n",
      "Epoch 757: 100%|██████████| 1/1 [00:00<00:00, 92.57it/s, v_num=0, train_loss_step=0.692, train_loss_epoch=0.692, valid_loss=0.0422] \n",
      "Epoch 757: 100%|██████████| 1/1 [00:00<00:00, 82.80it/s, v_num=0, train_loss_step=0.342, train_loss_epoch=0.692, valid_loss=0.0422]\n",
      "Epoch 757: 100%|██████████| 1/1 [00:00<00:00, 79.13it/s, v_num=0, train_loss_step=0.342, train_loss_epoch=0.342, valid_loss=0.0422]\n",
      "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.342, train_loss_epoch=0.342, valid_loss=0.0422]        \n",
      "Epoch 766:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.867, train_loss_epoch=0.867, valid_loss=0.0422]         \n",
      "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.719, train_loss_epoch=0.719, valid_loss=0.0422]         \n",
      "Epoch 781:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.664, train_loss_epoch=0.664, valid_loss=0.0422]         \n",
      "Epoch 781: 100%|██████████| 1/1 [00:00<00:00, 74.79it/s, v_num=0, train_loss_step=0.653, train_loss_epoch=0.664, valid_loss=0.0422]\n",
      "Epoch 781: 100%|██████████| 1/1 [00:00<00:00, 70.30it/s, v_num=0, train_loss_step=0.653, train_loss_epoch=0.653, valid_loss=0.0422]\n",
      "Epoch 781:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.653, train_loss_epoch=0.653, valid_loss=0.0422]        \n",
      "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.653, train_loss_epoch=0.653, valid_loss=0.0422]\n",
      "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.402, train_loss_epoch=0.402, valid_loss=0.0422]         \n",
      "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.688, train_loss_epoch=0.688, valid_loss=0.0422]         \n",
      "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 102.00it/s, v_num=0, train_loss_step=0.806, train_loss_epoch=0.553, valid_loss=0.0422]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 66.77it/s]\u001b[A\n",
      "Epoch 803: 100%|██████████| 1/1 [00:00<00:00, 85.18it/s, v_num=0, train_loss_step=0.784, train_loss_epoch=0.784, valid_loss=0.036]  \n",
      "Epoch 803: 100%|██████████| 1/1 [00:00<00:00, 77.96it/s, v_num=0, train_loss_step=0.827, train_loss_epoch=0.784, valid_loss=0.036]\n",
      "Epoch 803: 100%|██████████| 1/1 [00:00<00:00, 73.04it/s, v_num=0, train_loss_step=0.827, train_loss_epoch=0.827, valid_loss=0.036]\n",
      "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.827, train_loss_epoch=0.827, valid_loss=0.036]        \n",
      "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.635, train_loss_epoch=0.635, valid_loss=0.036]         \n",
      "Epoch 812: 100%|██████████| 1/1 [00:00<00:00, 120.33it/s, v_num=0, train_loss_step=0.635, train_loss_epoch=0.635, valid_loss=0.036]\n",
      "Epoch 812: 100%|██████████| 1/1 [00:00<00:00, 96.85it/s, v_num=0, train_loss_step=0.689, train_loss_epoch=0.689, valid_loss=0.036] \n",
      "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.689, train_loss_epoch=0.689, valid_loss=0.036]        \n",
      "Epoch 813:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.689, train_loss_epoch=0.689, valid_loss=0.036]\n",
      "Epoch 821: 100%|██████████| 1/1 [00:00<00:00, 109.12it/s, v_num=0, train_loss_step=0.915, train_loss_epoch=0.915, valid_loss=0.036]\n",
      "Epoch 821: 100%|██████████| 1/1 [00:00<00:00, 88.69it/s, v_num=0, train_loss_step=0.438, train_loss_epoch=0.438, valid_loss=0.036] \n",
      "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.820, train_loss_epoch=0.820, valid_loss=0.036]         \n",
      "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.958, train_loss_epoch=0.958, valid_loss=0.036]         \n",
      "Epoch 844: 100%|██████████| 1/1 [00:00<00:00, 98.11it/s, v_num=0, train_loss_step=0.630, train_loss_epoch=0.630, valid_loss=0.036] \n",
      "Epoch 844: 100%|██████████| 1/1 [00:00<00:00, 84.62it/s, v_num=0, train_loss_step=0.648, train_loss_epoch=0.648, valid_loss=0.036]\n",
      "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.648, train_loss_epoch=0.648, valid_loss=0.036]        \n",
      "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.690, train_loss_epoch=0.690, valid_loss=0.036]         \n",
      "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.745, train_loss_epoch=0.745, valid_loss=0.036]         \n",
      "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.280, train_loss_epoch=0.280, valid_loss=0.036]         \n",
      "Epoch 877:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.586, train_loss_epoch=0.586, valid_loss=0.036]         \n",
      "Epoch 877: 100%|██████████| 1/1 [00:00<00:00, 81.56it/s, v_num=0, train_loss_step=0.586, train_loss_epoch=0.586, valid_loss=0.036]\n",
      "Epoch 877: 100%|██████████| 1/1 [00:00<00:00, 70.35it/s, v_num=0, train_loss_step=0.652, train_loss_epoch=0.652, valid_loss=0.036]\n",
      "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.652, train_loss_epoch=0.652, valid_loss=0.036]        \n",
      "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.764, train_loss_epoch=0.764, valid_loss=0.036]         \n",
      "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.709, train_loss_epoch=0.709, valid_loss=0.036]         \n",
      "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 98.57it/s, v_num=0, train_loss_step=0.697, train_loss_epoch=0.699, valid_loss=0.036] \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 71.92it/s]\u001b[A\n",
      "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 30.34it/s, v_num=0, train_loss_step=0.697, train_loss_epoch=0.697, valid_loss=0.0475]\n",
      "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.697, train_loss_epoch=0.697, valid_loss=0.0475]        \n",
      "Epoch 908:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.681, train_loss_epoch=0.681, valid_loss=0.0475]         \n",
      "Epoch 916: 100%|██████████| 1/1 [00:00<00:00, 90.69it/s, v_num=0, train_loss_step=0.936, train_loss_epoch=0.936, valid_loss=0.0475] \n",
      "Epoch 917:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.936, train_loss_epoch=0.936, valid_loss=0.0475]        \n",
      "Epoch 925:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.712, train_loss_epoch=0.712, valid_loss=0.0475]         \n",
      "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.428, train_loss_epoch=0.428, valid_loss=0.0475]         \n",
      "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.737, train_loss_epoch=0.737, valid_loss=0.0475]         \n",
      "Epoch 949: 100%|██████████| 1/1 [00:00<00:00, 74.03it/s, v_num=0, train_loss_step=0.807, train_loss_epoch=0.807, valid_loss=0.0475]\n",
      "Epoch 950:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.807, train_loss_epoch=0.807, valid_loss=0.0475]        \n",
      "Epoch 957:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.392, train_loss_epoch=0.392, valid_loss=0.0475]         \n",
      "Epoch 965: 100%|██████████| 1/1 [00:00<00:00, 98.17it/s, v_num=0, train_loss_step=0.781, train_loss_epoch=0.781, valid_loss=0.0475] \n",
      "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.781, train_loss_epoch=0.781, valid_loss=0.0475]        \n",
      "Epoch 974: 100%|██████████| 1/1 [00:00<00:00, 102.06it/s, v_num=0, train_loss_step=0.644, train_loss_epoch=0.728, valid_loss=0.0475]\n",
      "Epoch 974: 100%|██████████| 1/1 [00:00<00:00, 97.85it/s, v_num=0, train_loss_step=0.644, train_loss_epoch=0.644, valid_loss=0.0475] \n",
      "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.644, train_loss_epoch=0.644, valid_loss=0.0475]        \n",
      "Epoch 983: 100%|██████████| 1/1 [00:00<00:00, 114.59it/s, v_num=0, train_loss_step=0.747, train_loss_epoch=0.747, valid_loss=0.0475]\n",
      "Epoch 983: 100%|██████████| 1/1 [00:00<00:00, 100.31it/s, v_num=0, train_loss_step=0.704, train_loss_epoch=0.747, valid_loss=0.0475]\n",
      "Epoch 983: 100%|██████████| 1/1 [00:00<00:00, 96.00it/s, v_num=0, train_loss_step=0.704, train_loss_epoch=0.704, valid_loss=0.0475] \n",
      "Epoch 984:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.704, train_loss_epoch=0.704, valid_loss=0.0475]        \n",
      "Epoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.731, train_loss_epoch=0.731, valid_loss=0.0475]         \n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 90.65it/s, v_num=0, train_loss_step=0.762, train_loss_epoch=0.438, valid_loss=0.0475] \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=3824)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.42it/s]\u001b[A\n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 25.55it/s, v_num=0, train_loss_step=0.762, train_loss_epoch=0.762, valid_loss=0.0362]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=3824)\u001b[0m `Trainer.fit` stopped: `max_steps=1000` reached.\n",
      "\u001b[36m(_train_tune pid=3945)\u001b[0m /home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=3945)\u001b[0m Seed set to 15\n",
      "\u001b[36m(_train_tune pid=3945)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=3945)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=3945)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=3945)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(_train_tune pid=3945)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_train_tune pid=3945)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=3945)\u001b[0m   | Name            | Type          | Params | Mode \n",
      "\u001b[36m(_train_tune pid=3945)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=3945)\u001b[0m 0 | loss            | WMAPE         | 0      | train\n",
      "\u001b[36m(_train_tune pid=3945)\u001b[0m 1 | padder          | ConstantPad1d | 0      | train\n",
      "\u001b[36m(_train_tune pid=3945)\u001b[0m 2 | scaler          | TemporalNorm  | 0      | train\n",
      "\u001b[36m(_train_tune pid=3945)\u001b[0m 3 | hist_encoder    | LSTM          | 51.4 K | train\n",
      "\u001b[36m(_train_tune pid=3945)\u001b[0m 4 | context_adapter | Linear        | 19.6 K | train\n",
      "\u001b[36m(_train_tune pid=3945)\u001b[0m 5 | mlp_decoder     | MLP           | 897    | train\n",
      "\u001b[36m(_train_tune pid=3945)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=3945)\u001b[0m 71.9 K    Trainable params\n",
      "\u001b[36m(_train_tune pid=3945)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=3945)\u001b[0m 71.9 K    Total params\n",
      "\u001b[36m(_train_tune pid=3945)\u001b[0m 0.288     Total estimated model params size (MB)\n",
      "\u001b[36m(_train_tune pid=3945)\u001b[0m 11        Modules in train mode\n",
      "\u001b[36m(_train_tune pid=3945)\u001b[0m 0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                                                                           \n",
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 58.10it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 70.41it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984]\n",
      "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.873, train_loss_epoch=0.873]        \n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00, 38.48it/s, v_num=0, train_loss_step=0.807, train_loss_epoch=0.807]\n",
      "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.807, train_loss_epoch=0.807]        \n",
      "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.802, train_loss_epoch=0.802]        \n",
      "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.761, train_loss_epoch=0.761]        \n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00, 46.29it/s, v_num=0, train_loss_step=0.761, train_loss_epoch=0.761]\n",
      "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.743, train_loss_epoch=0.743]        \n",
      "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.700, train_loss_epoch=0.700]        \n",
      "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.655, train_loss_epoch=0.655]        \n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00, 57.92it/s, v_num=0, train_loss_step=0.608, train_loss_epoch=0.608]\n",
      "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.595, train_loss_epoch=0.595]        \n",
      "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582]        \n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00, 58.85it/s, v_num=0, train_loss_step=0.577, train_loss_epoch=0.577]\n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00, 37.82it/s, v_num=0, train_loss_step=0.576, train_loss_epoch=0.576]\n",
      "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.576, train_loss_epoch=0.576]        \n",
      "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.575, train_loss_epoch=0.575]        \n",
      "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.570, train_loss_epoch=0.570]        \n",
      "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568]        \n",
      "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.566, train_loss_epoch=0.566]        \n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00, 50.99it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562]\n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00, 47.60it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560]\n",
      "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562]        \n",
      "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552]        \n",
      "Epoch 75: 100%|██████████| 1/1 [00:00<00:00, 28.36it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549]\n",
      "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549]        \n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00, 67.35it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538]\n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00, 41.53it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.538]\n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00, 39.41it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554]\n",
      "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554]        \n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00, 60.82it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549]\n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00, 37.00it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.549]\n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00, 33.88it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544]\n",
      "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544]        \n",
      "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535]        \n",
      "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530]        \n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00, 31.30it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526]\n",
      "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526]        \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 41.40it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.523]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 71.35it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=3945)\u001b[0m \n",
      "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0344]        \n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00, 53.69it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0344]\n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00, 38.72it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.516, valid_loss=0.0344]\n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00, 36.68it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0344]\n",
      "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0344]        \n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00, 54.42it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0344]\n",
      "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0344]        \n",
      "Epoch 117: 100%|██████████| 1/1 [00:00<00:00, 36.71it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.510, valid_loss=0.0344]\n",
      "Epoch 117: 100%|██████████| 1/1 [00:00<00:00, 34.48it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0344]\n",
      "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0344]        \n",
      "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0344]        \n",
      "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0344]        \n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00, 36.59it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.521, valid_loss=0.0344]\n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00, 34.96it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0344]\n",
      "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0344]        \n",
      "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0344]        \n",
      "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0344]        \n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00, 43.38it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0344]\n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00, 35.85it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.513, valid_loss=0.0344]\n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00, 33.96it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0344]\n",
      "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0344]        \n",
      "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0344]        \n",
      "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0344]        \n",
      "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0344]        \n",
      "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0344]        \n",
      "Epoch 150: 100%|██████████| 1/1 [00:00<00:00, 56.61it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0344]\n",
      "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0344]        \n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00, 59.73it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0344]\n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00, 40.34it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0344]\n",
      "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0344]        \n",
      "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0344]        \n",
      "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0344]        \n",
      "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0344]        \n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00, 61.06it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0344]\n",
      "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0344]        \n",
      "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0344]        \n",
      "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0344]        \n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00, 26.02it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0344]\n",
      "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0344]        \n",
      "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.0344]        \n",
      "Epoch 186: 100%|██████████| 1/1 [00:00<00:00, 33.67it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0344]\n",
      "Epoch 188: 100%|██████████| 1/1 [00:00<00:00, 32.31it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0344]\n",
      "Epoch 188: 100%|██████████| 1/1 [00:00<00:00, 22.75it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.510, valid_loss=0.0344]\n",
      "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0344]        \n",
      "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0344]        \n",
      "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0344]        \n",
      "Epoch 195: 100%|██████████| 1/1 [00:00<00:00, 24.57it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.506, valid_loss=0.0344]\n",
      "Epoch 195: 100%|██████████| 1/1 [00:00<00:00, 23.81it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0344]\n",
      "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0344]        \n",
      "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0344]\n",
      "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0344]        \n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 23.73it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.501, valid_loss=0.0344]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 43.93it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=3945)\u001b[0m \n",
      "Epoch 201: 100%|██████████| 1/1 [00:00<00:00, 32.78it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0379]\n",
      "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0379]        \n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00, 25.96it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0379]\n",
      "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0379]        \n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00, 45.75it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0379]\n",
      "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0379]        \n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00, 39.23it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0379]\n",
      "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0379]        \n",
      "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0379]        \n",
      "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0379]        \n",
      "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0379]        \n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00, 48.89it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0379]\n",
      "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0379]        \n",
      "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0379]        \n",
      "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0379]        \n",
      "Epoch 235: 100%|██████████| 1/1 [00:00<00:00, 44.18it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0379]\n",
      "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.0379]        \n",
      "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0379]        \n",
      "Epoch 242: 100%|██████████| 1/1 [00:00<00:00, 40.96it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0379]\n",
      "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0379]        \n",
      "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0379]        \n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00, 36.75it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0379]\n",
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00, 23.98it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.479, valid_loss=0.0379]\n",
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00, 22.25it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0379]\n",
      "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0379]        \n",
      "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.0379]        \n",
      "Epoch 254: 100%|██████████| 1/1 [00:00<00:00, 38.90it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471, valid_loss=0.0379]\n",
      "Epoch 256: 100%|██████████| 1/1 [00:00<00:00, 31.96it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=0.0379]\n",
      "Epoch 256: 100%|██████████| 1/1 [00:00<00:00, 22.26it/s, v_num=0, train_loss_step=0.474, train_loss_epoch=0.462, valid_loss=0.0379]\n",
      "Epoch 256: 100%|██████████| 1/1 [00:00<00:00, 21.33it/s, v_num=0, train_loss_step=0.474, train_loss_epoch=0.474, valid_loss=0.0379]\n",
      "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.474, train_loss_epoch=0.474, valid_loss=0.0379]        \n",
      "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0379]        \n",
      "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0379]        \n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00, 24.13it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.474, valid_loss=0.0379]\n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00, 23.24it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0379]\n",
      "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0379]        \n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00, 46.74it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=0.0379]\n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00, 23.32it/s, v_num=0, train_loss_step=0.459, train_loss_epoch=0.466, valid_loss=0.0379]\n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00, 22.63it/s, v_num=0, train_loss_step=0.459, train_loss_epoch=0.459, valid_loss=0.0379]\n",
      "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.459, train_loss_epoch=0.459, valid_loss=0.0379]        \n",
      "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.456, train_loss_epoch=0.456, valid_loss=0.0379]        \n",
      "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.453, train_loss_epoch=0.453, valid_loss=0.0379]        \n",
      "Epoch 275: 100%|██████████| 1/1 [00:00<00:00, 29.70it/s, v_num=0, train_loss_step=0.453, train_loss_epoch=0.453, valid_loss=0.0379]\n",
      "Epoch 277: 100%|██████████| 1/1 [00:00<00:00, 23.54it/s, v_num=0, train_loss_step=0.447, train_loss_epoch=0.447, valid_loss=0.0379]\n",
      "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.444, train_loss_epoch=0.444, valid_loss=0.0379]        \n",
      "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.441, train_loss_epoch=0.441, valid_loss=0.0379]        \n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00, 38.98it/s, v_num=0, train_loss_step=0.438, train_loss_epoch=0.438, valid_loss=0.0379]\n",
      "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.435, train_loss_epoch=0.435, valid_loss=0.0379]        \n",
      "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.434, train_loss_epoch=0.434, valid_loss=0.0379]        \n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00, 35.23it/s, v_num=0, train_loss_step=0.432, train_loss_epoch=0.432, valid_loss=0.0379]\n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00, 23.60it/s, v_num=0, train_loss_step=0.431, train_loss_epoch=0.431, valid_loss=0.0379]\n",
      "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.431, train_loss_epoch=0.431, valid_loss=0.0379]        \n",
      "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.429, train_loss_epoch=0.429, valid_loss=0.0379]        \n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00, 37.30it/s, v_num=0, train_loss_step=0.428, train_loss_epoch=0.428, valid_loss=0.0379]\n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00, 33.21it/s, v_num=0, train_loss_step=0.426, train_loss_epoch=0.426, valid_loss=0.0379]\n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00, 23.66it/s, v_num=0, train_loss_step=0.426, train_loss_epoch=0.426, valid_loss=0.0379]\n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00, 21.71it/s, v_num=0, train_loss_step=0.426, train_loss_epoch=0.426, valid_loss=0.0379]\n",
      "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.426, train_loss_epoch=0.426, valid_loss=0.0379]        \n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 23.10it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.426, valid_loss=0.0379]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 50.67it/s]\u001b[A\n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00, 45.29it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=0.0388]\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00, 37.11it/s, v_num=0, train_loss_step=0.424, train_loss_epoch=0.424, valid_loss=0.0388]\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00, 24.25it/s, v_num=0, train_loss_step=0.438, train_loss_epoch=0.424, valid_loss=0.0388]\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00, 22.61it/s, v_num=0, train_loss_step=0.438, train_loss_epoch=0.438, valid_loss=0.0388]\n",
      "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.438, train_loss_epoch=0.438, valid_loss=0.0388]        \n",
      "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.443, train_loss_epoch=0.443, valid_loss=0.0388]        \n",
      "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.441, train_loss_epoch=0.441, valid_loss=0.0388]        \n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00, 33.25it/s, v_num=0, train_loss_step=0.440, train_loss_epoch=0.440, valid_loss=0.0388]\n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00, 23.02it/s, v_num=0, train_loss_step=0.440, train_loss_epoch=0.440, valid_loss=0.0388]\n",
      "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.440, train_loss_epoch=0.440, valid_loss=0.0388]        \n",
      "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.439, train_loss_epoch=0.439, valid_loss=0.0388]        \n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00, 26.80it/s, v_num=0, train_loss_step=0.437, train_loss_epoch=0.437, valid_loss=0.0388]\n",
      "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.437, train_loss_epoch=0.437, valid_loss=0.0388]        \n",
      "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.436, train_loss_epoch=0.436, valid_loss=0.0388]        \n",
      "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=0.0388]        \n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00, 36.64it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0388]\n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00, 24.42it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.536, valid_loss=0.0388]\n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00, 23.55it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0388]\n",
      "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0388]        \n",
      "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0388]        \n",
      "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=0.0388]        \n",
      "Epoch 328: 100%|██████████| 1/1 [00:00<00:00, 36.84it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.0388]\n",
      "Epoch 330: 100%|██████████| 1/1 [00:00<00:00, 34.69it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=0.0388]\n",
      "Epoch 330: 100%|██████████| 1/1 [00:00<00:00, 22.66it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565, valid_loss=0.0388]\n",
      "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0388]        \n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00, 34.87it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.0388]\n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00, 24.27it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0388]\n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00, 22.94it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0388]\n",
      "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0388]        \n",
      "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0388]        \n",
      "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.0388]        \n",
      "Epoch 344: 100%|██████████| 1/1 [00:00<00:00, 40.43it/s, v_num=0, train_loss_step=0.570, train_loss_epoch=0.570, valid_loss=0.0388]\n",
      "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.0388]        \n",
      "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.0388]        \n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00, 35.88it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0388]\n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00, 32.35it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0388]\n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00, 22.26it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.534, valid_loss=0.0388]\n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00, 21.15it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.0388]\n",
      "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.0388]        \n",
      "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0388]        \n",
      "Epoch 358: 100%|██████████| 1/1 [00:00<00:00, 28.70it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0388]\n",
      "Epoch 358: 100%|██████████| 1/1 [00:00<00:00, 27.96it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0388]\n",
      "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0388]        \n",
      "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0388]        \n",
      "Epoch 363: 100%|██████████| 1/1 [00:00<00:00, 35.47it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0388]\n",
      "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0388]        \n",
      "Epoch 368: 100%|██████████| 1/1 [00:00<00:00, 35.27it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0388]\n",
      "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0388]        \n",
      "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0388]        \n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00, 26.88it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.493, valid_loss=0.0388]\n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00, 25.96it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0388]\n",
      "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0388]        \n",
      "Epoch 377: 100%|██████████| 1/1 [00:00<00:00, 23.42it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0388]\n",
      "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0388]        \n",
      "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0388]        \n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00, 40.53it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0388]\n",
      "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0388]        \n",
      "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0388]        \n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00, 29.50it/s, v_num=0, train_loss_step=0.474, train_loss_epoch=0.474, valid_loss=0.0388]\n",
      "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.0388]        \n",
      "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.0388]        \n",
      "Epoch 398: 100%|██████████| 1/1 [00:00<00:00, 40.86it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.0388]\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 26.33it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.467, valid_loss=0.0388]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 38.59it/s]\u001b[A\n",
      "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.0354]        \n",
      "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.459, train_loss_epoch=0.459, valid_loss=0.0354]        \n",
      "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=0.0354]        \n",
      "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=0.0354]        \n",
      "Epoch 409: 100%|██████████| 1/1 [00:00<00:00, 32.09it/s, v_num=0, train_loss_step=0.459, train_loss_epoch=0.459, valid_loss=0.0354]\n",
      "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.454, train_loss_epoch=0.454, valid_loss=0.0354]        \n",
      "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.447, train_loss_epoch=0.447, valid_loss=0.0354]        \n",
      "Epoch 416: 100%|██████████| 1/1 [00:00<00:00, 26.14it/s, v_num=0, train_loss_step=0.442, train_loss_epoch=0.444, valid_loss=0.0354]\n",
      "Epoch 416: 100%|██████████| 1/1 [00:00<00:00, 25.02it/s, v_num=0, train_loss_step=0.442, train_loss_epoch=0.442, valid_loss=0.0354]\n",
      "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.442, train_loss_epoch=0.442, valid_loss=0.0354]        \n",
      "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.449, train_loss_epoch=0.449, valid_loss=0.0354]        \n",
      "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.439, train_loss_epoch=0.439, valid_loss=0.0354]        \n",
      "Epoch 423: 100%|██████████| 1/1 [00:00<00:00, 31.53it/s, v_num=0, train_loss_step=0.438, train_loss_epoch=0.438, valid_loss=0.0354]\n",
      "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.432, train_loss_epoch=0.432, valid_loss=0.0354]        \n",
      "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=0.0354]        \n",
      "Epoch 430: 100%|██████████| 1/1 [00:00<00:00, 34.49it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=0.0354]\n",
      "Epoch 432: 100%|██████████| 1/1 [00:00<00:00, 24.12it/s, v_num=0, train_loss_step=0.426, train_loss_epoch=0.467, valid_loss=0.0354]\n",
      "Epoch 432: 100%|██████████| 1/1 [00:00<00:00, 22.95it/s, v_num=0, train_loss_step=0.426, train_loss_epoch=0.426, valid_loss=0.0354]\n",
      "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.426, train_loss_epoch=0.426, valid_loss=0.0354]        \n",
      "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.442, train_loss_epoch=0.442, valid_loss=0.0354]        \n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00, 37.94it/s, v_num=0, train_loss_step=0.442, train_loss_epoch=0.442, valid_loss=0.0354]\n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00, 22.73it/s, v_num=0, train_loss_step=0.428, train_loss_epoch=0.428, valid_loss=0.0354]\n",
      "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.428, train_loss_epoch=0.428, valid_loss=0.0354]        \n",
      "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.433, train_loss_epoch=0.433, valid_loss=0.0354]        \n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00, 36.13it/s, v_num=0, train_loss_step=0.422, train_loss_epoch=0.422, valid_loss=0.0354]\n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00, 25.90it/s, v_num=0, train_loss_step=0.413, train_loss_epoch=0.413, valid_loss=0.0354]\n",
      "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.413, train_loss_epoch=0.413, valid_loss=0.0354]        \n",
      "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=0.0354]        \n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00, 33.80it/s, v_num=0, train_loss_step=0.450, train_loss_epoch=0.450, valid_loss=0.0354]\n",
      "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=0.0354]        \n",
      "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.418, train_loss_epoch=0.418, valid_loss=0.0354]        \n",
      "Epoch 456: 100%|██████████| 1/1 [00:00<00:00, 32.26it/s, v_num=0, train_loss_step=0.417, train_loss_epoch=0.417, valid_loss=0.0354]\n",
      "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.424, train_loss_epoch=0.424, valid_loss=0.0354]        \n",
      "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.414, train_loss_epoch=0.414, valid_loss=0.0354]        \n",
      "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.403, train_loss_epoch=0.403, valid_loss=0.0354]        \n",
      "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.403, train_loss_epoch=0.403, valid_loss=0.0354]        \n",
      "Epoch 468: 100%|██████████| 1/1 [00:00<00:00, 35.24it/s, v_num=0, train_loss_step=0.400, train_loss_epoch=0.400, valid_loss=0.0354]\n",
      "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.394, train_loss_epoch=0.394, valid_loss=0.0354]        \n",
      "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.394, train_loss_epoch=0.394, valid_loss=0.0354]        \n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00, 34.43it/s, v_num=0, train_loss_step=0.391, train_loss_epoch=0.391, valid_loss=0.0354]\n",
      "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.386, train_loss_epoch=0.386, valid_loss=0.0354]        \n",
      "Epoch 480: 100%|██████████| 1/1 [00:00<00:00, 38.03it/s, v_num=0, train_loss_step=0.382, train_loss_epoch=0.382, valid_loss=0.0354]\n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00, 23.70it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.378, valid_loss=0.0354]\n",
      "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.378, valid_loss=0.0354]        \n",
      "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.378, valid_loss=0.0354]        \n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00, 33.82it/s, v_num=0, train_loss_step=0.375, train_loss_epoch=0.375, valid_loss=0.0354]\n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00, 23.80it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.375, valid_loss=0.0354]\n",
      "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=0.0354]        \n",
      "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.375, train_loss_epoch=0.375, valid_loss=0.0354]        \n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00, 42.14it/s, v_num=0, train_loss_step=0.371, train_loss_epoch=0.371, valid_loss=0.0354]\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00, 26.47it/s, v_num=0, train_loss_step=0.370, train_loss_epoch=0.371, valid_loss=0.0354]\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00, 25.66it/s, v_num=0, train_loss_step=0.370, train_loss_epoch=0.370, valid_loss=0.0354]\n",
      "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.370, train_loss_epoch=0.370, valid_loss=0.0354]        \n",
      "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365, valid_loss=0.0354]        \n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00, 37.14it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365, valid_loss=0.0354]\n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00, 23.65it/s, v_num=0, train_loss_step=0.362, train_loss_epoch=0.362, valid_loss=0.0354]\n",
      "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.362, train_loss_epoch=0.362, valid_loss=0.0354]        \n",
      "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.362, train_loss_epoch=0.362, valid_loss=0.0354]\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 27.68it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.361, valid_loss=0.0354]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 56.71it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=3945)\u001b[0m \n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 14.56it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.361, valid_loss=0.0432]\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 14.31it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=0.0432]\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 13.88it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=0.0432]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=3945)\u001b[0m `Trainer.fit` stopped: `max_steps=500` reached.\n",
      "\u001b[36m(_train_tune pid=4094)\u001b[0m /home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=4094)\u001b[0m Seed set to 7\n",
      "\u001b[36m(_train_tune pid=4094)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=4094)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=4094)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=4094)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(_train_tune pid=4094)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=4094)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=4094)\u001b[0m   | Name            | Type          | Params | Mode \n",
      "\u001b[36m(_train_tune pid=4094)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=4094)\u001b[0m 0 | loss            | WMAPE         | 0      | train\n",
      "\u001b[36m(_train_tune pid=4094)\u001b[0m 1 | padder          | ConstantPad1d | 0      | train\n",
      "\u001b[36m(_train_tune pid=4094)\u001b[0m 2 | scaler          | TemporalNorm  | 0      | train\n",
      "\u001b[36m(_train_tune pid=4094)\u001b[0m 3 | hist_encoder    | LSTM          | 51.4 K | train\n",
      "\u001b[36m(_train_tune pid=4094)\u001b[0m 4 | context_adapter | Linear        | 19.6 K | train\n",
      "\u001b[36m(_train_tune pid=4094)\u001b[0m 5 | mlp_decoder     | MLP           | 1.8 K  | train\n",
      "\u001b[36m(_train_tune pid=4094)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=4094)\u001b[0m 72.8 K    Trainable params\n",
      "\u001b[36m(_train_tune pid=4094)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=4094)\u001b[0m 72.8 K    Total params\n",
      "\u001b[36m(_train_tune pid=4094)\u001b[0m 0.291     Total estimated model params size (MB)\n",
      "\u001b[36m(_train_tune pid=4094)\u001b[0m 11        Modules in train mode\n",
      "\u001b[36m(_train_tune pid=4094)\u001b[0m 0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 50.79it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]\n",
      "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 48.32it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]\n",
      "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00, 25.93it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]\n",
      "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999]        \n",
      "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997]        \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 39.70it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994]\n",
      "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.986, train_loss_epoch=0.986]        \n",
      "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.975, train_loss_epoch=0.975]        \n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00, 39.36it/s, v_num=0, train_loss_step=0.959, train_loss_epoch=0.959]\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00, 26.19it/s, v_num=0, train_loss_step=0.948, train_loss_epoch=0.959]\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00, 24.84it/s, v_num=0, train_loss_step=0.948, train_loss_epoch=0.948]\n",
      "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.948, train_loss_epoch=0.948]        \n",
      "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.920, train_loss_epoch=0.920]        \n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00, 24.63it/s, v_num=0, train_loss_step=0.869, train_loss_epoch=0.869]\n",
      "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.869, train_loss_epoch=0.869]        \n",
      "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.837, train_loss_epoch=0.837]        \n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00, 22.85it/s, v_num=0, train_loss_step=0.810, train_loss_epoch=0.810]\n",
      "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.810, train_loss_epoch=0.810]        \n",
      "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.802, train_loss_epoch=0.802]        \n",
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00, 36.42it/s, v_num=0, train_loss_step=0.792, train_loss_epoch=0.792]\n",
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00, 25.73it/s, v_num=0, train_loss_step=0.785, train_loss_epoch=0.792]\n",
      "Epoch 41: 100%|██████████| 1/1 [00:00<00:00, 24.69it/s, v_num=0, train_loss_step=0.785, train_loss_epoch=0.785]\n",
      "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.785, train_loss_epoch=0.785]        \n",
      "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.771, train_loss_epoch=0.771]        \n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00, 40.37it/s, v_num=0, train_loss_step=0.771, train_loss_epoch=0.771]\n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00, 24.36it/s, v_num=0, train_loss_step=0.751, train_loss_epoch=0.751]\n",
      "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.751, train_loss_epoch=0.751]        \n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 57.57it/s, v_num=0, train_loss_step=0.741, train_loss_epoch=0.741]\n",
      "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.728, train_loss_epoch=0.728]        \n",
      "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.718, train_loss_epoch=0.718]        \n",
      "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.698, train_loss_epoch=0.698]        \n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 57.75it/s, v_num=0, train_loss_step=0.682, train_loss_epoch=0.682]\n",
      "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.660, train_loss_epoch=0.660]        \n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00, 40.48it/s, v_num=0, train_loss_step=0.660, train_loss_epoch=0.660]\n",
      "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.639, train_loss_epoch=0.639]        \n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00, 41.55it/s, v_num=0, train_loss_step=0.625, train_loss_epoch=0.625]\n",
      "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.607, train_loss_epoch=0.607]        \n",
      "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.601, train_loss_epoch=0.601]        \n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00, 35.76it/s, v_num=0, train_loss_step=0.601, train_loss_epoch=0.601]\n",
      "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.598, train_loss_epoch=0.598]        \n",
      "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.596, train_loss_epoch=0.596]        \n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00, 25.26it/s, v_num=0, train_loss_step=0.594, train_loss_epoch=0.594]\n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00, 23.78it/s, v_num=0, train_loss_step=0.594, train_loss_epoch=0.594]\n",
      "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.594, train_loss_epoch=0.594]        \n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00, 37.35it/s, v_num=0, train_loss_step=0.592, train_loss_epoch=0.592]\n",
      "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.588, train_loss_epoch=0.588]        \n",
      "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.586, train_loss_epoch=0.586]        \n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 36.54it/s, v_num=0, train_loss_step=0.585, train_loss_epoch=0.585]\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 25.29it/s, v_num=0, train_loss_step=0.585, train_loss_epoch=0.585]\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 24.38it/s, v_num=0, train_loss_step=0.585, train_loss_epoch=0.585]\n",
      "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.585, train_loss_epoch=0.585]        \n",
      "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.584, train_loss_epoch=0.584]        \n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00, 36.06it/s, v_num=0, train_loss_step=0.584, train_loss_epoch=0.584]\n",
      "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582]        \n",
      "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582]\n",
      "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.581, train_loss_epoch=0.581]        \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 30.69it/s, v_num=0, train_loss_step=0.580, train_loss_epoch=0.580]\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 21.68it/s, v_num=0, train_loss_step=0.579, train_loss_epoch=0.580]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 41.88it/s]\u001b[A\n",
      "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.579, train_loss_epoch=0.579, valid_loss=0.0441]        \n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00, 41.49it/s, v_num=0, train_loss_step=0.578, train_loss_epoch=0.578, valid_loss=0.0441]\n",
      "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.577, train_loss_epoch=0.577, valid_loss=0.0441]        \n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00, 34.06it/s, v_num=0, train_loss_step=0.576, train_loss_epoch=0.576, valid_loss=0.0441]\n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00, 23.45it/s, v_num=0, train_loss_step=0.576, train_loss_epoch=0.576, valid_loss=0.0441]\n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00, 21.96it/s, v_num=0, train_loss_step=0.576, train_loss_epoch=0.576, valid_loss=0.0441]\n",
      "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.576, train_loss_epoch=0.576, valid_loss=0.0441]        \n",
      "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.576, train_loss_epoch=0.576, valid_loss=0.0441]\n",
      "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.575, train_loss_epoch=0.575, valid_loss=0.0441]        \n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00, 37.64it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574, valid_loss=0.0441]\n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00, 25.75it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574, valid_loss=0.0441]\n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00, 22.74it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574, valid_loss=0.0441]\n",
      "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573, valid_loss=0.0441]        \n",
      "Epoch 118: 100%|██████████| 1/1 [00:00<00:00, 39.03it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573, valid_loss=0.0441]\n",
      "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.572, valid_loss=0.0441]        \n",
      "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571, valid_loss=0.0441]        \n",
      "Epoch 123: 100%|██████████| 1/1 [00:00<00:00, 33.23it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571, valid_loss=0.0441]\n",
      "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.570, train_loss_epoch=0.570, valid_loss=0.0441]        \n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00, 44.69it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569, valid_loss=0.0441]\n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00, 26.85it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569, valid_loss=0.0441]\n",
      "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568, valid_loss=0.0441]        \n",
      "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567, valid_loss=0.0441]        \n",
      "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.566, train_loss_epoch=0.566, valid_loss=0.0441]        \n",
      "Epoch 138: 100%|██████████| 1/1 [00:00<00:00, 38.96it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565, valid_loss=0.0441]\n",
      "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561, valid_loss=0.0441]        \n",
      "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569, valid_loss=0.0441]        \n",
      "Epoch 143: 100%|██████████| 1/1 [00:00<00:00, 40.55it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569, valid_loss=0.0441]\n",
      "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.575, train_loss_epoch=0.575, valid_loss=0.0441]        \n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00, 36.07it/s, v_num=0, train_loss_step=0.579, train_loss_epoch=0.579, valid_loss=0.0441]\n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00, 24.45it/s, v_num=0, train_loss_step=0.580, train_loss_epoch=0.579, valid_loss=0.0441]\n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00, 23.25it/s, v_num=0, train_loss_step=0.580, train_loss_epoch=0.580, valid_loss=0.0441]\n",
      "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.580, train_loss_epoch=0.580, valid_loss=0.0441]        \n",
      "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.576, train_loss_epoch=0.576, valid_loss=0.0441]        \n",
      "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571, valid_loss=0.0441]        \n",
      "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571, valid_loss=0.0441]        \n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00, 16.58it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567, valid_loss=0.0441]\n",
      "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567, valid_loss=0.0441]        \n",
      "Epoch 158: 100%|██████████| 1/1 [00:00<00:00, 30.24it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567, valid_loss=0.0441]\n",
      "Epoch 160: 100%|██████████| 1/1 [00:00<00:00, 30.24it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568, valid_loss=0.0441]\n",
      "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.566, train_loss_epoch=0.566, valid_loss=0.0441]        \n",
      "Epoch 162: 100%|██████████| 1/1 [00:00<00:00, 30.35it/s, v_num=0, train_loss_step=0.566, train_loss_epoch=0.566, valid_loss=0.0441]\n",
      "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567, valid_loss=0.0441]        \n",
      "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565, valid_loss=0.0441]        \n",
      "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=0.0441]        \n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00, 30.83it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=0.0441]\n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00, 19.08it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.564, valid_loss=0.0441]\n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00, 18.58it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563, valid_loss=0.0441]\n",
      "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563, valid_loss=0.0441]        \n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00, 30.41it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562, valid_loss=0.0441]\n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00, 29.39it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562, valid_loss=0.0441]\n",
      "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561, valid_loss=0.0441]        \n",
      "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=0.0441]        \n",
      "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=0.0441]        \n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00, 18.94it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0441]\n",
      "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0441]        \n",
      "Epoch 182: 100%|██████████| 1/1 [00:00<00:00, 26.34it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.0441]\n",
      "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0441]        \n",
      "Epoch 184: 100%|██████████| 1/1 [00:00<00:00, 43.45it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0441]\n",
      "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0441]        \n",
      "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=0.0441]        \n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00, 19.46it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=0.0441]\n",
      "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=0.0441]        \n",
      "Epoch 191: 100%|██████████| 1/1 [00:00<00:00, 28.51it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=0.0441]\n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00, 31.82it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=0.0441]\n",
      "Epoch 195: 100%|██████████| 1/1 [00:00<00:00, 32.93it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0441]\n",
      "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.0441]        \n",
      "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0441]        \n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 19.27it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.556, valid_loss=0.0441]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 42.50it/s]\u001b[A\n",
      "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0352]        \n",
      "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.0352]        \n",
      "Epoch 203: 100%|██████████| 1/1 [00:00<00:00, 19.14it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.556, valid_loss=0.0352]\n",
      "Epoch 203: 100%|██████████| 1/1 [00:00<00:00, 18.39it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.0352]\n",
      "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.0352]        \n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00, 32.78it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0352]\n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00, 18.88it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.0352]\n",
      "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.0352]        \n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00, 29.45it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.0352]\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 32.70it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0352]\n",
      "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0352]        \n",
      "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0352]        \n",
      "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0352]        \n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00, 18.34it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0352]\n",
      "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0352]        \n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00, 29.44it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0352]\n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00, 29.74it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0352]\n",
      "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=0.0352]        \n",
      "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0352]        \n",
      "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0352]        \n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00, 16.84it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=0.0352]\n",
      "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=0.0352]        \n",
      "Epoch 229: 100%|██████████| 1/1 [00:00<00:00, 33.05it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=0.0352]\n",
      "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.0352]        \n",
      "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=0.0352]        \n",
      "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=0.0352]        \n",
      "Epoch 236: 100%|██████████| 1/1 [00:00<00:00, 29.22it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0352]\n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00, 35.61it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.0352]\n",
      "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.0352]        \n",
      "Epoch 241: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0352]\n",
      "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0352]        \n",
      "Epoch 243: 100%|██████████| 1/1 [00:00<00:00, 22.33it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0352]\n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00, 31.84it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0352]\n",
      "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0352]        \n",
      "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.0352]        \n",
      "Epoch 250: 100%|██████████| 1/1 [00:00<00:00, 27.60it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0352]\n",
      "Epoch 250: 100%|██████████| 1/1 [00:00<00:00, 17.81it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0352]\n",
      "Epoch 250: 100%|██████████| 1/1 [00:00<00:00, 17.19it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0352]\n",
      "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0352]        \n",
      "Epoch 252: 100%|██████████| 1/1 [00:00<00:00, 29.75it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=0.0352]\n",
      "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0352]        \n",
      "Epoch 254: 100%|██████████| 1/1 [00:00<00:00, 27.25it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0352]\n",
      "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0352]        \n",
      "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.0352]        \n",
      "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.0352]        \n",
      "Epoch 261: 100%|██████████| 1/1 [00:00<00:00, 17.88it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0352]\n",
      "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0352]        \n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00, 33.76it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0352]\n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00, 18.85it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0352]\n",
      "Epoch 265: 100%|██████████| 1/1 [00:00<00:00, 26.50it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0352]\n",
      "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0352]        \n",
      "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0352]        \n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00, 19.28it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0352]\n",
      "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0352]        \n",
      "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0352]\n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00, 26.66it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0352]\n",
      "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0352]        \n",
      "Epoch 274: 100%|██████████| 1/1 [00:00<00:00, 28.60it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0352]\n",
      "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0352]        \n",
      "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0352]        \n",
      "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0352]        \n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00, 29.46it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0352]\n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00, 17.90it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0352]\n",
      "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0352]        \n",
      "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0352]\n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00, 26.39it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0352]\n",
      "Epoch 285: 100%|██████████| 1/1 [00:00<00:00, 32.43it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0352]\n",
      "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0352]        \n",
      "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0352]        \n",
      "Epoch 290: 100%|██████████| 1/1 [00:00<00:00, 17.72it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0352]\n",
      "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0352]        \n",
      "Epoch 292: 100%|██████████| 1/1 [00:00<00:00, 29.83it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0352]\n",
      "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0352]        \n",
      "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0352]        \n",
      "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0352]        \n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 18.87it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.513, valid_loss=0.0352]\n",
      "\u001b[36m(_train_tune pid=4094)\u001b[0m \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=4094)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 35.89it/s]\u001b[A\n",
      "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0344]        \n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00, 18.93it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0344]\n",
      "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0344]        \n",
      "Epoch 304: 100%|██████████| 1/1 [00:00<00:00, 31.02it/s, v_num=0, train_loss_step=0.590, train_loss_epoch=0.590, valid_loss=0.0344]\n",
      "Epoch 304: 100%|██████████| 1/1 [00:00<00:00, 19.09it/s, v_num=0, train_loss_step=0.581, train_loss_epoch=0.581, valid_loss=0.0344]\n",
      "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.581, train_loss_epoch=0.581, valid_loss=0.0344]        \n",
      "Epoch 306: 100%|██████████| 1/1 [00:00<00:00, 32.45it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=0.0344]\n",
      "Epoch 308: 100%|██████████| 1/1 [00:00<00:00, 29.37it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.0344]\n",
      "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.0344]        \n",
      "Epoch 311: 100%|██████████| 1/1 [00:00<00:00, 15.92it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=0.0344]\n",
      "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=0.0344]        \n",
      "Epoch 313: 100%|██████████| 1/1 [00:00<00:00, 19.59it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.0344]\n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00, 30.69it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0344]\n",
      "Epoch 317: 100%|██████████| 1/1 [00:00<00:00, 32.70it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0344]\n",
      "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.0344]        \n",
      "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=0.0344]        \n",
      "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0344]        \n",
      "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0344]        \n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00, 29.76it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0344]\n",
      "Epoch 328: 100%|██████████| 1/1 [00:00<00:00, 34.26it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0344]\n",
      "Epoch 330: 100%|██████████| 1/1 [00:00<00:00, 33.36it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0344]\n",
      "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0344]        \n",
      "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0344]        \n",
      "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0344]        \n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00, 18.84it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0344]\n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00, 18.23it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0344]\n",
      "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0344]        \n",
      "Epoch 339: 100%|██████████| 1/1 [00:00<00:00, 33.69it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0344]\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00, 31.54it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0344]\n",
      "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0344]        \n",
      "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0344]        \n",
      "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0344]        \n",
      "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0344]        \n",
      "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0344]\n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00, 20.26it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0344]\n",
      "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0344]        \n",
      "Epoch 352: 100%|██████████| 1/1 [00:00<00:00, 30.71it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0344]\n",
      "Epoch 354: 100%|██████████| 1/1 [00:00<00:00, 28.18it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0344]\n",
      "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0344]        \n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00, 25.52it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0344]\n",
      "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0344]        \n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 28.11it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0344]\n",
      "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0344]        \n",
      "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0344]        \n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00, 28.24it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0344]\n",
      "Epoch 366: 100%|██████████| 1/1 [00:00<00:00, 40.68it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0344]\n",
      "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0344]        \n",
      "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0344]        \n",
      "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0344]        \n",
      "Epoch 373: 100%|██████████| 1/1 [00:00<00:00, 29.59it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0344]\n",
      "Epoch 373: 100%|██████████| 1/1 [00:00<00:00, 18.00it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0344]\n",
      "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0344]        \n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00, 31.41it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0344]\n",
      "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0344]        \n",
      "Epoch 377: 100%|██████████| 1/1 [00:00<00:00, 29.19it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0344]\n",
      "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0344]        \n",
      "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0344]        \n",
      "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0344]        \n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00, 29.24it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0344]\n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00, 18.32it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0344]\n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00, 17.54it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0344]\n",
      "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0344]        \n",
      "Epoch 386: 100%|██████████| 1/1 [00:00<00:00, 19.12it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0344]\n",
      "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0344]        \n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00, 29.03it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0344]\n",
      "Epoch 390: 100%|██████████| 1/1 [00:00<00:00, 36.88it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0344]\n",
      "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0344]        \n",
      "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0344]        \n",
      "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0344]        \n",
      "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0344]        \n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 22.05it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0344]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=4094)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 56.22it/s]\u001b[A\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00, 49.03it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0354]\n",
      "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0354]        \n",
      "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0354]        \n",
      "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0354]        \n",
      "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0354]        \n",
      "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0354]        \n",
      "Epoch 413: 100%|██████████| 1/1 [00:00<00:00, 20.41it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.506, valid_loss=0.0354]\n",
      "Epoch 413: 100%|██████████| 1/1 [00:00<00:00, 19.78it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0354]\n",
      "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0354]        \n",
      "Epoch 415: 100%|██████████| 1/1 [00:00<00:00, 28.65it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0354]\n",
      "Epoch 417: 100%|██████████| 1/1 [00:00<00:00, 30.05it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0354]\n",
      "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0354]        \n",
      "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0354]        \n",
      "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0354]        \n",
      "Epoch 424: 100%|██████████| 1/1 [00:00<00:00, 32.47it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0354]\n",
      "Epoch 424: 100%|██████████| 1/1 [00:00<00:00, 18.73it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0354]\n",
      "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0354]        \n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00, 27.05it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0354]\n",
      "Epoch 428: 100%|██████████| 1/1 [00:00<00:00, 29.61it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0354]\n",
      "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0354]        \n",
      "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0354]        \n",
      "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0354]        \n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00, 18.48it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.501, valid_loss=0.0354]\n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00, 17.93it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0354]\n",
      "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0354]        \n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00, 28.58it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0354]\n",
      "Epoch 439: 100%|██████████| 1/1 [00:00<00:00, 42.12it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0354]\n",
      "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0354]        \n",
      "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0354]        \n",
      "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0354]        \n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00, 27.89it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0354]\n",
      "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0354]        \n",
      "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0354]        \n",
      "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0354]        \n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00, 33.02it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0354]\n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00, 18.36it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0354]\n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00, 39.41it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0354]\n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00, 20.51it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.500, valid_loss=0.0354]\n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00, 19.55it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0354]\n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00, 28.28it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0354]\n",
      "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0354]        \n",
      "Epoch 459: 100%|██████████| 1/1 [00:00<00:00, 27.87it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0354]\n",
      "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0354]        \n",
      "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0354]        \n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0354]\n",
      "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0354]        \n",
      "Epoch 466: 100%|██████████| 1/1 [00:00<00:00, 25.26it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0354]\n",
      "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0354]        \n",
      "Epoch 468: 100%|██████████| 1/1 [00:00<00:00, 26.62it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0354]\n",
      "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0354]        \n",
      "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0354]        \n",
      "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0354]        \n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00, 38.23it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0354]\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00, 19.92it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0354]\n",
      "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0354]        \n",
      "Epoch 477: 100%|██████████| 1/1 [00:00<00:00, 31.89it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0354]\n",
      "Epoch 477: 100%|██████████| 1/1 [00:00<00:00, 18.77it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0354]\n",
      "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0354]        \n",
      "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0354]\n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00, 29.61it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0354]\n",
      "Epoch 481: 100%|██████████| 1/1 [00:00<00:00, 33.15it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0354]\n",
      "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0354]        \n",
      "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0354]        \n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00, 17.80it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.499, valid_loss=0.0354]\n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00, 17.01it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0354]\n",
      "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0354]        \n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00, 25.13it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0354]\n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00, 40.41it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0354]\n",
      "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0354]        \n",
      "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0354]        \n",
      "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0354]        \n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00, 29.39it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0354]\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 31.60it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0354]\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 19.01it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.494, valid_loss=0.0354]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 30.70it/s]\u001b[A\n",
      "Epoch 500: 100%|██████████| 1/1 [00:00<00:00, 39.57it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0347]\n",
      "Epoch 502: 100%|██████████| 1/1 [00:00<00:00, 30.44it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0347]\n",
      "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0347]        \n",
      "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0347]        \n",
      "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0347]        \n",
      "Epoch 509: 100%|██████████| 1/1 [00:00<00:00, 31.77it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0347]\n",
      "Epoch 511: 100%|██████████| 1/1 [00:00<00:00, 32.48it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0347]\n",
      "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0347]        \n",
      "Epoch 513: 100%|██████████| 1/1 [00:00<00:00, 28.04it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0347]\n",
      "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0347]        \n",
      "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0347]        \n",
      "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0347]        \n",
      "Epoch 520: 100%|██████████| 1/1 [00:00<00:00, 30.52it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0347]\n",
      "Epoch 522: 100%|██████████| 1/1 [00:00<00:00, 38.96it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0347]\n",
      "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0347]        \n",
      "Epoch 524: 100%|██████████| 1/1 [00:00<00:00, 26.40it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0347]\n",
      "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0347]        \n",
      "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0347]        \n",
      "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0347]        \n",
      "Epoch 531: 100%|██████████| 1/1 [00:00<00:00, 27.73it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0347]\n",
      "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0347]        \n",
      "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0347]        \n",
      "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0347]        \n",
      "Epoch 538: 100%|██████████| 1/1 [00:00<00:00, 17.12it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0347]\n",
      "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0347]        \n",
      "Epoch 540: 100%|██████████| 1/1 [00:00<00:00, 30.44it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0347]\n",
      "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0347]        \n",
      "Epoch 542: 100%|██████████| 1/1 [00:00<00:00, 26.75it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0347]\n",
      "Epoch 544: 100%|██████████| 1/1 [00:00<00:00, 35.31it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0347]\n",
      "Epoch 546: 100%|██████████| 1/1 [00:00<00:00, 43.09it/s, v_num=0, train_loss_step=0.475, train_loss_epoch=0.475, valid_loss=0.0347]\n",
      "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.474, train_loss_epoch=0.474, valid_loss=0.0347]        \n",
      "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473, valid_loss=0.0347]        \n",
      "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.0347]        \n",
      "Epoch 553: 100%|██████████| 1/1 [00:00<00:00, 28.87it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471, valid_loss=0.0347]\n",
      "Epoch 553: 100%|██████████| 1/1 [00:00<00:00, 18.27it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471, valid_loss=0.0347]\n",
      "Epoch 553: 100%|██████████| 1/1 [00:00<00:00, 17.63it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471, valid_loss=0.0347]\n",
      "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471, valid_loss=0.0347]        \n",
      "Epoch 555: 100%|██████████| 1/1 [00:00<00:00, 40.65it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=0.0347]\n",
      "Epoch 555: 100%|██████████| 1/1 [00:00<00:00, 20.16it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.0347]\n",
      "Epoch 557: 100%|██████████| 1/1 [00:00<00:00, 29.41it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.0347]\n",
      "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.468, valid_loss=0.0347]        \n",
      "Epoch 559: 100%|██████████| 1/1 [00:00<00:00, 27.18it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.468, valid_loss=0.0347]\n",
      "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=0.0347]        \n",
      "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=0.0347]        \n",
      "Epoch 564: 100%|██████████| 1/1 [00:00<00:00, 17.43it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.0347]\n",
      "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.0347]        \n",
      "Epoch 566: 100%|██████████| 1/1 [00:00<00:00, 35.04it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=0.0347]\n",
      "Epoch 566: 100%|██████████| 1/1 [00:00<00:00, 19.33it/s, v_num=0, train_loss_step=0.461, train_loss_epoch=0.461, valid_loss=0.0347]\n",
      "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.461, train_loss_epoch=0.461, valid_loss=0.0347]        \n",
      "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=0.0347]        \n",
      "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.458, train_loss_epoch=0.458, valid_loss=0.0347]        \n",
      "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0347]        \n",
      "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.468, valid_loss=0.0347]        \n",
      "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473, valid_loss=0.0347]        \n",
      "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=0.0347]        \n",
      "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.461, train_loss_epoch=0.461, valid_loss=0.0347]        \n",
      "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=0.0347]        \n",
      "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=0.0347]        \n",
      "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455, valid_loss=0.0347]        \n",
      "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.453, train_loss_epoch=0.453, valid_loss=0.0347]        \n",
      "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.446, train_loss_epoch=0.446, valid_loss=0.0347]        \n",
      "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.439, train_loss_epoch=0.439, valid_loss=0.0347]        \n",
      "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.431, train_loss_epoch=0.431, valid_loss=0.0347]        \n",
      "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0347]        \n",
      "Epoch 597: 100%|██████████| 1/1 [00:00<00:00, 33.52it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0347]\n",
      "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 41.00it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0347]\n",
      "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 21.18it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.518, valid_loss=0.0347]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 51.19it/s]\u001b[A\n",
      "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0511]        \n",
      "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0511]        \n",
      "Epoch 604: 100%|██████████| 1/1 [00:00<00:00, 21.83it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0511]\n",
      "Epoch 606: 100%|██████████| 1/1 [00:00<00:00, 33.82it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0511]\n",
      "Epoch 608: 100%|██████████| 1/1 [00:00<00:00, 33.01it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0511]\n",
      "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0511]        \n",
      "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0511]        \n",
      "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=0.0511]        \n",
      "Epoch 615: 100%|██████████| 1/1 [00:00<00:00, 29.69it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=0.0511]\n",
      "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=0.0511]        \n",
      "Epoch 617: 100%|██████████| 1/1 [00:00<00:00, 28.74it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=0.0511]\n",
      "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0511]        \n",
      "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0511]        \n",
      "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0511]        \n",
      "Epoch 624: 100%|██████████| 1/1 [00:00<00:00, 17.63it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0511]\n",
      "Epoch 626: 100%|██████████| 1/1 [00:00<00:00, 40.11it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0511]\n",
      "Epoch 628: 100%|██████████| 1/1 [00:00<00:00, 29.24it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0511]\n",
      "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0511]        \n",
      "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0511]        \n",
      "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0511]        \n",
      "Epoch 635: 100%|██████████| 1/1 [00:00<00:00, 18.90it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0511]\n",
      "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0511]        \n",
      "Epoch 637: 100%|██████████| 1/1 [00:00<00:00, 20.59it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0511]\n",
      "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0511]        \n",
      "Epoch 639: 100%|██████████| 1/1 [00:00<00:00, 20.52it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0511]\n",
      "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0511]        \n",
      "Epoch 641: 100%|██████████| 1/1 [00:00<00:00, 28.60it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0511]\n",
      "Epoch 643: 100%|██████████| 1/1 [00:00<00:00, 30.17it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0511]\n",
      "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0511]        \n",
      "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0511]        \n",
      "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0511]        \n",
      "Epoch 650: 100%|██████████| 1/1 [00:00<00:00, 27.00it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0511]\n",
      "Epoch 652: 100%|██████████| 1/1 [00:00<00:00, 31.54it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0511]\n",
      "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0511]        \n",
      "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0511]        \n",
      "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0511]        \n",
      "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0511]        \n",
      "Epoch 661: 100%|██████████| 1/1 [00:00<00:00, 17.86it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0511]\n",
      "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0511]        \n",
      "Epoch 663: 100%|██████████| 1/1 [00:00<00:00, 35.42it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0511]\n",
      "Epoch 663: 100%|██████████| 1/1 [00:00<00:00, 19.83it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0511]\n",
      "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0511]        \n",
      "Epoch 665: 100%|██████████| 1/1 [00:00<00:00, 30.29it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0511]\n",
      "Epoch 665: 100%|██████████| 1/1 [00:00<00:00, 18.71it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.499, valid_loss=0.0511]\n",
      "Epoch 665: 100%|██████████| 1/1 [00:00<00:00, 18.11it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0511]\n",
      "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0511]        \n",
      "Epoch 667: 100%|██████████| 1/1 [00:00<00:00, 29.79it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0511]\n",
      "Epoch 669: 100%|██████████| 1/1 [00:00<00:00, 31.13it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0511]\n",
      "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0511]        \n",
      "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0511]        \n",
      "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0511]        \n",
      "Epoch 676: 100%|██████████| 1/1 [00:00<00:00, 29.70it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0511]\n",
      "Epoch 678: 100%|██████████| 1/1 [00:00<00:00, 34.57it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0511]\n",
      "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0511]        \n",
      "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0511]        \n",
      "Epoch 683: 100%|██████████| 1/1 [00:00<00:00, 28.92it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0511]\n",
      "Epoch 685: 100%|██████████| 1/1 [00:00<00:00, 31.67it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0511]\n",
      "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0511]        \n",
      "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0511]        \n",
      "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0511]        \n",
      "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0511]        \n",
      "Epoch 694: 100%|██████████| 1/1 [00:00<00:00, 17.17it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0511]\n",
      "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0511]        \n",
      "Epoch 696: 100%|██████████| 1/1 [00:00<00:00, 32.21it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.0511]\n",
      "Epoch 698: 100%|██████████| 1/1 [00:00<00:00, 29.77it/s, v_num=0, train_loss_step=0.474, train_loss_epoch=0.474, valid_loss=0.0511]\n",
      "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 19.84it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.473, valid_loss=0.0511]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 41.13it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=4094)\u001b[0m \n",
      "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=0.0356]        \n",
      "Epoch 701: 100%|██████████| 1/1 [00:00<00:00, 30.37it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=0.0356]\n",
      "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.468, valid_loss=0.0356]        \n",
      "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=0.0356]        \n",
      "Epoch 706: 100%|██████████| 1/1 [00:00<00:00, 17.88it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0356]\n",
      "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0356]        \n",
      "Epoch 708: 100%|██████████| 1/1 [00:00<00:00, 28.67it/s, v_num=0, train_loss_step=0.474, train_loss_epoch=0.474, valid_loss=0.0356]\n",
      "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0356]        \n",
      "Epoch 710: 100%|██████████| 1/1 [00:00<00:00, 28.46it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0356]\n",
      "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0356]        \n",
      "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.468, valid_loss=0.0356]        \n",
      "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=0.0356]        \n",
      "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.0356]        \n",
      "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.458, train_loss_epoch=0.458, valid_loss=0.0356]        \n",
      "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.454, train_loss_epoch=0.454, valid_loss=0.0356]        \n",
      "Epoch 722: 100%|██████████| 1/1 [00:00<00:00, 27.42it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455, valid_loss=0.0356]\n",
      "Epoch 724:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.451, train_loss_epoch=0.451, valid_loss=0.0356]        \n",
      "Epoch 724: 100%|██████████| 1/1 [00:00<00:00, 33.32it/s, v_num=0, train_loss_step=0.451, train_loss_epoch=0.451, valid_loss=0.0356]\n",
      "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.446, train_loss_epoch=0.446, valid_loss=0.0356]        \n",
      "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.442, train_loss_epoch=0.442, valid_loss=0.0356]        \n",
      "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.440, train_loss_epoch=0.440, valid_loss=0.0356]        \n",
      "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.442, train_loss_epoch=0.442, valid_loss=0.0356]        \n",
      "Epoch 733: 100%|██████████| 1/1 [00:00<00:00, 30.30it/s, v_num=0, train_loss_step=0.435, train_loss_epoch=0.435, valid_loss=0.0356]\n",
      "Epoch 735: 100%|██████████| 1/1 [00:00<00:00, 31.53it/s, v_num=0, train_loss_step=0.432, train_loss_epoch=0.432, valid_loss=0.0356]\n",
      "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.433, train_loss_epoch=0.433, valid_loss=0.0356]        \n",
      "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.434, train_loss_epoch=0.434, valid_loss=0.0356]        \n",
      "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.434, train_loss_epoch=0.434, valid_loss=0.0356]\n",
      "Epoch 740: 100%|██████████| 1/1 [00:00<00:00, 30.28it/s, v_num=0, train_loss_step=0.436, train_loss_epoch=0.436, valid_loss=0.0356]\n",
      "Epoch 740: 100%|██████████| 1/1 [00:00<00:00, 18.54it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.448, valid_loss=0.0356]\n",
      "Epoch 742: 100%|██████████| 1/1 [00:00<00:00, 32.31it/s, v_num=0, train_loss_step=0.440, train_loss_epoch=0.440, valid_loss=0.0356]\n",
      "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0356]        \n",
      "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0356]        \n",
      "Epoch 747: 100%|██████████| 1/1 [00:00<00:00, 18.94it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0356]\n",
      "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0356]        \n",
      "Epoch 749: 100%|██████████| 1/1 [00:00<00:00, 19.22it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0356]\n",
      "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0356]        \n",
      "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0356]        \n",
      "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0356]        \n",
      "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0356]        \n",
      "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.0356]        \n",
      "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.474, train_loss_epoch=0.474, valid_loss=0.0356]        \n",
      "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473, valid_loss=0.0356]        \n",
      "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=0.0356]        \n",
      "Epoch 766:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.0356]        \n",
      "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=0.0356]        \n",
      "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.465, valid_loss=0.0356]        \n",
      "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.0356]        \n",
      "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=0.0356]        \n",
      "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.459, train_loss_epoch=0.459, valid_loss=0.0356]        \n",
      "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.458, train_loss_epoch=0.458, valid_loss=0.0356]        \n",
      "Epoch 779: 100%|██████████| 1/1 [00:00<00:00, 28.12it/s, v_num=0, train_loss_step=0.457, train_loss_epoch=0.457, valid_loss=0.0356]\n",
      "Epoch 779: 100%|██████████| 1/1 [00:00<00:00, 18.16it/s, v_num=0, train_loss_step=0.456, train_loss_epoch=0.457, valid_loss=0.0356]\n",
      "Epoch 779: 100%|██████████| 1/1 [00:00<00:00, 17.04it/s, v_num=0, train_loss_step=0.456, train_loss_epoch=0.456, valid_loss=0.0356]\n",
      "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.456, train_loss_epoch=0.456, valid_loss=0.0356]        \n",
      "Epoch 781:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.454, train_loss_epoch=0.454, valid_loss=0.0356]        \n",
      "Epoch 781: 100%|██████████| 1/1 [00:00<00:00, 21.33it/s, v_num=0, train_loss_step=0.454, train_loss_epoch=0.454, valid_loss=0.0356]\n",
      "Epoch 783: 100%|██████████| 1/1 [00:00<00:00, 33.53it/s, v_num=0, train_loss_step=0.459, train_loss_epoch=0.459, valid_loss=0.0356]\n",
      "Epoch 785: 100%|██████████| 1/1 [00:00<00:00, 42.15it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=0.0356]\n",
      "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0356]        \n",
      "Epoch 787: 100%|██████████| 1/1 [00:00<00:00, 27.32it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0356]\n",
      "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0356]        \n",
      "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0356]        \n",
      "Epoch 792: 100%|██████████| 1/1 [00:00<00:00, 20.32it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0356]\n",
      "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0356]        \n",
      "Epoch 794: 100%|██████████| 1/1 [00:00<00:00, 31.08it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0356]\n",
      "Epoch 794: 100%|██████████| 1/1 [00:00<00:00, 18.99it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.489, valid_loss=0.0356]\n",
      "Epoch 794: 100%|██████████| 1/1 [00:00<00:00, 18.35it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0356]\n",
      "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0356]        \n",
      "Epoch 796: 100%|██████████| 1/1 [00:00<00:00, 19.52it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0356]\n",
      "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0356]        \n",
      "Epoch 798: 100%|██████████| 1/1 [00:00<00:00, 30.59it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0356]\n",
      "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 18.95it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.479, valid_loss=0.0356]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 45.66it/s]\u001b[A\n",
      "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 11.10it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0375]\n",
      "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0375]        \n",
      "Epoch 801: 100%|██████████| 1/1 [00:00<00:00, 20.28it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473, valid_loss=0.0375]\n",
      "Epoch 803: 100%|██████████| 1/1 [00:00<00:00, 33.64it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473, valid_loss=0.0375]\n",
      "Epoch 803: 100%|██████████| 1/1 [00:00<00:00, 19.68it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.473, valid_loss=0.0375]\n",
      "Epoch 803: 100%|██████████| 1/1 [00:00<00:00, 19.12it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.0375]\n",
      "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.0375]        \n",
      "Epoch 805: 100%|██████████| 1/1 [00:00<00:00, 26.91it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471, valid_loss=0.0375]\n",
      "Epoch 807: 100%|██████████| 1/1 [00:00<00:00, 30.33it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.0375]\n",
      "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=0.0375]        \n",
      "Epoch 811:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.0375]        \n",
      "Epoch 813:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=0.0375]        \n",
      "Epoch 814: 100%|██████████| 1/1 [00:00<00:00, 20.55it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=0.0375]\n",
      "Epoch 815:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=0.0375]        \n",
      "Epoch 816: 100%|██████████| 1/1 [00:00<00:00, 28.22it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=0.0375]\n",
      "Epoch 818: 100%|██████████| 1/1 [00:00<00:00, 35.53it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=0.0375]\n",
      "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.458, train_loss_epoch=0.458, valid_loss=0.0375]        \n",
      "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455, valid_loss=0.0375]        \n",
      "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.449, train_loss_epoch=0.449, valid_loss=0.0375]        \n",
      "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.448, valid_loss=0.0375]        \n",
      "Epoch 827: 100%|██████████| 1/1 [00:00<00:00, 29.24it/s, v_num=0, train_loss_step=0.446, train_loss_epoch=0.446, valid_loss=0.0375]\n",
      "Epoch 829: 100%|██████████| 1/1 [00:00<00:00, 31.70it/s, v_num=0, train_loss_step=0.438, train_loss_epoch=0.438, valid_loss=0.0375]\n",
      "Epoch 831:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0375]        \n",
      "Epoch 833:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0375]        \n",
      "Epoch 833: 100%|██████████| 1/1 [00:00<00:00, 38.21it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0375]\n",
      "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0375]        \n",
      "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0375]        \n",
      "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0375]        \n",
      "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0375]        \n",
      "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0375]        \n",
      "Epoch 844: 100%|██████████| 1/1 [00:00<00:00, 20.59it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0375]\n",
      "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0375]        \n",
      "Epoch 846: 100%|██████████| 1/1 [00:00<00:00, 28.13it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0375]\n",
      "Epoch 848: 100%|██████████| 1/1 [00:00<00:00, 30.95it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0375]\n",
      "Epoch 850:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.474, train_loss_epoch=0.474, valid_loss=0.0375]        \n",
      "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0375]        \n",
      "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.461, train_loss_epoch=0.461, valid_loss=0.0375]        \n",
      "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.461, train_loss_epoch=0.461, valid_loss=0.0375]        \n",
      "Epoch 857: 100%|██████████| 1/1 [00:00<00:00, 19.39it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473, valid_loss=0.0375]\n",
      "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473, valid_loss=0.0375]        \n",
      "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473, valid_loss=0.0375]\n",
      "Epoch 859: 100%|██████████| 1/1 [00:00<00:00, 20.48it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=0.0375]\n",
      "Epoch 860:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=0.0375]        \n",
      "Epoch 861: 100%|██████████| 1/1 [00:00<00:00, 27.94it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.465, valid_loss=0.0375]\n",
      "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.0375]        \n",
      "Epoch 865:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=0.0375]        \n",
      "Epoch 866: 100%|██████████| 1/1 [00:00<00:00, 19.36it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.461, valid_loss=0.0375]\n",
      "Epoch 866: 100%|██████████| 1/1 [00:00<00:00, 18.63it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=0.0375]\n",
      "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=0.0375]        \n",
      "Epoch 868: 100%|██████████| 1/1 [00:00<00:00, 27.46it/s, v_num=0, train_loss_step=0.459, train_loss_epoch=0.459, valid_loss=0.0375]\n",
      "Epoch 870: 100%|██████████| 1/1 [00:00<00:00, 39.34it/s, v_num=0, train_loss_step=0.458, train_loss_epoch=0.458, valid_loss=0.0375]\n",
      "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455, valid_loss=0.0375]        \n",
      "Epoch 874:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.453, train_loss_epoch=0.453, valid_loss=0.0375]        \n",
      "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0375]        \n",
      "Epoch 877: 100%|██████████| 1/1 [00:00<00:00, 17.05it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.499, valid_loss=0.0375]\n",
      "Epoch 877: 100%|██████████| 1/1 [00:00<00:00, 15.84it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0375]\n",
      "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0375]        \n",
      "Epoch 879: 100%|██████████| 1/1 [00:00<00:00, 36.63it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0375]\n",
      "Epoch 879: 100%|██████████| 1/1 [00:00<00:00, 20.37it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.515, valid_loss=0.0375]\n",
      "Epoch 879: 100%|██████████| 1/1 [00:00<00:00, 19.60it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0375]\n",
      "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0375]        \n",
      "Epoch 881: 100%|██████████| 1/1 [00:00<00:00, 42.28it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0375]\n",
      "Epoch 883: 100%|██████████| 1/1 [00:00<00:00, 26.56it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0375]\n",
      "Epoch 885: 100%|██████████| 1/1 [00:00<00:00, 37.30it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0375]\n",
      "Epoch 887: 100%|██████████| 1/1 [00:00<00:00, 33.32it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0375]\n",
      "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=0.0375]        \n",
      "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=0.0375]        \n",
      "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.468, valid_loss=0.0375]        \n",
      "Epoch 894: 100%|██████████| 1/1 [00:00<00:00, 33.51it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=0.0375]\n",
      "Epoch 894: 100%|██████████| 1/1 [00:00<00:00, 18.65it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.0375]\n",
      "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.0375]        \n",
      "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.0375]\n",
      "Epoch 896: 100%|██████████| 1/1 [00:00<00:00, 19.43it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.474, valid_loss=0.0375]\n",
      "Epoch 896: 100%|██████████| 1/1 [00:00<00:00, 18.75it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=0.0375]\n",
      "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=0.0375]        \n",
      "Epoch 898: 100%|██████████| 1/1 [00:00<00:00, 28.13it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.465, valid_loss=0.0375]\n",
      "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 19.73it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.461, valid_loss=0.0375]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 50.92it/s]\u001b[A\n",
      "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=0.041]         \n",
      "Epoch 902:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.461, train_loss_epoch=0.461, valid_loss=0.041]        \n",
      "Epoch 904:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.457, train_loss_epoch=0.457, valid_loss=0.041]        \n",
      "Epoch 905: 100%|██████████| 1/1 [00:00<00:00, 33.67it/s, v_num=0, train_loss_step=0.457, train_loss_epoch=0.457, valid_loss=0.041]\n",
      "Epoch 907: 100%|██████████| 1/1 [00:00<00:00, 38.18it/s, v_num=0, train_loss_step=0.456, train_loss_epoch=0.456, valid_loss=0.041]\n",
      "Epoch 909:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452, valid_loss=0.041]        \n",
      "Epoch 909: 100%|██████████| 1/1 [00:00<00:00, 28.22it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452, valid_loss=0.041]\n",
      "Epoch 911:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.450, train_loss_epoch=0.450, valid_loss=0.041]        \n",
      "Epoch 913:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.448, valid_loss=0.041]        \n",
      "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.446, train_loss_epoch=0.446, valid_loss=0.041]        \n",
      "Epoch 917:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=0.041]        \n",
      "Epoch 918: 100%|██████████| 1/1 [00:00<00:00, 35.55it/s, v_num=0, train_loss_step=0.444, train_loss_epoch=0.444, valid_loss=0.041]\n",
      "Epoch 918: 100%|██████████| 1/1 [00:00<00:00, 19.18it/s, v_num=0, train_loss_step=0.442, train_loss_epoch=0.442, valid_loss=0.041]\n",
      "Epoch 919:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.442, train_loss_epoch=0.442, valid_loss=0.041]        \n",
      "Epoch 920: 100%|██████████| 1/1 [00:00<00:00, 29.41it/s, v_num=0, train_loss_step=0.440, train_loss_epoch=0.440, valid_loss=0.041]\n",
      "Epoch 922: 100%|██████████| 1/1 [00:00<00:00, 38.60it/s, v_num=0, train_loss_step=0.439, train_loss_epoch=0.439, valid_loss=0.041]\n",
      "Epoch 924: 100%|██████████| 1/1 [00:00<00:00, 34.94it/s, v_num=0, train_loss_step=0.437, train_loss_epoch=0.437, valid_loss=0.041]\n",
      "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.435, train_loss_epoch=0.435, valid_loss=0.041]        \n",
      "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.433, train_loss_epoch=0.433, valid_loss=0.041]        \n",
      "Epoch 930:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.431, train_loss_epoch=0.431, valid_loss=0.041]        \n",
      "Epoch 931: 100%|██████████| 1/1 [00:00<00:00, 27.87it/s, v_num=0, train_loss_step=0.431, train_loss_epoch=0.431, valid_loss=0.041]\n",
      "Epoch 931: 100%|██████████| 1/1 [00:00<00:00, 17.85it/s, v_num=0, train_loss_step=0.435, train_loss_epoch=0.431, valid_loss=0.041]\n",
      "Epoch 931: 100%|██████████| 1/1 [00:00<00:00, 16.86it/s, v_num=0, train_loss_step=0.435, train_loss_epoch=0.435, valid_loss=0.041]\n",
      "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.435, train_loss_epoch=0.435, valid_loss=0.041]        \n",
      "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.432, train_loss_epoch=0.432, valid_loss=0.041]        \n",
      "Epoch 935: 100%|██████████| 1/1 [00:00<00:00, 28.67it/s, v_num=0, train_loss_step=0.430, train_loss_epoch=0.430, valid_loss=0.041]\n",
      "Epoch 937: 100%|██████████| 1/1 [00:00<00:00, 30.63it/s, v_num=0, train_loss_step=0.450, train_loss_epoch=0.450, valid_loss=0.041]\n",
      "Epoch 939:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.432, train_loss_epoch=0.432, valid_loss=0.041]        \n",
      "Epoch 941:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.432, train_loss_epoch=0.432, valid_loss=0.041]        \n",
      "Epoch 942: 100%|██████████| 1/1 [00:00<00:00, 26.87it/s, v_num=0, train_loss_step=0.432, train_loss_epoch=0.432, valid_loss=0.041]\n",
      "Epoch 942: 100%|██████████| 1/1 [00:00<00:00, 17.59it/s, v_num=0, train_loss_step=0.434, train_loss_epoch=0.432, valid_loss=0.041]\n",
      "Epoch 942: 100%|██████████| 1/1 [00:00<00:00, 16.69it/s, v_num=0, train_loss_step=0.434, train_loss_epoch=0.434, valid_loss=0.041]\n",
      "Epoch 944: 100%|██████████| 1/1 [00:00<00:00, 33.83it/s, v_num=0, train_loss_step=0.432, train_loss_epoch=0.432, valid_loss=0.041]\n",
      "Epoch 946: 100%|██████████| 1/1 [00:00<00:00, 27.70it/s, v_num=0, train_loss_step=0.433, train_loss_epoch=0.433, valid_loss=0.041]\n",
      "Epoch 948: 100%|██████████| 1/1 [00:00<00:00, 39.78it/s, v_num=0, train_loss_step=0.459, train_loss_epoch=0.459, valid_loss=0.041]\n",
      "Epoch 950:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.041]        \n",
      "Epoch 952:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.041]        \n",
      "Epoch 953: 100%|██████████| 1/1 [00:00<00:00, 17.30it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.041]\n",
      "Epoch 954:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.041]        \n",
      "Epoch 955: 100%|██████████| 1/1 [00:00<00:00, 19.59it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.041]\n",
      "Epoch 957: 100%|██████████| 1/1 [00:00<00:00, 28.16it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.041]\n",
      "Epoch 959: 100%|██████████| 1/1 [00:00<00:00, 36.97it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.041]\n",
      "Epoch 961:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.041]        \n",
      "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.041]        \n",
      "Epoch 965:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.041]        \n",
      "Epoch 967:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.041]        \n",
      "Epoch 968: 100%|██████████| 1/1 [00:00<00:00, 28.40it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.041]\n",
      "Epoch 970: 100%|██████████| 1/1 [00:00<00:00, 35.16it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.041]\n",
      "Epoch 972:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.041]        \n",
      "Epoch 974:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.041]        \n",
      "Epoch 975: 100%|██████████| 1/1 [00:00<00:00, 29.52it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.041]\n",
      "Epoch 975: 100%|██████████| 1/1 [00:00<00:00, 17.14it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.041]\n",
      "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.041]        \n",
      "Epoch 976:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.041]\n",
      "Epoch 977: 100%|██████████| 1/1 [00:00<00:00, 19.59it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.041]\n",
      "Epoch 978:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.041]        \n",
      "Epoch 979: 100%|██████████| 1/1 [00:00<00:00, 20.34it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.481, valid_loss=0.041]\n",
      "Epoch 979: 100%|██████████| 1/1 [00:00<00:00, 19.86it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.041]\n",
      "Epoch 980:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.041]        \n",
      "Epoch 981: 100%|██████████| 1/1 [00:00<00:00, 34.04it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.041]\n",
      "Epoch 983: 100%|██████████| 1/1 [00:00<00:00, 26.62it/s, v_num=0, train_loss_step=0.475, train_loss_epoch=0.475, valid_loss=0.041]\n",
      "Epoch 984: 100%|██████████| 1/1 [00:00<00:00, 11.56it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=0.041]\n",
      "Epoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=0.041]        \n",
      "Epoch 986: 100%|██████████| 1/1 [00:00<00:00, 34.78it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.468, valid_loss=0.041]\n",
      "Epoch 988: 100%|██████████| 1/1 [00:00<00:00, 32.11it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.465, valid_loss=0.041]\n",
      "Epoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.041]        \n",
      "Epoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.468, valid_loss=0.041]        \n",
      "Epoch 993: 100%|██████████| 1/1 [00:00<00:00, 17.89it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.041]\n",
      "Epoch 995: 100%|██████████| 1/1 [00:00<00:00, 36.79it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.041]\n",
      "Epoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.041]        \n",
      "Epoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.041]        \n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 20.03it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.534, valid_loss=0.041]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 42.52it/s]\u001b[A\n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 10.35it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0389]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=4094)\u001b[0m `Trainer.fit` stopped: `max_steps=1000` reached.\n",
      "\u001b[36m(_train_tune pid=4346)\u001b[0m /home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=4346)\u001b[0m Seed set to 7\n",
      "\u001b[36m(_train_tune pid=4346)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=4346)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=4346)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=4346)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(_train_tune pid=4346)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_train_tune pid=4346)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=4346)\u001b[0m   | Name            | Type          | Params | Mode \n",
      "\u001b[36m(_train_tune pid=4346)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=4346)\u001b[0m 0 | loss            | WMAPE         | 0      | train\n",
      "\u001b[36m(_train_tune pid=4346)\u001b[0m 1 | padder          | ConstantPad1d | 0      | train\n",
      "\u001b[36m(_train_tune pid=4346)\u001b[0m 2 | scaler          | TemporalNorm  | 0      | train\n",
      "\u001b[36m(_train_tune pid=4346)\u001b[0m 3 | hist_encoder    | LSTM          | 122 K  | train\n",
      "\u001b[36m(_train_tune pid=4346)\u001b[0m 4 | context_adapter | Linear        | 38.9 K | train\n",
      "\u001b[36m(_train_tune pid=4346)\u001b[0m 5 | mlp_decoder     | MLP           | 449    | train\n",
      "\u001b[36m(_train_tune pid=4346)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=4346)\u001b[0m 161 K     Trainable params\n",
      "\u001b[36m(_train_tune pid=4346)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=4346)\u001b[0m 161 K     Total params\n",
      "\u001b[36m(_train_tune pid=4346)\u001b[0m 0.645     Total estimated model params size (MB)\n",
      "\u001b[36m(_train_tune pid=4346)\u001b[0m 11        Modules in train mode\n",
      "\u001b[36m(_train_tune pid=4346)\u001b[0m 0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994]        \n",
      "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.832, train_loss_epoch=0.832]        \n",
      "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.757, train_loss_epoch=0.757]        \n",
      "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.677, train_loss_epoch=0.677]        \n",
      "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.645, train_loss_epoch=0.645]        \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 65.66it/s, v_num=0, train_loss_step=0.578, train_loss_epoch=0.578]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 46.81it/s, v_num=0, train_loss_step=0.691, train_loss_epoch=0.691]\n",
      "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.691, train_loss_epoch=0.691]        \n",
      "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.670, train_loss_epoch=0.670]        \n",
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00, 65.64it/s, v_num=0, train_loss_step=0.670, train_loss_epoch=0.670]\n",
      "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.595, train_loss_epoch=0.595]        \n",
      "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.674, train_loss_epoch=0.674]        \n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00, 67.58it/s, v_num=0, train_loss_step=0.720, train_loss_epoch=0.720]\n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00, 47.11it/s, v_num=0, train_loss_step=0.621, train_loss_epoch=0.621]\n",
      "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.621, train_loss_epoch=0.621]        \n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00, 68.95it/s, v_num=0, train_loss_step=0.696, train_loss_epoch=0.696]\n",
      "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550]        \n",
      "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.602, train_loss_epoch=0.602]        \n",
      "Epoch 52: 100%|██████████| 1/1 [00:00<00:00, 41.31it/s, v_num=0, train_loss_step=0.602, train_loss_epoch=0.602]\n",
      "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562]        \n",
      "Epoch 60: 100%|██████████| 1/1 [00:00<00:00, 61.53it/s, v_num=0, train_loss_step=0.664, train_loss_epoch=0.664]\n",
      "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557]        \n",
      "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.683, train_loss_epoch=0.683]        \n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00, 59.40it/s, v_num=0, train_loss_step=0.635, train_loss_epoch=0.635]\n",
      "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.669, train_loss_epoch=0.669]        \n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00, 74.67it/s, v_num=0, train_loss_step=0.661, train_loss_epoch=0.661]\n",
      "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.649, train_loss_epoch=0.649]        \n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00, 49.23it/s, v_num=0, train_loss_step=0.708, train_loss_epoch=0.708]\n",
      "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.708, train_loss_epoch=0.708]        \n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00, 72.27it/s, v_num=0, train_loss_step=0.602, train_loss_epoch=0.602]\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 50.51it/s, v_num=0, train_loss_step=0.617, train_loss_epoch=0.591]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 73.02it/s]\u001b[A\n",
      "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.603, train_loss_epoch=0.603, valid_loss=0.0715]        \n",
      "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.685, train_loss_epoch=0.685, valid_loss=0.0715]        \n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00, 69.50it/s, v_num=0, train_loss_step=0.680, train_loss_epoch=0.680, valid_loss=0.0715]\n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00, 50.77it/s, v_num=0, train_loss_step=0.688, train_loss_epoch=0.680, valid_loss=0.0715]\n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00, 49.11it/s, v_num=0, train_loss_step=0.688, train_loss_epoch=0.688, valid_loss=0.0715]\n",
      "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.688, train_loss_epoch=0.688, valid_loss=0.0715]        \n",
      "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.674, train_loss_epoch=0.674, valid_loss=0.0715]        \n",
      "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.688, train_loss_epoch=0.688, valid_loss=0.0715]        \n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00, 73.59it/s, v_num=0, train_loss_step=0.615, train_loss_epoch=0.615, valid_loss=0.0715]\n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00, 49.93it/s, v_num=0, train_loss_step=0.596, train_loss_epoch=0.596, valid_loss=0.0715]\n",
      "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.596, train_loss_epoch=0.596, valid_loss=0.0715]        \n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00, 73.47it/s, v_num=0, train_loss_step=0.627, train_loss_epoch=0.627, valid_loss=0.0715]\n",
      "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.637, train_loss_epoch=0.637, valid_loss=0.0715]        \n",
      "Epoch 138: 100%|██████████| 1/1 [00:00<00:00, 49.79it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563, valid_loss=0.0715]\n",
      "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563, valid_loss=0.0715]        \n",
      "Epoch 143: 100%|██████████| 1/1 [00:00<00:00, 72.88it/s, v_num=0, train_loss_step=0.663, train_loss_epoch=0.663, valid_loss=0.0715]\n",
      "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.666, train_loss_epoch=0.666, valid_loss=0.0715]        \n",
      "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.633, train_loss_epoch=0.633, valid_loss=0.0715]        \n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00, 73.81it/s, v_num=0, train_loss_step=0.603, train_loss_epoch=0.603, valid_loss=0.0715]\n",
      "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.696, train_loss_epoch=0.696, valid_loss=0.0715]        \n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00, 63.27it/s, v_num=0, train_loss_step=0.659, train_loss_epoch=0.659, valid_loss=0.0715]\n",
      "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0715]        \n",
      "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.669, train_loss_epoch=0.669, valid_loss=0.0715]        \n",
      "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.672, train_loss_epoch=0.672, valid_loss=0.0715]        \n",
      "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.606, train_loss_epoch=0.606, valid_loss=0.0715]        \n",
      "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.666, train_loss_epoch=0.666, valid_loss=0.0715]        \n",
      "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.580, train_loss_epoch=0.580, valid_loss=0.0715]        \n",
      "Epoch 191: 100%|██████████| 1/1 [00:00<00:00, 69.90it/s, v_num=0, train_loss_step=0.580, train_loss_epoch=0.580, valid_loss=0.0715]\n",
      "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.614, train_loss_epoch=0.614, valid_loss=0.0715]        \n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 46.26it/s, v_num=0, train_loss_step=0.615, train_loss_epoch=0.695, valid_loss=0.0715]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 77.51it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=4346)\u001b[0m \n",
      "                                                                      \u001b[A\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 22.99it/s, v_num=0, train_loss_step=0.615, train_loss_epoch=0.615, valid_loss=0.0317]\n",
      "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.615, train_loss_epoch=0.615, valid_loss=0.0317]        \n",
      "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.577, train_loss_epoch=0.577, valid_loss=0.0317]        \n",
      "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.652, train_loss_epoch=0.652, valid_loss=0.0317]        \n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00, 69.90it/s, v_num=0, train_loss_step=0.652, train_loss_epoch=0.652, valid_loss=0.0317]\n",
      "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.0317]        \n",
      "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.603, train_loss_epoch=0.603, valid_loss=0.0317]        \n",
      "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.608, train_loss_epoch=0.608, valid_loss=0.0317]        \n",
      "Epoch 223: 100%|██████████| 1/1 [00:00<00:00, 60.54it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0317]\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00, 56.18it/s, v_num=0, train_loss_step=0.645, train_loss_epoch=0.645, valid_loss=0.0317]\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00, 44.90it/s, v_num=0, train_loss_step=0.625, train_loss_epoch=0.645, valid_loss=0.0317]\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00, 41.99it/s, v_num=0, train_loss_step=0.625, train_loss_epoch=0.625, valid_loss=0.0317]\n",
      "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.625, train_loss_epoch=0.625, valid_loss=0.0317]        \n",
      "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.635, train_loss_epoch=0.635, valid_loss=0.0317]        \n",
      "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.618, train_loss_epoch=0.618, valid_loss=0.0317]        \n",
      "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.630, train_loss_epoch=0.630, valid_loss=0.0317]        \n",
      "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.610, train_loss_epoch=0.610, valid_loss=0.0317]        \n",
      "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.584, train_loss_epoch=0.584, valid_loss=0.0317]        \n",
      "Epoch 250: 100%|██████████| 1/1 [00:00<00:00, 22.30it/s, v_num=0, train_loss_step=0.601, train_loss_epoch=0.601, valid_loss=0.0317]\n",
      "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.601, train_loss_epoch=0.601, valid_loss=0.0317]        \n",
      "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.593, train_loss_epoch=0.593, valid_loss=0.0317]        \n",
      "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=0.0317]        \n",
      "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.875, train_loss_epoch=0.875, valid_loss=0.0317]        \n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00, 48.93it/s, v_num=0, train_loss_step=0.769, train_loss_epoch=0.767, valid_loss=0.0317]\n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00, 45.70it/s, v_num=0, train_loss_step=0.769, train_loss_epoch=0.769, valid_loss=0.0317]\n",
      "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.769, train_loss_epoch=0.769, valid_loss=0.0317]        \n",
      "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.769, train_loss_epoch=0.769, valid_loss=0.0317]\n",
      "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.701, train_loss_epoch=0.701, valid_loss=0.0317]        \n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00, 46.32it/s, v_num=0, train_loss_step=0.684, train_loss_epoch=0.684, valid_loss=0.0317]\n",
      "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.684, train_loss_epoch=0.684, valid_loss=0.0317]        \n",
      "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.618, train_loss_epoch=0.618, valid_loss=0.0317]        \n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00, 67.84it/s, v_num=0, train_loss_step=0.618, train_loss_epoch=0.618, valid_loss=0.0317]\n",
      "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.596, train_loss_epoch=0.596, valid_loss=0.0317]        \n",
      "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.665, train_loss_epoch=0.665, valid_loss=0.0317]        \n",
      "Epoch 294: 100%|██████████| 1/1 [00:00<00:00, 44.62it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.698, valid_loss=0.0317]\n",
      "Epoch 294: 100%|██████████| 1/1 [00:00<00:00, 42.29it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.572, valid_loss=0.0317]\n",
      "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.572, valid_loss=0.0317]        \n",
      "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.572, valid_loss=0.0317]\n",
      "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.610, train_loss_epoch=0.610, valid_loss=0.0317]        \n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 51.28it/s, v_num=0, train_loss_step=0.674, train_loss_epoch=0.610, valid_loss=0.0317]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 75.32it/s]\u001b[A\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00, 65.06it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0415]\n",
      "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.731, train_loss_epoch=0.731, valid_loss=0.0415]        \n",
      "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.680, train_loss_epoch=0.680, valid_loss=0.0415]        \n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00, 68.40it/s, v_num=0, train_loss_step=0.648, train_loss_epoch=0.648, valid_loss=0.0415]\n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00, 47.66it/s, v_num=0, train_loss_step=0.655, train_loss_epoch=0.655, valid_loss=0.0415]\n",
      "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.655, train_loss_epoch=0.655, valid_loss=0.0415]        \n",
      "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.623, train_loss_epoch=0.623, valid_loss=0.0415]        \n",
      "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568, valid_loss=0.0415]        \n",
      "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.656, train_loss_epoch=0.656, valid_loss=0.0415]        \n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00, 64.49it/s, v_num=0, train_loss_step=0.655, train_loss_epoch=0.655, valid_loss=0.0415]\n",
      "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.676, train_loss_epoch=0.676, valid_loss=0.0415]        \n",
      "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.608, train_loss_epoch=0.608, valid_loss=0.0415]        \n",
      "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562, valid_loss=0.0415]        \n",
      "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=0.0415]        \n",
      "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.614, train_loss_epoch=0.614, valid_loss=0.0415]        \n",
      "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0415]        \n",
      "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.651, train_loss_epoch=0.651, valid_loss=0.0415]        \n",
      "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.642, train_loss_epoch=0.642, valid_loss=0.0415]        \n",
      "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.640, train_loss_epoch=0.640, valid_loss=0.0415]        \n",
      "Epoch 371: 100%|██████████| 1/1 [00:00<00:00, 53.85it/s, v_num=0, train_loss_step=0.590, train_loss_epoch=0.590, valid_loss=0.0415]\n",
      "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.618, train_loss_epoch=0.618, valid_loss=0.0415]        \n",
      "Epoch 377: 100%|██████████| 1/1 [00:00<00:00, 31.65it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565, valid_loss=0.0415]\n",
      "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565, valid_loss=0.0415]        \n",
      "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0415]        \n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00, 33.91it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.494, valid_loss=0.0415]\n",
      "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.0415]        \n",
      "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.0415]\n",
      "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.585, train_loss_epoch=0.585, valid_loss=0.0415]        \n",
      "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.597, train_loss_epoch=0.597, valid_loss=0.0415]        \n",
      "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0415]        \n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 41.25it/s, v_num=0, train_loss_step=0.613, train_loss_epoch=0.466, valid_loss=0.0415]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 71.18it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=4346)\u001b[0m \n",
      "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.592, train_loss_epoch=0.592, valid_loss=0.0309]        \n",
      "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.461, train_loss_epoch=0.461, valid_loss=0.0309]        \n",
      "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.599, train_loss_epoch=0.599, valid_loss=0.0309]        \n",
      "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473, valid_loss=0.0309]        \n",
      "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0309]        \n",
      "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0309]        \n",
      "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0309]        \n",
      "Epoch 431: 100%|██████████| 1/1 [00:00<00:00, 60.54it/s, v_num=0, train_loss_step=0.614, train_loss_epoch=0.614, valid_loss=0.0309]\n",
      "Epoch 431: 100%|██████████| 1/1 [00:00<00:00, 45.96it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574, valid_loss=0.0309]\n",
      "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574, valid_loss=0.0309]        \n",
      "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0309]        \n",
      "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455, valid_loss=0.0309]        \n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00, 35.35it/s, v_num=0, train_loss_step=0.594, train_loss_epoch=0.594, valid_loss=0.0309]\n",
      "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.594, train_loss_epoch=0.594, valid_loss=0.0309]        \n",
      "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0309]        \n",
      "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0309]        \n",
      "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.448, valid_loss=0.0309]        \n",
      "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0309]        \n",
      "Epoch 458: 100%|██████████| 1/1 [00:00<00:00, 45.17it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0309]\n",
      "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.426, train_loss_epoch=0.426, valid_loss=0.0309]        \n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00, 31.77it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0309]\n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00, 23.64it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.548, valid_loss=0.0309]\n",
      "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0309]        \n",
      "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0309]\n",
      "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=0.0309]        \n",
      "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.418, train_loss_epoch=0.418, valid_loss=0.0309]        \n",
      "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.424, train_loss_epoch=0.424, valid_loss=0.0309]        \n",
      "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0309]        \n",
      "Epoch 474: 100%|██████████| 1/1 [00:00<00:00, 32.66it/s, v_num=0, train_loss_step=0.387, train_loss_epoch=0.387, valid_loss=0.0309]\n",
      "Epoch 476: 100%|██████████| 1/1 [00:00<00:00, 31.50it/s, v_num=0, train_loss_step=0.385, train_loss_epoch=0.385, valid_loss=0.0309]\n",
      "Epoch 476: 100%|██████████| 1/1 [00:00<00:00, 21.54it/s, v_num=0, train_loss_step=0.384, train_loss_epoch=0.384, valid_loss=0.0309]\n",
      "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.375, train_loss_epoch=0.375, valid_loss=0.0309]        \n",
      "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.378, valid_loss=0.0309]        \n",
      "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.415, valid_loss=0.0309]        \n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00, 32.16it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.415, valid_loss=0.0309]\n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00, 23.63it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.507, valid_loss=0.0309]\n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00, 22.69it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0309]\n",
      "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0309]        \n",
      "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0309]        \n",
      "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0309]        \n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00, 28.57it/s, v_num=0, train_loss_step=0.423, train_loss_epoch=0.423, valid_loss=0.0309]\n",
      "Epoch 494: 100%|██████████| 1/1 [00:00<00:00, 35.08it/s, v_num=0, train_loss_step=0.398, train_loss_epoch=0.398, valid_loss=0.0309]\n",
      "Epoch 494: 100%|██████████| 1/1 [00:00<00:00, 23.17it/s, v_num=0, train_loss_step=0.447, train_loss_epoch=0.447, valid_loss=0.0309]\n",
      "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.421, train_loss_epoch=0.421, valid_loss=0.0309]        \n",
      "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.367, train_loss_epoch=0.367, valid_loss=0.0309]        \n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 21.94it/s, v_num=0, train_loss_step=0.447, train_loss_epoch=0.367, valid_loss=0.0309]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 34.46it/s]\u001b[A\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 10.31it/s, v_num=0, train_loss_step=0.447, train_loss_epoch=0.447, valid_loss=0.0396]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=4346)\u001b[0m `Trainer.fit` stopped: `max_steps=500` reached.\n",
      "\u001b[36m(_train_tune pid=4470)\u001b[0m /home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=4470)\u001b[0m Seed set to 7\n",
      "\u001b[36m(_train_tune pid=4470)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=4470)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=4470)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=4470)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(_train_tune pid=4470)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]\n",
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=4470)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=4470)\u001b[0m   | Name            | Type          | Params | Mode \n",
      "\u001b[36m(_train_tune pid=4470)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=4470)\u001b[0m 0 | loss            | WMAPE         | 0      | train\n",
      "\u001b[36m(_train_tune pid=4470)\u001b[0m 1 | padder          | ConstantPad1d | 0      | train\n",
      "\u001b[36m(_train_tune pid=4470)\u001b[0m 2 | scaler          | TemporalNorm  | 0      | train\n",
      "\u001b[36m(_train_tune pid=4470)\u001b[0m 3 | hist_encoder    | LSTM          | 1.8 M  | train\n",
      "\u001b[36m(_train_tune pid=4470)\u001b[0m 4 | context_adapter | Linear        | 231 K  | train\n",
      "\u001b[36m(_train_tune pid=4470)\u001b[0m 5 | mlp_decoder     | MLP           | 769    | train\n",
      "\u001b[36m(_train_tune pid=4470)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=4470)\u001b[0m 2.0 M     Trainable params\n",
      "\u001b[36m(_train_tune pid=4470)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=4470)\u001b[0m 2.0 M     Total params\n",
      "\u001b[36m(_train_tune pid=4470)\u001b[0m 8.164     Total estimated model params size (MB)\n",
      "\u001b[36m(_train_tune pid=4470)\u001b[0m 11        Modules in train mode\n",
      "\u001b[36m(_train_tune pid=4470)\u001b[0m 0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00,  4.20it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]\n",
      "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996]        \n",
      "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.924, train_loss_epoch=0.924]        \n",
      "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]        \n",
      "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.861, train_loss_epoch=0.861]        \n",
      "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.871, train_loss_epoch=0.871]        \n",
      "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.826, train_loss_epoch=0.826]        \n",
      "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.828, train_loss_epoch=0.828]        \n",
      "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.822, train_loss_epoch=0.822]        \n",
      "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.796, train_loss_epoch=0.796]       \n",
      "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.759, train_loss_epoch=0.759]        \n",
      "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.746, train_loss_epoch=0.746]        \n",
      "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.720, train_loss_epoch=0.720]        \n",
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.686, train_loss_epoch=0.686]        \n",
      "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.673, train_loss_epoch=0.673]        \n",
      "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.639, train_loss_epoch=0.639]        \n",
      "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.610, train_loss_epoch=0.610]        \n",
      "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.611, train_loss_epoch=0.611]        \n",
      "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.604, train_loss_epoch=0.604]        \n",
      "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.577, train_loss_epoch=0.577]        \n",
      "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.600, train_loss_epoch=0.600]        \n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00,  4.78it/s, v_num=0, train_loss_step=0.600, train_loss_epoch=0.600]\n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00,  4.64it/s, v_num=0, train_loss_step=0.575, train_loss_epoch=0.600]\n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00,  4.62it/s, v_num=0, train_loss_step=0.575, train_loss_epoch=0.575]\n",
      "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.575, train_loss_epoch=0.575]        \n",
      "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569]        \n",
      "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.572]        \n",
      "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563]        \n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00,  3.69it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563]\n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00,  3.59it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.563]\n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00,  3.58it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571]\n",
      "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571]        \n",
      "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560]        \n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00,  3.55it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560]\n",
      "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565]        \n",
      "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560]        \n",
      "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558]        \n",
      "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560]        \n",
      "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557]        \n",
      "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559]        \n",
      "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554]        \n",
      "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556]        \n",
      "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553]        \n",
      "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555]        \n",
      "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552]        \n",
      "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552]        \n",
      "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550]        \n",
      "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547]        \n",
      "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544]        \n",
      "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.576, train_loss_epoch=0.576]        \n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00,  3.27it/s, v_num=0, train_loss_step=0.576, train_loss_epoch=0.576]\n",
      "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548]        \n",
      "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547]        \n",
      "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543]        \n",
      "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540]        \n",
      "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564]        \n",
      "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541]        \n",
      "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545]        \n",
      "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539]        \n",
      "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538]        \n",
      "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533]        \n",
      "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523]        \n",
      "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532]        \n",
      "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540]        \n",
      "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552]        \n",
      "Epoch 57: 100%|██████████| 1/1 [00:00<00:00,  3.52it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542]\n",
      "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542]        \n",
      "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537]        \n",
      "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540]        \n",
      "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536]        \n",
      "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532]        \n",
      "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533]        \n",
      "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532]        \n",
      "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529]        \n",
      "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526]        \n",
      "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525]        \n",
      "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524]        \n",
      "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520]        \n",
      "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519]        \n",
      "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518]        \n",
      "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517]        \n",
      "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528]        \n",
      "Epoch 73: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528]\n",
      "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532]        \n",
      "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539]        \n",
      "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.583, train_loss_epoch=0.583]        \n",
      "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565]        \n",
      "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.577, train_loss_epoch=0.577]        \n",
      "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556]        \n",
      "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536]        \n",
      "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530]        \n",
      "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561]        \n",
      "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544]        \n",
      "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567]        \n",
      "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551]        \n",
      "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547]        \n",
      "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558]        \n",
      "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542]        \n",
      "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529]        \n",
      "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562]        \n",
      "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536]        \n",
      "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528]        \n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528]\n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00,  3.02it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.528]\n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518]\n",
      "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518]        \n",
      "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521]        \n",
      "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526]        \n",
      "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508]        \n",
      "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504]        \n",
      "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501]        \n",
      "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531]        \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  3.68it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.531]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=4470)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=4470)\u001b[0m \n",
      "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0719]       \n",
      "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.576, train_loss_epoch=0.576, valid_loss=0.0719]        \n",
      "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0719]        \n",
      "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=0.0719]        \n",
      "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0719]        \n",
      "Epoch 104: 100%|██████████| 1/1 [00:00<00:00,  3.59it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0719]\n",
      "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0719]        \n",
      "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0719]        \n",
      "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0719]        \n",
      "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0719]        \n",
      "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0719]        \n",
      "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0719]        \n",
      "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0719]        \n",
      "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0719]        \n",
      "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=0.0719]        \n",
      "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0719]        \n",
      "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0719]        \n",
      "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.0719]        \n",
      "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0719]        \n",
      "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0719]        \n",
      "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0719]        \n",
      "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0719]        \n",
      "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0719]        \n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0719]\n",
      "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0719]        \n",
      "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0719]        \n",
      "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0719]        \n",
      "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0719]        \n",
      "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0719]        \n",
      "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0719]        \n",
      "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0719]        \n",
      "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.475, train_loss_epoch=0.475, valid_loss=0.0719]        \n",
      "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0719]        \n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00,  3.18it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0719]\n",
      "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0719]        \n",
      "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471, valid_loss=0.0719]        \n",
      "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.0719]        \n",
      "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=0.0719]        \n",
      "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.465, valid_loss=0.0719]        \n",
      "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=0.0719]        \n",
      "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=0.0719]        \n",
      "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.474, train_loss_epoch=0.474, valid_loss=0.0719]        \n",
      "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.465, valid_loss=0.0719]        \n",
      "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.453, train_loss_epoch=0.453, valid_loss=0.0719]        \n",
      "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.444, train_loss_epoch=0.444, valid_loss=0.0719]        \n",
      "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.446, train_loss_epoch=0.446, valid_loss=0.0719]        \n",
      "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0719]        \n",
      "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0719]        \n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0719]\n",
      "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.461, train_loss_epoch=0.461, valid_loss=0.0719]        \n",
      "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=0.0719]        \n",
      "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.444, train_loss_epoch=0.444, valid_loss=0.0719]        \n",
      "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.447, train_loss_epoch=0.447, valid_loss=0.0719]        \n",
      "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.447, train_loss_epoch=0.447, valid_loss=0.0719]        \n",
      "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.461, train_loss_epoch=0.461, valid_loss=0.0719]        \n",
      "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473, valid_loss=0.0719]        \n",
      "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.465, valid_loss=0.0719]        \n",
      "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.453, train_loss_epoch=0.453, valid_loss=0.0719]        \n",
      "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0719]        \n",
      "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0719]        \n",
      "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0719]        \n",
      "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.457, train_loss_epoch=0.457, valid_loss=0.0719]        \n",
      "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=0.0719]        \n",
      "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0719]        \n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00,  3.78it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0719]\n",
      "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0719]        \n",
      "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0719]        \n",
      "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0719]        \n",
      "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0719]        \n",
      "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0719]        \n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00,  3.69it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0719]\n",
      "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0719]        \n",
      "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0719]        \n",
      "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0719]        \n",
      "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0719]        \n",
      "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0719]        \n",
      "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=0.0719]        \n",
      "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=0.0719]        \n",
      "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=0.0719]        \n",
      "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0719]        \n",
      "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0719]        \n",
      "Epoch 174: 100%|██████████| 1/1 [00:00<00:00,  3.90it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.483, valid_loss=0.0719]\n",
      "Epoch 174: 100%|██████████| 1/1 [00:00<00:00,  3.88it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0719]\n",
      "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0719]        \n",
      "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473, valid_loss=0.0719]        \n",
      "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.0719]        \n",
      "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452, valid_loss=0.0719]        \n",
      "Epoch 178: 100%|██████████| 1/1 [00:00<00:00,  3.61it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452, valid_loss=0.0719]\n",
      "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.449, train_loss_epoch=0.449, valid_loss=0.0719]        \n",
      "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.433, train_loss_epoch=0.433, valid_loss=0.0719]        \n",
      "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.428, train_loss_epoch=0.428, valid_loss=0.0719]        \n",
      "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=0.0719]        \n",
      "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=0.0719]        \n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00,  3.53it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=0.0719]\n",
      "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.448, valid_loss=0.0719]        \n",
      "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.438, train_loss_epoch=0.438, valid_loss=0.0719]        \n",
      "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.442, train_loss_epoch=0.442, valid_loss=0.0719]        \n",
      "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.443, train_loss_epoch=0.443, valid_loss=0.0719]        \n",
      "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=0.0719]        \n",
      "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.461, train_loss_epoch=0.461, valid_loss=0.0719]        \n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00,  3.60it/s, v_num=0, train_loss_step=0.461, train_loss_epoch=0.461, valid_loss=0.0719]\n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00,  3.46it/s, v_num=0, train_loss_step=0.447, train_loss_epoch=0.461, valid_loss=0.0719]\n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00,  3.45it/s, v_num=0, train_loss_step=0.447, train_loss_epoch=0.447, valid_loss=0.0719]\n",
      "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.447, train_loss_epoch=0.447, valid_loss=0.0719]        \n",
      "Epoch 190: 100%|██████████| 1/1 [00:00<00:00,  3.29it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0719]\n",
      "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0719]        \n",
      "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.447, train_loss_epoch=0.447, valid_loss=0.0719]        \n",
      "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569, valid_loss=0.0719]        \n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00,  3.56it/s, v_num=0, train_loss_step=0.581, train_loss_epoch=0.569, valid_loss=0.0719]\n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00,  3.54it/s, v_num=0, train_loss_step=0.581, train_loss_epoch=0.581, valid_loss=0.0719]\n",
      "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.581, train_loss_epoch=0.581, valid_loss=0.0719]        \n",
      "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0719]        \n",
      "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0719]        \n",
      "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0719]        \n",
      "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0719]        \n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00,  3.87it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0719]\n",
      "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0719]        \n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  3.77it/s, v_num=0, train_loss_step=0.475, train_loss_epoch=0.496, valid_loss=0.0719]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=4470)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  7.14it/s]\u001b[A\n",
      "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.475, train_loss_epoch=0.475, valid_loss=0.046]         \n",
      "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.703, train_loss_epoch=0.703, valid_loss=0.046]        \n",
      "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.046]        \n",
      "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.579, train_loss_epoch=0.579, valid_loss=0.046]        \n",
      "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.046]        \n",
      "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.046]        \n",
      "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.046]        \n",
      "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.046]        \n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00,  3.27it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.046]\n",
      "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.046]        \n",
      "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.046]        \n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00,  3.61it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.046]\n",
      "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.046]        \n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00,  3.38it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.477, valid_loss=0.046]\n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00,  3.37it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.468, valid_loss=0.046]\n",
      "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.468, valid_loss=0.046]        \n",
      "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.046]        \n",
      "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.046]        \n",
      "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.449, train_loss_epoch=0.449, valid_loss=0.046]        \n",
      "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.046]        \n",
      "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.046]        \n",
      "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.046]        \n",
      "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.046]        \n",
      "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.046]        \n",
      "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471, valid_loss=0.046]        \n",
      "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.468, valid_loss=0.046]        \n",
      "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473, valid_loss=0.046]        \n",
      "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=0.046]        \n",
      "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.459, train_loss_epoch=0.459, valid_loss=0.046]        \n",
      "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=0.046]        \n",
      "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.448, valid_loss=0.046]        \n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00,  3.94it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.448, valid_loss=0.046]\n",
      "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.440, train_loss_epoch=0.440, valid_loss=0.046]        \n",
      "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.437, train_loss_epoch=0.437, valid_loss=0.046]        \n",
      "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.433, train_loss_epoch=0.433, valid_loss=0.046]        \n",
      "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.423, train_loss_epoch=0.423, valid_loss=0.046]        \n",
      "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.416, valid_loss=0.046]        \n",
      "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.408, train_loss_epoch=0.408, valid_loss=0.046]        \n",
      "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.404, train_loss_epoch=0.404, valid_loss=0.046]        \n",
      "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.392, train_loss_epoch=0.392, valid_loss=0.046]        \n",
      "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.391, train_loss_epoch=0.391, valid_loss=0.046]        \n",
      "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=0.046]        \n",
      "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.376, train_loss_epoch=0.376, valid_loss=0.046]        \n",
      "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.375, train_loss_epoch=0.375, valid_loss=0.046]        \n",
      "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.407, train_loss_epoch=0.407, valid_loss=0.046]        \n",
      "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.385, train_loss_epoch=0.385, valid_loss=0.046]        \n",
      "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=0.046]        \n",
      "Epoch 241: 100%|██████████| 1/1 [00:00<00:00,  3.57it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=0.046]\n",
      "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365, valid_loss=0.046]        \n",
      "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.362, train_loss_epoch=0.362, valid_loss=0.046]        \n",
      "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351, valid_loss=0.046]        \n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351, valid_loss=0.046]\n",
      "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=0.046]        \n",
      "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=0.046]        \n",
      "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=0.046]        \n",
      "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=0.046]        \n",
      "Epoch 248: 100%|██████████| 1/1 [00:00<00:00,  3.66it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=0.046]\n",
      "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=0.046]        \n",
      "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=0.046]        \n",
      "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=0.046]        \n",
      "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=0.046]        \n",
      "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=0.046]        \n",
      "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=0.046]        \n",
      "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=0.046]        \n",
      "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=0.046]        \n",
      "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=0.046]        \n",
      "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=0.046]        \n",
      "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=0.046]        \n",
      "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396, valid_loss=0.046]        \n",
      "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.435, train_loss_epoch=0.435, valid_loss=0.046]        \n",
      "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.435, train_loss_epoch=0.435, valid_loss=0.046]        \n",
      "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.046]        \n",
      "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.456, train_loss_epoch=0.456, valid_loss=0.046]        \n",
      "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452, valid_loss=0.046]        \n",
      "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.426, train_loss_epoch=0.426, valid_loss=0.046]        \n",
      "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.422, train_loss_epoch=0.422, valid_loss=0.046]        \n",
      "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.410, train_loss_epoch=0.410, valid_loss=0.046]        \n",
      "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.389, valid_loss=0.046]        \n",
      "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396, valid_loss=0.046]        \n",
      "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.381, train_loss_epoch=0.381, valid_loss=0.046]        \n",
      "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.368, train_loss_epoch=0.368, valid_loss=0.046]        \n",
      "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=0.046]        \n",
      "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=0.046]        \n",
      "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.376, train_loss_epoch=0.376, valid_loss=0.046]        \n",
      "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354, valid_loss=0.046]        \n",
      "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354, valid_loss=0.046]        \n",
      "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.342, train_loss_epoch=0.342, valid_loss=0.046]        \n",
      "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351, valid_loss=0.046]        \n",
      "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.345, train_loss_epoch=0.345, valid_loss=0.046]        \n",
      "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=0.046]        \n",
      "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.430, train_loss_epoch=0.430, valid_loss=0.046]        \n",
      "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.046]        \n",
      "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.430, train_loss_epoch=0.430, valid_loss=0.046]        \n",
      "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.403, train_loss_epoch=0.403, valid_loss=0.046]        \n",
      "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.406, train_loss_epoch=0.406, valid_loss=0.046]        \n",
      "Epoch 286: 100%|██████████| 1/1 [00:00<00:00,  3.56it/s, v_num=0, train_loss_step=0.406, train_loss_epoch=0.406, valid_loss=0.046]\n",
      "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.411, train_loss_epoch=0.411, valid_loss=0.046]        \n",
      "Epoch 287: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s, v_num=0, train_loss_step=0.406, train_loss_epoch=0.406, valid_loss=0.046]\n",
      "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.406, train_loss_epoch=0.406, valid_loss=0.046]        \n",
      "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.391, train_loss_epoch=0.391, valid_loss=0.046]        \n",
      "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.407, train_loss_epoch=0.407, valid_loss=0.046]        \n",
      "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.386, train_loss_epoch=0.386, valid_loss=0.046]        \n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00,  2.89it/s, v_num=0, train_loss_step=0.394, train_loss_epoch=0.394, valid_loss=0.046]\n",
      "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.394, train_loss_epoch=0.394, valid_loss=0.046]        \n",
      "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.394, train_loss_epoch=0.394, valid_loss=0.046]\n",
      "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.391, train_loss_epoch=0.391, valid_loss=0.046]        \n",
      "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.374, train_loss_epoch=0.374, valid_loss=0.046]        \n",
      "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.374, train_loss_epoch=0.374, valid_loss=0.046]        \n",
      "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.374, train_loss_epoch=0.374, valid_loss=0.046]        \n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00,  3.92it/s, v_num=0, train_loss_step=0.374, train_loss_epoch=0.374, valid_loss=0.046]\n",
      "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.364, train_loss_epoch=0.364, valid_loss=0.046]        \n",
      "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.356, train_loss_epoch=0.356, valid_loss=0.046]        \n",
      "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.368, train_loss_epoch=0.368, valid_loss=0.046]        \n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  3.54it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.368, valid_loss=0.046]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=4470)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  7.06it/s]\u001b[A\n",
      "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=0.0301]        \n",
      "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=0.0301]        \n",
      "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=0.0301]        \n",
      "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.342, train_loss_epoch=0.342, valid_loss=0.0301]        \n",
      "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=0.0301]        \n",
      "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=0.0301]        \n",
      "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=0.0301]        \n",
      "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=0.0301]        \n",
      "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=0.0301]        \n",
      "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=0.0301]        \n",
      "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=0.0301]        \n",
      "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=0.0301]        \n",
      "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=0.0301]        \n",
      "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.368, train_loss_epoch=0.368, valid_loss=0.0301]        \n",
      "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.364, train_loss_epoch=0.364, valid_loss=0.0301]        \n",
      "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.342, train_loss_epoch=0.342, valid_loss=0.0301]        \n",
      "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.342, train_loss_epoch=0.342, valid_loss=0.0301]        \n",
      "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=0.0301]        \n",
      "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=0.0301]        \n",
      "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=0.0301]        \n",
      "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=0.0301]        \n",
      "Epoch 320: 100%|██████████| 1/1 [00:00<00:00,  3.60it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=0.0301]\n",
      "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=0.0301]        \n",
      "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=0.0301]        \n",
      "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=0.0301]        \n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00,  3.75it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=0.0301]\n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00,  3.58it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=0.0301]\n",
      "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=0.0301]        \n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00,  3.30it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=0.0301]\n",
      "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=0.0301]        \n",
      "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=0.0301]        \n",
      "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=0.0301]        \n",
      "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.286, valid_loss=0.0301]        \n",
      "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.281, train_loss_epoch=0.281, valid_loss=0.0301]        \n",
      "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.289, valid_loss=0.0301]        \n",
      "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276, valid_loss=0.0301]        \n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276, valid_loss=0.0301]\n",
      "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=0.0301]        \n",
      "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.279, train_loss_epoch=0.279, valid_loss=0.0301]        \n",
      "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.278, train_loss_epoch=0.278, valid_loss=0.0301]        \n",
      "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.270, train_loss_epoch=0.270, valid_loss=0.0301]        \n",
      "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=0.0301]        \n",
      "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=0.0301]        \n",
      "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.256, train_loss_epoch=0.256, valid_loss=0.0301]        \n",
      "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.253, train_loss_epoch=0.253, valid_loss=0.0301]        \n",
      "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.251, train_loss_epoch=0.251, valid_loss=0.0301]        \n",
      "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.247, train_loss_epoch=0.247, valid_loss=0.0301]        \n",
      "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=0.0301]        \n",
      "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.243, train_loss_epoch=0.243, valid_loss=0.0301]        \n",
      "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.241, train_loss_epoch=0.241, valid_loss=0.0301]        \n",
      "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.236, train_loss_epoch=0.236, valid_loss=0.0301]        \n",
      "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.233, train_loss_epoch=0.233, valid_loss=0.0301]        \n",
      "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.231, train_loss_epoch=0.231, valid_loss=0.0301]        \n",
      "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.227, train_loss_epoch=0.227, valid_loss=0.0301]        \n",
      "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.225, train_loss_epoch=0.225, valid_loss=0.0301]        \n",
      "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.225, train_loss_epoch=0.225, valid_loss=0.0301]        \n",
      "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.231, train_loss_epoch=0.231, valid_loss=0.0301]        \n",
      "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.229, train_loss_epoch=0.229, valid_loss=0.0301]        \n",
      "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.224, train_loss_epoch=0.224, valid_loss=0.0301]        \n",
      "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=0.0301]        \n",
      "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.222, train_loss_epoch=0.222, valid_loss=0.0301]        \n",
      "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217, valid_loss=0.0301]        \n",
      "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=0.0301]        \n",
      "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=0.0301]        \n",
      "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=0.0301]        \n",
      "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=0.0301]        \n",
      "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206, valid_loss=0.0301]        \n",
      "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=0.0301]        \n",
      "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.207, valid_loss=0.0301]        \n",
      "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=0.0301]        \n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00,  3.72it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=0.0301]\n",
      "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=0.0301]        \n",
      "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.210, train_loss_epoch=0.210, valid_loss=0.0301]        \n",
      "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=0.0301]        \n",
      "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206, valid_loss=0.0301]        \n",
      "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=0.0301]        \n",
      "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=0.0301]        \n",
      "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=0.0301]        \n",
      "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=0.0301]        \n",
      "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196, valid_loss=0.0301]        \n",
      "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=0.0301]        \n",
      "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=0.0301]        \n",
      "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=0.0301]        \n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00,  3.80it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=0.0301]\n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00,  3.67it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.191, valid_loss=0.0301]\n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00,  3.66it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=0.0301]\n",
      "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=0.0301]        \n",
      "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=0.0301]        \n",
      "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=0.0301]        \n",
      "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.187, train_loss_epoch=0.187, valid_loss=0.0301]        \n",
      "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=0.0301]        \n",
      "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=0.0301]        \n",
      "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=0.0301]        \n",
      "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=0.0301]        \n",
      "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.225, train_loss_epoch=0.225, valid_loss=0.0301]        \n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00,  3.33it/s, v_num=0, train_loss_step=0.225, train_loss_epoch=0.225, valid_loss=0.0301]\n",
      "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216, valid_loss=0.0301]        \n",
      "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=0.0301]        \n",
      "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.251, train_loss_epoch=0.251, valid_loss=0.0301]        \n",
      "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.234, train_loss_epoch=0.234, valid_loss=0.0301]        \n",
      "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.250, train_loss_epoch=0.250, valid_loss=0.0301]        \n",
      "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.237, train_loss_epoch=0.237, valid_loss=0.0301]        \n",
      "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.229, train_loss_epoch=0.229, valid_loss=0.0301]        \n",
      "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.273, train_loss_epoch=0.273, valid_loss=0.0301]        \n",
      "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=0.0301]        \n",
      "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.245, valid_loss=0.0301]        \n",
      "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.239, valid_loss=0.0301]        \n",
      "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.230, train_loss_epoch=0.230, valid_loss=0.0301]        \n",
      "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.233, train_loss_epoch=0.233, valid_loss=0.0301]        \n",
      "Epoch 398: 100%|██████████| 1/1 [00:00<00:00,  3.88it/s, v_num=0, train_loss_step=0.233, train_loss_epoch=0.233, valid_loss=0.0301]\n",
      "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.224, train_loss_epoch=0.224, valid_loss=0.0301]        \n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  3.77it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.224, valid_loss=0.0301]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=4470)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s]\u001b[A\n",
      "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216, valid_loss=0.0261]        \n",
      "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=0.0261]        \n",
      "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=0.0261]        \n",
      "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206, valid_loss=0.0261]        \n",
      "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204, valid_loss=0.0261]        \n",
      "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=0.0261]        \n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00,  3.71it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=0.0261]\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00,  3.64it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.202, valid_loss=0.0261]\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00,  3.63it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=0.0261]\n",
      "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=0.0261]        \n",
      "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=0.0261]        \n",
      "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196, valid_loss=0.0261]        \n",
      "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=0.0261]        \n",
      "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.187, train_loss_epoch=0.187, valid_loss=0.0261]        \n",
      "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=0.0261]        \n",
      "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.181, train_loss_epoch=0.181, valid_loss=0.0261]        \n",
      "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=0.0261]        \n",
      "Epoch 413: 100%|██████████| 1/1 [00:00<00:00,  3.92it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=0.0261]\n",
      "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.180, train_loss_epoch=0.180, valid_loss=0.0261]        \n",
      "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=0.0261]        \n",
      "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=0.0261]        \n",
      "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=0.0261]        \n",
      "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=0.0261]        \n",
      "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=0.0261]        \n",
      "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.179, train_loss_epoch=0.179, valid_loss=0.0261]        \n",
      "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=0.0261]        \n",
      "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.174, valid_loss=0.0261]        \n",
      "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.172, train_loss_epoch=0.172, valid_loss=0.0261]        \n",
      "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=0.0261]        \n",
      "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=0.0261]        \n",
      "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=0.0261]        \n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00,  4.23it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=0.0261]\n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00,  4.06it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.168, valid_loss=0.0261]\n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00,  4.05it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=0.0261]\n",
      "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=0.0261]        \n",
      "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=0.0261]        \n",
      "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.164, train_loss_epoch=0.164, valid_loss=0.0261]        \n",
      "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=0.0261]        \n",
      "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.161, train_loss_epoch=0.161, valid_loss=0.0261]        \n",
      "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.160, train_loss_epoch=0.160, valid_loss=0.0261]        \n",
      "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.159, train_loss_epoch=0.159, valid_loss=0.0261]        \n",
      "Epoch 433: 100%|██████████| 1/1 [00:00<00:00,  4.02it/s, v_num=0, train_loss_step=0.159, train_loss_epoch=0.159, valid_loss=0.0261]\n",
      "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.158, train_loss_epoch=0.158, valid_loss=0.0261]        \n",
      "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.156, train_loss_epoch=0.156, valid_loss=0.0261]        \n",
      "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.155, train_loss_epoch=0.155, valid_loss=0.0261]        \n",
      "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.154, train_loss_epoch=0.154, valid_loss=0.0261]        \n",
      "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.153, train_loss_epoch=0.153, valid_loss=0.0261]        \n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00,  4.23it/s, v_num=0, train_loss_step=0.153, train_loss_epoch=0.153, valid_loss=0.0261]\n",
      "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.152, train_loss_epoch=0.152, valid_loss=0.0261]        \n",
      "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.151, train_loss_epoch=0.151, valid_loss=0.0261]        \n",
      "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.151, train_loss_epoch=0.151, valid_loss=0.0261]        \n",
      "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.150, train_loss_epoch=0.150, valid_loss=0.0261]        \n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00,  4.12it/s, v_num=0, train_loss_step=0.150, train_loss_epoch=0.150, valid_loss=0.0261]\n",
      "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.149, train_loss_epoch=0.149, valid_loss=0.0261]        \n",
      "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.149, train_loss_epoch=0.149, valid_loss=0.0261]        \n",
      "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.149, train_loss_epoch=0.149, valid_loss=0.0261]        \n",
      "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.149, train_loss_epoch=0.149, valid_loss=0.0261]        \n",
      "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.148, train_loss_epoch=0.148, valid_loss=0.0261]        \n",
      "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.147, train_loss_epoch=0.147, valid_loss=0.0261]        \n",
      "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.146, train_loss_epoch=0.146, valid_loss=0.0261]        \n",
      "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.145, train_loss_epoch=0.145, valid_loss=0.0261]        \n",
      "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.145, train_loss_epoch=0.145, valid_loss=0.0261]        \n",
      "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.145, train_loss_epoch=0.145, valid_loss=0.0261]        \n",
      "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.144, train_loss_epoch=0.144, valid_loss=0.0261]        \n",
      "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.143, train_loss_epoch=0.143, valid_loss=0.0261]        \n",
      "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.142, train_loss_epoch=0.142, valid_loss=0.0261]        \n",
      "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.142, train_loss_epoch=0.142, valid_loss=0.0261]        \n",
      "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.142, train_loss_epoch=0.142, valid_loss=0.0261]        \n",
      "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.141, train_loss_epoch=0.141, valid_loss=0.0261]        \n",
      "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.142, train_loss_epoch=0.142, valid_loss=0.0261]        \n",
      "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.142, train_loss_epoch=0.142, valid_loss=0.0261]        \n",
      "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.141, train_loss_epoch=0.141, valid_loss=0.0261]        \n",
      "Epoch 461: 100%|██████████| 1/1 [00:00<00:00,  3.85it/s, v_num=0, train_loss_step=0.141, train_loss_epoch=0.141, valid_loss=0.0261]\n",
      "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.140, train_loss_epoch=0.140, valid_loss=0.0261]        \n",
      "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.140, train_loss_epoch=0.140, valid_loss=0.0261]        \n",
      "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.140, train_loss_epoch=0.140, valid_loss=0.0261]        \n",
      "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.139, train_loss_epoch=0.139, valid_loss=0.0261]        \n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00,  4.11it/s, v_num=0, train_loss_step=0.139, train_loss_epoch=0.139, valid_loss=0.0261]\n",
      "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.139, train_loss_epoch=0.139, valid_loss=0.0261]        \n",
      "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.139, train_loss_epoch=0.139, valid_loss=0.0261]        \n",
      "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.138, train_loss_epoch=0.138, valid_loss=0.0261]        \n",
      "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.137, train_loss_epoch=0.137, valid_loss=0.0261]        \n",
      "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.136, train_loss_epoch=0.136, valid_loss=0.0261]        \n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00,  3.97it/s, v_num=0, train_loss_step=0.136, train_loss_epoch=0.136, valid_loss=0.0261]\n",
      "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.136, train_loss_epoch=0.136, valid_loss=0.0261]        \n",
      "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.135, train_loss_epoch=0.135, valid_loss=0.0261]        \n",
      "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.135, train_loss_epoch=0.135, valid_loss=0.0261]        \n",
      "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.134, train_loss_epoch=0.134, valid_loss=0.0261]        \n",
      "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.134, train_loss_epoch=0.134, valid_loss=0.0261]        \n",
      "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.134, train_loss_epoch=0.134, valid_loss=0.0261]        \n",
      "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.134, train_loss_epoch=0.134, valid_loss=0.0261]        \n",
      "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.134, train_loss_epoch=0.134, valid_loss=0.0261]        \n",
      "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.135, train_loss_epoch=0.135, valid_loss=0.0261]        \n",
      "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.134, train_loss_epoch=0.134, valid_loss=0.0261]        \n",
      "Epoch 480: 100%|██████████| 1/1 [00:00<00:00,  3.79it/s, v_num=0, train_loss_step=0.134, train_loss_epoch=0.134, valid_loss=0.0261]\n",
      "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.132, train_loss_epoch=0.132, valid_loss=0.0261]        \n",
      "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.131, train_loss_epoch=0.131, valid_loss=0.0261]        \n",
      "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.131, train_loss_epoch=0.131, valid_loss=0.0261]        \n",
      "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.131, train_loss_epoch=0.131, valid_loss=0.0261]        \n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00,  3.80it/s, v_num=0, train_loss_step=0.131, train_loss_epoch=0.131, valid_loss=0.0261]\n",
      "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.132, train_loss_epoch=0.132, valid_loss=0.0261]        \n",
      "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.132, train_loss_epoch=0.132, valid_loss=0.0261]        \n",
      "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.131, train_loss_epoch=0.131, valid_loss=0.0261]        \n",
      "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.130, train_loss_epoch=0.130, valid_loss=0.0261]        \n",
      "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.129, train_loss_epoch=0.129, valid_loss=0.0261]        \n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00,  3.68it/s, v_num=0, train_loss_step=0.129, train_loss_epoch=0.129, valid_loss=0.0261]\n",
      "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.129, train_loss_epoch=0.129, valid_loss=0.0261]        \n",
      "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.130, train_loss_epoch=0.130, valid_loss=0.0261]        \n",
      "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.130, train_loss_epoch=0.130, valid_loss=0.0261]        \n",
      "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.128, train_loss_epoch=0.128, valid_loss=0.0261]        \n",
      "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.127, train_loss_epoch=0.127, valid_loss=0.0261]        \n",
      "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.127, train_loss_epoch=0.127, valid_loss=0.0261]        \n",
      "Epoch 495: 100%|██████████| 1/1 [00:00<00:00,  3.54it/s, v_num=0, train_loss_step=0.127, train_loss_epoch=0.127, valid_loss=0.0261]\n",
      "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.127, train_loss_epoch=0.127, valid_loss=0.0261]        \n",
      "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.127, train_loss_epoch=0.127, valid_loss=0.0261]        \n",
      "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.127, train_loss_epoch=0.127, valid_loss=0.0261]        \n",
      "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.126, train_loss_epoch=0.126, valid_loss=0.0261]        \n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  3.91it/s, v_num=0, train_loss_step=0.125, train_loss_epoch=0.126, valid_loss=0.0261]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=4470)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  7.28it/s]\u001b[A\n",
      "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.125, train_loss_epoch=0.125, valid_loss=0.0329]        \n",
      "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.125, train_loss_epoch=0.125, valid_loss=0.0329]        \n",
      "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.126, train_loss_epoch=0.126, valid_loss=0.0329]        \n",
      "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.126, train_loss_epoch=0.126, valid_loss=0.0329]        \n",
      "Epoch 503: 100%|██████████| 1/1 [00:00<00:00,  3.81it/s, v_num=0, train_loss_step=0.126, train_loss_epoch=0.126, valid_loss=0.0329]\n",
      "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.124, train_loss_epoch=0.124, valid_loss=0.0329]        \n",
      "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.123, train_loss_epoch=0.123, valid_loss=0.0329]        \n",
      "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.123, train_loss_epoch=0.123, valid_loss=0.0329]        \n",
      "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.123, train_loss_epoch=0.123, valid_loss=0.0329]        \n",
      "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.124, train_loss_epoch=0.124, valid_loss=0.0329]        \n",
      "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.123, train_loss_epoch=0.123, valid_loss=0.0329]        \n",
      "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.122, train_loss_epoch=0.122, valid_loss=0.0329]        \n",
      "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.122, train_loss_epoch=0.122, valid_loss=0.0329]        \n",
      "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.122, train_loss_epoch=0.122, valid_loss=0.0329]        \n",
      "Epoch 512: 100%|██████████| 1/1 [00:00<00:00,  3.65it/s, v_num=0, train_loss_step=0.122, train_loss_epoch=0.122, valid_loss=0.0329]\n",
      "Epoch 512: 100%|██████████| 1/1 [00:00<00:00,  3.50it/s, v_num=0, train_loss_step=0.121, train_loss_epoch=0.122, valid_loss=0.0329]\n",
      "Epoch 512: 100%|██████████| 1/1 [00:00<00:00,  3.49it/s, v_num=0, train_loss_step=0.121, train_loss_epoch=0.121, valid_loss=0.0329]\n",
      "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.121, train_loss_epoch=0.121, valid_loss=0.0329]        \n",
      "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.121, train_loss_epoch=0.121, valid_loss=0.0329]        \n",
      "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=0.0329]        \n",
      "Epoch 515: 100%|██████████| 1/1 [00:00<00:00,  3.85it/s, v_num=0, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=0.0329]\n",
      "Epoch 515: 100%|██████████| 1/1 [00:00<00:00,  3.84it/s, v_num=0, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=0.0329]\n",
      "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=0.0329]        \n",
      "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=0.0329]        \n",
      "Epoch 517: 100%|██████████| 1/1 [00:00<00:00,  3.99it/s, v_num=0, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=0.0329]\n",
      "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.119, train_loss_epoch=0.119, valid_loss=0.0329]        \n",
      "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.119, train_loss_epoch=0.119, valid_loss=0.0329]        \n",
      "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.119, train_loss_epoch=0.119, valid_loss=0.0329]        \n",
      "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.119, train_loss_epoch=0.119, valid_loss=0.0329]        \n",
      "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.118, train_loss_epoch=0.118, valid_loss=0.0329]        \n",
      "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.119, train_loss_epoch=0.119, valid_loss=0.0329]        \n",
      "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.119, train_loss_epoch=0.119, valid_loss=0.0329]        \n",
      "Epoch 524: 100%|██████████| 1/1 [00:00<00:00,  3.91it/s, v_num=0, train_loss_step=0.120, train_loss_epoch=0.119, valid_loss=0.0329]\n",
      "Epoch 524: 100%|██████████| 1/1 [00:00<00:00,  3.89it/s, v_num=0, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=0.0329]\n",
      "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=0.0329]        \n",
      "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=0.0329]        \n",
      "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.119, train_loss_epoch=0.119, valid_loss=0.0329]        \n",
      "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.117, train_loss_epoch=0.117, valid_loss=0.0329]        \n",
      "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.116, train_loss_epoch=0.116, valid_loss=0.0329]        \n",
      "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.115, train_loss_epoch=0.115, valid_loss=0.0329]        \n",
      "Epoch 530: 100%|██████████| 1/1 [00:00<00:00,  4.27it/s, v_num=0, train_loss_step=0.115, train_loss_epoch=0.115, valid_loss=0.0329]\n",
      "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.117, train_loss_epoch=0.117, valid_loss=0.0329]        \n",
      "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.118, train_loss_epoch=0.118, valid_loss=0.0329]        \n",
      "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.117, train_loss_epoch=0.117, valid_loss=0.0329]        \n",
      "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.116, train_loss_epoch=0.116, valid_loss=0.0329]        \n",
      "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.116, train_loss_epoch=0.116, valid_loss=0.0329]        \n",
      "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.114, train_loss_epoch=0.114, valid_loss=0.0329]        \n",
      "Epoch 536: 100%|██████████| 1/1 [00:00<00:00,  3.71it/s, v_num=0, train_loss_step=0.114, train_loss_epoch=0.114, valid_loss=0.0329]\n",
      "Epoch 536: 100%|██████████| 1/1 [00:00<00:00,  3.59it/s, v_num=0, train_loss_step=0.115, train_loss_epoch=0.114, valid_loss=0.0329]\n",
      "Epoch 536: 100%|██████████| 1/1 [00:00<00:00,  3.58it/s, v_num=0, train_loss_step=0.115, train_loss_epoch=0.115, valid_loss=0.0329]\n",
      "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.115, train_loss_epoch=0.115, valid_loss=0.0329]        \n",
      "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.114, train_loss_epoch=0.114, valid_loss=0.0329]        \n",
      "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.115, train_loss_epoch=0.115, valid_loss=0.0329]        \n",
      "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.114, train_loss_epoch=0.114, valid_loss=0.0329]        \n",
      "Epoch 540: 100%|██████████| 1/1 [00:00<00:00,  4.11it/s, v_num=0, train_loss_step=0.112, train_loss_epoch=0.112, valid_loss=0.0329]\n",
      "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.112, train_loss_epoch=0.112, valid_loss=0.0329]        \n",
      "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=0.0329]        \n",
      "Epoch 542: 100%|██████████| 1/1 [00:00<00:00,  3.89it/s, v_num=0, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=0.0329]\n",
      "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=0.0329]        \n",
      "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.112, train_loss_epoch=0.112, valid_loss=0.0329]        \n",
      "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.112, train_loss_epoch=0.112, valid_loss=0.0329]        \n",
      "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=0.0329]        \n",
      "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=0.0329]        \n",
      "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.112, train_loss_epoch=0.112, valid_loss=0.0329]        \n",
      "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.112, train_loss_epoch=0.112, valid_loss=0.0329]        \n",
      "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.111, train_loss_epoch=0.111, valid_loss=0.0329]        \n",
      "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.112, train_loss_epoch=0.112, valid_loss=0.0329]        \n",
      "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.112, train_loss_epoch=0.112, valid_loss=0.0329]        \n",
      "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=0.0329]        \n",
      "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=0.0329]        \n",
      "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.111, train_loss_epoch=0.111, valid_loss=0.0329]        \n",
      "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.109, train_loss_epoch=0.109, valid_loss=0.0329]        \n",
      "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.109, train_loss_epoch=0.109, valid_loss=0.0329]        \n",
      "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.109, train_loss_epoch=0.109, valid_loss=0.0329]        \n",
      "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.109, train_loss_epoch=0.109, valid_loss=0.0329]        \n",
      "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.109, train_loss_epoch=0.109, valid_loss=0.0329]        \n",
      "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.110, train_loss_epoch=0.110, valid_loss=0.0329]        \n",
      "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.110, train_loss_epoch=0.110, valid_loss=0.0329]        \n",
      "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.109, train_loss_epoch=0.109, valid_loss=0.0329]        \n",
      "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.109, train_loss_epoch=0.109, valid_loss=0.0329]        \n",
      "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.108, train_loss_epoch=0.108, valid_loss=0.0329]        \n",
      "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=0.0329]        \n",
      "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=0.0329]        \n",
      "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=0.0329]        \n",
      "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=0.0329]        \n",
      "Epoch 569: 100%|██████████| 1/1 [00:00<00:00,  4.01it/s, v_num=0, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=0.0329]\n",
      "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=0.0329]        \n",
      "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=0.0329]        \n",
      "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=0.0329]        \n",
      "Epoch 572: 100%|██████████| 1/1 [00:00<00:00,  3.55it/s, v_num=0, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=0.0329]\n",
      "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=0.0329]        \n",
      "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=0.0329]        \n",
      "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=0.0329]        \n",
      "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=0.0329]        \n",
      "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=0.0329]        \n",
      "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=0.0329]        \n",
      "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=0.0329]        \n",
      "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=0.0329]        \n",
      "Epoch 580: 100%|██████████| 1/1 [00:00<00:00,  3.28it/s, v_num=0, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=0.0329]\n",
      "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=0.0329]        \n",
      "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=0.0329]        \n",
      "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.104, train_loss_epoch=0.104, valid_loss=0.0329]        \n",
      "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.104, train_loss_epoch=0.104, valid_loss=0.0329]        \n",
      "Epoch 584: 100%|██████████| 1/1 [00:00<00:00,  3.58it/s, v_num=0, train_loss_step=0.104, train_loss_epoch=0.104, valid_loss=0.0329]\n",
      "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.103, train_loss_epoch=0.103, valid_loss=0.0329]        \n",
      "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.104, train_loss_epoch=0.104, valid_loss=0.0329]        \n",
      "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.104, train_loss_epoch=0.104, valid_loss=0.0329]        \n",
      "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.103, train_loss_epoch=0.103, valid_loss=0.0329]        \n",
      "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.104, train_loss_epoch=0.104, valid_loss=0.0329]        \n",
      "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=0.0329]        \n",
      "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=0.0329]        \n",
      "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=0.0329]        \n",
      "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.103, train_loss_epoch=0.103, valid_loss=0.0329]        \n",
      "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.102, train_loss_epoch=0.102, valid_loss=0.0329]        \n",
      "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.102, train_loss_epoch=0.102, valid_loss=0.0329]        \n",
      "Epoch 595: 100%|██████████| 1/1 [00:00<00:00,  3.72it/s, v_num=0, train_loss_step=0.102, train_loss_epoch=0.102, valid_loss=0.0329]\n",
      "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.102, train_loss_epoch=0.102, valid_loss=0.0329]        \n",
      "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.103, train_loss_epoch=0.103, valid_loss=0.0329]        \n",
      "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.102, train_loss_epoch=0.102, valid_loss=0.0329]        \n",
      "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=0.0329]        \n",
      "Epoch 599: 100%|██████████| 1/1 [00:00<00:00,  3.69it/s, v_num=0, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=0.0329]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=4470)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s]\u001b[A\n",
      "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=0.0346]        \n",
      "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=0.0346]        \n",
      "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=0.0346]        \n",
      "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=0.0346]        \n",
      "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=0.0346]        \n",
      "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=0.0346]        \n",
      "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=0.0346]        \n",
      "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.102, train_loss_epoch=0.102, valid_loss=0.0346]        \n",
      "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.100, train_loss_epoch=0.100, valid_loss=0.0346]        \n",
      "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.100, train_loss_epoch=0.100, valid_loss=0.0346]        \n",
      "Epoch 609: 100%|██████████| 1/1 [00:00<00:00,  3.85it/s, v_num=0, train_loss_step=0.100, train_loss_epoch=0.100, valid_loss=0.0346]\n",
      "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.100, train_loss_epoch=0.100, valid_loss=0.0346]        \n",
      "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0996, train_loss_epoch=0.0996, valid_loss=0.0346]        \n",
      "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0991, train_loss_epoch=0.0991, valid_loss=0.0346]        \n",
      "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0983, train_loss_epoch=0.0983, valid_loss=0.0346]        \n",
      "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.097, train_loss_epoch=0.097, valid_loss=0.0346]          \n",
      "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0971, train_loss_epoch=0.0971, valid_loss=0.0346]        \n",
      "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0978, train_loss_epoch=0.0978, valid_loss=0.0346]        \n",
      "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0983, train_loss_epoch=0.0983, valid_loss=0.0346]        \n",
      "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0983, train_loss_epoch=0.0983, valid_loss=0.0346]        \n",
      "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.098, train_loss_epoch=0.098, valid_loss=0.0346]          \n",
      "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0977, train_loss_epoch=0.0977, valid_loss=0.0346]        \n",
      "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0992, train_loss_epoch=0.0992, valid_loss=0.0346]        \n",
      "Epoch 622:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0989, train_loss_epoch=0.0989, valid_loss=0.0346]        \n",
      "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0982, train_loss_epoch=0.0982, valid_loss=0.0346]        \n",
      "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0967, train_loss_epoch=0.0967, valid_loss=0.0346]        \n",
      "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0958, train_loss_epoch=0.0958, valid_loss=0.0346]        \n",
      "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0959, train_loss_epoch=0.0959, valid_loss=0.0346]        \n",
      "Epoch 626: 100%|██████████| 1/1 [00:00<00:00,  3.73it/s, v_num=0, train_loss_step=0.0959, train_loss_epoch=0.0959, valid_loss=0.0346]\n",
      "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0957, train_loss_epoch=0.0957, valid_loss=0.0346]        \n",
      "Epoch 628:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.096, train_loss_epoch=0.096, valid_loss=0.0346]          \n",
      "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0971, train_loss_epoch=0.0971, valid_loss=0.0346]        \n",
      "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.096, train_loss_epoch=0.096, valid_loss=0.0346]          \n",
      "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0965, train_loss_epoch=0.0965, valid_loss=0.0346]        \n",
      "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.098, train_loss_epoch=0.098, valid_loss=0.0346]          \n",
      "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0979, train_loss_epoch=0.0979, valid_loss=0.0346]        \n",
      "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0983, train_loss_epoch=0.0983, valid_loss=0.0346]        \n",
      "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.098, train_loss_epoch=0.098, valid_loss=0.0346]          \n",
      "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.098, train_loss_epoch=0.098, valid_loss=0.0346]        \n",
      "Epoch 636: 100%|██████████| 1/1 [00:00<00:00,  3.64it/s, v_num=0, train_loss_step=0.098, train_loss_epoch=0.098, valid_loss=0.0346]\n",
      "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0973, train_loss_epoch=0.0973, valid_loss=0.0346]        \n",
      "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0948, train_loss_epoch=0.0948, valid_loss=0.0346]        \n",
      "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0942, train_loss_epoch=0.0942, valid_loss=0.0346]        \n",
      "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.094, train_loss_epoch=0.094, valid_loss=0.0346]          \n",
      "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0938, train_loss_epoch=0.0938, valid_loss=0.0346]        \n",
      "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0951, train_loss_epoch=0.0951, valid_loss=0.0346]        \n",
      "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.096, train_loss_epoch=0.096, valid_loss=0.0346]          \n",
      "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0974, train_loss_epoch=0.0974, valid_loss=0.0346]        \n",
      "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0982, train_loss_epoch=0.0982, valid_loss=0.0346]        \n",
      "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0958, train_loss_epoch=0.0958, valid_loss=0.0346]        \n",
      "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0946, train_loss_epoch=0.0946, valid_loss=0.0346]        \n",
      "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0939, train_loss_epoch=0.0939, valid_loss=0.0346]        \n",
      "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0938, train_loss_epoch=0.0938, valid_loss=0.0346]        \n",
      "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0937, train_loss_epoch=0.0937, valid_loss=0.0346]        \n",
      "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0937, train_loss_epoch=0.0937, valid_loss=0.0346]        \n",
      "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0939, train_loss_epoch=0.0939, valid_loss=0.0346]        \n",
      "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0935, train_loss_epoch=0.0935, valid_loss=0.0346]        \n",
      "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0919, train_loss_epoch=0.0919, valid_loss=0.0346]        \n",
      "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0914, train_loss_epoch=0.0914, valid_loss=0.0346]        \n",
      "Epoch 655: 100%|██████████| 1/1 [00:00<00:00,  3.74it/s, v_num=0, train_loss_step=0.0915, train_loss_epoch=0.0915, valid_loss=0.0346]\n",
      "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0915, train_loss_epoch=0.0915, valid_loss=0.0346]        \n",
      "Epoch 657:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0914, train_loss_epoch=0.0914, valid_loss=0.0346]        \n",
      "Epoch 657: 100%|██████████| 1/1 [00:00<00:00,  4.12it/s, v_num=0, train_loss_step=0.0914, train_loss_epoch=0.0914, valid_loss=0.0346]\n",
      "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0916, train_loss_epoch=0.0916, valid_loss=0.0346]        \n",
      "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0921, train_loss_epoch=0.0921, valid_loss=0.0346]        \n",
      "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0931, train_loss_epoch=0.0931, valid_loss=0.0346]        \n",
      "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0937, train_loss_epoch=0.0937, valid_loss=0.0346]        \n",
      "Epoch 661: 100%|██████████| 1/1 [00:00<00:00,  3.80it/s, v_num=0, train_loss_step=0.0937, train_loss_epoch=0.0937, valid_loss=0.0346]\n",
      "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0938, train_loss_epoch=0.0938, valid_loss=0.0346]        \n",
      "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0927, train_loss_epoch=0.0927, valid_loss=0.0346]        \n",
      "Epoch 663: 100%|██████████| 1/1 [00:00<00:00,  3.81it/s, v_num=0, train_loss_step=0.0927, train_loss_epoch=0.0927, valid_loss=0.0346]\n",
      "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0913, train_loss_epoch=0.0913, valid_loss=0.0346]        \n",
      "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0906, train_loss_epoch=0.0906, valid_loss=0.0346]        \n",
      "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0919, train_loss_epoch=0.0919, valid_loss=0.0346]        \n",
      "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0934, train_loss_epoch=0.0934, valid_loss=0.0346]        \n",
      "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0931, train_loss_epoch=0.0931, valid_loss=0.0346]        \n",
      "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0924, train_loss_epoch=0.0924, valid_loss=0.0346]        \n",
      "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0913, train_loss_epoch=0.0913, valid_loss=0.0346]        \n",
      "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.090, train_loss_epoch=0.090, valid_loss=0.0346]          \n",
      "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0898, train_loss_epoch=0.0898, valid_loss=0.0346]        \n",
      "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0898, train_loss_epoch=0.0898, valid_loss=0.0346]        \n",
      "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0902, train_loss_epoch=0.0902, valid_loss=0.0346]        \n",
      "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.090, train_loss_epoch=0.090, valid_loss=0.0346]          \n",
      "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0904, train_loss_epoch=0.0904, valid_loss=0.0346]        \n",
      "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.090, train_loss_epoch=0.090, valid_loss=0.0346]          \n",
      "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.089, train_loss_epoch=0.089, valid_loss=0.0346]        \n",
      "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0882, train_loss_epoch=0.0882, valid_loss=0.0346]        \n",
      "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0888, train_loss_epoch=0.0888, valid_loss=0.0346]        \n",
      "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0897, train_loss_epoch=0.0897, valid_loss=0.0346]        \n",
      "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0906, train_loss_epoch=0.0906, valid_loss=0.0346]        \n",
      "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0917, train_loss_epoch=0.0917, valid_loss=0.0346]        \n",
      "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0919, train_loss_epoch=0.0919, valid_loss=0.0346]        \n",
      "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0919, train_loss_epoch=0.0919, valid_loss=0.0346]        \n",
      "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.090, train_loss_epoch=0.090, valid_loss=0.0346]          \n",
      "Epoch 686: 100%|██████████| 1/1 [00:00<00:00,  4.24it/s, v_num=0, train_loss_step=0.090, train_loss_epoch=0.090, valid_loss=0.0346]\n",
      "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0891, train_loss_epoch=0.0891, valid_loss=0.0346]        \n",
      "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.089, train_loss_epoch=0.089, valid_loss=0.0346]          \n",
      "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0882, train_loss_epoch=0.0882, valid_loss=0.0346]        \n",
      "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.088, train_loss_epoch=0.088, valid_loss=0.0346]          \n",
      "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0874, train_loss_epoch=0.0874, valid_loss=0.0346]        \n",
      "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0883, train_loss_epoch=0.0883, valid_loss=0.0346]        \n",
      "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.090, train_loss_epoch=0.090, valid_loss=0.0346]          \n",
      "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0905, train_loss_epoch=0.0905, valid_loss=0.0346]        \n",
      "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0888, train_loss_epoch=0.0888, valid_loss=0.0346]        \n",
      "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0885, train_loss_epoch=0.0885, valid_loss=0.0346]        \n",
      "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0883, train_loss_epoch=0.0883, valid_loss=0.0346]        \n",
      "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0877, train_loss_epoch=0.0877, valid_loss=0.0346]        \n",
      "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0871, train_loss_epoch=0.0871, valid_loss=0.0346]        \n",
      "Epoch 699: 100%|██████████| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=0.0869, train_loss_epoch=0.0871, valid_loss=0.0346]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=4470)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s]\u001b[A\n",
      "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0869, train_loss_epoch=0.0869, valid_loss=0.0381]        \n",
      "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0874, train_loss_epoch=0.0874, valid_loss=0.0381]        \n",
      "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0877, train_loss_epoch=0.0877, valid_loss=0.0381]        \n",
      "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0889, train_loss_epoch=0.0889, valid_loss=0.0381]        \n",
      "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0892, train_loss_epoch=0.0892, valid_loss=0.0381]        \n",
      "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0881, train_loss_epoch=0.0881, valid_loss=0.0381]        \n",
      "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0866, train_loss_epoch=0.0866, valid_loss=0.0381]        \n",
      "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0857, train_loss_epoch=0.0857, valid_loss=0.0381]        \n",
      "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0865, train_loss_epoch=0.0865, valid_loss=0.0381]        \n",
      "Epoch 708: 100%|██████████| 1/1 [00:00<00:00,  4.11it/s, v_num=0, train_loss_step=0.0865, train_loss_epoch=0.0865, valid_loss=0.0381]\n",
      "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0871, train_loss_epoch=0.0871, valid_loss=0.0381]        \n",
      "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0867, train_loss_epoch=0.0867, valid_loss=0.0381]        \n",
      "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0854, train_loss_epoch=0.0854, valid_loss=0.0381]        \n",
      "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0849, train_loss_epoch=0.0849, valid_loss=0.0381]        \n",
      "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.085, train_loss_epoch=0.085, valid_loss=0.0381]          \n",
      "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0861, train_loss_epoch=0.0861, valid_loss=0.0381]        \n",
      "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0875, train_loss_epoch=0.0875, valid_loss=0.0381]        \n",
      "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.088, train_loss_epoch=0.088, valid_loss=0.0381]          \n",
      "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.087, train_loss_epoch=0.087, valid_loss=0.0381]        \n",
      "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0844, train_loss_epoch=0.0844, valid_loss=0.0381]        \n",
      "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0841, train_loss_epoch=0.0841, valid_loss=0.0381]        \n",
      "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0856, train_loss_epoch=0.0856, valid_loss=0.0381]        \n",
      "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0859, train_loss_epoch=0.0859, valid_loss=0.0381]        \n",
      "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.085, train_loss_epoch=0.085, valid_loss=0.0381]          \n",
      "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0848, train_loss_epoch=0.0848, valid_loss=0.0381]        \n",
      "Epoch 724:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0852, train_loss_epoch=0.0852, valid_loss=0.0381]        \n",
      "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0859, train_loss_epoch=0.0859, valid_loss=0.0381]        \n",
      "Epoch 725: 100%|██████████| 1/1 [00:00<00:00,  3.91it/s, v_num=0, train_loss_step=0.0859, train_loss_epoch=0.0859, valid_loss=0.0381]\n",
      "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.085, train_loss_epoch=0.085, valid_loss=0.0381]          \n",
      "Epoch 726: 100%|██████████| 1/1 [00:00<00:00,  3.37it/s, v_num=0, train_loss_step=0.085, train_loss_epoch=0.085, valid_loss=0.0381]\n",
      "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0839, train_loss_epoch=0.0839, valid_loss=0.0381]        \n",
      "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0841, train_loss_epoch=0.0841, valid_loss=0.0381]        \n",
      "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0849, train_loss_epoch=0.0849, valid_loss=0.0381]        \n",
      "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0843, train_loss_epoch=0.0843, valid_loss=0.0381]        \n",
      "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0836, train_loss_epoch=0.0836, valid_loss=0.0381]        \n",
      "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0834, train_loss_epoch=0.0834, valid_loss=0.0381]        \n",
      "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0836, train_loss_epoch=0.0836, valid_loss=0.0381]        \n",
      "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0838, train_loss_epoch=0.0838, valid_loss=0.0381]        \n",
      "Epoch 734: 100%|██████████| 1/1 [00:00<00:00,  3.84it/s, v_num=0, train_loss_step=0.0838, train_loss_epoch=0.0838, valid_loss=0.0381]\n",
      "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.084, train_loss_epoch=0.084, valid_loss=0.0381]          \n",
      "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0839, train_loss_epoch=0.0839, valid_loss=0.0381]        \n",
      "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0834, train_loss_epoch=0.0834, valid_loss=0.0381]        \n",
      "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0841, train_loss_epoch=0.0841, valid_loss=0.0381]        \n",
      "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0849, train_loss_epoch=0.0849, valid_loss=0.0381]        \n",
      "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.085, train_loss_epoch=0.085, valid_loss=0.0381]          \n",
      "Epoch 740: 100%|██████████| 1/1 [00:00<00:00,  4.23it/s, v_num=0, train_loss_step=0.085, train_loss_epoch=0.085, valid_loss=0.0381]\n",
      "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0852, train_loss_epoch=0.0852, valid_loss=0.0381]        \n",
      "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0836, train_loss_epoch=0.0836, valid_loss=0.0381]        \n",
      "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0825, train_loss_epoch=0.0825, valid_loss=0.0381]        \n",
      "Epoch 743: 100%|██████████| 1/1 [00:00<00:00,  3.62it/s, v_num=0, train_loss_step=0.0825, train_loss_epoch=0.0825, valid_loss=0.0381]\n",
      "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0823, train_loss_epoch=0.0823, valid_loss=0.0381]        \n",
      "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0822, train_loss_epoch=0.0822, valid_loss=0.0381]        \n",
      "Epoch 745: 100%|██████████| 1/1 [00:00<00:00,  4.08it/s, v_num=0, train_loss_step=0.0828, train_loss_epoch=0.0828, valid_loss=0.0381]\n",
      "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0828, train_loss_epoch=0.0828, valid_loss=0.0381]        \n",
      "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0838, train_loss_epoch=0.0838, valid_loss=0.0381]        \n",
      "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0832, train_loss_epoch=0.0832, valid_loss=0.0381]        \n",
      "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0831, train_loss_epoch=0.0831, valid_loss=0.0381]        \n",
      "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0838, train_loss_epoch=0.0838, valid_loss=0.0381]        \n",
      "Epoch 750: 100%|██████████| 1/1 [00:00<00:00,  3.66it/s, v_num=0, train_loss_step=0.0838, train_loss_epoch=0.0838, valid_loss=0.0381]\n",
      "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0834, train_loss_epoch=0.0834, valid_loss=0.0381]        \n",
      "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0816, train_loss_epoch=0.0816, valid_loss=0.0381]        \n",
      "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0801, train_loss_epoch=0.0801, valid_loss=0.0381]        \n",
      "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0805, train_loss_epoch=0.0805, valid_loss=0.0381]        \n",
      "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0814, train_loss_epoch=0.0814, valid_loss=0.0381]        \n",
      "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0808, train_loss_epoch=0.0808, valid_loss=0.0381]        \n",
      "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0804, train_loss_epoch=0.0804, valid_loss=0.0381]        \n",
      "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.081, train_loss_epoch=0.081, valid_loss=0.0381]          \n",
      "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0824, train_loss_epoch=0.0824, valid_loss=0.0381]        \n",
      "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0824, train_loss_epoch=0.0824, valid_loss=0.0381]        \n",
      "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0831, train_loss_epoch=0.0831, valid_loss=0.0381]        \n",
      "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0836, train_loss_epoch=0.0836, valid_loss=0.0381]        \n",
      "Epoch 762: 100%|██████████| 1/1 [00:00<00:00,  3.71it/s, v_num=0, train_loss_step=0.0815, train_loss_epoch=0.0836, valid_loss=0.0381]\n",
      "Epoch 762: 100%|██████████| 1/1 [00:00<00:00,  3.70it/s, v_num=0, train_loss_step=0.0815, train_loss_epoch=0.0815, valid_loss=0.0381]\n",
      "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0815, train_loss_epoch=0.0815, valid_loss=0.0381]        \n",
      "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0801, train_loss_epoch=0.0801, valid_loss=0.0381]        \n",
      "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0805, train_loss_epoch=0.0805, valid_loss=0.0381]        \n",
      "Epoch 766:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0805, train_loss_epoch=0.0805, valid_loss=0.0381]        \n",
      "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0798, train_loss_epoch=0.0798, valid_loss=0.0381]        \n",
      "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0792, train_loss_epoch=0.0792, valid_loss=0.0381]        \n",
      "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0795, train_loss_epoch=0.0795, valid_loss=0.0381]        \n",
      "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0791, train_loss_epoch=0.0791, valid_loss=0.0381]        \n",
      "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0792, train_loss_epoch=0.0792, valid_loss=0.0381]        \n",
      "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0795, train_loss_epoch=0.0795, valid_loss=0.0381]        \n",
      "Epoch 772: 100%|██████████| 1/1 [00:00<00:00,  3.86it/s, v_num=0, train_loss_step=0.0795, train_loss_epoch=0.0795, valid_loss=0.0381]\n",
      "Epoch 773:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0804, train_loss_epoch=0.0804, valid_loss=0.0381]        \n",
      "Epoch 773: 100%|██████████| 1/1 [00:00<00:00,  3.52it/s, v_num=0, train_loss_step=0.0804, train_loss_epoch=0.0804, valid_loss=0.0381]\n",
      "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0802, train_loss_epoch=0.0802, valid_loss=0.0381]        \n",
      "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0788, train_loss_epoch=0.0788, valid_loss=0.0381]        \n",
      "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0786, train_loss_epoch=0.0786, valid_loss=0.0381]        \n",
      "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0793, train_loss_epoch=0.0793, valid_loss=0.0381]        \n",
      "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0793, train_loss_epoch=0.0793, valid_loss=0.0381]        \n",
      "Epoch 779:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0794, train_loss_epoch=0.0794, valid_loss=0.0381]        \n",
      "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0797, train_loss_epoch=0.0797, valid_loss=0.0381]        \n",
      "Epoch 781:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0811, train_loss_epoch=0.0811, valid_loss=0.0381]        \n",
      "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0812, train_loss_epoch=0.0812, valid_loss=0.0381]        \n",
      "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0822, train_loss_epoch=0.0822, valid_loss=0.0381]        \n",
      "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.082, train_loss_epoch=0.082, valid_loss=0.0381]          \n",
      "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0806, train_loss_epoch=0.0806, valid_loss=0.0381]        \n",
      "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.080, train_loss_epoch=0.080, valid_loss=0.0381]          \n",
      "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0791, train_loss_epoch=0.0791, valid_loss=0.0381]        \n",
      "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0793, train_loss_epoch=0.0793, valid_loss=0.0381]        \n",
      "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0798, train_loss_epoch=0.0798, valid_loss=0.0381]        \n",
      "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0799, train_loss_epoch=0.0799, valid_loss=0.0381]        \n",
      "Epoch 790: 100%|██████████| 1/1 [00:00<00:00,  3.54it/s, v_num=0, train_loss_step=0.0799, train_loss_epoch=0.0799, valid_loss=0.0381]\n",
      "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0789, train_loss_epoch=0.0789, valid_loss=0.0381]        \n",
      "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0779, train_loss_epoch=0.0779, valid_loss=0.0381]        \n",
      "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0776, train_loss_epoch=0.0776, valid_loss=0.0381]        \n",
      "Epoch 794:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0783, train_loss_epoch=0.0783, valid_loss=0.0381]        \n",
      "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0795, train_loss_epoch=0.0795, valid_loss=0.0381]        \n",
      "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0798, train_loss_epoch=0.0798, valid_loss=0.0381]        \n",
      "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0799, train_loss_epoch=0.0799, valid_loss=0.0381]        \n",
      "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0799, train_loss_epoch=0.0799, valid_loss=0.0381]        \n",
      "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0796, train_loss_epoch=0.0796, valid_loss=0.0381]        \n",
      "Epoch 799: 100%|██████████| 1/1 [00:00<00:00,  3.58it/s, v_num=0, train_loss_step=0.0781, train_loss_epoch=0.0796, valid_loss=0.0381]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=4470)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  5.71it/s]\u001b[A\n",
      "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0781, train_loss_epoch=0.0781, valid_loss=0.0365]        \n",
      "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0766, train_loss_epoch=0.0766, valid_loss=0.0365]        \n",
      "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0756, train_loss_epoch=0.0756, valid_loss=0.0365]        \n",
      "Epoch 803:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0758, train_loss_epoch=0.0758, valid_loss=0.0365]        \n",
      "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0765, train_loss_epoch=0.0765, valid_loss=0.0365]        \n",
      "Epoch 805:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0773, train_loss_epoch=0.0773, valid_loss=0.0365]        \n",
      "Epoch 806:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0782, train_loss_epoch=0.0782, valid_loss=0.0365]        \n",
      "Epoch 806: 100%|██████████| 1/1 [00:00<00:00,  4.18it/s, v_num=0, train_loss_step=0.0782, train_loss_epoch=0.0782, valid_loss=0.0365]\n",
      "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0776, train_loss_epoch=0.0776, valid_loss=0.0365]        \n",
      "Epoch 808:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0766, train_loss_epoch=0.0766, valid_loss=0.0365]        \n",
      "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0758, train_loss_epoch=0.0758, valid_loss=0.0365]        \n",
      "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.076, train_loss_epoch=0.076, valid_loss=0.0365]          \n",
      "Epoch 811:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0771, train_loss_epoch=0.0771, valid_loss=0.0365]        \n",
      "Epoch 811: 100%|██████████| 1/1 [00:00<00:00,  3.67it/s, v_num=0, train_loss_step=0.0771, train_loss_epoch=0.0771, valid_loss=0.0365]\n",
      "Epoch 811: 100%|██████████| 1/1 [00:00<00:00,  3.54it/s, v_num=0, train_loss_step=0.0796, train_loss_epoch=0.0771, valid_loss=0.0365]\n",
      "Epoch 811: 100%|██████████| 1/1 [00:00<00:00,  3.52it/s, v_num=0, train_loss_step=0.0796, train_loss_epoch=0.0796, valid_loss=0.0365]\n",
      "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0796, train_loss_epoch=0.0796, valid_loss=0.0365]        \n",
      "Epoch 813:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0804, train_loss_epoch=0.0804, valid_loss=0.0365]        \n",
      "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0786, train_loss_epoch=0.0786, valid_loss=0.0365]        \n",
      "Epoch 815:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0776, train_loss_epoch=0.0776, valid_loss=0.0365]        \n",
      "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.078, train_loss_epoch=0.078, valid_loss=0.0365]          \n",
      "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.077, train_loss_epoch=0.077, valid_loss=0.0365]        \n",
      "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.076, train_loss_epoch=0.076, valid_loss=0.0365]        \n",
      "Epoch 819:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0752, train_loss_epoch=0.0752, valid_loss=0.0365]        \n",
      "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0753, train_loss_epoch=0.0753, valid_loss=0.0365]        \n",
      "Epoch 820: 100%|██████████| 1/1 [00:00<00:00,  3.74it/s, v_num=0, train_loss_step=0.0768, train_loss_epoch=0.0768, valid_loss=0.0365]\n",
      "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0768, train_loss_epoch=0.0768, valid_loss=0.0365]        \n",
      "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.078, train_loss_epoch=0.078, valid_loss=0.0365]          \n",
      "Epoch 823:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0783, train_loss_epoch=0.0783, valid_loss=0.0365]        \n",
      "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0773, train_loss_epoch=0.0773, valid_loss=0.0365]        \n",
      "Epoch 825:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0767, train_loss_epoch=0.0767, valid_loss=0.0365]        \n",
      "Epoch 825: 100%|██████████| 1/1 [00:00<00:00,  4.30it/s, v_num=0, train_loss_step=0.0767, train_loss_epoch=0.0767, valid_loss=0.0365]\n",
      "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0763, train_loss_epoch=0.0763, valid_loss=0.0365]        \n",
      "Epoch 827:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0752, train_loss_epoch=0.0752, valid_loss=0.0365]        \n",
      "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0739, train_loss_epoch=0.0739, valid_loss=0.0365]        \n",
      "Epoch 828: 100%|██████████| 1/1 [00:00<00:00,  3.70it/s, v_num=0, train_loss_step=0.0739, train_loss_epoch=0.0739, valid_loss=0.0365]\n",
      "Epoch 829:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0736, train_loss_epoch=0.0736, valid_loss=0.0365]        \n",
      "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.074, train_loss_epoch=0.074, valid_loss=0.0365]          \n",
      "Epoch 831:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0748, train_loss_epoch=0.0748, valid_loss=0.0365]        \n",
      "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0751, train_loss_epoch=0.0751, valid_loss=0.0365]        \n",
      "Epoch 833:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0755, train_loss_epoch=0.0755, valid_loss=0.0365]        \n",
      "Epoch 833: 100%|██████████| 1/1 [00:00<00:00,  3.23it/s, v_num=0, train_loss_step=0.0755, train_loss_epoch=0.0755, valid_loss=0.0365]\n",
      "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0749, train_loss_epoch=0.0749, valid_loss=0.0365]        \n",
      "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0744, train_loss_epoch=0.0744, valid_loss=0.0365]        \n",
      "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0744, train_loss_epoch=0.0744, valid_loss=0.0365]        \n",
      "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0748, train_loss_epoch=0.0748, valid_loss=0.0365]        \n",
      "Epoch 838:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0758, train_loss_epoch=0.0758, valid_loss=0.0365]        \n",
      "Epoch 838: 100%|██████████| 1/1 [00:00<00:00,  3.61it/s, v_num=0, train_loss_step=0.0761, train_loss_epoch=0.0761, valid_loss=0.0365]\n",
      "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0761, train_loss_epoch=0.0761, valid_loss=0.0365]        \n",
      "Epoch 840:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.077, train_loss_epoch=0.077, valid_loss=0.0365]          \n",
      "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0781, train_loss_epoch=0.0781, valid_loss=0.0365]        \n",
      "Epoch 842:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0765, train_loss_epoch=0.0765, valid_loss=0.0365]        \n",
      "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0738, train_loss_epoch=0.0738, valid_loss=0.0365]        \n",
      "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0734, train_loss_epoch=0.0734, valid_loss=0.0365]        \n",
      "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0744, train_loss_epoch=0.0744, valid_loss=0.0365]        \n",
      "Epoch 845: 100%|██████████| 1/1 [00:00<00:00,  3.65it/s, v_num=0, train_loss_step=0.0744, train_loss_epoch=0.0744, valid_loss=0.0365]\n",
      "Epoch 845: 100%|██████████| 1/1 [00:00<00:00,  3.50it/s, v_num=0, train_loss_step=0.075, train_loss_epoch=0.075, valid_loss=0.0365]  \n",
      "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.075, train_loss_epoch=0.075, valid_loss=0.0365]        \n",
      "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.075, train_loss_epoch=0.075, valid_loss=0.0365]\n",
      "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0756, train_loss_epoch=0.0756, valid_loss=0.0365]        \n",
      "Epoch 848:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0742, train_loss_epoch=0.0742, valid_loss=0.0365]        \n",
      "Epoch 849:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0733, train_loss_epoch=0.0733, valid_loss=0.0365]        \n",
      "Epoch 850:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0729, train_loss_epoch=0.0729, valid_loss=0.0365]        \n",
      "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0732, train_loss_epoch=0.0732, valid_loss=0.0365]        \n",
      "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0735, train_loss_epoch=0.0735, valid_loss=0.0365]        \n",
      "Epoch 853:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0736, train_loss_epoch=0.0736, valid_loss=0.0365]        \n",
      "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0739, train_loss_epoch=0.0739, valid_loss=0.0365]        \n",
      "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0749, train_loss_epoch=0.0749, valid_loss=0.0365]        \n",
      "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.076, train_loss_epoch=0.076, valid_loss=0.0365]          \n",
      "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0767, train_loss_epoch=0.0767, valid_loss=0.0365]        \n",
      "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0757, train_loss_epoch=0.0757, valid_loss=0.0365]        \n",
      "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0748, train_loss_epoch=0.0748, valid_loss=0.0365]        \n",
      "Epoch 860:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0734, train_loss_epoch=0.0734, valid_loss=0.0365]        \n",
      "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0726, train_loss_epoch=0.0726, valid_loss=0.0365]        \n",
      "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0725, train_loss_epoch=0.0725, valid_loss=0.0365]        \n",
      "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0733, train_loss_epoch=0.0733, valid_loss=0.0365]        \n",
      "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0749, train_loss_epoch=0.0749, valid_loss=0.0365]        \n",
      "Epoch 865:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0747, train_loss_epoch=0.0747, valid_loss=0.0365]        \n",
      "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0743, train_loss_epoch=0.0743, valid_loss=0.0365]        \n",
      "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0733, train_loss_epoch=0.0733, valid_loss=0.0365]        \n",
      "Epoch 867: 100%|██████████| 1/1 [00:00<00:00,  3.47it/s, v_num=0, train_loss_step=0.0733, train_loss_epoch=0.0733, valid_loss=0.0365]\n",
      "Epoch 868:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0723, train_loss_epoch=0.0723, valid_loss=0.0365]        \n",
      "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0714, train_loss_epoch=0.0714, valid_loss=0.0365]        \n",
      "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0712, train_loss_epoch=0.0712, valid_loss=0.0365]        \n",
      "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.071, train_loss_epoch=0.071, valid_loss=0.0365]          \n",
      "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0715, train_loss_epoch=0.0715, valid_loss=0.0365]        \n",
      "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0735, train_loss_epoch=0.0735, valid_loss=0.0365]        \n",
      "Epoch 874:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0762, train_loss_epoch=0.0762, valid_loss=0.0365]        \n",
      "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0758, train_loss_epoch=0.0758, valid_loss=0.0365]        \n",
      "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0741, train_loss_epoch=0.0741, valid_loss=0.0365]        \n",
      "Epoch 877:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0741, train_loss_epoch=0.0741, valid_loss=0.0365]        \n",
      "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0736, train_loss_epoch=0.0736, valid_loss=0.0365]        \n",
      "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0728, train_loss_epoch=0.0728, valid_loss=0.0365]        \n",
      "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0716, train_loss_epoch=0.0716, valid_loss=0.0365]        \n",
      "Epoch 881:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0712, train_loss_epoch=0.0712, valid_loss=0.0365]        \n",
      "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0722, train_loss_epoch=0.0722, valid_loss=0.0365]        \n",
      "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0738, train_loss_epoch=0.0738, valid_loss=0.0365]        \n",
      "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0748, train_loss_epoch=0.0748, valid_loss=0.0365]        \n",
      "Epoch 884: 100%|██████████| 1/1 [00:00<00:00,  3.79it/s, v_num=0, train_loss_step=0.0748, train_loss_epoch=0.0748, valid_loss=0.0365]\n",
      "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0751, train_loss_epoch=0.0751, valid_loss=0.0365]        \n",
      "Epoch 885: 100%|██████████| 1/1 [00:00<00:00,  3.38it/s, v_num=0, train_loss_step=0.0751, train_loss_epoch=0.0751, valid_loss=0.0365]\n",
      "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0735, train_loss_epoch=0.0735, valid_loss=0.0365]        \n",
      "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0717, train_loss_epoch=0.0717, valid_loss=0.0365]        \n",
      "Epoch 887: 100%|██████████| 1/1 [00:00<00:00,  3.20it/s, v_num=0, train_loss_step=0.0717, train_loss_epoch=0.0717, valid_loss=0.0365]\n",
      "Epoch 888:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0712, train_loss_epoch=0.0712, valid_loss=0.0365]        \n",
      "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.071, train_loss_epoch=0.071, valid_loss=0.0365]          \n",
      "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0712, train_loss_epoch=0.0712, valid_loss=0.0365]        \n",
      "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0719, train_loss_epoch=0.0719, valid_loss=0.0365]        \n",
      "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0722, train_loss_epoch=0.0722, valid_loss=0.0365]        \n",
      "Epoch 892: 100%|██████████| 1/1 [00:00<00:00,  3.35it/s, v_num=0, train_loss_step=0.0725, train_loss_epoch=0.0725, valid_loss=0.0365]\n",
      "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0725, train_loss_epoch=0.0725, valid_loss=0.0365]        \n",
      "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0732, train_loss_epoch=0.0732, valid_loss=0.0365]        \n",
      "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0732, train_loss_epoch=0.0732, valid_loss=0.0365]        \n",
      "Epoch 896:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0719, train_loss_epoch=0.0719, valid_loss=0.0365]        \n",
      "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0712, train_loss_epoch=0.0712, valid_loss=0.0365]        \n",
      "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.071, train_loss_epoch=0.071, valid_loss=0.0365]          \n",
      "Epoch 898: 100%|██████████| 1/1 [00:00<00:00,  3.30it/s, v_num=0, train_loss_step=0.071, train_loss_epoch=0.071, valid_loss=0.0365]\n",
      "Epoch 898: 100%|██████████| 1/1 [00:00<00:00,  3.18it/s, v_num=0, train_loss_step=0.0712, train_loss_epoch=0.0712, valid_loss=0.0365]\n",
      "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0712, train_loss_epoch=0.0712, valid_loss=0.0365]        \n",
      "Epoch 899: 100%|██████████| 1/1 [00:00<00:00,  3.35it/s, v_num=0, train_loss_step=0.0718, train_loss_epoch=0.0712, valid_loss=0.0365]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=4470)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s]\u001b[A\n",
      "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0718, train_loss_epoch=0.0718, valid_loss=0.0344]        \n",
      "Epoch 901:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0721, train_loss_epoch=0.0721, valid_loss=0.0344]        \n",
      "Epoch 902:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0721, train_loss_epoch=0.0721, valid_loss=0.0344]        \n",
      "Epoch 903:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0722, train_loss_epoch=0.0722, valid_loss=0.0344]        \n",
      "Epoch 904:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0725, train_loss_epoch=0.0725, valid_loss=0.0344]        \n",
      "Epoch 905:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0721, train_loss_epoch=0.0721, valid_loss=0.0344]        \n",
      "Epoch 906:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.071, train_loss_epoch=0.071, valid_loss=0.0344]          \n",
      "Epoch 907:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0707, train_loss_epoch=0.0707, valid_loss=0.0344]        \n",
      "Epoch 908:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0709, train_loss_epoch=0.0709, valid_loss=0.0344]        \n",
      "Epoch 908: 100%|██████████| 1/1 [00:00<00:00,  2.79it/s, v_num=0, train_loss_step=0.0709, train_loss_epoch=0.0709, valid_loss=0.0344]\n",
      "Epoch 909:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0709, train_loss_epoch=0.0709, valid_loss=0.0344]        \n",
      "Epoch 909: 100%|██████████| 1/1 [00:00<00:00,  3.32it/s, v_num=0, train_loss_step=0.0709, train_loss_epoch=0.0709, valid_loss=0.0344]\n",
      "Epoch 910:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0707, train_loss_epoch=0.0707, valid_loss=0.0344]        \n",
      "Epoch 911:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0706, train_loss_epoch=0.0706, valid_loss=0.0344]        \n",
      "Epoch 912:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0707, train_loss_epoch=0.0707, valid_loss=0.0344]        \n",
      "Epoch 913:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0707, train_loss_epoch=0.0707, valid_loss=0.0344]        \n",
      "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0704, train_loss_epoch=0.0704, valid_loss=0.0344]        \n",
      "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0704, train_loss_epoch=0.0704, valid_loss=0.0344]        \n",
      "Epoch 916:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0699, train_loss_epoch=0.0699, valid_loss=0.0344]        \n",
      "Epoch 916: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, v_num=0, train_loss_step=0.0695, train_loss_epoch=0.0699, valid_loss=0.0344]\n",
      "Epoch 916: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, v_num=0, train_loss_step=0.0695, train_loss_epoch=0.0695, valid_loss=0.0344]\n",
      "Epoch 917:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0695, train_loss_epoch=0.0695, valid_loss=0.0344]        \n",
      "Epoch 918:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0697, train_loss_epoch=0.0697, valid_loss=0.0344]        \n",
      "Epoch 919:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0704, train_loss_epoch=0.0704, valid_loss=0.0344]        \n",
      "Epoch 920:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0714, train_loss_epoch=0.0714, valid_loss=0.0344]        \n",
      "Epoch 921:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0724, train_loss_epoch=0.0724, valid_loss=0.0344]        \n",
      "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0728, train_loss_epoch=0.0728, valid_loss=0.0344]        \n",
      "Epoch 923:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0713, train_loss_epoch=0.0713, valid_loss=0.0344]        \n",
      "Epoch 924:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0705, train_loss_epoch=0.0705, valid_loss=0.0344]        \n",
      "Epoch 925:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0696, train_loss_epoch=0.0696, valid_loss=0.0344]        \n",
      "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.069, train_loss_epoch=0.069, valid_loss=0.0344]          \n",
      "Epoch 927:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0693, train_loss_epoch=0.0693, valid_loss=0.0344]        \n",
      "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0697, train_loss_epoch=0.0697, valid_loss=0.0344]        \n",
      "Epoch 929:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0702, train_loss_epoch=0.0702, valid_loss=0.0344]        \n",
      "Epoch 930:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0711, train_loss_epoch=0.0711, valid_loss=0.0344]        \n",
      "Epoch 931:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0716, train_loss_epoch=0.0716, valid_loss=0.0344]        \n",
      "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.070, train_loss_epoch=0.070, valid_loss=0.0344]          \n",
      "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0691, train_loss_epoch=0.0691, valid_loss=0.0344]        \n",
      "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0688, train_loss_epoch=0.0688, valid_loss=0.0344]        \n",
      "Epoch 934: 100%|██████████| 1/1 [00:00<00:00,  3.28it/s, v_num=0, train_loss_step=0.0688, train_loss_epoch=0.0688, valid_loss=0.0344]\n",
      "Epoch 935:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0689, train_loss_epoch=0.0689, valid_loss=0.0344]        \n",
      "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0691, train_loss_epoch=0.0691, valid_loss=0.0344]        \n",
      "Epoch 937:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0687, train_loss_epoch=0.0687, valid_loss=0.0344]        \n",
      "Epoch 938:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0684, train_loss_epoch=0.0684, valid_loss=0.0344]        \n",
      "Epoch 939:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0683, train_loss_epoch=0.0683, valid_loss=0.0344]        \n",
      "Epoch 939: 100%|██████████| 1/1 [00:00<00:00,  3.22it/s, v_num=0, train_loss_step=0.0683, train_loss_epoch=0.0683, valid_loss=0.0344]\n",
      "Epoch 939: 100%|██████████| 1/1 [00:00<00:00,  3.21it/s, v_num=0, train_loss_step=0.0683, train_loss_epoch=0.0683, valid_loss=0.0344]\n",
      "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0683, train_loss_epoch=0.0683, valid_loss=0.0344]        \n",
      "Epoch 940: 100%|██████████| 1/1 [00:00<00:00,  3.36it/s, v_num=0, train_loss_step=0.0683, train_loss_epoch=0.0683, valid_loss=0.0344]\n",
      "Epoch 940: 100%|██████████| 1/1 [00:00<00:00,  3.25it/s, v_num=0, train_loss_step=0.0682, train_loss_epoch=0.0683, valid_loss=0.0344]\n",
      "Epoch 940: 100%|██████████| 1/1 [00:00<00:00,  3.23it/s, v_num=0, train_loss_step=0.0682, train_loss_epoch=0.0682, valid_loss=0.0344]\n",
      "Epoch 941:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0682, train_loss_epoch=0.0682, valid_loss=0.0344]        \n",
      "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0677, train_loss_epoch=0.0677, valid_loss=0.0344]        \n",
      "Epoch 943:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0672, train_loss_epoch=0.0672, valid_loss=0.0344]        \n",
      "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0673, train_loss_epoch=0.0673, valid_loss=0.0344]        \n",
      "Epoch 945:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0683, train_loss_epoch=0.0683, valid_loss=0.0344]        \n",
      "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0711, train_loss_epoch=0.0711, valid_loss=0.0344]        \n",
      "Epoch 947:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0718, train_loss_epoch=0.0718, valid_loss=0.0344]        \n",
      "Epoch 948:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0699, train_loss_epoch=0.0699, valid_loss=0.0344]        \n",
      "Epoch 949:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0682, train_loss_epoch=0.0682, valid_loss=0.0344]        \n",
      "Epoch 949: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, v_num=0, train_loss_step=0.0677, train_loss_epoch=0.0682, valid_loss=0.0344]\n",
      "Epoch 949: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, v_num=0, train_loss_step=0.0677, train_loss_epoch=0.0677, valid_loss=0.0344]\n",
      "Epoch 950:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0677, train_loss_epoch=0.0677, valid_loss=0.0344]        \n",
      "Epoch 951:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0681, train_loss_epoch=0.0681, valid_loss=0.0344]        \n",
      "Epoch 952:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0688, train_loss_epoch=0.0688, valid_loss=0.0344]        \n",
      "Epoch 953:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0694, train_loss_epoch=0.0694, valid_loss=0.0344]        \n",
      "Epoch 953: 100%|██████████| 1/1 [00:00<00:00,  3.64it/s, v_num=0, train_loss_step=0.0692, train_loss_epoch=0.0692, valid_loss=0.0344]\n",
      "Epoch 954:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0692, train_loss_epoch=0.0692, valid_loss=0.0344]        \n",
      "Epoch 955:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0693, train_loss_epoch=0.0693, valid_loss=0.0344]        \n",
      "Epoch 955: 100%|██████████| 1/1 [00:00<00:00,  4.19it/s, v_num=0, train_loss_step=0.0693, train_loss_epoch=0.0693, valid_loss=0.0344]\n",
      "Epoch 956:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0689, train_loss_epoch=0.0689, valid_loss=0.0344]        \n",
      "Epoch 957:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0686, train_loss_epoch=0.0686, valid_loss=0.0344]        \n",
      "Epoch 958:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0694, train_loss_epoch=0.0694, valid_loss=0.0344]        \n",
      "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0699, train_loss_epoch=0.0699, valid_loss=0.0344]        \n",
      "Epoch 960:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0688, train_loss_epoch=0.0688, valid_loss=0.0344]        \n",
      "Epoch 961:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0678, train_loss_epoch=0.0678, valid_loss=0.0344]        \n",
      "Epoch 962:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0672, train_loss_epoch=0.0672, valid_loss=0.0344]        \n",
      "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0678, train_loss_epoch=0.0678, valid_loss=0.0344]        \n",
      "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0679, train_loss_epoch=0.0679, valid_loss=0.0344]        \n",
      "Epoch 965:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0676, train_loss_epoch=0.0676, valid_loss=0.0344]        \n",
      "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0676, train_loss_epoch=0.0676, valid_loss=0.0344]        \n",
      "Epoch 966: 100%|██████████| 1/1 [00:00<00:00,  3.23it/s, v_num=0, train_loss_step=0.0676, train_loss_epoch=0.0676, valid_loss=0.0344]\n",
      "Epoch 967:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0682, train_loss_epoch=0.0682, valid_loss=0.0344]        \n",
      "Epoch 968:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0684, train_loss_epoch=0.0684, valid_loss=0.0344]        \n",
      "Epoch 969:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0685, train_loss_epoch=0.0685, valid_loss=0.0344]        \n",
      "Epoch 969: 100%|██████████| 1/1 [00:00<00:00,  3.40it/s, v_num=0, train_loss_step=0.0684, train_loss_epoch=0.0684, valid_loss=0.0344]\n",
      "Epoch 970:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0684, train_loss_epoch=0.0684, valid_loss=0.0344]        \n",
      "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0683, train_loss_epoch=0.0683, valid_loss=0.0344]        \n",
      "Epoch 972:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0683, train_loss_epoch=0.0683, valid_loss=0.0344]        \n",
      "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0666, train_loss_epoch=0.0666, valid_loss=0.0344]        \n",
      "Epoch 973: 100%|██████████| 1/1 [00:00<00:00,  3.67it/s, v_num=0, train_loss_step=0.0666, train_loss_epoch=0.0666, valid_loss=0.0344]\n",
      "Epoch 973: 100%|██████████| 1/1 [00:00<00:00,  3.53it/s, v_num=0, train_loss_step=0.0656, train_loss_epoch=0.0656, valid_loss=0.0344]\n",
      "Epoch 974:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0656, train_loss_epoch=0.0656, valid_loss=0.0344]        \n",
      "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0653, train_loss_epoch=0.0653, valid_loss=0.0344]        \n",
      "Epoch 976:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0656, train_loss_epoch=0.0656, valid_loss=0.0344]        \n",
      "Epoch 977:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0667, train_loss_epoch=0.0667, valid_loss=0.0344]        \n",
      "Epoch 978:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0683, train_loss_epoch=0.0683, valid_loss=0.0344]        \n",
      "Epoch 979:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0689, train_loss_epoch=0.0689, valid_loss=0.0344]        \n",
      "Epoch 980:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0696, train_loss_epoch=0.0696, valid_loss=0.0344]        \n",
      "Epoch 981:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0699, train_loss_epoch=0.0699, valid_loss=0.0344]        \n",
      "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0684, train_loss_epoch=0.0684, valid_loss=0.0344]        \n",
      "Epoch 983:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0667, train_loss_epoch=0.0667, valid_loss=0.0344]        \n",
      "Epoch 984:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0664, train_loss_epoch=0.0664, valid_loss=0.0344]        \n",
      "Epoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0663, train_loss_epoch=0.0663, valid_loss=0.0344]        \n",
      "Epoch 986:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0669, train_loss_epoch=0.0669, valid_loss=0.0344]        \n",
      "Epoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0678, train_loss_epoch=0.0678, valid_loss=0.0344]        \n",
      "Epoch 987: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s, v_num=0, train_loss_step=0.0693, train_loss_epoch=0.0678, valid_loss=0.0344]\n",
      "Epoch 987: 100%|██████████| 1/1 [00:00<00:00,  2.94it/s, v_num=0, train_loss_step=0.0693, train_loss_epoch=0.0693, valid_loss=0.0344]\n",
      "Epoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0693, train_loss_epoch=0.0693, valid_loss=0.0344]        \n",
      "Epoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0683, train_loss_epoch=0.0683, valid_loss=0.0344]        \n",
      "Epoch 989: 100%|██████████| 1/1 [00:00<00:00,  3.35it/s, v_num=0, train_loss_step=0.0683, train_loss_epoch=0.0683, valid_loss=0.0344]\n",
      "Epoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0668, train_loss_epoch=0.0668, valid_loss=0.0344]        \n",
      "Epoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0658, train_loss_epoch=0.0658, valid_loss=0.0344]        \n",
      "Epoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0653, train_loss_epoch=0.0653, valid_loss=0.0344]        \n",
      "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0652, train_loss_epoch=0.0652, valid_loss=0.0344]        \n",
      "Epoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0663, train_loss_epoch=0.0663, valid_loss=0.0344]        \n",
      "Epoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0674, train_loss_epoch=0.0674, valid_loss=0.0344]        \n",
      "Epoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0693, train_loss_epoch=0.0693, valid_loss=0.0344]        \n",
      "Epoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0686, train_loss_epoch=0.0686, valid_loss=0.0344]        \n",
      "Epoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0671, train_loss_epoch=0.0671, valid_loss=0.0344]        \n",
      "Epoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.066, train_loss_epoch=0.066, valid_loss=0.0344]          \n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00,  2.83it/s, v_num=0, train_loss_step=0.0658, train_loss_epoch=0.066, valid_loss=0.0344]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=4470)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s]\u001b[A\n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00,  1.93it/s, v_num=0, train_loss_step=0.0658, train_loss_epoch=0.0658, valid_loss=0.0346]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=4470)\u001b[0m `Trainer.fit` stopped: `max_steps=1000` reached.\n",
      "\u001b[36m(_train_tune pid=5412)\u001b[0m /home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=5412)\u001b[0m Seed set to 7\n",
      "\u001b[36m(_train_tune pid=5412)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=5412)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=5412)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=5412)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(_train_tune pid=5412)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_train_tune pid=5412)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=5412)\u001b[0m   | Name            | Type          | Params | Mode \n",
      "\u001b[36m(_train_tune pid=5412)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=5412)\u001b[0m 0 | loss            | WMAPE         | 0      | train\n",
      "\u001b[36m(_train_tune pid=5412)\u001b[0m 1 | padder          | ConstantPad1d | 0      | train\n",
      "\u001b[36m(_train_tune pid=5412)\u001b[0m 2 | scaler          | TemporalNorm  | 0      | train\n",
      "\u001b[36m(_train_tune pid=5412)\u001b[0m 3 | hist_encoder    | LSTM          | 122 K  | train\n",
      "\u001b[36m(_train_tune pid=5412)\u001b[0m 4 | context_adapter | Linear        | 388 K  | train\n",
      "\u001b[36m(_train_tune pid=5412)\u001b[0m 5 | mlp_decoder     | MLP           | 26.6 K | train\n",
      "\u001b[36m(_train_tune pid=5412)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=5412)\u001b[0m 537 K     Trainable params\n",
      "\u001b[36m(_train_tune pid=5412)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=5412)\u001b[0m 537 K     Total params\n",
      "\u001b[36m(_train_tune pid=5412)\u001b[0m 2.150     Total estimated model params size (MB)\n",
      "\u001b[36m(_train_tune pid=5412)\u001b[0m 11        Modules in train mode\n",
      "\u001b[36m(_train_tune pid=5412)\u001b[0m 0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 14.13it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=1.000]\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 13.72it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997]\n",
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997]        \n",
      "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997]\n",
      "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.931, train_loss_epoch=0.931]        \n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 22.01it/s, v_num=0, train_loss_step=0.726, train_loss_epoch=0.726]\n",
      "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.737, train_loss_epoch=0.737]        \n",
      "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.780, train_loss_epoch=0.780]        \n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 30.20it/s, v_num=0, train_loss_step=0.870, train_loss_epoch=0.870]\n",
      "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.923, train_loss_epoch=0.923]       \n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00, 31.50it/s, v_num=0, train_loss_step=0.924, train_loss_epoch=0.924]\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00, 20.32it/s, v_num=0, train_loss_step=0.915, train_loss_epoch=0.915]\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00, 12.43it/s, v_num=0, train_loss_step=0.896, train_loss_epoch=0.896]\n",
      "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.896, train_loss_epoch=0.896]        \n",
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.862, train_loss_epoch=0.862]        \n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00, 27.66it/s, v_num=0, train_loss_step=0.810, train_loss_epoch=0.810]\n",
      "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.714, train_loss_epoch=0.714]        \n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00, 27.23it/s, v_num=0, train_loss_step=0.723, train_loss_epoch=0.723]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.07it/s, v_num=0, train_loss_step=0.700, train_loss_epoch=0.721]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.68it/s, v_num=0, train_loss_step=0.700, train_loss_epoch=0.700]\n",
      "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.700, train_loss_epoch=0.700]        \n",
      "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.668, train_loss_epoch=0.668]        \n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00, 25.32it/s, v_num=0, train_loss_step=0.647, train_loss_epoch=0.647]\n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00, 13.21it/s, v_num=0, train_loss_step=0.633, train_loss_epoch=0.633]\n",
      "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.633, train_loss_epoch=0.633]        \n",
      "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.641, train_loss_epoch=0.641]        \n",
      "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.624, train_loss_epoch=0.624]        \n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00, 23.91it/s, v_num=0, train_loss_step=0.631, train_loss_epoch=0.631]\n",
      "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.600, train_loss_epoch=0.600]        \n",
      "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.599, train_loss_epoch=0.599]        \n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00, 27.57it/s, v_num=0, train_loss_step=0.584, train_loss_epoch=0.584]\n",
      "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.596, train_loss_epoch=0.596]        \n",
      "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.587, train_loss_epoch=0.587]        \n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00, 23.67it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582]\n",
      "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582]        \n",
      "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.584, train_loss_epoch=0.584]        \n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00, 21.55it/s, v_num=0, train_loss_step=0.576, train_loss_epoch=0.576]\n",
      "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.572]        \n",
      "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.572]        \n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00, 28.88it/s, v_num=0, train_loss_step=0.575, train_loss_epoch=0.575]\n",
      "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567]        \n",
      "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.566, train_loss_epoch=0.566]        \n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00, 23.82it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567]\n",
      "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565]        \n",
      "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565]        \n",
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00, 23.08it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564]\n",
      "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564]        \n",
      "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563]        \n",
      "Epoch 55: 100%|██████████| 1/1 [00:00<00:00, 23.98it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562]\n",
      "Epoch 56: 100%|██████████| 1/1 [00:00<00:00, 12.43it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563]\n",
      "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563]        \n",
      "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562]        \n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 22.88it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561]\n",
      "Epoch 60: 100%|██████████| 1/1 [00:00<00:00, 22.07it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561]\n",
      "Epoch 60: 100%|██████████| 1/1 [00:00<00:00, 12.45it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561]\n",
      "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560]        \n",
      "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560]        \n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00, 24.68it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559]\n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00, 12.53it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.560]\n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00, 12.21it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559]\n",
      "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559]        \n",
      "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558]        \n",
      "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558]        \n",
      "Epoch 69: 100%|██████████| 1/1 [00:00<00:00, 22.56it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558]\n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00, 19.47it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558]\n",
      "Epoch 71: 100%|██████████| 1/1 [00:00<00:00, 18.58it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557]\n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00, 18.02it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557]\n",
      "Epoch 73: 100%|██████████| 1/1 [00:00<00:00, 17.85it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557]\n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00, 17.82it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557]\n",
      "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556]        \n",
      "Epoch 75: 100%|██████████| 1/1 [00:00<00:00, 16.21it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556]\n",
      "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556]        \n",
      "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556]        \n",
      "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555]        \n",
      "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555]        \n",
      "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554]        \n",
      "Epoch 80: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.554]\n",
      "Epoch 80: 100%|██████████| 1/1 [00:00<00:00,  8.84it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553]\n",
      "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553]        \n",
      "Epoch 81: 100%|██████████| 1/1 [00:00<00:00, 17.09it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553]\n",
      "Epoch 81: 100%|██████████| 1/1 [00:00<00:00,  8.96it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552]\n",
      "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552]        \n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00, 17.49it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552]\n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00,  9.08it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.552]\n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00,  8.90it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550]\n",
      "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550]        \n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00, 18.14it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550]\n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00,  9.25it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549]\n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00, 18.59it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549]\n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00, 17.43it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564]\n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00, 18.48it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562]\n",
      "Epoch 87: 100%|██████████| 1/1 [00:00<00:00, 19.10it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561]\n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00, 17.83it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545]\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00, 17.40it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568]\n",
      "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546]        \n",
      "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552]        \n",
      "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553]        \n",
      "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544]        \n",
      "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548]        \n",
      "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543]        \n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00, 17.77it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543]\n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00,  9.11it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.543]\n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00,  8.96it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571]\n",
      "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571]        \n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00, 16.91it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571]\n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00,  8.92it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.571]\n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00,  8.61it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553]\n",
      "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553]        \n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00, 16.29it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553]\n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00,  8.89it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.553]\n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00,  8.70it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561]\n",
      "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561]        \n",
      "Epoch 98: 100%|██████████| 1/1 [00:00<00:00, 17.25it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561]\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 18.34it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545]\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  9.38it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.545]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 20.58it/s]\u001b[A\n",
      "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571, valid_loss=0.0426]       \n",
      "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=0.0426]        \n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00,  8.43it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=0.0426]\n",
      "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=0.0426]        \n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00, 16.76it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=0.0426]\n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00,  9.08it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.564, valid_loss=0.0426]\n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00,  8.91it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.0426]\n",
      "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.0426]        \n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00,  9.61it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.557, valid_loss=0.0426]\n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00,  9.44it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561, valid_loss=0.0426]\n",
      "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561, valid_loss=0.0426]        \n",
      "Epoch 104: 100%|██████████| 1/1 [00:00<00:00, 15.65it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561, valid_loss=0.0426]\n",
      "Epoch 105: 100%|██████████| 1/1 [00:00<00:00, 19.12it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0426]\n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00, 17.85it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.0426]\n",
      "Epoch 107: 100%|██████████| 1/1 [00:00<00:00, 18.17it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.0426]\n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00, 18.88it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.0426]\n",
      "Epoch 109: 100%|██████████| 1/1 [00:00<00:00, 17.21it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0426]\n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00, 17.97it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0426]\n",
      "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0426]        \n",
      "Epoch 111: 100%|██████████| 1/1 [00:00<00:00, 18.27it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0426]\n",
      "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0426]        \n",
      "Epoch 112: 100%|██████████| 1/1 [00:00<00:00, 20.34it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0426]\n",
      "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.0426]        \n",
      "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.0426]        \n",
      "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0426]        \n",
      "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=0.0426]        \n",
      "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574, valid_loss=0.0426]        \n",
      "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.566, train_loss_epoch=0.566, valid_loss=0.0426]        \n",
      "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.0426]        \n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00,  9.71it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=0.0426]\n",
      "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=0.0426]        \n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00,  9.08it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0426]\n",
      "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0426]        \n",
      "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0426]\n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00,  9.20it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.547, valid_loss=0.0426]\n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00,  8.96it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=0.0426]\n",
      "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=0.0426]        \n",
      "Epoch 122: 100%|██████████| 1/1 [00:00<00:00, 16.34it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=0.0426]\n",
      "Epoch 122: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.543, valid_loss=0.0426]\n",
      "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565, valid_loss=0.0426]        \n",
      "Epoch 123: 100%|██████████| 1/1 [00:00<00:00, 18.11it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565, valid_loss=0.0426]\n",
      "Epoch 123: 100%|██████████| 1/1 [00:00<00:00,  9.05it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.565, valid_loss=0.0426]\n",
      "Epoch 123: 100%|██████████| 1/1 [00:00<00:00,  8.89it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.0426]\n",
      "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.0426]        \n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00, 15.94it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.0426]\n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00,  8.78it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.550, valid_loss=0.0426]\n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00,  8.57it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.0426]\n",
      "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.0426]        \n",
      "Epoch 125: 100%|██████████| 1/1 [00:00<00:00,  9.20it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0426]\n",
      "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0426]        \n",
      "Epoch 126: 100%|██████████| 1/1 [00:00<00:00, 16.44it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0426]\n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00, 18.18it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.0426]\n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00, 17.58it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0426]\n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00, 18.69it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0426]\n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00, 17.21it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0426]\n",
      "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0426]        \n",
      "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0426]        \n",
      "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0426]        \n",
      "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=0.0426]        \n",
      "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0426]        \n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00, 16.63it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0426]\n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00,  8.73it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.527, valid_loss=0.0426]\n",
      "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0426]        \n",
      "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0426]\n",
      "Epoch 136: 100%|██████████| 1/1 [00:00<00:00, 14.34it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0426]\n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00, 18.30it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=0.0426]\n",
      "Epoch 138: 100%|██████████| 1/1 [00:00<00:00, 18.48it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0426]\n",
      "Epoch 139: 100%|██████████| 1/1 [00:00<00:00, 17.17it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0426]\n",
      "Epoch 140: 100%|██████████| 1/1 [00:00<00:00, 18.17it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=0.0426]\n",
      "Epoch 141: 100%|██████████| 1/1 [00:00<00:00, 20.55it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0426]\n",
      "Epoch 142: 100%|██████████| 1/1 [00:00<00:00, 17.18it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.0426]\n",
      "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0426]        \n",
      "Epoch 143: 100%|██████████| 1/1 [00:00<00:00, 16.44it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0426]\n",
      "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0426]        \n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00, 17.41it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0426]\n",
      "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0426]        \n",
      "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0426]        \n",
      "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0426]        \n",
      "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0426]        \n",
      "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0426]        \n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 16.93it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0426]\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.519, valid_loss=0.0426]\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00,  8.55it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0426]\n",
      "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0426]        \n",
      "Epoch 150: 100%|██████████| 1/1 [00:00<00:00, 17.27it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0426]\n",
      "Epoch 151: 100%|██████████| 1/1 [00:00<00:00, 19.59it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0426]\n",
      "Epoch 152: 100%|██████████| 1/1 [00:00<00:00, 17.67it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0426]\n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0426]\n",
      "Epoch 154: 100%|██████████| 1/1 [00:00<00:00, 16.66it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0426]\n",
      "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0426]        \n",
      "Epoch 155: 100%|██████████| 1/1 [00:00<00:00, 17.22it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0426]\n",
      "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0426]        \n",
      "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0426]        \n",
      "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0426]        \n",
      "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0426]        \n",
      "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0426]        \n",
      "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0426]        \n",
      "Epoch 161: 100%|██████████| 1/1 [00:00<00:00,  8.71it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0426]\n",
      "Epoch 162: 100%|██████████| 1/1 [00:00<00:00, 16.94it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0426]\n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00, 17.34it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0426]\n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00, 18.14it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0426]\n",
      "Epoch 165: 100%|██████████| 1/1 [00:00<00:00, 17.98it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0426]\n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00, 18.02it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0426]\n",
      "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0426]        \n",
      "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0426]        \n",
      "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0426]        \n",
      "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0426]        \n",
      "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0426]        \n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00,  8.85it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0426]\n",
      "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0426]        \n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00, 18.42it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0426]\n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00,  8.90it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0426]\n",
      "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0426]        \n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0426]\n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00,  8.90it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.504, valid_loss=0.0426]\n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00,  8.81it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0426]\n",
      "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0426]        \n",
      "Epoch 174: 100%|██████████| 1/1 [00:00<00:00, 17.96it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0426]\n",
      "Epoch 174: 100%|██████████| 1/1 [00:00<00:00,  9.28it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.502, valid_loss=0.0426]\n",
      "Epoch 174: 100%|██████████| 1/1 [00:00<00:00,  8.85it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0426]\n",
      "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0426]        \n",
      "Epoch 175: 100%|██████████| 1/1 [00:00<00:00,  9.20it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.501, valid_loss=0.0426]\n",
      "Epoch 175: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0426]\n",
      "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0426]        \n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00, 18.08it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0426]\n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00,  9.22it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.500, valid_loss=0.0426]\n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00,  8.79it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0426]\n",
      "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0426]        \n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00, 16.99it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0426]\n",
      "Epoch 178: 100%|██████████| 1/1 [00:00<00:00, 19.61it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0426]\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 18.47it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0426]\n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00, 18.45it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0426]\n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00, 18.41it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0426]\n",
      "Epoch 182: 100%|██████████| 1/1 [00:00<00:00, 14.31it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0426]\n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00, 21.25it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0426]\n",
      "Epoch 184: 100%|██████████| 1/1 [00:00<00:00, 19.10it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0426]\n",
      "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0426]        \n",
      "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0426]        \n",
      "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0426]        \n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00,  8.78it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0426]\n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00,  8.55it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0426]\n",
      "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0426]        \n",
      "Epoch 188: 100%|██████████| 1/1 [00:00<00:00, 16.27it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0426]\n",
      "Epoch 188: 100%|██████████| 1/1 [00:00<00:00,  8.44it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0426]\n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00, 15.86it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0426]\n",
      "Epoch 190: 100%|██████████| 1/1 [00:00<00:00, 17.59it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0426]\n",
      "Epoch 191: 100%|██████████| 1/1 [00:00<00:00, 16.16it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0426]\n",
      "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0426]        \n",
      "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0426]        \n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00, 20.58it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0426]\n",
      "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0426]        \n",
      "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0426]        \n",
      "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0426]        \n",
      "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0426]        \n",
      "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0426]        \n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00,  9.02it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.491, valid_loss=0.0426]\n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00,  8.81it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0426]\n",
      "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0426]        \n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  9.30it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.490, valid_loss=0.0426]\n",
      "\u001b[36m(_train_tune pid=5412)\u001b[0m \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 19.72it/s]\u001b[A\n",
      "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0371]        \n",
      "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0371]        \n",
      "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0371]        \n",
      "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0371]        \n",
      "Epoch 203: 100%|██████████| 1/1 [00:00<00:00, 16.09it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0371]\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00, 19.16it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0371]\n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00, 22.16it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0371]\n",
      "Epoch 206: 100%|██████████| 1/1 [00:00<00:00, 16.78it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0371]\n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00, 17.82it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0371]\n",
      "Epoch 208: 100%|██████████| 1/1 [00:00<00:00, 17.53it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0371]\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 17.12it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0371]\n",
      "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0371]        \n",
      "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0371]        \n",
      "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0371]        \n",
      "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0371]        \n",
      "Epoch 213: 100%|██████████| 1/1 [00:00<00:00,  9.02it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.484, valid_loss=0.0371]\n",
      "Epoch 213: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0371]\n",
      "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0371]        \n",
      "Epoch 214: 100%|██████████| 1/1 [00:00<00:00, 16.35it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0371]\n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00, 18.88it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.0371]\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00, 17.37it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=0.0371]\n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00, 17.93it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.0371]\n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00, 16.87it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.0371]\n",
      "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0371]        \n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00, 16.99it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0371]\n",
      "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0371]        \n",
      "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=0.0371]        \n",
      "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.579, train_loss_epoch=0.579, valid_loss=0.0371]        \n",
      "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.579, train_loss_epoch=0.579, valid_loss=0.0371]        \n",
      "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.570, train_loss_epoch=0.570, valid_loss=0.0371]        \n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00, 16.07it/s, v_num=0, train_loss_step=0.570, train_loss_epoch=0.570, valid_loss=0.0371]\n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00, 18.26it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568, valid_loss=0.0371]\n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00, 13.73it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.0371]\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562, valid_loss=0.0371]\n",
      "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0371]        \n",
      "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0371]        \n",
      "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0371]        \n",
      "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0371]        \n",
      "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=0.0371]        \n",
      "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=0.0371]        \n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00, 16.85it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=0.0371]\n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00, 19.98it/s, v_num=0, train_loss_step=0.575, train_loss_epoch=0.575, valid_loss=0.0371]\n",
      "Epoch 235: 100%|██████████| 1/1 [00:00<00:00, 20.65it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0371]\n",
      "Epoch 236: 100%|██████████| 1/1 [00:00<00:00, 19.24it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0371]\n",
      "Epoch 237: 100%|██████████| 1/1 [00:00<00:00, 17.95it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.0371]\n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00, 20.47it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.0371]\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 20.46it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569, valid_loss=0.0371]\n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00, 20.88it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562, valid_loss=0.0371]\n",
      "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0371]        \n",
      "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0371]        \n",
      "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.0371]        \n",
      "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.0371]        \n",
      "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0371]        \n",
      "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574, valid_loss=0.0371]        \n",
      "Epoch 246: 100%|██████████| 1/1 [00:00<00:00, 19.13it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574, valid_loss=0.0371]\n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00, 18.65it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0371]\n",
      "Epoch 248: 100%|██████████| 1/1 [00:00<00:00, 17.69it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.0371]\n",
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=0.0371]\n",
      "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0371]        \n",
      "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=0.0371]        \n",
      "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=0.0371]        \n",
      "Epoch 252: 100%|██████████| 1/1 [00:00<00:00, 13.56it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=0.0371]\n",
      "Epoch 253: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.0371]\n",
      "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.0371]        \n",
      "Epoch 254: 100%|██████████| 1/1 [00:00<00:00, 15.81it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.0371]\n",
      "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0371]        \n",
      "Epoch 255: 100%|██████████| 1/1 [00:00<00:00, 19.12it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0371]\n",
      "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0371]        \n",
      "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0371]        \n",
      "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0371]        \n",
      "Epoch 258: 100%|██████████| 1/1 [00:00<00:00,  9.12it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0371]\n",
      "Epoch 258: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0371]\n",
      "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0371]        \n",
      "Epoch 259: 100%|██████████| 1/1 [00:00<00:00, 17.36it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0371]\n",
      "Epoch 260: 100%|██████████| 1/1 [00:00<00:00, 20.10it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0371]\n",
      "Epoch 261: 100%|██████████| 1/1 [00:00<00:00, 19.30it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0371]\n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00, 16.84it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0371]\n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00, 15.58it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0371]\n",
      "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0371]        \n",
      "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0371]        \n",
      "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0371]        \n",
      "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0371]        \n",
      "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0371]\n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00,  9.48it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.515, valid_loss=0.0371]\n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00,  9.35it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0371]\n",
      "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0371]        \n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00, 17.93it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0371]\n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 17.39it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0371]\n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00, 16.65it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0371]\n",
      "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0371]        \n",
      "Epoch 271: 100%|██████████| 1/1 [00:00<00:00, 15.52it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0371]\n",
      "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0371]        \n",
      "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0371]        \n",
      "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0371]        \n",
      "Epoch 274: 100%|██████████| 1/1 [00:00<00:00, 13.96it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0371]\n",
      "Epoch 274: 100%|██████████| 1/1 [00:00<00:00,  8.16it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.504, valid_loss=0.0371]\n",
      "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0371]        \n",
      "Epoch 275: 100%|██████████| 1/1 [00:00<00:00, 19.30it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0371]\n",
      "Epoch 275: 100%|██████████| 1/1 [00:00<00:00,  9.26it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.532, valid_loss=0.0371]\n",
      "Epoch 275: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0371]\n",
      "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0371]        \n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00, 12.32it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0371]\n",
      "Epoch 277: 100%|██████████| 1/1 [00:00<00:00, 21.15it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0371]\n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00, 18.07it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0371]\n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00, 18.77it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0371]\n",
      "Epoch 280: 100%|██████████| 1/1 [00:00<00:00, 19.88it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0371]\n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00, 21.42it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0371]\n",
      "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0371]        \n",
      "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0371]        \n",
      "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0371]        \n",
      "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0371]        \n",
      "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0371]        \n",
      "Epoch 286: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.507, valid_loss=0.0371]\n",
      "Epoch 286: 100%|██████████| 1/1 [00:00<00:00,  8.60it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0371]\n",
      "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0371]        \n",
      "Epoch 287: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0371]\n",
      "Epoch 288: 100%|██████████| 1/1 [00:00<00:00, 15.45it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0371]\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00, 16.59it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0371]\n",
      "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0371]        \n",
      "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0371]        \n",
      "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0371]        \n",
      "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0371]        \n",
      "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0371]        \n",
      "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0371]        \n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00, 15.74it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0371]\n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00,  8.29it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.513, valid_loss=0.0371]\n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00,  8.14it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0371]\n",
      "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0371]        \n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00, 15.68it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0371]\n",
      "Epoch 297: 100%|██████████| 1/1 [00:00<00:00, 19.41it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0371]\n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00, 18.32it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0371]\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 17.53it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0371]\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  9.06it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.509, valid_loss=0.0371]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 21.88it/s]\u001b[A\n",
      "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0321]        \n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00,  9.30it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0321]\n",
      "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0321]        \n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00, 17.13it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0321]\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00, 19.61it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0321]\n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00, 14.27it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0321]\n",
      "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0321]        \n",
      "Epoch 304: 100%|██████████| 1/1 [00:00<00:00, 16.46it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0321]\n",
      "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0321]        \n",
      "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0321]        \n",
      "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0321]        \n",
      "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0321]        \n",
      "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0321]        \n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00, 18.12it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0321]\n",
      "Epoch 310: 100%|██████████| 1/1 [00:00<00:00, 20.54it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0321]\n",
      "Epoch 311: 100%|██████████| 1/1 [00:00<00:00, 18.32it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0321]\n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00, 15.65it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0321]\n",
      "Epoch 313: 100%|██████████| 1/1 [00:00<00:00, 19.37it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0321]\n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00, 17.85it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0321]\n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00, 21.75it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0321]\n",
      "Epoch 316: 100%|██████████| 1/1 [00:00<00:00, 20.89it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0321]\n",
      "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0321]        \n",
      "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0321]        \n",
      "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0321]        \n",
      "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0321]        \n",
      "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0321]        \n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00,  8.93it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0321]\n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00,  8.77it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0321]\n",
      "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0321]        \n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00, 15.16it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0321]\n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00, 14.07it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0321]\n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00, 17.46it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0321]\n",
      "Epoch 325: 100%|██████████| 1/1 [00:00<00:00, 18.47it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0321]\n",
      "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0321]        \n",
      "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0321]        \n",
      "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0321]        \n",
      "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0321]        \n",
      "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0321]        \n",
      "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0321]        \n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00, 17.43it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0321]\n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00,  8.93it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0321]\n",
      "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0321]        \n",
      "Epoch 332: 100%|██████████| 1/1 [00:00<00:00,  9.18it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.491, valid_loss=0.0321]\n",
      "Epoch 332: 100%|██████████| 1/1 [00:00<00:00,  8.98it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0321]\n",
      "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0321]        \n",
      "Epoch 333: 100%|██████████| 1/1 [00:00<00:00, 16.30it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0321]\n",
      "Epoch 334: 100%|██████████| 1/1 [00:00<00:00, 17.92it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0321]\n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00, 17.07it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0321]\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00, 17.90it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0321]\n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00, 16.93it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0321]\n",
      "Epoch 338: 100%|██████████| 1/1 [00:00<00:00, 20.22it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0321]\n",
      "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0321]        \n",
      "Epoch 339: 100%|██████████| 1/1 [00:00<00:00, 17.13it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0321]\n",
      "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0321]        \n",
      "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0321]        \n",
      "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0321]        \n",
      "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0321]        \n",
      "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0321]        \n",
      "Epoch 344: 100%|██████████| 1/1 [00:00<00:00, 17.28it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0321]\n",
      "Epoch 344: 100%|██████████| 1/1 [00:00<00:00,  8.90it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0321]\n",
      "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0321]        \n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00, 19.22it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0321]\n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00,  8.98it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0321]\n",
      "Epoch 346: 100%|██████████| 1/1 [00:00<00:00, 18.24it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0321]\n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00, 15.49it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0321]\n",
      "Epoch 348: 100%|██████████| 1/1 [00:00<00:00, 17.08it/s, v_num=0, train_loss_step=0.475, train_loss_epoch=0.475, valid_loss=0.0321]\n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00, 17.90it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0321]\n",
      "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.0321]        \n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00, 16.73it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.0321]\n",
      "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0321]        \n",
      "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0321]        \n",
      "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.474, train_loss_epoch=0.474, valid_loss=0.0321]        \n",
      "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0321]        \n",
      "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0321]        \n",
      "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.0321]        \n",
      "Epoch 356: 100%|██████████| 1/1 [00:00<00:00, 18.02it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.0321]\n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00, 17.49it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0321]\n",
      "Epoch 358: 100%|██████████| 1/1 [00:00<00:00, 17.32it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.468, valid_loss=0.0321]\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 16.08it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0321]\n",
      "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0321]        \n",
      "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0321]        \n",
      "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0321]        \n",
      "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0321]        \n",
      "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0321]        \n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00,  9.03it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.506, valid_loss=0.0321]\n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00,  8.69it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0321]\n",
      "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0321]        \n",
      "Epoch 365: 100%|██████████| 1/1 [00:00<00:00,  8.98it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0321]\n",
      "Epoch 365: 100%|██████████| 1/1 [00:00<00:00,  8.73it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0321]\n",
      "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0321]        \n",
      "Epoch 366: 100%|██████████| 1/1 [00:00<00:00, 13.85it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0321]\n",
      "Epoch 367: 100%|██████████| 1/1 [00:00<00:00, 14.63it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0321]\n",
      "Epoch 368: 100%|██████████| 1/1 [00:00<00:00, 17.87it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0321]\n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00, 18.19it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0321]\n",
      "Epoch 370: 100%|██████████| 1/1 [00:00<00:00, 22.34it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0321]\n",
      "Epoch 371: 100%|██████████| 1/1 [00:00<00:00, 19.11it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0321]\n",
      "Epoch 372: 100%|██████████| 1/1 [00:00<00:00, 21.82it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0321]\n",
      "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0321]        \n",
      "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0321]        \n",
      "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0321]        \n",
      "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0321]        \n",
      "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0321]        \n",
      "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0321]        \n",
      "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0321]        \n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00,  9.26it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.478, valid_loss=0.0321]\n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00,  9.02it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.0321]\n",
      "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.0321]        \n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00, 15.80it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.0321]\n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00,  8.52it/s, v_num=0, train_loss_step=0.475, train_loss_epoch=0.476, valid_loss=0.0321]\n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00,  8.24it/s, v_num=0, train_loss_step=0.475, train_loss_epoch=0.475, valid_loss=0.0321]\n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00, 16.92it/s, v_num=0, train_loss_step=0.475, train_loss_epoch=0.475, valid_loss=0.0321]\n",
      "Epoch 382: 100%|██████████| 1/1 [00:00<00:00, 17.25it/s, v_num=0, train_loss_step=0.475, train_loss_epoch=0.475, valid_loss=0.0321]\n",
      "Epoch 383: 100%|██████████| 1/1 [00:00<00:00, 17.47it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.0321]\n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=0.0321]\n",
      "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.0321]        \n",
      "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=0.0321]        \n",
      "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=0.0321]        \n",
      "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471, valid_loss=0.0321]        \n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00, 16.77it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471, valid_loss=0.0321]\n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00,  8.82it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=0.0321]\n",
      "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=0.0321]        \n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00, 17.91it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=0.0321]\n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=0.0321]\n",
      "Epoch 390: 100%|██████████| 1/1 [00:00<00:00, 16.40it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=0.0321]\n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00, 17.29it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.0321]\n",
      "Epoch 392: 100%|██████████| 1/1 [00:00<00:00, 19.74it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.465, valid_loss=0.0321]\n",
      "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=0.0321]        \n",
      "Epoch 393: 100%|██████████| 1/1 [00:00<00:00, 13.25it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=0.0321]\n",
      "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.457, train_loss_epoch=0.457, valid_loss=0.0321]        \n",
      "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.456, train_loss_epoch=0.456, valid_loss=0.0321]        \n",
      "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.454, train_loss_epoch=0.454, valid_loss=0.0321]        \n",
      "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.446, train_loss_epoch=0.446, valid_loss=0.0321]        \n",
      "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455, valid_loss=0.0321]        \n",
      "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.450, train_loss_epoch=0.450, valid_loss=0.0321]        \n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  9.40it/s, v_num=0, train_loss_step=0.453, train_loss_epoch=0.450, valid_loss=0.0321]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=5412)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 20.41it/s]\u001b[A\n",
      "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.453, train_loss_epoch=0.453, valid_loss=0.0369]        \n",
      "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.453, train_loss_epoch=0.453, valid_loss=0.0369]        \n",
      "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.454, train_loss_epoch=0.454, valid_loss=0.0369]        \n",
      "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.450, train_loss_epoch=0.450, valid_loss=0.0369]        \n",
      "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.448, valid_loss=0.0369]        \n",
      "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.447, train_loss_epoch=0.447, valid_loss=0.0369]        \n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00, 16.60it/s, v_num=0, train_loss_step=0.447, train_loss_epoch=0.447, valid_loss=0.0369]\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00,  8.73it/s, v_num=0, train_loss_step=0.444, train_loss_epoch=0.447, valid_loss=0.0369]\n",
      "Epoch 405: 100%|██████████| 1/1 [00:00<00:00,  8.59it/s, v_num=0, train_loss_step=0.444, train_loss_epoch=0.444, valid_loss=0.0369]\n",
      "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.444, train_loss_epoch=0.444, valid_loss=0.0369]        \n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00, 18.02it/s, v_num=0, train_loss_step=0.444, train_loss_epoch=0.444, valid_loss=0.0369]\n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00,  9.10it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=0.0369]\n",
      "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=0.0369]        \n",
      "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=0.0369]\n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00, 18.47it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=0.0369]\n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00,  8.97it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455, valid_loss=0.0369]\n",
      "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455, valid_loss=0.0369]        \n",
      "Epoch 408: 100%|██████████| 1/1 [00:00<00:00, 16.91it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455, valid_loss=0.0369]\n",
      "Epoch 409: 100%|██████████| 1/1 [00:00<00:00, 19.18it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=0.0369]\n",
      "Epoch 410: 100%|██████████| 1/1 [00:00<00:00, 17.49it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0369]\n",
      "Epoch 411: 100%|██████████| 1/1 [00:00<00:00, 18.76it/s, v_num=0, train_loss_step=0.456, train_loss_epoch=0.456, valid_loss=0.0369]\n",
      "Epoch 412: 100%|██████████| 1/1 [00:00<00:00, 16.76it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.0369]\n",
      "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.0369]        \n",
      "Epoch 413: 100%|██████████| 1/1 [00:00<00:00, 16.98it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.0369]\n",
      "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.454, train_loss_epoch=0.454, valid_loss=0.0369]        \n",
      "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0369]        \n",
      "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.0369]        \n",
      "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=0.0369]        \n",
      "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0369]        \n",
      "Epoch 418: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0369]\n",
      "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0369]        \n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00, 17.98it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0369]\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00,  9.29it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0369]\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0369]\n",
      "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0369]        \n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00,  9.47it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.529, valid_loss=0.0369]\n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00,  9.30it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569, valid_loss=0.0369]\n",
      "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569, valid_loss=0.0369]        \n",
      "Epoch 421: 100%|██████████| 1/1 [00:00<00:00, 17.13it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569, valid_loss=0.0369]\n",
      "Epoch 421: 100%|██████████| 1/1 [00:00<00:00,  8.85it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563, valid_loss=0.0369]\n",
      "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563, valid_loss=0.0369]        \n",
      "Epoch 422: 100%|██████████| 1/1 [00:00<00:00, 15.81it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563, valid_loss=0.0369]\n",
      "Epoch 423: 100%|██████████| 1/1 [00:00<00:00, 17.49it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0369]\n",
      "Epoch 424: 100%|██████████| 1/1 [00:00<00:00, 18.66it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0369]\n",
      "Epoch 425: 100%|██████████| 1/1 [00:00<00:00, 17.45it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=0.0369]\n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00, 16.33it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=0.0369]\n",
      "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=0.0369]        \n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00, 20.34it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=0.0369]\n",
      "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0369]        \n",
      "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0369]        \n",
      "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0369]        \n",
      "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0369]        \n",
      "Epoch 431: 100%|██████████| 1/1 [00:00<00:00,  8.64it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.0369]\n",
      "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.0369]        \n",
      "Epoch 432: 100%|██████████| 1/1 [00:00<00:00, 16.18it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.0369]\n",
      "Epoch 433: 100%|██████████| 1/1 [00:00<00:00, 17.60it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0369]\n",
      "Epoch 434: 100%|██████████| 1/1 [00:00<00:00, 17.14it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0369]\n",
      "Epoch 435: 100%|██████████| 1/1 [00:00<00:00, 19.26it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0369]\n",
      "Epoch 436: 100%|██████████| 1/1 [00:00<00:00, 16.47it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0369]\n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00, 19.50it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0369]\n",
      "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565, valid_loss=0.0369]        \n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00, 17.60it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565, valid_loss=0.0369]\n",
      "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.0369]        \n",
      "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.0369]        \n",
      "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567, valid_loss=0.0369]        \n",
      "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561, valid_loss=0.0369]        \n",
      "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.0369]        \n",
      "Epoch 443: 100%|██████████| 1/1 [00:00<00:00, 16.78it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.0369]\n",
      "Epoch 443: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.557, valid_loss=0.0369]\n",
      "Epoch 443: 100%|██████████| 1/1 [00:00<00:00,  8.68it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0369]\n",
      "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0369]        \n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00,  9.40it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.548, valid_loss=0.0369]\n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00,  9.15it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0369]\n",
      "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0369]        \n",
      "Epoch 445: 100%|██████████| 1/1 [00:00<00:00,  9.42it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0369]\n",
      "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0369]        \n",
      "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0369]\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00, 16.35it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0369]\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00,  8.72it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.0369]\n",
      "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.0369]        \n",
      "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.0369]\n",
      "Epoch 447: 100%|██████████| 1/1 [00:00<00:00,  9.16it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.550, valid_loss=0.0369]\n",
      "Epoch 447: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0369]\n",
      "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0369]        \n",
      "Epoch 448: 100%|██████████| 1/1 [00:00<00:00, 17.47it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0369]\n",
      "Epoch 448: 100%|██████████| 1/1 [00:00<00:00,  9.10it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.545, valid_loss=0.0369]\n",
      "Epoch 448: 100%|██████████| 1/1 [00:00<00:00,  8.86it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=0.0369]\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00, 17.60it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=0.0369]\n",
      "Epoch 450: 100%|██████████| 1/1 [00:00<00:00, 17.90it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0369]\n",
      "Epoch 451: 100%|██████████| 1/1 [00:00<00:00, 17.67it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0369]\n",
      "Epoch 452: 100%|██████████| 1/1 [00:00<00:00, 18.40it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0369]\n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00, 17.41it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0369]\n",
      "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0369]        \n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00, 17.76it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0369]\n",
      "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0369]        \n",
      "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.0369]        \n",
      "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0369]        \n",
      "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0369]        \n",
      "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0369]        \n",
      "Epoch 459: 100%|██████████| 1/1 [00:00<00:00,  9.17it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.544, valid_loss=0.0369]\n",
      "Epoch 459: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.0369]\n",
      "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.0369]        \n",
      "Epoch 460: 100%|██████████| 1/1 [00:00<00:00, 16.92it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.0369]\n",
      "Epoch 460: 100%|██████████| 1/1 [00:00<00:00,  9.06it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.533, valid_loss=0.0369]\n",
      "Epoch 460: 100%|██████████| 1/1 [00:00<00:00,  8.89it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.0369]\n",
      "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.0369]        \n",
      "Epoch 461: 100%|██████████| 1/1 [00:00<00:00,  9.04it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0369]\n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00, 16.32it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0369]\n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00, 17.99it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0369]\n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00, 16.71it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=0.0369]\n",
      "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.0369]        \n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00, 16.40it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.0369]\n",
      "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0369]        \n",
      "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0369]        \n",
      "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0369]        \n",
      "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0369]        \n",
      "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0369]        \n",
      "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0369]        \n",
      "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0369]        \n",
      "Epoch 472: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0369]\n",
      "Epoch 473: 100%|██████████| 1/1 [00:00<00:00, 17.79it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0369]\n",
      "Epoch 474: 100%|██████████| 1/1 [00:00<00:00, 19.25it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0369]\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00, 17.84it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0369]\n",
      "Epoch 476: 100%|██████████| 1/1 [00:00<00:00, 18.86it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0369]\n",
      "Epoch 477: 100%|██████████| 1/1 [00:00<00:00, 17.59it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0369]\n",
      "Epoch 478: 100%|██████████| 1/1 [00:00<00:00, 18.47it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0369]\n",
      "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0369]        \n",
      "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.623, train_loss_epoch=0.623, valid_loss=0.0369]        \n",
      "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.0369]        \n",
      "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0369]        \n",
      "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0369]        \n",
      "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0369]        \n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00,  9.22it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0369]\n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00,  9.07it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0369]\n",
      "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0369]        \n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00, 16.26it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0369]\n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00, 17.88it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0369]\n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00, 16.76it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0369]\n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00, 16.87it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0369]\n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00, 17.67it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0369]\n",
      "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0369]        \n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00, 16.47it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0369]\n",
      "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0369]        \n",
      "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0369]        \n",
      "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0369]        \n",
      "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0369]        \n",
      "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0369]        \n",
      "Epoch 495: 100%|██████████| 1/1 [00:00<00:00,  8.64it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0369]\n",
      "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0369]        \n",
      "Epoch 496: 100%|██████████| 1/1 [00:00<00:00, 17.04it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0369]\n",
      "Epoch 496: 100%|██████████| 1/1 [00:00<00:00,  8.93it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.502, valid_loss=0.0369]\n",
      "Epoch 496: 100%|██████████| 1/1 [00:00<00:00,  8.73it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0369]\n",
      "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0369]        \n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00, 16.78it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0369]\n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00,  8.90it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.505, valid_loss=0.0369]\n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00,  8.68it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0369]\n",
      "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0369]        \n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00, 16.97it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0369]\n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00,  8.77it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0369]\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 16.46it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0369]\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  8.80it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.496, valid_loss=0.0369]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 23.69it/s]\u001b[A\n",
      "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0362]        \n",
      "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0362]        \n",
      "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0362]        \n",
      "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0362]        \n",
      "Epoch 503: 100%|██████████| 1/1 [00:00<00:00,  8.79it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0362]\n",
      "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0362]        \n",
      "Epoch 504: 100%|██████████| 1/1 [00:00<00:00, 16.86it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0362]\n",
      "Epoch 504: 100%|██████████| 1/1 [00:00<00:00,  8.75it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0362]\n",
      "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0362]        \n",
      "Epoch 505: 100%|██████████| 1/1 [00:00<00:00,  9.28it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0362]\n",
      "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0362]        \n",
      "Epoch 506: 100%|██████████| 1/1 [00:00<00:00, 16.42it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0362]\n",
      "Epoch 507: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0362]\n",
      "Epoch 508: 100%|██████████| 1/1 [00:00<00:00, 17.22it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.0362]\n",
      "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0362]        \n",
      "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0362]        \n",
      "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0362]        \n",
      "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0362]        \n",
      "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0362]        \n",
      "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0362]        \n",
      "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0362]\n",
      "Epoch 514: 100%|██████████| 1/1 [00:00<00:00,  8.91it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0362]\n",
      "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0362]        \n",
      "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0362]\n",
      "Epoch 515: 100%|██████████| 1/1 [00:00<00:00, 16.36it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0362]\n",
      "Epoch 516: 100%|██████████| 1/1 [00:00<00:00, 20.27it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=0.0362]\n",
      "Epoch 517: 100%|██████████| 1/1 [00:00<00:00, 19.88it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473, valid_loss=0.0362]\n",
      "Epoch 518: 100%|██████████| 1/1 [00:00<00:00, 19.06it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.0362]\n",
      "Epoch 519: 100%|██████████| 1/1 [00:00<00:00, 16.15it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=0.0362]\n",
      "Epoch 520: 100%|██████████| 1/1 [00:00<00:00, 16.74it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.465, valid_loss=0.0362]\n",
      "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=0.0362]        \n",
      "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.0362]        \n",
      "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=0.0362]        \n",
      "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.461, train_loss_epoch=0.461, valid_loss=0.0362]        \n",
      "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.459, train_loss_epoch=0.459, valid_loss=0.0362]        \n",
      "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.458, train_loss_epoch=0.458, valid_loss=0.0362]        \n",
      "Epoch 526: 100%|██████████| 1/1 [00:00<00:00, 17.55it/s, v_num=0, train_loss_step=0.458, train_loss_epoch=0.458, valid_loss=0.0362]\n",
      "Epoch 526: 100%|██████████| 1/1 [00:00<00:00,  9.13it/s, v_num=0, train_loss_step=0.458, train_loss_epoch=0.458, valid_loss=0.0362]\n",
      "Epoch 526: 100%|██████████| 1/1 [00:00<00:00,  8.74it/s, v_num=0, train_loss_step=0.458, train_loss_epoch=0.458, valid_loss=0.0362]\n",
      "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.458, train_loss_epoch=0.458, valid_loss=0.0362]        \n",
      "Epoch 527: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=0, train_loss_step=0.458, train_loss_epoch=0.458, valid_loss=0.0362]\n",
      "Epoch 528: 100%|██████████| 1/1 [00:00<00:00, 20.40it/s, v_num=0, train_loss_step=0.457, train_loss_epoch=0.457, valid_loss=0.0362]\n",
      "Epoch 529: 100%|██████████| 1/1 [00:00<00:00, 20.18it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455, valid_loss=0.0362]\n",
      "Epoch 530: 100%|██████████| 1/1 [00:00<00:00, 17.93it/s, v_num=0, train_loss_step=0.454, train_loss_epoch=0.454, valid_loss=0.0362]\n",
      "Epoch 531: 100%|██████████| 1/1 [00:00<00:00, 19.64it/s, v_num=0, train_loss_step=0.454, train_loss_epoch=0.454, valid_loss=0.0362]\n",
      "Epoch 532: 100%|██████████| 1/1 [00:00<00:00, 16.48it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452, valid_loss=0.0362]\n",
      "Epoch 533: 100%|██████████| 1/1 [00:00<00:00, 19.54it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452, valid_loss=0.0362]\n",
      "Epoch 534: 100%|██████████| 1/1 [00:00<00:00, 17.37it/s, v_num=0, train_loss_step=0.450, train_loss_epoch=0.450, valid_loss=0.0362]\n",
      "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.451, train_loss_epoch=0.451, valid_loss=0.0362]        \n",
      "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.451, train_loss_epoch=0.451, valid_loss=0.0362]        \n",
      "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.451, train_loss_epoch=0.451, valid_loss=0.0362]        \n",
      "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.459, train_loss_epoch=0.459, valid_loss=0.0362]        \n",
      "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.447, train_loss_epoch=0.447, valid_loss=0.0362]        \n",
      "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.449, train_loss_epoch=0.449, valid_loss=0.0362]        \n",
      "Epoch 540: 100%|██████████| 1/1 [00:00<00:00,  9.17it/s, v_num=0, train_loss_step=0.451, train_loss_epoch=0.449, valid_loss=0.0362]\n",
      "Epoch 540: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s, v_num=0, train_loss_step=0.451, train_loss_epoch=0.451, valid_loss=0.0362]\n",
      "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.451, train_loss_epoch=0.451, valid_loss=0.0362]        \n",
      "Epoch 541: 100%|██████████| 1/1 [00:00<00:00, 16.81it/s, v_num=0, train_loss_step=0.451, train_loss_epoch=0.451, valid_loss=0.0362]\n",
      "Epoch 541: 100%|██████████| 1/1 [00:00<00:00,  8.59it/s, v_num=0, train_loss_step=0.450, train_loss_epoch=0.450, valid_loss=0.0362]\n",
      "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.450, train_loss_epoch=0.450, valid_loss=0.0362]        \n",
      "Epoch 542: 100%|██████████| 1/1 [00:00<00:00, 18.12it/s, v_num=0, train_loss_step=0.450, train_loss_epoch=0.450, valid_loss=0.0362]\n",
      "Epoch 542: 100%|██████████| 1/1 [00:00<00:00,  9.11it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.450, valid_loss=0.0362]\n",
      "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.448, valid_loss=0.0362]        \n",
      "Epoch 543: 100%|██████████| 1/1 [00:00<00:00, 17.99it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.448, valid_loss=0.0362]\n",
      "Epoch 543: 100%|██████████| 1/1 [00:00<00:00,  9.18it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.448, valid_loss=0.0362]\n",
      "Epoch 543: 100%|██████████| 1/1 [00:00<00:00,  8.97it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=0.0362]\n",
      "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=0.0362]        \n",
      "Epoch 544: 100%|██████████| 1/1 [00:00<00:00, 17.35it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=0.0362]\n",
      "Epoch 545: 100%|██████████| 1/1 [00:00<00:00, 18.64it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=0.0362]\n",
      "Epoch 546: 100%|██████████| 1/1 [00:00<00:00, 18.59it/s, v_num=0, train_loss_step=0.443, train_loss_epoch=0.443, valid_loss=0.0362]\n",
      "Epoch 547: 100%|██████████| 1/1 [00:00<00:00, 20.71it/s, v_num=0, train_loss_step=0.441, train_loss_epoch=0.441, valid_loss=0.0362]\n",
      "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=0.0362]        \n",
      "Epoch 548: 100%|██████████| 1/1 [00:00<00:00, 14.28it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=0.0362]\n",
      "Epoch 549: 100%|██████████| 1/1 [00:00<00:00, 20.12it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0362]\n",
      "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0362]        \n",
      "Epoch 550: 100%|██████████| 1/1 [00:00<00:00, 19.23it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0362]\n",
      "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0362]        \n",
      "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0362]        \n",
      "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0362]        \n",
      "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471, valid_loss=0.0362]        \n",
      "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471, valid_loss=0.0362]        \n",
      "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.0362]        \n",
      "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.0362]        \n",
      "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.0362]\n",
      "Epoch 557: 100%|██████████| 1/1 [00:00<00:00, 15.09it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.0362]\n",
      "Epoch 557: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.469, valid_loss=0.0362]\n",
      "Epoch 557: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.465, valid_loss=0.0362]\n",
      "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.465, valid_loss=0.0362]        \n",
      "Epoch 558: 100%|██████████| 1/1 [00:00<00:00, 16.97it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.465, valid_loss=0.0362]\n",
      "Epoch 559: 100%|██████████| 1/1 [00:00<00:00, 18.40it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.465, valid_loss=0.0362]\n",
      "Epoch 560: 100%|██████████| 1/1 [00:00<00:00, 17.37it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=0.0362]\n",
      "Epoch 561: 100%|██████████| 1/1 [00:00<00:00, 14.19it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.0362]\n",
      "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=0.0362]        \n",
      "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.461, train_loss_epoch=0.461, valid_loss=0.0362]        \n",
      "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=0.0362]        \n",
      "Epoch 564: 100%|██████████| 1/1 [00:00<00:00,  8.41it/s, v_num=0, train_loss_step=0.459, train_loss_epoch=0.459, valid_loss=0.0362]\n",
      "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.459, train_loss_epoch=0.459, valid_loss=0.0362]        \n",
      "Epoch 565: 100%|██████████| 1/1 [00:00<00:00,  9.37it/s, v_num=0, train_loss_step=0.458, train_loss_epoch=0.459, valid_loss=0.0362]\n",
      "Epoch 565: 100%|██████████| 1/1 [00:00<00:00,  9.18it/s, v_num=0, train_loss_step=0.458, train_loss_epoch=0.458, valid_loss=0.0362]\n",
      "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.458, train_loss_epoch=0.458, valid_loss=0.0362]        \n",
      "Epoch 566: 100%|██████████| 1/1 [00:00<00:00, 14.34it/s, v_num=0, train_loss_step=0.458, train_loss_epoch=0.458, valid_loss=0.0362]\n",
      "Epoch 567: 100%|██████████| 1/1 [00:00<00:00, 19.73it/s, v_num=0, train_loss_step=0.456, train_loss_epoch=0.456, valid_loss=0.0362]\n",
      "Epoch 568: 100%|██████████| 1/1 [00:00<00:00, 19.40it/s, v_num=0, train_loss_step=0.454, train_loss_epoch=0.454, valid_loss=0.0362]\n",
      "Epoch 569: 100%|██████████| 1/1 [00:00<00:00, 19.45it/s, v_num=0, train_loss_step=0.453, train_loss_epoch=0.453, valid_loss=0.0362]\n",
      "Epoch 570: 100%|██████████| 1/1 [00:00<00:00, 17.05it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452, valid_loss=0.0362]\n",
      "Epoch 571: 100%|██████████| 1/1 [00:00<00:00, 21.85it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452, valid_loss=0.0362]\n",
      "Epoch 572: 100%|██████████| 1/1 [00:00<00:00, 18.85it/s, v_num=0, train_loss_step=0.451, train_loss_epoch=0.451, valid_loss=0.0362]\n",
      "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.451, train_loss_epoch=0.451, valid_loss=0.0362]        \n",
      "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.450, train_loss_epoch=0.450, valid_loss=0.0362]        \n",
      "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.447, train_loss_epoch=0.447, valid_loss=0.0362]        \n",
      "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=0.0362]        \n",
      "Epoch 576: 100%|██████████| 1/1 [00:00<00:00,  8.65it/s, v_num=0, train_loss_step=0.444, train_loss_epoch=0.444, valid_loss=0.0362]\n",
      "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.444, train_loss_epoch=0.444, valid_loss=0.0362]        \n",
      "Epoch 577: 100%|██████████| 1/1 [00:00<00:00, 18.73it/s, v_num=0, train_loss_step=0.444, train_loss_epoch=0.444, valid_loss=0.0362]\n",
      "Epoch 577: 100%|██████████| 1/1 [00:00<00:00,  8.95it/s, v_num=0, train_loss_step=0.442, train_loss_epoch=0.442, valid_loss=0.0362]\n",
      "Epoch 578: 100%|██████████| 1/1 [00:00<00:00, 18.04it/s, v_num=0, train_loss_step=0.442, train_loss_epoch=0.442, valid_loss=0.0362]\n",
      "Epoch 579: 100%|██████████| 1/1 [00:00<00:00, 17.49it/s, v_num=0, train_loss_step=0.441, train_loss_epoch=0.441, valid_loss=0.0362]\n",
      "Epoch 580: 100%|██████████| 1/1 [00:00<00:00, 18.25it/s, v_num=0, train_loss_step=0.442, train_loss_epoch=0.442, valid_loss=0.0362]\n",
      "Epoch 581: 100%|██████████| 1/1 [00:00<00:00, 16.06it/s, v_num=0, train_loss_step=0.453, train_loss_epoch=0.453, valid_loss=0.0362]\n",
      "Epoch 582: 100%|██████████| 1/1 [00:00<00:00, 17.69it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=0.0362]\n",
      "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.439, train_loss_epoch=0.439, valid_loss=0.0362]        \n",
      "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.438, train_loss_epoch=0.438, valid_loss=0.0362]        \n",
      "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.436, train_loss_epoch=0.436, valid_loss=0.0362]        \n",
      "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.448, valid_loss=0.0362]        \n",
      "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.442, train_loss_epoch=0.442, valid_loss=0.0362]        \n",
      "Epoch 587: 100%|██████████| 1/1 [00:00<00:00,  8.85it/s, v_num=0, train_loss_step=0.443, train_loss_epoch=0.442, valid_loss=0.0362]\n",
      "Epoch 587: 100%|██████████| 1/1 [00:00<00:00,  8.66it/s, v_num=0, train_loss_step=0.443, train_loss_epoch=0.443, valid_loss=0.0362]\n",
      "Epoch 588: 100%|██████████| 1/1 [00:00<00:00, 16.22it/s, v_num=0, train_loss_step=0.443, train_loss_epoch=0.443, valid_loss=0.0362]\n",
      "Epoch 589: 100%|██████████| 1/1 [00:00<00:00, 21.46it/s, v_num=0, train_loss_step=0.450, train_loss_epoch=0.450, valid_loss=0.0362]\n",
      "Epoch 590: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s, v_num=0, train_loss_step=0.461, train_loss_epoch=0.461, valid_loss=0.0362]\n",
      "Epoch 591: 100%|██████████| 1/1 [00:00<00:00, 21.40it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=0.0362]\n",
      "Epoch 592: 100%|██████████| 1/1 [00:00<00:00, 18.01it/s, v_num=0, train_loss_step=0.458, train_loss_epoch=0.458, valid_loss=0.0362]\n",
      "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0362]        \n",
      "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=0.0362]        \n",
      "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=0.0362]        \n",
      "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.0362]        \n",
      "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=0.0362]        \n",
      "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.454, train_loss_epoch=0.454, valid_loss=0.0362]        \n",
      "Epoch 598: 100%|██████████| 1/1 [00:00<00:00, 17.72it/s, v_num=0, train_loss_step=0.454, train_loss_epoch=0.454, valid_loss=0.0362]\n",
      "Epoch 598: 100%|██████████| 1/1 [00:00<00:00,  8.89it/s, v_num=0, train_loss_step=0.454, train_loss_epoch=0.454, valid_loss=0.0362]\n",
      "Epoch 598: 100%|██████████| 1/1 [00:00<00:00,  8.64it/s, v_num=0, train_loss_step=0.454, train_loss_epoch=0.454, valid_loss=0.0362]\n",
      "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.454, train_loss_epoch=0.454, valid_loss=0.0362]        \n",
      "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 18.28it/s, v_num=0, train_loss_step=0.454, train_loss_epoch=0.454, valid_loss=0.0362]\n",
      "Epoch 599: 100%|██████████| 1/1 [00:00<00:00,  8.91it/s, v_num=0, train_loss_step=0.444, train_loss_epoch=0.454, valid_loss=0.0362]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 21.23it/s]\u001b[A\n",
      "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.444, train_loss_epoch=0.444, valid_loss=0.0457]        \n",
      "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.446, train_loss_epoch=0.446, valid_loss=0.0457]        \n",
      "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.442, train_loss_epoch=0.442, valid_loss=0.0457]        \n",
      "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.442, train_loss_epoch=0.442, valid_loss=0.0457]\n",
      "Epoch 602: 100%|██████████| 1/1 [00:00<00:00, 13.95it/s, v_num=0, train_loss_step=0.442, train_loss_epoch=0.442, valid_loss=0.0457]\n",
      "Epoch 603: 100%|██████████| 1/1 [00:00<00:00, 18.21it/s, v_num=0, train_loss_step=0.437, train_loss_epoch=0.437, valid_loss=0.0457]\n",
      "Epoch 604: 100%|██████████| 1/1 [00:00<00:00, 19.41it/s, v_num=0, train_loss_step=0.435, train_loss_epoch=0.435, valid_loss=0.0457]\n",
      "Epoch 605: 100%|██████████| 1/1 [00:00<00:00, 15.82it/s, v_num=0, train_loss_step=0.431, train_loss_epoch=0.431, valid_loss=0.0457]\n",
      "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.429, train_loss_epoch=0.429, valid_loss=0.0457]        \n",
      "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.424, train_loss_epoch=0.424, valid_loss=0.0457]        \n",
      "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.424, train_loss_epoch=0.424, valid_loss=0.0457]        \n",
      "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.420, train_loss_epoch=0.420, valid_loss=0.0457]        \n",
      "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.420, train_loss_epoch=0.420, valid_loss=0.0457]        \n",
      "Epoch 610: 100%|██████████| 1/1 [00:00<00:00,  9.31it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.0457]\n",
      "Epoch 611: 100%|██████████| 1/1 [00:00<00:00, 19.65it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.0457]\n",
      "Epoch 612: 100%|██████████| 1/1 [00:00<00:00, 19.98it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0457]\n",
      "Epoch 613: 100%|██████████| 1/1 [00:00<00:00, 20.56it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.0457]\n",
      "Epoch 614: 100%|██████████| 1/1 [00:00<00:00, 21.16it/s, v_num=0, train_loss_step=0.457, train_loss_epoch=0.457, valid_loss=0.0457]\n",
      "Epoch 615: 100%|██████████| 1/1 [00:00<00:00, 21.43it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.0457]\n",
      "Epoch 616: 100%|██████████| 1/1 [00:00<00:00, 21.08it/s, v_num=0, train_loss_step=0.454, train_loss_epoch=0.454, valid_loss=0.0457]\n",
      "Epoch 617: 100%|██████████| 1/1 [00:00<00:00, 22.07it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455, valid_loss=0.0457]\n",
      "Epoch 618: 100%|██████████| 1/1 [00:00<00:00, 18.65it/s, v_num=0, train_loss_step=0.451, train_loss_epoch=0.451, valid_loss=0.0457]\n",
      "Epoch 619: 100%|██████████| 1/1 [00:00<00:00, 17.51it/s, v_num=0, train_loss_step=0.451, train_loss_epoch=0.451, valid_loss=0.0457]\n",
      "Epoch 620: 100%|██████████| 1/1 [00:00<00:00, 18.09it/s, v_num=0, train_loss_step=0.456, train_loss_epoch=0.456, valid_loss=0.0457]\n",
      "Epoch 621: 100%|██████████| 1/1 [00:00<00:00, 20.30it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.448, valid_loss=0.0457]\n",
      "Epoch 622:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.450, train_loss_epoch=0.450, valid_loss=0.0457]        \n",
      "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.444, train_loss_epoch=0.444, valid_loss=0.0457]        \n",
      "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0457]        \n",
      "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.0457]        \n",
      "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.459, train_loss_epoch=0.459, valid_loss=0.0457]        \n",
      "Epoch 626: 100%|██████████| 1/1 [00:00<00:00, 14.17it/s, v_num=0, train_loss_step=0.459, train_loss_epoch=0.459, valid_loss=0.0457]\n",
      "Epoch 627: 100%|██████████| 1/1 [00:00<00:00, 21.06it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=0.0457]\n",
      "Epoch 628: 100%|██████████| 1/1 [00:00<00:00, 17.89it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471, valid_loss=0.0457]\n",
      "Epoch 629: 100%|██████████| 1/1 [00:00<00:00, 18.34it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.465, valid_loss=0.0457]\n",
      "Epoch 630: 100%|██████████| 1/1 [00:00<00:00, 20.79it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=0.0457]\n",
      "Epoch 631: 100%|██████████| 1/1 [00:00<00:00, 19.10it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=0.0457]\n",
      "Epoch 632: 100%|██████████| 1/1 [00:00<00:00, 20.04it/s, v_num=0, train_loss_step=0.461, train_loss_epoch=0.461, valid_loss=0.0457]\n",
      "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.459, train_loss_epoch=0.459, valid_loss=0.0457]        \n",
      "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.458, train_loss_epoch=0.458, valid_loss=0.0457]        \n",
      "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455, valid_loss=0.0457]        \n",
      "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452, valid_loss=0.0457]        \n",
      "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452, valid_loss=0.0457]        \n",
      "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.450, train_loss_epoch=0.450, valid_loss=0.0457]        \n",
      "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.448, valid_loss=0.0457]        \n",
      "Epoch 639: 100%|██████████| 1/1 [00:00<00:00, 17.56it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.448, valid_loss=0.0457]\n",
      "Epoch 639: 100%|██████████| 1/1 [00:00<00:00,  8.77it/s, v_num=0, train_loss_step=0.446, train_loss_epoch=0.448, valid_loss=0.0457]\n",
      "Epoch 639: 100%|██████████| 1/1 [00:00<00:00,  8.50it/s, v_num=0, train_loss_step=0.446, train_loss_epoch=0.446, valid_loss=0.0457]\n",
      "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.446, train_loss_epoch=0.446, valid_loss=0.0457]        \n",
      "Epoch 640: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=0, train_loss_step=0.446, train_loss_epoch=0.446, valid_loss=0.0457]\n",
      "Epoch 641: 100%|██████████| 1/1 [00:00<00:00, 16.94it/s, v_num=0, train_loss_step=0.444, train_loss_epoch=0.444, valid_loss=0.0457]\n",
      "Epoch 642: 100%|██████████| 1/1 [00:00<00:00, 19.75it/s, v_num=0, train_loss_step=0.441, train_loss_epoch=0.441, valid_loss=0.0457]\n",
      "Epoch 643: 100%|██████████| 1/1 [00:00<00:00, 17.25it/s, v_num=0, train_loss_step=0.439, train_loss_epoch=0.439, valid_loss=0.0457]\n",
      "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.438, train_loss_epoch=0.438, valid_loss=0.0457]        \n",
      "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.436, train_loss_epoch=0.436, valid_loss=0.0457]        \n",
      "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.433, train_loss_epoch=0.433, valid_loss=0.0457]        \n",
      "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.431, train_loss_epoch=0.431, valid_loss=0.0457]        \n",
      "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.429, train_loss_epoch=0.429, valid_loss=0.0457]        \n",
      "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.428, train_loss_epoch=0.428, valid_loss=0.0457]        \n",
      "Epoch 649: 100%|██████████| 1/1 [00:00<00:00, 16.18it/s, v_num=0, train_loss_step=0.428, train_loss_epoch=0.428, valid_loss=0.0457]\n",
      "Epoch 649: 100%|██████████| 1/1 [00:00<00:00,  8.60it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.428, valid_loss=0.0457]\n",
      "Epoch 649: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=0.0457]\n",
      "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=0.0457]        \n",
      "Epoch 650: 100%|██████████| 1/1 [00:00<00:00, 15.95it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=0.0457]\n",
      "Epoch 651: 100%|██████████| 1/1 [00:00<00:00, 17.48it/s, v_num=0, train_loss_step=0.423, train_loss_epoch=0.423, valid_loss=0.0457]\n",
      "Epoch 652: 100%|██████████| 1/1 [00:00<00:00, 21.08it/s, v_num=0, train_loss_step=0.428, train_loss_epoch=0.428, valid_loss=0.0457]\n",
      "Epoch 653: 100%|██████████| 1/1 [00:00<00:00, 19.57it/s, v_num=0, train_loss_step=0.440, train_loss_epoch=0.440, valid_loss=0.0457]\n",
      "Epoch 654: 100%|██████████| 1/1 [00:00<00:00, 16.86it/s, v_num=0, train_loss_step=0.431, train_loss_epoch=0.431, valid_loss=0.0457]\n",
      "Epoch 655: 100%|██████████| 1/1 [00:00<00:00, 19.70it/s, v_num=0, train_loss_step=0.428, train_loss_epoch=0.428, valid_loss=0.0457]\n",
      "Epoch 656: 100%|██████████| 1/1 [00:00<00:00, 21.43it/s, v_num=0, train_loss_step=0.426, train_loss_epoch=0.426, valid_loss=0.0457]\n",
      "Epoch 657: 100%|██████████| 1/1 [00:00<00:00, 20.52it/s, v_num=0, train_loss_step=0.428, train_loss_epoch=0.428, valid_loss=0.0457]\n",
      "Epoch 658: 100%|██████████| 1/1 [00:00<00:00, 22.07it/s, v_num=0, train_loss_step=0.420, train_loss_epoch=0.420, valid_loss=0.0457]\n",
      "Epoch 659: 100%|██████████| 1/1 [00:00<00:00, 20.24it/s, v_num=0, train_loss_step=0.421, train_loss_epoch=0.421, valid_loss=0.0457]\n",
      "Epoch 660: 100%|██████████| 1/1 [00:00<00:00, 20.70it/s, v_num=0, train_loss_step=0.420, train_loss_epoch=0.420, valid_loss=0.0457]\n",
      "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.418, train_loss_epoch=0.418, valid_loss=0.0457]        \n",
      "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.418, train_loss_epoch=0.418, valid_loss=0.0457]        \n",
      "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.418, train_loss_epoch=0.418, valid_loss=0.0457]        \n",
      "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.414, train_loss_epoch=0.414, valid_loss=0.0457]        \n",
      "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.414, train_loss_epoch=0.414, valid_loss=0.0457]        \n",
      "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.413, train_loss_epoch=0.413, valid_loss=0.0457]        \n",
      "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.409, train_loss_epoch=0.409, valid_loss=0.0457]        \n",
      "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.408, train_loss_epoch=0.408, valid_loss=0.0457]        \n",
      "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=0.0457]        \n",
      "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.404, train_loss_epoch=0.404, valid_loss=0.0457]        \n",
      "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.403, train_loss_epoch=0.403, valid_loss=0.0457]        \n",
      "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.400, train_loss_epoch=0.400, valid_loss=0.0457]        \n",
      "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.398, train_loss_epoch=0.398, valid_loss=0.0457]        \n",
      "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396, valid_loss=0.0457]        \n",
      "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.393, train_loss_epoch=0.393, valid_loss=0.0457]        \n",
      "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.390, train_loss_epoch=0.390, valid_loss=0.0457]        \n",
      "Epoch 676: 100%|██████████| 1/1 [00:00<00:00, 18.07it/s, v_num=0, train_loss_step=0.390, train_loss_epoch=0.390, valid_loss=0.0457]\n",
      "Epoch 677: 100%|██████████| 1/1 [00:00<00:00, 19.33it/s, v_num=0, train_loss_step=0.402, train_loss_epoch=0.402, valid_loss=0.0457]\n",
      "Epoch 678: 100%|██████████| 1/1 [00:00<00:00, 21.25it/s, v_num=0, train_loss_step=0.407, train_loss_epoch=0.407, valid_loss=0.0457]\n",
      "Epoch 679: 100%|██████████| 1/1 [00:00<00:00, 21.51it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=0.0457]\n",
      "Epoch 680: 100%|██████████| 1/1 [00:00<00:00, 22.05it/s, v_num=0, train_loss_step=0.394, train_loss_epoch=0.394, valid_loss=0.0457]\n",
      "Epoch 681: 100%|██████████| 1/1 [00:00<00:00, 21.26it/s, v_num=0, train_loss_step=0.401, train_loss_epoch=0.401, valid_loss=0.0457]\n",
      "Epoch 682: 100%|██████████| 1/1 [00:00<00:00, 21.51it/s, v_num=0, train_loss_step=0.393, train_loss_epoch=0.393, valid_loss=0.0457]\n",
      "Epoch 683: 100%|██████████| 1/1 [00:00<00:00, 22.00it/s, v_num=0, train_loss_step=0.387, train_loss_epoch=0.387, valid_loss=0.0457]\n",
      "Epoch 684: 100%|██████████| 1/1 [00:00<00:00, 22.21it/s, v_num=0, train_loss_step=0.387, train_loss_epoch=0.387, valid_loss=0.0457]\n",
      "Epoch 685: 100%|██████████| 1/1 [00:00<00:00, 21.43it/s, v_num=0, train_loss_step=0.388, train_loss_epoch=0.388, valid_loss=0.0457]\n",
      "Epoch 686: 100%|██████████| 1/1 [00:00<00:00, 16.99it/s, v_num=0, train_loss_step=0.384, train_loss_epoch=0.384, valid_loss=0.0457]\n",
      "Epoch 687: 100%|██████████| 1/1 [00:00<00:00, 16.42it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.389, valid_loss=0.0457]\n",
      "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.388, train_loss_epoch=0.388, valid_loss=0.0457]        \n",
      "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.385, train_loss_epoch=0.385, valid_loss=0.0457]        \n",
      "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.386, train_loss_epoch=0.386, valid_loss=0.0457]        \n",
      "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.392, train_loss_epoch=0.392, valid_loss=0.0457]        \n",
      "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.435, train_loss_epoch=0.435, valid_loss=0.0457]        \n",
      "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.422, train_loss_epoch=0.422, valid_loss=0.0457]        \n",
      "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.404, train_loss_epoch=0.404, valid_loss=0.0457]        \n",
      "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.414, train_loss_epoch=0.414, valid_loss=0.0457]        \n",
      "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.400, train_loss_epoch=0.400, valid_loss=0.0457]        \n",
      "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.410, train_loss_epoch=0.410, valid_loss=0.0457]        \n",
      "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.401, train_loss_epoch=0.401, valid_loss=0.0457]        \n",
      "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.400, train_loss_epoch=0.400, valid_loss=0.0457]        \n",
      "Epoch 699: 100%|██████████| 1/1 [00:00<00:00,  9.90it/s, v_num=0, train_loss_step=0.394, train_loss_epoch=0.400, valid_loss=0.0457]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=5412)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 23.71it/s]\u001b[A\n",
      "Epoch 700: 100%|██████████| 1/1 [00:00<00:00, 21.83it/s, v_num=0, train_loss_step=0.394, train_loss_epoch=0.394, valid_loss=0.0588]\n",
      "Epoch 701: 100%|██████████| 1/1 [00:00<00:00, 18.79it/s, v_num=0, train_loss_step=0.418, train_loss_epoch=0.418, valid_loss=0.0588]\n",
      "Epoch 702: 100%|██████████| 1/1 [00:00<00:00, 21.94it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.389, valid_loss=0.0588]\n",
      "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=0.0588]        \n",
      "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=0.0588]        \n",
      "Epoch 704: 100%|██████████| 1/1 [00:00<00:00, 21.68it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=0.0588]\n",
      "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.399, train_loss_epoch=0.399, valid_loss=0.0588]        \n",
      "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.392, train_loss_epoch=0.392, valid_loss=0.0588]        \n",
      "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.398, train_loss_epoch=0.398, valid_loss=0.0588]        \n",
      "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379, valid_loss=0.0588]        \n",
      "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=0.0588]        \n",
      "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.374, train_loss_epoch=0.374, valid_loss=0.0588]        \n",
      "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.372, valid_loss=0.0588]        \n",
      "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.367, train_loss_epoch=0.367, valid_loss=0.0588]        \n",
      "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.370, train_loss_epoch=0.370, valid_loss=0.0588]        \n",
      "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.370, train_loss_epoch=0.370, valid_loss=0.0588]        \n",
      "Epoch 714: 100%|██████████| 1/1 [00:00<00:00,  8.70it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=0.0588]\n",
      "Epoch 715: 100%|██████████| 1/1 [00:00<00:00, 17.35it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=0.0588]\n",
      "Epoch 716: 100%|██████████| 1/1 [00:00<00:00, 16.73it/s, v_num=0, train_loss_step=0.362, train_loss_epoch=0.362, valid_loss=0.0588]\n",
      "Epoch 717: 100%|██████████| 1/1 [00:00<00:00, 20.40it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=0.0588]\n",
      "Epoch 718: 100%|██████████| 1/1 [00:00<00:00, 17.18it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=0.0588]\n",
      "Epoch 719: 100%|██████████| 1/1 [00:00<00:00, 18.20it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346, valid_loss=0.0588]\n",
      "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=0.0588]        \n",
      "Epoch 720: 100%|██████████| 1/1 [00:00<00:00, 17.39it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=0.0588]\n",
      "Epoch 721: 100%|██████████| 1/1 [00:00<00:00, 20.11it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=0.0588]\n",
      "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=0.0588]        \n",
      "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.362, train_loss_epoch=0.362, valid_loss=0.0588]        \n",
      "Epoch 724:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=0.0588]        \n",
      "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=0.0588]        \n",
      "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=0.0588]        \n",
      "Epoch 726: 100%|██████████| 1/1 [00:00<00:00,  8.57it/s, v_num=0, train_loss_step=0.393, train_loss_epoch=0.393, valid_loss=0.0588]\n",
      "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.393, train_loss_epoch=0.393, valid_loss=0.0588]        \n",
      "Epoch 727: 100%|██████████| 1/1 [00:00<00:00, 18.04it/s, v_num=0, train_loss_step=0.393, train_loss_epoch=0.393, valid_loss=0.0588]\n",
      "Epoch 727: 100%|██████████| 1/1 [00:00<00:00,  9.16it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.416, valid_loss=0.0588]\n",
      "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.416, valid_loss=0.0588]        \n",
      "Epoch 728: 100%|██████████| 1/1 [00:00<00:00, 17.82it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.416, valid_loss=0.0588]\n",
      "Epoch 728: 100%|██████████| 1/1 [00:00<00:00,  8.85it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=0.0588]\n",
      "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=0.0588]        \n",
      "Epoch 729: 100%|██████████| 1/1 [00:00<00:00, 19.78it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=0.0588]\n",
      "Epoch 729: 100%|██████████| 1/1 [00:00<00:00,  9.38it/s, v_num=0, train_loss_step=0.412, train_loss_epoch=0.425, valid_loss=0.0588]\n",
      "Epoch 729: 100%|██████████| 1/1 [00:00<00:00,  9.29it/s, v_num=0, train_loss_step=0.412, train_loss_epoch=0.412, valid_loss=0.0588]\n",
      "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.412, train_loss_epoch=0.412, valid_loss=0.0588]        \n",
      "Epoch 730: 100%|██████████| 1/1 [00:00<00:00, 20.02it/s, v_num=0, train_loss_step=0.412, train_loss_epoch=0.412, valid_loss=0.0588]\n",
      "Epoch 730: 100%|██████████| 1/1 [00:00<00:00,  9.34it/s, v_num=0, train_loss_step=0.602, train_loss_epoch=0.602, valid_loss=0.0588]\n",
      "Epoch 731: 100%|██████████| 1/1 [00:00<00:00, 19.11it/s, v_num=0, train_loss_step=0.602, train_loss_epoch=0.602, valid_loss=0.0588]\n",
      "Epoch 732: 100%|██████████| 1/1 [00:00<00:00, 20.91it/s, v_num=0, train_loss_step=0.577, train_loss_epoch=0.577, valid_loss=0.0588]\n",
      "Epoch 733: 100%|██████████| 1/1 [00:00<00:00, 20.24it/s, v_num=0, train_loss_step=0.596, train_loss_epoch=0.596, valid_loss=0.0588]\n",
      "Epoch 734: 100%|██████████| 1/1 [00:00<00:00, 21.79it/s, v_num=0, train_loss_step=0.624, train_loss_epoch=0.624, valid_loss=0.0588]\n",
      "Epoch 735: 100%|██████████| 1/1 [00:00<00:00, 17.31it/s, v_num=0, train_loss_step=0.585, train_loss_epoch=0.585, valid_loss=0.0588]\n",
      "Epoch 736: 100%|██████████| 1/1 [00:00<00:00, 19.15it/s, v_num=0, train_loss_step=0.596, train_loss_epoch=0.596, valid_loss=0.0588]\n",
      "Epoch 737: 100%|██████████| 1/1 [00:00<00:00, 21.55it/s, v_num=0, train_loss_step=0.616, train_loss_epoch=0.616, valid_loss=0.0588]\n",
      "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0588]        \n",
      "Epoch 738: 100%|██████████| 1/1 [00:00<00:00, 13.63it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0588]\n",
      "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.572, valid_loss=0.0588]        \n",
      "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=0.0588]        \n",
      "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=0.0588]        \n",
      "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=0.0588]        \n",
      "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0588]        \n",
      "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.0588]        \n",
      "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0588]        \n",
      "Epoch 745: 100%|██████████| 1/1 [00:00<00:00, 18.76it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0588]\n",
      "Epoch 745: 100%|██████████| 1/1 [00:00<00:00,  8.97it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0588]\n",
      "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0588]        \n",
      "Epoch 746: 100%|██████████| 1/1 [00:00<00:00, 16.78it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0588]\n",
      "Epoch 747: 100%|██████████| 1/1 [00:00<00:00, 20.18it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0588]\n",
      "Epoch 748: 100%|██████████| 1/1 [00:00<00:00, 16.25it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0588]\n",
      "Epoch 749: 100%|██████████| 1/1 [00:00<00:00, 18.48it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0588]\n",
      "Epoch 750: 100%|██████████| 1/1 [00:00<00:00, 18.06it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0588]\n",
      "Epoch 751: 100%|██████████| 1/1 [00:00<00:00, 18.81it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0588]\n",
      "Epoch 752: 100%|██████████| 1/1 [00:00<00:00, 18.33it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0588]\n",
      "Epoch 753: 100%|██████████| 1/1 [00:00<00:00, 21.76it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0588]\n",
      "Epoch 754: 100%|██████████| 1/1 [00:00<00:00, 21.26it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0588]\n",
      "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0588]        \n",
      "Epoch 755: 100%|██████████| 1/1 [00:00<00:00, 19.98it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0588]\n",
      "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0588]        \n",
      "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=0.0588]        \n",
      "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0588]        \n",
      "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0588]        \n",
      "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0588]        \n",
      "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.0588]        \n",
      "Epoch 761: 100%|██████████| 1/1 [00:00<00:00,  9.50it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0588]\n",
      "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0588]        \n",
      "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0588]\n",
      "Epoch 762: 100%|██████████| 1/1 [00:00<00:00, 17.91it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0588]\n",
      "Epoch 762: 100%|██████████| 1/1 [00:00<00:00,  8.77it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0588]\n",
      "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0588]        \n",
      "Epoch 763: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0588]\n",
      "Epoch 764: 100%|██████████| 1/1 [00:00<00:00, 19.86it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0588]\n",
      "Epoch 765: 100%|██████████| 1/1 [00:00<00:00, 17.46it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0588]\n",
      "Epoch 766: 100%|██████████| 1/1 [00:00<00:00, 15.86it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0588]\n",
      "Epoch 767: 100%|██████████| 1/1 [00:00<00:00, 17.15it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0588]\n",
      "Epoch 768: 100%|██████████| 1/1 [00:00<00:00, 20.85it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0588]\n",
      "Epoch 769: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0588]\n",
      "Epoch 770: 100%|██████████| 1/1 [00:00<00:00, 18.95it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0588]\n",
      "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.0588]        \n",
      "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=0.0588]        \n",
      "Epoch 773:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=0.0588]        \n",
      "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.457, train_loss_epoch=0.457, valid_loss=0.0588]        \n",
      "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.0588]        \n",
      "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.0588]        \n",
      "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=0.0588]        \n",
      "Epoch 777: 100%|██████████| 1/1 [00:00<00:00, 15.73it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=0.0588]\n",
      "Epoch 778: 100%|██████████| 1/1 [00:00<00:00, 17.47it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471, valid_loss=0.0588]\n",
      "Epoch 779: 100%|██████████| 1/1 [00:00<00:00, 17.12it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.0588]\n",
      "Epoch 780: 100%|██████████| 1/1 [00:00<00:00, 18.22it/s, v_num=0, train_loss_step=0.453, train_loss_epoch=0.453, valid_loss=0.0588]\n",
      "Epoch 781: 100%|██████████| 1/1 [00:00<00:00, 21.39it/s, v_num=0, train_loss_step=0.444, train_loss_epoch=0.444, valid_loss=0.0588]\n",
      "Epoch 782: 100%|██████████| 1/1 [00:00<00:00, 16.91it/s, v_num=0, train_loss_step=0.456, train_loss_epoch=0.456, valid_loss=0.0588]\n",
      "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452, valid_loss=0.0588]        \n",
      "Epoch 783: 100%|██████████| 1/1 [00:00<00:00, 19.37it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452, valid_loss=0.0588]\n",
      "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455, valid_loss=0.0588]        \n",
      "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.448, valid_loss=0.0588]        \n",
      "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.428, train_loss_epoch=0.428, valid_loss=0.0588]        \n",
      "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.436, train_loss_epoch=0.436, valid_loss=0.0588]        \n",
      "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.449, train_loss_epoch=0.449, valid_loss=0.0588]        \n",
      "Epoch 788: 100%|██████████| 1/1 [00:00<00:00,  8.70it/s, v_num=0, train_loss_step=0.442, train_loss_epoch=0.442, valid_loss=0.0588]\n",
      "Epoch 789: 100%|██████████| 1/1 [00:00<00:00, 16.69it/s, v_num=0, train_loss_step=0.442, train_loss_epoch=0.442, valid_loss=0.0588]\n",
      "Epoch 790: 100%|██████████| 1/1 [00:00<00:00, 17.84it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=0.0588]\n",
      "Epoch 791: 100%|██████████| 1/1 [00:00<00:00, 17.55it/s, v_num=0, train_loss_step=0.434, train_loss_epoch=0.434, valid_loss=0.0588]\n",
      "Epoch 792: 100%|██████████| 1/1 [00:00<00:00, 21.32it/s, v_num=0, train_loss_step=0.429, train_loss_epoch=0.429, valid_loss=0.0588]\n",
      "Epoch 793: 100%|██████████| 1/1 [00:00<00:00, 16.21it/s, v_num=0, train_loss_step=0.440, train_loss_epoch=0.440, valid_loss=0.0588]\n",
      "Epoch 794: 100%|██████████| 1/1 [00:00<00:00, 19.51it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0588]\n",
      "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0588]        \n",
      "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0588]        \n",
      "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0588]        \n",
      "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0588]        \n",
      "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0588]        \n",
      "Epoch 799: 100%|██████████| 1/1 [00:00<00:00,  9.32it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.518, valid_loss=0.0588]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=5412)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 20.03it/s]\u001b[A\n",
      "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0318]        \n",
      "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0318]        \n",
      "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0318]        \n",
      "Epoch 803:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0318]        \n",
      "Epoch 803: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0318]\n",
      "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0318]        \n",
      "Epoch 804: 100%|██████████| 1/1 [00:00<00:00, 17.96it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0318]\n",
      "Epoch 804: 100%|██████████| 1/1 [00:00<00:00,  8.94it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.482, valid_loss=0.0318]\n",
      "Epoch 805:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0318]        \n",
      "Epoch 805: 100%|██████████| 1/1 [00:00<00:00, 16.19it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0318]\n",
      "Epoch 806: 100%|██████████| 1/1 [00:00<00:00, 20.57it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.0318]\n",
      "Epoch 807: 100%|██████████| 1/1 [00:00<00:00, 17.84it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=0.0318]\n",
      "Epoch 808: 100%|██████████| 1/1 [00:00<00:00, 18.06it/s, v_num=0, train_loss_step=0.454, train_loss_epoch=0.454, valid_loss=0.0318]\n",
      "Epoch 809: 100%|██████████| 1/1 [00:00<00:00, 17.17it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=0.0318]\n",
      "Epoch 810: 100%|██████████| 1/1 [00:00<00:00, 20.22it/s, v_num=0, train_loss_step=0.457, train_loss_epoch=0.457, valid_loss=0.0318]\n",
      "Epoch 811:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.444, train_loss_epoch=0.444, valid_loss=0.0318]        \n",
      "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.439, train_loss_epoch=0.439, valid_loss=0.0318]        \n",
      "Epoch 813:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.447, train_loss_epoch=0.447, valid_loss=0.0318]        \n",
      "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.436, train_loss_epoch=0.436, valid_loss=0.0318]        \n",
      "Epoch 815:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.434, train_loss_epoch=0.434, valid_loss=0.0318]        \n",
      "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.428, train_loss_epoch=0.428, valid_loss=0.0318]        \n",
      "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.449, train_loss_epoch=0.449, valid_loss=0.0318]        \n",
      "Epoch 817: 100%|██████████| 1/1 [00:00<00:00, 14.05it/s, v_num=0, train_loss_step=0.449, train_loss_epoch=0.449, valid_loss=0.0318]\n",
      "Epoch 818: 100%|██████████| 1/1 [00:00<00:00, 19.55it/s, v_num=0, train_loss_step=0.433, train_loss_epoch=0.433, valid_loss=0.0318]\n",
      "Epoch 819: 100%|██████████| 1/1 [00:00<00:00, 16.77it/s, v_num=0, train_loss_step=0.431, train_loss_epoch=0.431, valid_loss=0.0318]\n",
      "Epoch 820: 100%|██████████| 1/1 [00:00<00:00, 17.41it/s, v_num=0, train_loss_step=0.420, train_loss_epoch=0.420, valid_loss=0.0318]\n",
      "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.418, train_loss_epoch=0.418, valid_loss=0.0318]        \n",
      "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.417, train_loss_epoch=0.417, valid_loss=0.0318]        \n",
      "Epoch 822: 100%|██████████| 1/1 [00:00<00:00, 20.25it/s, v_num=0, train_loss_step=0.417, train_loss_epoch=0.417, valid_loss=0.0318]\n",
      "Epoch 823:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.418, train_loss_epoch=0.418, valid_loss=0.0318]        \n",
      "Epoch 823: 100%|██████████| 1/1 [00:00<00:00, 20.64it/s, v_num=0, train_loss_step=0.418, train_loss_epoch=0.418, valid_loss=0.0318]\n",
      "Epoch 824: 100%|██████████| 1/1 [00:00<00:00, 20.34it/s, v_num=0, train_loss_step=0.408, train_loss_epoch=0.408, valid_loss=0.0318]\n",
      "Epoch 825:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.406, train_loss_epoch=0.406, valid_loss=0.0318]        \n",
      "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=0.0318]        \n",
      "Epoch 827:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.400, train_loss_epoch=0.400, valid_loss=0.0318]        \n",
      "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.399, train_loss_epoch=0.399, valid_loss=0.0318]        \n",
      "Epoch 829:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396, valid_loss=0.0318]        \n",
      "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.398, train_loss_epoch=0.398, valid_loss=0.0318]        \n",
      "Epoch 831:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.415, valid_loss=0.0318]        \n",
      "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.409, train_loss_epoch=0.409, valid_loss=0.0318]        \n",
      "Epoch 832: 100%|██████████| 1/1 [00:00<00:00, 17.11it/s, v_num=0, train_loss_step=0.409, train_loss_epoch=0.409, valid_loss=0.0318]\n",
      "Epoch 832: 100%|██████████| 1/1 [00:00<00:00,  8.70it/s, v_num=0, train_loss_step=0.412, train_loss_epoch=0.412, valid_loss=0.0318]\n",
      "Epoch 833:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.412, train_loss_epoch=0.412, valid_loss=0.0318]        \n",
      "Epoch 833: 100%|██████████| 1/1 [00:00<00:00, 17.07it/s, v_num=0, train_loss_step=0.412, train_loss_epoch=0.412, valid_loss=0.0318]\n",
      "Epoch 833: 100%|██████████| 1/1 [00:00<00:00,  8.98it/s, v_num=0, train_loss_step=0.589, train_loss_epoch=0.412, valid_loss=0.0318]\n",
      "Epoch 833: 100%|██████████| 1/1 [00:00<00:00,  8.75it/s, v_num=0, train_loss_step=0.589, train_loss_epoch=0.589, valid_loss=0.0318]\n",
      "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.589, train_loss_epoch=0.589, valid_loss=0.0318]        \n",
      "Epoch 834: 100%|██████████| 1/1 [00:00<00:00,  9.25it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.589, valid_loss=0.0318]\n",
      "Epoch 834: 100%|██████████| 1/1 [00:00<00:00,  9.06it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0318]\n",
      "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0318]        \n",
      "Epoch 835: 100%|██████████| 1/1 [00:00<00:00,  9.58it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.530, valid_loss=0.0318]\n",
      "Epoch 835: 100%|██████████| 1/1 [00:00<00:00,  9.43it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567, valid_loss=0.0318]\n",
      "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567, valid_loss=0.0318]        \n",
      "Epoch 836: 100%|██████████| 1/1 [00:00<00:00,  9.48it/s, v_num=0, train_loss_step=0.591, train_loss_epoch=0.567, valid_loss=0.0318]\n",
      "Epoch 836: 100%|██████████| 1/1 [00:00<00:00,  9.23it/s, v_num=0, train_loss_step=0.591, train_loss_epoch=0.591, valid_loss=0.0318]\n",
      "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.591, train_loss_epoch=0.591, valid_loss=0.0318]        \n",
      "Epoch 837: 100%|██████████| 1/1 [00:00<00:00, 17.07it/s, v_num=0, train_loss_step=0.591, train_loss_epoch=0.591, valid_loss=0.0318]\n",
      "Epoch 837: 100%|██████████| 1/1 [00:00<00:00,  8.81it/s, v_num=0, train_loss_step=0.617, train_loss_epoch=0.617, valid_loss=0.0318]\n",
      "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.617, train_loss_epoch=0.617, valid_loss=0.0318]        \n",
      "Epoch 838:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.617, train_loss_epoch=0.617, valid_loss=0.0318]\n",
      "Epoch 838: 100%|██████████| 1/1 [00:00<00:00,  9.36it/s, v_num=0, train_loss_step=0.630, train_loss_epoch=0.630, valid_loss=0.0318]\n",
      "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.630, train_loss_epoch=0.630, valid_loss=0.0318]        \n",
      "Epoch 839: 100%|██████████| 1/1 [00:00<00:00, 18.30it/s, v_num=0, train_loss_step=0.630, train_loss_epoch=0.630, valid_loss=0.0318]\n",
      "Epoch 839: 100%|██████████| 1/1 [00:00<00:00,  9.28it/s, v_num=0, train_loss_step=0.716, train_loss_epoch=0.630, valid_loss=0.0318]\n",
      "Epoch 839: 100%|██████████| 1/1 [00:00<00:00,  9.04it/s, v_num=0, train_loss_step=0.716, train_loss_epoch=0.716, valid_loss=0.0318]\n",
      "Epoch 840:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.716, train_loss_epoch=0.716, valid_loss=0.0318]        \n",
      "Epoch 840: 100%|██████████| 1/1 [00:00<00:00,  9.41it/s, v_num=0, train_loss_step=0.648, train_loss_epoch=0.716, valid_loss=0.0318]\n",
      "Epoch 840: 100%|██████████| 1/1 [00:00<00:00,  9.20it/s, v_num=0, train_loss_step=0.648, train_loss_epoch=0.648, valid_loss=0.0318]\n",
      "Epoch 840:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.648, train_loss_epoch=0.648, valid_loss=0.0318]        \n",
      "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.648, train_loss_epoch=0.648, valid_loss=0.0318]\n",
      "Epoch 841: 100%|██████████| 1/1 [00:00<00:00, 19.10it/s, v_num=0, train_loss_step=0.648, train_loss_epoch=0.648, valid_loss=0.0318]\n",
      "Epoch 841: 100%|██████████| 1/1 [00:00<00:00,  9.26it/s, v_num=0, train_loss_step=0.785, train_loss_epoch=0.785, valid_loss=0.0318]\n",
      "Epoch 842:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.785, train_loss_epoch=0.785, valid_loss=0.0318]        \n",
      "Epoch 842: 100%|██████████| 1/1 [00:00<00:00,  9.52it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=0.785, valid_loss=0.0318]\n",
      "Epoch 842: 100%|██████████| 1/1 [00:00<00:00,  9.31it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.0318]\n",
      "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.0318]        \n",
      "Epoch 843: 100%|██████████| 1/1 [00:00<00:00, 17.06it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.0318]\n",
      "Epoch 844: 100%|██████████| 1/1 [00:00<00:00, 20.16it/s, v_num=0, train_loss_step=0.889, train_loss_epoch=0.889, valid_loss=0.0318]\n",
      "Epoch 845: 100%|██████████| 1/1 [00:00<00:00, 16.80it/s, v_num=0, train_loss_step=0.928, train_loss_epoch=0.928, valid_loss=0.0318]\n",
      "Epoch 846: 100%|██████████| 1/1 [00:00<00:00, 14.70it/s, v_num=0, train_loss_step=0.915, train_loss_epoch=0.915, valid_loss=0.0318]\n",
      "Epoch 847: 100%|██████████| 1/1 [00:00<00:00, 20.02it/s, v_num=0, train_loss_step=0.874, train_loss_epoch=0.874, valid_loss=0.0318]\n",
      "Epoch 848: 100%|██████████| 1/1 [00:00<00:00, 18.87it/s, v_num=0, train_loss_step=0.796, train_loss_epoch=0.796, valid_loss=0.0318]\n",
      "Epoch 849:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080, valid_loss=0.0318]        \n",
      "Epoch 850:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.975, train_loss_epoch=0.975, valid_loss=0.0318]        \n",
      "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.0318]        \n",
      "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.0318]        \n",
      "Epoch 853:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.0318]        \n",
      "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.0318]        \n",
      "Epoch 854: 100%|██████████| 1/1 [00:00<00:00,  9.41it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=1.050, valid_loss=0.0318]\n",
      "Epoch 854: 100%|██████████| 1/1 [00:00<00:00,  9.04it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988, valid_loss=0.0318]\n",
      "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988, valid_loss=0.0318]        \n",
      "Epoch 855: 100%|██████████| 1/1 [00:00<00:00,  9.41it/s, v_num=0, train_loss_step=0.966, train_loss_epoch=0.988, valid_loss=0.0318]\n",
      "Epoch 855: 100%|██████████| 1/1 [00:00<00:00,  9.17it/s, v_num=0, train_loss_step=0.966, train_loss_epoch=0.966, valid_loss=0.0318]\n",
      "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.966, train_loss_epoch=0.966, valid_loss=0.0318]        \n",
      "Epoch 856: 100%|██████████| 1/1 [00:00<00:00, 17.16it/s, v_num=0, train_loss_step=0.966, train_loss_epoch=0.966, valid_loss=0.0318]\n",
      "Epoch 856: 100%|██████████| 1/1 [00:00<00:00,  8.94it/s, v_num=0, train_loss_step=0.951, train_loss_epoch=0.951, valid_loss=0.0318]\n",
      "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.951, train_loss_epoch=0.951, valid_loss=0.0318]        \n",
      "Epoch 857: 100%|██████████| 1/1 [00:00<00:00,  9.54it/s, v_num=0, train_loss_step=0.926, train_loss_epoch=0.926, valid_loss=0.0318]\n",
      "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.926, train_loss_epoch=0.926, valid_loss=0.0318]        \n",
      "Epoch 858: 100%|██████████| 1/1 [00:00<00:00, 17.29it/s, v_num=0, train_loss_step=0.926, train_loss_epoch=0.926, valid_loss=0.0318]\n",
      "Epoch 858: 100%|██████████| 1/1 [00:00<00:00,  9.04it/s, v_num=0, train_loss_step=0.882, train_loss_epoch=0.926, valid_loss=0.0318]\n",
      "Epoch 858: 100%|██████████| 1/1 [00:00<00:00,  8.78it/s, v_num=0, train_loss_step=0.882, train_loss_epoch=0.882, valid_loss=0.0318]\n",
      "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.882, train_loss_epoch=0.882, valid_loss=0.0318]        \n",
      "Epoch 859: 100%|██████████| 1/1 [00:00<00:00, 18.90it/s, v_num=0, train_loss_step=0.882, train_loss_epoch=0.882, valid_loss=0.0318]\n",
      "Epoch 859: 100%|██████████| 1/1 [00:00<00:00,  9.36it/s, v_num=0, train_loss_step=0.889, train_loss_epoch=0.882, valid_loss=0.0318]\n",
      "Epoch 859: 100%|██████████| 1/1 [00:00<00:00,  9.12it/s, v_num=0, train_loss_step=0.889, train_loss_epoch=0.889, valid_loss=0.0318]\n",
      "Epoch 860:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.889, train_loss_epoch=0.889, valid_loss=0.0318]        \n",
      "Epoch 860: 100%|██████████| 1/1 [00:00<00:00, 15.98it/s, v_num=0, train_loss_step=0.889, train_loss_epoch=0.889, valid_loss=0.0318]\n",
      "Epoch 861: 100%|██████████| 1/1 [00:00<00:00, 18.86it/s, v_num=0, train_loss_step=0.893, train_loss_epoch=0.893, valid_loss=0.0318]\n",
      "Epoch 862: 100%|██████████| 1/1 [00:00<00:00, 17.89it/s, v_num=0, train_loss_step=0.979, train_loss_epoch=0.979, valid_loss=0.0318]\n",
      "Epoch 863: 100%|██████████| 1/1 [00:00<00:00, 18.55it/s, v_num=0, train_loss_step=0.876, train_loss_epoch=0.876, valid_loss=0.0318]\n",
      "Epoch 864: 100%|██████████| 1/1 [00:00<00:00, 16.76it/s, v_num=0, train_loss_step=0.845, train_loss_epoch=0.845, valid_loss=0.0318]\n",
      "Epoch 865: 100%|██████████| 1/1 [00:00<00:00, 19.42it/s, v_num=0, train_loss_step=0.811, train_loss_epoch=0.811, valid_loss=0.0318]\n",
      "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.766, train_loss_epoch=0.766, valid_loss=0.0318]        \n",
      "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.806, train_loss_epoch=0.806, valid_loss=0.0318]        \n",
      "Epoch 868:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.718, train_loss_epoch=0.718, valid_loss=0.0318]        \n",
      "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.748, train_loss_epoch=0.748, valid_loss=0.0318]        \n",
      "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.677, train_loss_epoch=0.677, valid_loss=0.0318]        \n",
      "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.715, train_loss_epoch=0.715, valid_loss=0.0318]        \n",
      "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.671, train_loss_epoch=0.671, valid_loss=0.0318]        \n",
      "Epoch 872: 100%|██████████| 1/1 [00:00<00:00,  9.21it/s, v_num=0, train_loss_step=0.654, train_loss_epoch=0.654, valid_loss=0.0318]\n",
      "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.654, train_loss_epoch=0.654, valid_loss=0.0318]        \n",
      "Epoch 873: 100%|██████████| 1/1 [00:00<00:00, 17.47it/s, v_num=0, train_loss_step=0.654, train_loss_epoch=0.654, valid_loss=0.0318]\n",
      "Epoch 874: 100%|██████████| 1/1 [00:00<00:00, 19.08it/s, v_num=0, train_loss_step=0.645, train_loss_epoch=0.645, valid_loss=0.0318]\n",
      "Epoch 875: 100%|██████████| 1/1 [00:00<00:00, 17.82it/s, v_num=0, train_loss_step=0.605, train_loss_epoch=0.605, valid_loss=0.0318]\n",
      "Epoch 876: 100%|██████████| 1/1 [00:00<00:00, 18.55it/s, v_num=0, train_loss_step=0.605, train_loss_epoch=0.605, valid_loss=0.0318]\n",
      "Epoch 877: 100%|██████████| 1/1 [00:00<00:00, 17.78it/s, v_num=0, train_loss_step=0.600, train_loss_epoch=0.600, valid_loss=0.0318]\n",
      "Epoch 878: 100%|██████████| 1/1 [00:00<00:00, 18.65it/s, v_num=0, train_loss_step=0.596, train_loss_epoch=0.596, valid_loss=0.0318]\n",
      "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.595, train_loss_epoch=0.595, valid_loss=0.0318]        \n",
      "Epoch 879: 100%|██████████| 1/1 [00:00<00:00, 17.62it/s, v_num=0, train_loss_step=0.595, train_loss_epoch=0.595, valid_loss=0.0318]\n",
      "Epoch 880: 100%|██████████| 1/1 [00:00<00:00, 20.61it/s, v_num=0, train_loss_step=0.570, train_loss_epoch=0.570, valid_loss=0.0318]\n",
      "Epoch 881:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569, valid_loss=0.0318]        \n",
      "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.579, train_loss_epoch=0.579, valid_loss=0.0318]        \n",
      "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.0318]        \n",
      "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=0.0318]        \n",
      "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.0318]        \n",
      "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.0318]        \n",
      "Epoch 886: 100%|██████████| 1/1 [00:00<00:00,  9.38it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.557, valid_loss=0.0318]\n",
      "Epoch 886: 100%|██████████| 1/1 [00:00<00:00,  9.09it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0318]\n",
      "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0318]        \n",
      "Epoch 887: 100%|██████████| 1/1 [00:00<00:00, 19.65it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0318]\n",
      "Epoch 887: 100%|██████████| 1/1 [00:00<00:00,  9.34it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.552, valid_loss=0.0318]\n",
      "Epoch 887: 100%|██████████| 1/1 [00:00<00:00,  9.17it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0318]\n",
      "Epoch 888:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0318]        \n",
      "Epoch 888: 100%|██████████| 1/1 [00:00<00:00,  9.45it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0318]\n",
      "Epoch 888: 100%|██████████| 1/1 [00:00<00:00,  9.34it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0318]\n",
      "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0318]        \n",
      "Epoch 889: 100%|██████████| 1/1 [00:00<00:00, 18.96it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0318]\n",
      "Epoch 889: 100%|██████████| 1/1 [00:00<00:00,  9.16it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0318]\n",
      "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0318]        \n",
      "Epoch 890: 100%|██████████| 1/1 [00:00<00:00, 17.18it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0318]\n",
      "Epoch 890: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.545, valid_loss=0.0318]\n",
      "Epoch 890: 100%|██████████| 1/1 [00:00<00:00,  8.84it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.0318]\n",
      "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.0318]        \n",
      "Epoch 891: 100%|██████████| 1/1 [00:00<00:00,  9.32it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.0318]\n",
      "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.0318]        \n",
      "Epoch 892: 100%|██████████| 1/1 [00:00<00:00, 16.97it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.0318]\n",
      "Epoch 893: 100%|██████████| 1/1 [00:00<00:00, 19.84it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.0318]\n",
      "Epoch 894: 100%|██████████| 1/1 [00:00<00:00, 16.60it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0318]\n",
      "Epoch 895: 100%|██████████| 1/1 [00:00<00:00, 19.19it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.0318]\n",
      "Epoch 896: 100%|██████████| 1/1 [00:00<00:00, 16.55it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0318]\n",
      "Epoch 897: 100%|██████████| 1/1 [00:00<00:00, 18.83it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0318]\n",
      "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0318]        \n",
      "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=0.0318]        \n",
      "Epoch 899: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.540, valid_loss=0.0318]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=5412)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 19.55it/s]\u001b[A\n",
      "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=0.0445]        \n",
      "Epoch 900: 100%|██████████| 1/1 [00:00<00:00, 18.72it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=0.0445]\n",
      "Epoch 901:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=0.0445]        \n",
      "Epoch 902:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=0.0445]        \n",
      "Epoch 903:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0445]        \n",
      "Epoch 904:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0445]        \n",
      "Epoch 905:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0445]        \n",
      "Epoch 905: 100%|██████████| 1/1 [00:00<00:00, 17.94it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0445]\n",
      "Epoch 906: 100%|██████████| 1/1 [00:00<00:00, 17.45it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0445]\n",
      "Epoch 907: 100%|██████████| 1/1 [00:00<00:00, 20.12it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0445]\n",
      "Epoch 908: 100%|██████████| 1/1 [00:00<00:00, 17.38it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0445]\n",
      "Epoch 909: 100%|██████████| 1/1 [00:00<00:00, 18.82it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.0445]\n",
      "Epoch 910: 100%|██████████| 1/1 [00:00<00:00, 18.39it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0445]\n",
      "Epoch 911: 100%|██████████| 1/1 [00:00<00:00, 21.79it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0445]\n",
      "Epoch 912:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0445]        \n",
      "Epoch 913:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0445]        \n",
      "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0445]        \n",
      "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0445]        \n",
      "Epoch 916:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0445]        \n",
      "Epoch 917:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0445]        \n",
      "Epoch 917: 100%|██████████| 1/1 [00:00<00:00,  8.92it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.520, valid_loss=0.0445]\n",
      "Epoch 917: 100%|██████████| 1/1 [00:00<00:00,  8.76it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0445]\n",
      "Epoch 918:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0445]        \n",
      "Epoch 918: 100%|██████████| 1/1 [00:00<00:00,  9.24it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0445]\n",
      "Epoch 919:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0445]        \n",
      "Epoch 919: 100%|██████████| 1/1 [00:00<00:00, 17.71it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0445]\n",
      "Epoch 919: 100%|██████████| 1/1 [00:00<00:00,  9.05it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0445]\n",
      "Epoch 919: 100%|██████████| 1/1 [00:00<00:00,  8.79it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0445]\n",
      "Epoch 920:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0445]        \n",
      "Epoch 920: 100%|██████████| 1/1 [00:00<00:00,  9.10it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.518, valid_loss=0.0445]\n",
      "Epoch 920: 100%|██████████| 1/1 [00:00<00:00,  8.93it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0445]\n",
      "Epoch 921:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0445]        \n",
      "Epoch 921: 100%|██████████| 1/1 [00:00<00:00, 17.41it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0445]\n",
      "Epoch 921: 100%|██████████| 1/1 [00:00<00:00,  9.17it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.517, valid_loss=0.0445]\n",
      "Epoch 921: 100%|██████████| 1/1 [00:00<00:00,  9.03it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0445]\n",
      "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0445]        \n",
      "Epoch 922: 100%|██████████| 1/1 [00:00<00:00,  9.56it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0445]\n",
      "Epoch 923: 100%|██████████| 1/1 [00:00<00:00, 18.03it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0445]\n",
      "Epoch 924: 100%|██████████| 1/1 [00:00<00:00, 17.43it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0445]\n",
      "Epoch 925: 100%|██████████| 1/1 [00:00<00:00, 17.82it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0445]\n",
      "Epoch 926: 100%|██████████| 1/1 [00:00<00:00, 20.44it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0445]\n",
      "Epoch 927: 100%|██████████| 1/1 [00:00<00:00, 17.76it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0445]\n",
      "Epoch 928: 100%|██████████| 1/1 [00:00<00:00, 20.82it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0445]\n",
      "Epoch 929: 100%|██████████| 1/1 [00:00<00:00, 17.30it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0445]\n",
      "Epoch 930: 100%|██████████| 1/1 [00:00<00:00, 21.06it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0445]\n",
      "Epoch 931:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0445]        \n",
      "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0445]        \n",
      "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0445]        \n",
      "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0445]        \n",
      "Epoch 935:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0445]        \n",
      "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0445]        \n",
      "Epoch 936: 100%|██████████| 1/1 [00:00<00:00, 17.20it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0445]\n",
      "Epoch 936: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.509, valid_loss=0.0445]\n",
      "Epoch 936: 100%|██████████| 1/1 [00:00<00:00,  8.75it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0445]\n",
      "Epoch 937: 100%|██████████| 1/1 [00:00<00:00, 19.57it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0445]\n",
      "Epoch 938: 100%|██████████| 1/1 [00:00<00:00, 17.46it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0445]\n",
      "Epoch 939: 100%|██████████| 1/1 [00:00<00:00, 21.38it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0445]\n",
      "Epoch 940: 100%|██████████| 1/1 [00:00<00:00, 17.82it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0445]\n",
      "Epoch 941: 100%|██████████| 1/1 [00:00<00:00, 19.34it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0445]\n",
      "Epoch 942: 100%|██████████| 1/1 [00:00<00:00, 17.06it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0445]\n",
      "Epoch 943: 100%|██████████| 1/1 [00:00<00:00, 18.01it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0445]\n",
      "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0445]        \n",
      "Epoch 945:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0445]        \n",
      "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0445]        \n",
      "Epoch 947:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0445]        \n",
      "Epoch 948:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0445]        \n",
      "Epoch 948: 100%|██████████| 1/1 [00:00<00:00,  8.78it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0445]\n",
      "Epoch 949: 100%|██████████| 1/1 [00:00<00:00, 18.48it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0445]\n",
      "Epoch 950: 100%|██████████| 1/1 [00:00<00:00, 21.01it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0445]\n",
      "Epoch 951: 100%|██████████| 1/1 [00:00<00:00, 18.86it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0445]\n",
      "Epoch 952: 100%|██████████| 1/1 [00:00<00:00, 13.57it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0445]\n",
      "Epoch 953: 100%|██████████| 1/1 [00:00<00:00, 20.79it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0445]\n",
      "Epoch 954: 100%|██████████| 1/1 [00:00<00:00, 17.28it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0445]\n",
      "Epoch 955:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0445]        \n",
      "Epoch 955: 100%|██████████| 1/1 [00:00<00:00, 17.55it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0445]\n",
      "Epoch 956: 100%|██████████| 1/1 [00:00<00:00, 19.32it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0445]\n",
      "Epoch 957:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0445]        \n",
      "Epoch 958:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0445]        \n",
      "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0445]        \n",
      "Epoch 960:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0445]        \n",
      "Epoch 961:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0445]        \n",
      "Epoch 962:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0445]        \n",
      "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0445]        \n",
      "Epoch 963: 100%|██████████| 1/1 [00:00<00:00,  9.21it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0445]\n",
      "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0445]        \n",
      "Epoch 964: 100%|██████████| 1/1 [00:00<00:00, 17.38it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0445]\n",
      "Epoch 964: 100%|██████████| 1/1 [00:00<00:00,  9.02it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.504, valid_loss=0.0445]\n",
      "Epoch 964: 100%|██████████| 1/1 [00:00<00:00,  8.73it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0445]\n",
      "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0445]        \n",
      "Epoch 965:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0445]\n",
      "Epoch 965: 100%|██████████| 1/1 [00:00<00:00,  9.02it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0445]\n",
      "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0445]        \n",
      "Epoch 966: 100%|██████████| 1/1 [00:00<00:00, 16.41it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0445]\n",
      "Epoch 967: 100%|██████████| 1/1 [00:00<00:00, 20.47it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0445]\n",
      "Epoch 968: 100%|██████████| 1/1 [00:00<00:00, 17.48it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0445]\n",
      "Epoch 969: 100%|██████████| 1/1 [00:00<00:00, 18.98it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0445]\n",
      "Epoch 970: 100%|██████████| 1/1 [00:00<00:00, 17.32it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0445]\n",
      "Epoch 971: 100%|██████████| 1/1 [00:00<00:00, 19.12it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0445]\n",
      "Epoch 972:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0445]        \n",
      "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0445]        \n",
      "Epoch 974:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0445]        \n",
      "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0445]        \n",
      "Epoch 976:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0445]        \n",
      "Epoch 977:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0445]        \n",
      "Epoch 978:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0445]        \n",
      "Epoch 978: 100%|██████████| 1/1 [00:00<00:00, 16.46it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0445]\n",
      "Epoch 978: 100%|██████████| 1/1 [00:00<00:00,  8.70it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0445]\n",
      "Epoch 979:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0445]        \n",
      "Epoch 979: 100%|██████████| 1/1 [00:00<00:00, 18.04it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0445]\n",
      "Epoch 979: 100%|██████████| 1/1 [00:00<00:00,  9.26it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0445]\n",
      "Epoch 979: 100%|██████████| 1/1 [00:00<00:00,  9.11it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0445]\n",
      "Epoch 980:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0445]        \n",
      "Epoch 980: 100%|██████████| 1/1 [00:00<00:00, 19.61it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0445]\n",
      "Epoch 980: 100%|██████████| 1/1 [00:00<00:00,  9.15it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0445]\n",
      "Epoch 981:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0445]        \n",
      "Epoch 981: 100%|██████████| 1/1 [00:00<00:00, 18.06it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0445]\n",
      "Epoch 981: 100%|██████████| 1/1 [00:00<00:00,  9.02it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0445]\n",
      "Epoch 982: 100%|██████████| 1/1 [00:00<00:00, 18.49it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0445]\n",
      "Epoch 983: 100%|██████████| 1/1 [00:00<00:00, 16.84it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0445]\n",
      "Epoch 984: 100%|██████████| 1/1 [00:00<00:00, 17.31it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0445]\n",
      "Epoch 985: 100%|██████████| 1/1 [00:00<00:00, 16.33it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0445]\n",
      "Epoch 986: 100%|██████████| 1/1 [00:00<00:00, 18.98it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0445]\n",
      "Epoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0445]        \n",
      "Epoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0445]        \n",
      "Epoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0445]        \n",
      "Epoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0445]        \n",
      "Epoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0445]        \n",
      "Epoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0445]        \n",
      "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0445]        \n",
      "Epoch 993: 100%|██████████| 1/1 [00:00<00:00, 18.03it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0445]\n",
      "Epoch 994: 100%|██████████| 1/1 [00:00<00:00, 19.71it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0445]\n",
      "Epoch 995: 100%|██████████| 1/1 [00:00<00:00, 18.57it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0445]\n",
      "Epoch 996: 100%|██████████| 1/1 [00:00<00:00, 17.12it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0445]\n",
      "Epoch 997: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0445]\n",
      "Epoch 998: 100%|██████████| 1/1 [00:00<00:00, 19.53it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0445]\n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 18.27it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0445]\n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00,  9.19it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.493, valid_loss=0.0445]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 21.33it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=5412)\u001b[0m \n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00,  5.69it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0446]\n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0446]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=5412)\u001b[0m `Trainer.fit` stopped: `max_steps=1000` reached.\n",
      "\u001b[36m(_train_tune pid=5844)\u001b[0m /home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=5844)\u001b[0m Seed set to 11\n",
      "\u001b[36m(_train_tune pid=5844)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=5844)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=5844)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=5844)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(_train_tune pid=5844)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=5844)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=5844)\u001b[0m   | Name            | Type          | Params | Mode \n",
      "\u001b[36m(_train_tune pid=5844)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=5844)\u001b[0m 0 | loss            | WMAPE         | 0      | train\n",
      "\u001b[36m(_train_tune pid=5844)\u001b[0m 1 | padder          | ConstantPad1d | 0      | train\n",
      "\u001b[36m(_train_tune pid=5844)\u001b[0m 2 | scaler          | TemporalNorm  | 0      | train\n",
      "\u001b[36m(_train_tune pid=5844)\u001b[0m 3 | hist_encoder    | LSTM          | 484 K  | train\n",
      "\u001b[36m(_train_tune pid=5844)\u001b[0m 4 | context_adapter | Linear        | 773 K  | train\n",
      "\u001b[36m(_train_tune pid=5844)\u001b[0m 5 | mlp_decoder     | MLP           | 13.3 K | train\n",
      "\u001b[36m(_train_tune pid=5844)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=5844)\u001b[0m 1.3 M     Trainable params\n",
      "\u001b[36m(_train_tune pid=5844)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=5844)\u001b[0m 1.3 M     Total params\n",
      "\u001b[36m(_train_tune pid=5844)\u001b[0m 5.085     Total estimated model params size (MB)\n",
      "\u001b[36m(_train_tune pid=5844)\u001b[0m 11        Modules in train mode\n",
      "\u001b[36m(_train_tune pid=5844)\u001b[0m 0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.987, train_loss_epoch=0.987]        \n",
      "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.130, train_loss_epoch=5.130]        \n",
      "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190]        \n",
      "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020]        \n",
      "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030]        \n",
      "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180]        \n",
      "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070]        \n",
      "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]       \n",
      "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]        \n",
      "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00,  5.82it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998]\n",
      "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998]        \n",
      "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.987, train_loss_epoch=0.987]        \n",
      "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.962, train_loss_epoch=0.962]        \n",
      "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.897, train_loss_epoch=0.897]        \n",
      "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240]        \n",
      "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680]        \n",
      "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320]        \n",
      "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]        \n",
      "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]        \n",
      "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030]        \n",
      "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030]        \n",
      "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]        \n",
      "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]        \n",
      "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]        \n",
      "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996]        \n",
      "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994]        \n",
      "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.986, train_loss_epoch=0.986]        \n",
      "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.982, train_loss_epoch=0.982]        \n",
      "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.968, train_loss_epoch=0.968]        \n",
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00,  5.21it/s, v_num=0, train_loss_step=0.968, train_loss_epoch=0.968]\n",
      "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.967, train_loss_epoch=0.967]        \n",
      "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.941, train_loss_epoch=0.941]        \n",
      "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=0.914]        \n",
      "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]        \n",
      "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]        \n",
      "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]        \n",
      "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030]        \n",
      "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030]        \n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030]\n",
      "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]        \n",
      "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]        \n",
      "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]        \n",
      "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]\n",
      "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999]        \n",
      "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997]        \n",
      "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995]        \n",
      "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993]        \n",
      "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.991]        \n",
      "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995]        \n",
      "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994]        \n",
      "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988]        \n",
      "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984]        \n",
      "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.985, train_loss_epoch=0.985]        \n",
      "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.975, train_loss_epoch=0.975]        \n",
      "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.973, train_loss_epoch=0.973]        \n",
      "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984]        \n",
      "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.967, train_loss_epoch=0.967]        \n",
      "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]        \n",
      "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.979, train_loss_epoch=0.979]        \n",
      "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992]        \n",
      "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.991]        \n",
      "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.985, train_loss_epoch=0.985]        \n",
      "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.978, train_loss_epoch=0.978]        \n",
      "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.975, train_loss_epoch=0.975]        \n",
      "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.969, train_loss_epoch=0.969]        \n",
      "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.964, train_loss_epoch=0.964]        \n",
      "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.960, train_loss_epoch=0.960]        \n",
      "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.952, train_loss_epoch=0.952]        \n",
      "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.944, train_loss_epoch=0.944]        \n",
      "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.931, train_loss_epoch=0.931]        \n",
      "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.924, train_loss_epoch=0.924]        \n",
      "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.921, train_loss_epoch=0.921]        \n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00,  5.39it/s, v_num=0, train_loss_step=0.921, train_loss_epoch=0.921]\n",
      "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.928, train_loss_epoch=0.928]        \n",
      "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.897, train_loss_epoch=0.897]        \n",
      "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.911, train_loss_epoch=0.911]        \n",
      "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.909, train_loss_epoch=0.909]        \n",
      "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.899, train_loss_epoch=0.899]        \n",
      "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.897, train_loss_epoch=0.897]        \n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00,  5.28it/s, v_num=0, train_loss_step=0.893, train_loss_epoch=0.897]\n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00,  5.26it/s, v_num=0, train_loss_step=0.893, train_loss_epoch=0.893]\n",
      "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.893, train_loss_epoch=0.893]        \n",
      "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.885, train_loss_epoch=0.885]        \n",
      "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.871, train_loss_epoch=0.871]        \n",
      "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.864, train_loss_epoch=0.864]        \n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00,  5.21it/s, v_num=0, train_loss_step=0.864, train_loss_epoch=0.864]\n",
      "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.878, train_loss_epoch=0.878]        \n",
      "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.884, train_loss_epoch=0.884]        \n",
      "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.900, train_loss_epoch=0.900]        \n",
      "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.841, train_loss_epoch=0.841]        \n",
      "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.884, train_loss_epoch=0.884]        \n",
      "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.866, train_loss_epoch=0.866]        \n",
      "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.839, train_loss_epoch=0.839]        \n",
      "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.882, train_loss_epoch=0.882]        \n",
      "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.818, train_loss_epoch=0.818]        \n",
      "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.853, train_loss_epoch=0.853]        \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.816, train_loss_epoch=0.853]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=5844)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  9.00it/s]\u001b[A\n",
      "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.816, train_loss_epoch=0.816, valid_loss=0.273]       \n",
      "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.838, train_loss_epoch=0.838, valid_loss=0.273]        \n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00,  5.21it/s, v_num=0, train_loss_step=0.838, train_loss_epoch=0.838, valid_loss=0.273]\n",
      "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.815, train_loss_epoch=0.815, valid_loss=0.273]        \n",
      "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.804, train_loss_epoch=0.804, valid_loss=0.273]        \n",
      "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.810, train_loss_epoch=0.810, valid_loss=0.273]        \n",
      "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.777, train_loss_epoch=0.777, valid_loss=0.273]        \n",
      "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.791, train_loss_epoch=0.791, valid_loss=0.273]        \n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00,  4.66it/s, v_num=0, train_loss_step=0.791, train_loss_epoch=0.791, valid_loss=0.273]\n",
      "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.772, train_loss_epoch=0.772, valid_loss=0.273]        \n",
      "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.747, train_loss_epoch=0.747, valid_loss=0.273]        \n",
      "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.743, train_loss_epoch=0.743, valid_loss=0.273]        \n",
      "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.760, train_loss_epoch=0.760, valid_loss=0.273]        \n",
      "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.765, train_loss_epoch=0.765, valid_loss=0.273]        \n",
      "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.694, train_loss_epoch=0.694, valid_loss=0.273]        \n",
      "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.728, train_loss_epoch=0.728, valid_loss=0.273]        \n",
      "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.704, train_loss_epoch=0.704, valid_loss=0.273]        \n",
      "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.621, train_loss_epoch=0.621, valid_loss=0.273]        \n",
      "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.685, train_loss_epoch=0.685, valid_loss=0.273]        \n",
      "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.665, train_loss_epoch=0.665, valid_loss=0.273]        \n",
      "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.605, train_loss_epoch=0.605, valid_loss=0.273]        \n",
      "Epoch 118: 100%|██████████| 1/1 [00:00<00:00,  5.37it/s, v_num=0, train_loss_step=0.605, train_loss_epoch=0.605, valid_loss=0.273]\n",
      "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.650, train_loss_epoch=0.650, valid_loss=0.273]        \n",
      "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.711, train_loss_epoch=0.711, valid_loss=0.273]        \n",
      "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.613, train_loss_epoch=0.613, valid_loss=0.273]        \n",
      "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.632, train_loss_epoch=0.632, valid_loss=0.273]        \n",
      "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.619, train_loss_epoch=0.619, valid_loss=0.273]        \n",
      "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.587, train_loss_epoch=0.587, valid_loss=0.273]        \n",
      "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.629, train_loss_epoch=0.629, valid_loss=0.273]        \n",
      "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.579, train_loss_epoch=0.579, valid_loss=0.273]        \n",
      "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.616, train_loss_epoch=0.616, valid_loss=0.273]        \n",
      "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.600, train_loss_epoch=0.600, valid_loss=0.273]        \n",
      "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.583, train_loss_epoch=0.583, valid_loss=0.273]        \n",
      "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.595, train_loss_epoch=0.595, valid_loss=0.273]        \n",
      "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.576, train_loss_epoch=0.576, valid_loss=0.273]        \n",
      "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.588, train_loss_epoch=0.588, valid_loss=0.273]        \n",
      "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573, valid_loss=0.273]        \n",
      "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.587, train_loss_epoch=0.587, valid_loss=0.273]        \n",
      "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568, valid_loss=0.273]        \n",
      "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.570, train_loss_epoch=0.570, valid_loss=0.273]        \n",
      "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.575, train_loss_epoch=0.575, valid_loss=0.273]        \n",
      "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569, valid_loss=0.273]        \n",
      "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.570, train_loss_epoch=0.570, valid_loss=0.273]        \n",
      "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561, valid_loss=0.273]        \n",
      "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.566, train_loss_epoch=0.566, valid_loss=0.273]        \n",
      "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565, valid_loss=0.273]        \n",
      "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=0.273]        \n",
      "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562, valid_loss=0.273]        \n",
      "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=0.273]        \n",
      "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563, valid_loss=0.273]        \n",
      "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=0.273]        \n",
      "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=0.273]        \n",
      "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=0.273]        \n",
      "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.273]        \n",
      "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.273]        \n",
      "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.273]        \n",
      "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.273]        \n",
      "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.273]        \n",
      "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.273]        \n",
      "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.273]        \n",
      "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.273]        \n",
      "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.273]        \n",
      "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.273]        \n",
      "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.273]        \n",
      "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.273]        \n",
      "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.273]        \n",
      "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.273]        \n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00,  5.49it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.273]\n",
      "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.273]        \n",
      "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.273]        \n",
      "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.273]        \n",
      "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.273]        \n",
      "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.273]        \n",
      "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.273]        \n",
      "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.273]        \n",
      "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.273]        \n",
      "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.273]        \n",
      "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.273]        \n",
      "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.273]        \n",
      "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.273]        \n",
      "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.273]        \n",
      "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.273]        \n",
      "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.273]        \n",
      "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.273]        \n",
      "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.273]        \n",
      "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.273]        \n",
      "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.273]        \n",
      "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.273]        \n",
      "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.273]        \n",
      "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.273]        \n",
      "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.273]        \n",
      "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.273]        \n",
      "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.273]        \n",
      "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.273]        \n",
      "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.273]        \n",
      "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.273]        \n",
      "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.273]        \n",
      "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.273]        \n",
      "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.273]        \n",
      "Epoch 194: 100%|██████████| 1/1 [00:00<00:00,  4.43it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.273]\n",
      "Epoch 194: 100%|██████████| 1/1 [00:00<00:00,  4.30it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.273]\n",
      "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.273]        \n",
      "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565, valid_loss=0.273]        \n",
      "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.597, train_loss_epoch=0.597, valid_loss=0.273]        \n",
      "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.575, train_loss_epoch=0.575, valid_loss=0.273]        \n",
      "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.575, train_loss_epoch=0.575, valid_loss=0.273]        \n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.575, valid_loss=0.273]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=5844)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 10.43it/s]\u001b[A\n",
      "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569, valid_loss=0.046]        \n",
      "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567, valid_loss=0.046]        \n",
      "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568, valid_loss=0.046]        \n",
      "Epoch 202: 100%|██████████| 1/1 [00:00<00:00,  4.62it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568, valid_loss=0.046]\n",
      "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562, valid_loss=0.046]        \n",
      "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.570, train_loss_epoch=0.570, valid_loss=0.046]        \n",
      "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.046]        \n",
      "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561, valid_loss=0.046]        \n",
      "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=0.046]        \n",
      "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.046]        \n",
      "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.046]        \n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.046]\n",
      "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.046]        \n",
      "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565, valid_loss=0.046]        \n",
      "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.046]        \n",
      "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.046]        \n",
      "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.046]        \n",
      "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.046]        \n",
      "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.046]        \n",
      "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.046]        \n",
      "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.046]        \n",
      "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.046]        \n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00,  4.64it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.548, valid_loss=0.046]\n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00,  4.62it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.046]\n",
      "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.046]        \n",
      "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.046]        \n",
      "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=0.046]        \n",
      "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.046]        \n",
      "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.046]        \n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00,  4.43it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.545, valid_loss=0.046]\n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00,  4.42it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.046]\n",
      "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.046]        \n",
      "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=0.046]        \n",
      "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=0.046]        \n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00,  5.28it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=0.046]\n",
      "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.046]        \n",
      "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.046]        \n",
      "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.046]        \n",
      "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=0.046]        \n",
      "Epoch 231: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=0.046]\n",
      "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.046]        \n",
      "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=0.046]        \n",
      "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=0.046]        \n",
      "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=0.046]        \n",
      "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=0.046]        \n",
      "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.046]        \n",
      "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.046]        \n",
      "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.046]        \n",
      "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.046]        \n",
      "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.046]        \n",
      "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.046]        \n",
      "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.046]        \n",
      "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.046]        \n",
      "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.046]        \n",
      "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.046]        \n",
      "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.046]        \n",
      "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.046]        \n",
      "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.046]        \n",
      "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.046]        \n",
      "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.046]        \n",
      "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.046]        \n",
      "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.046]        \n",
      "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.046]        \n",
      "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.046]        \n",
      "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.046]        \n",
      "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.046]        \n",
      "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.046]        \n",
      "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.046]        \n",
      "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.046]        \n",
      "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.046]        \n",
      "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.046]        \n",
      "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.046]        \n",
      "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.046]        \n",
      "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.046]        \n",
      "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.046]        \n",
      "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.046]        \n",
      "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.046]        \n",
      "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.046]        \n",
      "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.046]        \n",
      "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.046]        \n",
      "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.046]        \n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00,  3.85it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.046]\n",
      "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.046]        \n",
      "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.046]        \n",
      "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.046]        \n",
      "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.046]        \n",
      "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.046]        \n",
      "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.046]        \n",
      "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.046]        \n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.046]\n",
      "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.046]        \n",
      "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.046]        \n",
      "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.046]        \n",
      "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.046]        \n",
      "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.046]        \n",
      "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.046]        \n",
      "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=0.046]        \n",
      "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.046]        \n",
      "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.046]        \n",
      "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.046]        \n",
      "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.046]        \n",
      "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.046]        \n",
      "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.046]        \n",
      "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.046]        \n",
      "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.046]        \n",
      "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.046]        \n",
      "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563, valid_loss=0.046]        \n",
      "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565, valid_loss=0.046]        \n",
      "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.046]        \n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.046]\n",
      "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.046]        \n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  5.34it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.046]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=5844)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 10.34it/s]\u001b[A\n",
      "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.0418]        \n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0418]\n",
      "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0418]        \n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0418]\n",
      "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0418]        \n",
      "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.0418]        \n",
      "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0418]        \n",
      "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0418]        \n",
      "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=0.0418]        \n",
      "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=0.0418]        \n",
      "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=0.0418]        \n",
      "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.0418]        \n",
      "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0418]        \n",
      "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0418]        \n",
      "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0418]        \n",
      "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.0418]        \n",
      "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0418]        \n",
      "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0418]        \n",
      "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0418]        \n",
      "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.0418]        \n",
      "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.0418]        \n",
      "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0418]        \n",
      "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.0418]        \n",
      "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0418]        \n",
      "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0418]        \n",
      "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0418]        \n",
      "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0418]        \n",
      "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0418]        \n",
      "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0418]        \n",
      "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0418]        \n",
      "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.0418]        \n",
      "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0418]        \n",
      "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.0418]        \n",
      "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.0418]        \n",
      "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0418]        \n",
      "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0418]        \n",
      "Epoch 333: 100%|██████████| 1/1 [00:00<00:00,  5.20it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0418]\n",
      "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0418]        \n",
      "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0418]        \n",
      "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0418]        \n",
      "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=0.0418]        \n",
      "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0418]        \n",
      "Epoch 338: 100%|██████████| 1/1 [00:00<00:00,  4.57it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0418]\n",
      "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0418]        \n",
      "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0418]        \n",
      "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=0.0418]        \n",
      "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=0.0418]        \n",
      "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=0.0418]        \n",
      "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.0418]        \n",
      "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=0.0418]        \n",
      "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0418]        \n",
      "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0418]        \n",
      "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0418]        \n",
      "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0418]        \n",
      "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0418]        \n",
      "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.0418]        \n",
      "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0418]        \n",
      "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0418]        \n",
      "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0418]        \n",
      "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0418]        \n",
      "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0418]        \n",
      "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.0418]        \n",
      "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0418]        \n",
      "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0418]        \n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0418]\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00,  4.63it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.0418]\n",
      "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.0418]        \n",
      "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.0418]\n",
      "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0418]        \n",
      "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0418]        \n",
      "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.0418]        \n",
      "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0418]        \n",
      "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0418]        \n",
      "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0418]        \n",
      "Epoch 366: 100%|██████████| 1/1 [00:00<00:00,  5.26it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0418]\n",
      "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0418]        \n",
      "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0418]        \n",
      "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0418]        \n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00,  4.47it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0418]\n",
      "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0418]        \n",
      "Epoch 370: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0418]\n",
      "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0418]        \n",
      "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0418]        \n",
      "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0418]        \n",
      "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0418]        \n",
      "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0418]        \n",
      "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0418]        \n",
      "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0418]        \n",
      "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0418]        \n",
      "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0418]        \n",
      "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0418]        \n",
      "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0418]        \n",
      "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0418]        \n",
      "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.0418]        \n",
      "Epoch 383: 100%|██████████| 1/1 [00:00<00:00,  5.45it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.0418]\n",
      "Epoch 383: 100%|██████████| 1/1 [00:00<00:00,  5.24it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=0.0418]\n",
      "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=0.0418]        \n",
      "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0418]        \n",
      "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0418]        \n",
      "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0418]        \n",
      "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0418]        \n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00,  5.63it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0418]\n",
      "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0418]        \n",
      "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0418]        \n",
      "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0418]        \n",
      "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0418]        \n",
      "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0418]        \n",
      "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0418]        \n",
      "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0418]        \n",
      "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0418]        \n",
      "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0418]        \n",
      "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0418]        \n",
      "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0418]        \n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  4.47it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.509, valid_loss=0.0418]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=5844)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 10.48it/s]\u001b[A\n",
      "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0341]        \n",
      "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0341]        \n",
      "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0341]        \n",
      "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0341]        \n",
      "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0341]        \n",
      "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0341]        \n",
      "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0341]        \n",
      "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0341]        \n",
      "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0341]        \n",
      "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0341]        \n",
      "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0341]        \n",
      "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0341]        \n",
      "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0341]        \n",
      "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0341]        \n",
      "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0341]        \n",
      "Epoch 414: 100%|██████████| 1/1 [00:00<00:00,  4.19it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0341]\n",
      "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0341]        \n",
      "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0341]        \n",
      "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0341]        \n",
      "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0341]        \n",
      "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0341]        \n",
      "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0341]        \n",
      "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0341]        \n",
      "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0341]        \n",
      "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0341]        \n",
      "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0341]        \n",
      "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0341]        \n",
      "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0341]        \n",
      "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0341]        \n",
      "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0341]        \n",
      "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0341]        \n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00,  4.45it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0341]\n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00,  4.33it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.507, valid_loss=0.0341]\n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00,  4.31it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0341]\n",
      "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0341]        \n",
      "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0341]        \n",
      "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0341]        \n",
      "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0341]        \n",
      "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0341]        \n",
      "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0341]        \n",
      "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0341]        \n",
      "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0341]        \n",
      "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0341]        \n",
      "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0341]        \n",
      "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0341]        \n",
      "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0341]        \n",
      "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0341]        \n",
      "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0341]        \n",
      "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0341]        \n",
      "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0341]        \n",
      "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0341]        \n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00,  4.03it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0341]\n",
      "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0341]        \n",
      "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0341]        \n",
      "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0341]        \n",
      "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0341]        \n",
      "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0341]        \n",
      "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0341]        \n",
      "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0341]        \n",
      "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0341]        \n",
      "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0341]        \n",
      "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0341]        \n",
      "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0341]        \n",
      "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0341]        \n",
      "Epoch 458: 100%|██████████| 1/1 [00:00<00:00,  4.68it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0341]\n",
      "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0341]        \n",
      "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0341]        \n",
      "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0341]        \n",
      "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0341]        \n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00,  4.02it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0341]\n",
      "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0341]        \n",
      "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0341]        \n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00,  4.28it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0341]\n",
      "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0341]        \n",
      "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0341]        \n",
      "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0341]        \n",
      "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0341]        \n",
      "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0341]        \n",
      "Epoch 469: 100%|██████████| 1/1 [00:00<00:00,  5.51it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0341]\n",
      "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0341]        \n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.497, valid_loss=0.0341]\n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0341]\n",
      "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0341]        \n",
      "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0341]        \n",
      "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0341]        \n",
      "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0341]        \n",
      "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0341]        \n",
      "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0341]        \n",
      "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0341]        \n",
      "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0341]        \n",
      "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0341]        \n",
      "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0341]        \n",
      "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0341]        \n",
      "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0341]        \n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00,  5.39it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0341]\n",
      "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0341]        \n",
      "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0341]        \n",
      "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0341]        \n",
      "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0341]        \n",
      "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0341]        \n",
      "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0341]        \n",
      "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0341]        \n",
      "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0341]        \n",
      "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0341]        \n",
      "Epoch 491: 100%|██████████| 1/1 [00:00<00:00,  5.33it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0341]\n",
      "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0341]        \n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0341]\n",
      "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0341]        \n",
      "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0341]        \n",
      "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0341]        \n",
      "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0341]        \n",
      "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0341]        \n",
      "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0341]        \n",
      "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0341]        \n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  4.83it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.495, valid_loss=0.0341]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=5844)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  9.37it/s]\u001b[A\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0356]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=5844)\u001b[0m `Trainer.fit` stopped: `max_steps=500` reached.\n",
      "\u001b[36m(_train_tune pid=6409)\u001b[0m /home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=6409)\u001b[0m Seed set to 7\n",
      "\u001b[36m(_train_tune pid=6409)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=6409)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=6409)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=6409)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(_train_tune pid=6409)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_train_tune pid=6409)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=6409)\u001b[0m   | Name            | Type          | Params | Mode \n",
      "\u001b[36m(_train_tune pid=6409)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=6409)\u001b[0m 0 | loss            | WMAPE         | 0      | train\n",
      "\u001b[36m(_train_tune pid=6409)\u001b[0m 1 | padder          | ConstantPad1d | 0      | train\n",
      "\u001b[36m(_train_tune pid=6409)\u001b[0m 2 | scaler          | TemporalNorm  | 0      | train\n",
      "\u001b[36m(_train_tune pid=6409)\u001b[0m 3 | hist_encoder    | LSTM          | 51.4 K | train\n",
      "\u001b[36m(_train_tune pid=6409)\u001b[0m 4 | context_adapter | Linear        | 196 K  | train\n",
      "\u001b[36m(_train_tune pid=6409)\u001b[0m 5 | mlp_decoder     | MLP           | 26.6 K | train\n",
      "\u001b[36m(_train_tune pid=6409)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=6409)\u001b[0m 274 K     Trainable params\n",
      "\u001b[36m(_train_tune pid=6409)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=6409)\u001b[0m 274 K     Total params\n",
      "\u001b[36m(_train_tune pid=6409)\u001b[0m 1.097     Total estimated model params size (MB)\n",
      "\u001b[36m(_train_tune pid=6409)\u001b[0m 11        Modules in train mode\n",
      "\u001b[36m(_train_tune pid=6409)\u001b[0m 0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 16.94it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]\n",
      "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 27.49it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]\n",
      "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999]        \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 30.84it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999]\n",
      "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999]        \n",
      "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998]        \n",
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998]        \n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00, 25.85it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998]\n",
      "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996]        \n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00, 24.66it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996]\n",
      "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993]        \n",
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00, 25.12it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992]\n",
      "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988]        \n",
      "Epoch 23: 100%|██████████| 1/1 [00:00<00:00, 24.13it/s, v_num=0, train_loss_step=0.986, train_loss_epoch=0.986]\n",
      "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.980, train_loss_epoch=0.980]        \n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00, 27.79it/s, v_num=0, train_loss_step=0.975, train_loss_epoch=0.975]\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00, 16.18it/s, v_num=0, train_loss_step=0.970, train_loss_epoch=0.975]\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00, 15.31it/s, v_num=0, train_loss_step=0.970, train_loss_epoch=0.970]\n",
      "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.970, train_loss_epoch=0.970]        \n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00, 25.66it/s, v_num=0, train_loss_step=0.965, train_loss_epoch=0.965]\n",
      "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.949, train_loss_epoch=0.949]        \n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00, 35.61it/s, v_num=0, train_loss_step=0.939, train_loss_epoch=0.939]\n",
      "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.913, train_loss_epoch=0.913]        \n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00, 15.44it/s, v_num=0, train_loss_step=0.879, train_loss_epoch=0.897]\n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=0, train_loss_step=0.879, train_loss_epoch=0.879]\n",
      "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.858, train_loss_epoch=0.858]        \n",
      "Epoch 37: 100%|██████████| 1/1 [00:00<00:00, 15.98it/s, v_num=0, train_loss_step=0.810, train_loss_epoch=0.810]\n",
      "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.810, train_loss_epoch=0.810]        \n",
      "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.784, train_loss_epoch=0.784]        \n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00, 26.77it/s, v_num=0, train_loss_step=0.784, train_loss_epoch=0.784]\n",
      "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.737, train_loss_epoch=0.737]        \n",
      "Epoch 42: 100%|██████████| 1/1 [00:00<00:00, 26.27it/s, v_num=0, train_loss_step=0.723, train_loss_epoch=0.723]\n",
      "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.719, train_loss_epoch=0.719]        \n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00, 25.20it/s, v_num=0, train_loss_step=0.726, train_loss_epoch=0.726]\n",
      "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.733, train_loss_epoch=0.733]        \n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00, 28.21it/s, v_num=0, train_loss_step=0.728, train_loss_epoch=0.728]\n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00, 15.92it/s, v_num=0, train_loss_step=0.718, train_loss_epoch=0.718]\n",
      "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.718, train_loss_epoch=0.718]        \n",
      "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.707, train_loss_epoch=0.707]        \n",
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00, 14.55it/s, v_num=0, train_loss_step=0.688, train_loss_epoch=0.688]\n",
      "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.688, train_loss_epoch=0.688]        \n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00, 28.91it/s, v_num=0, train_loss_step=0.683, train_loss_epoch=0.683]\n",
      "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.678, train_loss_epoch=0.678]        \n",
      "Epoch 56: 100%|██████████| 1/1 [00:00<00:00, 29.76it/s, v_num=0, train_loss_step=0.678, train_loss_epoch=0.678]\n",
      "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.674, train_loss_epoch=0.674]        \n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00, 25.43it/s, v_num=0, train_loss_step=0.672, train_loss_epoch=0.672]\n",
      "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.663, train_loss_epoch=0.663]        \n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00, 36.44it/s, v_num=0, train_loss_step=0.657, train_loss_epoch=0.657]\n",
      "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.645, train_loss_epoch=0.645]        \n",
      "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.641, train_loss_epoch=0.641]        \n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00, 24.34it/s, v_num=0, train_loss_step=0.641, train_loss_epoch=0.641]\n",
      "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.636, train_loss_epoch=0.636]        \n",
      "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.635, train_loss_epoch=0.635]        \n",
      "Epoch 68: 100%|██████████| 1/1 [00:00<00:00, 24.03it/s, v_num=0, train_loss_step=0.635, train_loss_epoch=0.635]\n",
      "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.630, train_loss_epoch=0.630]        \n",
      "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.625, train_loss_epoch=0.625]        \n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00, 14.50it/s, v_num=0, train_loss_step=0.617, train_loss_epoch=0.620]\n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00, 14.04it/s, v_num=0, train_loss_step=0.617, train_loss_epoch=0.617]\n",
      "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.617, train_loss_epoch=0.617]        \n",
      "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.616, train_loss_epoch=0.616]        \n",
      "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.614, train_loss_epoch=0.614]        \n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00, 26.46it/s, v_num=0, train_loss_step=0.612, train_loss_epoch=0.612]\n",
      "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.607, train_loss_epoch=0.607]        \n",
      "Epoch 80: 100%|██████████| 1/1 [00:00<00:00, 29.68it/s, v_num=0, train_loss_step=0.607, train_loss_epoch=0.607]\n",
      "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.606, train_loss_epoch=0.606]        \n",
      "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.602, train_loss_epoch=0.602]        \n",
      "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.602, train_loss_epoch=0.602]        \n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00, 21.61it/s, v_num=0, train_loss_step=0.602, train_loss_epoch=0.602]\n",
      "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.601, train_loss_epoch=0.601]        \n",
      "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.600, train_loss_epoch=0.600]        \n",
      "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.600, train_loss_epoch=0.600]        \n",
      "Epoch 91: 100%|██████████| 1/1 [00:00<00:00, 24.37it/s, v_num=0, train_loss_step=0.600, train_loss_epoch=0.600]\n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00, 20.88it/s, v_num=0, train_loss_step=0.600, train_loss_epoch=0.600]\n",
      "Epoch 93: 100%|██████████| 1/1 [00:00<00:00, 21.09it/s, v_num=0, train_loss_step=0.599, train_loss_epoch=0.599]\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00, 20.49it/s, v_num=0, train_loss_step=0.598, train_loss_epoch=0.598]\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00, 11.07it/s, v_num=0, train_loss_step=0.598, train_loss_epoch=0.598]\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00, 10.78it/s, v_num=0, train_loss_step=0.598, train_loss_epoch=0.598]\n",
      "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.598, train_loss_epoch=0.598]        \n",
      "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.598, train_loss_epoch=0.598]        \n",
      "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.598, train_loss_epoch=0.598]        \n",
      "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.597, train_loss_epoch=0.597]        \n",
      "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.597, train_loss_epoch=0.597]        \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 10.35it/s, v_num=0, train_loss_step=0.597, train_loss_epoch=0.597]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=6409)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 22.22it/s]\u001b[A\n",
      "Epoch 100: 100%|██████████| 1/1 [00:00<00:00, 25.01it/s, v_num=0, train_loss_step=0.597, train_loss_epoch=0.597, valid_loss=0.0442]\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00, 22.01it/s, v_num=0, train_loss_step=0.597, train_loss_epoch=0.597, valid_loss=0.0442]\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00, 11.13it/s, v_num=0, train_loss_step=0.596, train_loss_epoch=0.596, valid_loss=0.0442]\n",
      "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.596, train_loss_epoch=0.596, valid_loss=0.0442]        \n",
      "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.596, train_loss_epoch=0.596, valid_loss=0.0442]        \n",
      "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.596, train_loss_epoch=0.596, valid_loss=0.0442]        \n",
      "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.595, train_loss_epoch=0.595, valid_loss=0.0442]        \n",
      "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.595, train_loss_epoch=0.595, valid_loss=0.0442]        \n",
      "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.595, train_loss_epoch=0.595, valid_loss=0.0442]        \n",
      "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.594, train_loss_epoch=0.594, valid_loss=0.0442]        \n",
      "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.594, train_loss_epoch=0.594, valid_loss=0.0442]        \n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00, 22.41it/s, v_num=0, train_loss_step=0.594, train_loss_epoch=0.594, valid_loss=0.0442]\n",
      "Epoch 111: 100%|██████████| 1/1 [00:00<00:00, 25.08it/s, v_num=0, train_loss_step=0.594, train_loss_epoch=0.594, valid_loss=0.0442]\n",
      "Epoch 112: 100%|██████████| 1/1 [00:00<00:00, 21.17it/s, v_num=0, train_loss_step=0.593, train_loss_epoch=0.593, valid_loss=0.0442]\n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00, 11.46it/s, v_num=0, train_loss_step=0.593, train_loss_epoch=0.593, valid_loss=0.0442]\n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s, v_num=0, train_loss_step=0.593, train_loss_epoch=0.593, valid_loss=0.0442]\n",
      "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.593, train_loss_epoch=0.593, valid_loss=0.0442]        \n",
      "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.592, train_loss_epoch=0.592, valid_loss=0.0442]        \n",
      "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.592, train_loss_epoch=0.592, valid_loss=0.0442]        \n",
      "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.592, train_loss_epoch=0.592, valid_loss=0.0442]        \n",
      "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.592, train_loss_epoch=0.592, valid_loss=0.0442]        \n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 26.23it/s, v_num=0, train_loss_step=0.591, train_loss_epoch=0.591, valid_loss=0.0442]\n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00, 27.24it/s, v_num=0, train_loss_step=0.591, train_loss_epoch=0.591, valid_loss=0.0442]\n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00, 21.02it/s, v_num=0, train_loss_step=0.591, train_loss_epoch=0.591, valid_loss=0.0442]\n",
      "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.590, train_loss_epoch=0.590, valid_loss=0.0442]        \n",
      "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.590, train_loss_epoch=0.590, valid_loss=0.0442]        \n",
      "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.590, train_loss_epoch=0.590, valid_loss=0.0442]        \n",
      "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.590, train_loss_epoch=0.590, valid_loss=0.0442]        \n",
      "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.589, train_loss_epoch=0.589, valid_loss=0.0442]        \n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00, 24.86it/s, v_num=0, train_loss_step=0.589, train_loss_epoch=0.589, valid_loss=0.0442]\n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00, 27.62it/s, v_num=0, train_loss_step=0.589, train_loss_epoch=0.589, valid_loss=0.0442]\n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00, 23.33it/s, v_num=0, train_loss_step=0.589, train_loss_epoch=0.589, valid_loss=0.0442]\n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00, 11.23it/s, v_num=0, train_loss_step=0.588, train_loss_epoch=0.588, valid_loss=0.0442]\n",
      "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.588, train_loss_epoch=0.588, valid_loss=0.0442]        \n",
      "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.588, train_loss_epoch=0.588, valid_loss=0.0442]        \n",
      "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.588, train_loss_epoch=0.588, valid_loss=0.0442]        \n",
      "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.588, train_loss_epoch=0.588, valid_loss=0.0442]        \n",
      "Epoch 134: 100%|██████████| 1/1 [00:00<00:00, 22.79it/s, v_num=0, train_loss_step=0.588, train_loss_epoch=0.588, valid_loss=0.0442]\n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00, 24.26it/s, v_num=0, train_loss_step=0.588, train_loss_epoch=0.588, valid_loss=0.0442]\n",
      "Epoch 136: 100%|██████████| 1/1 [00:00<00:00, 26.38it/s, v_num=0, train_loss_step=0.587, train_loss_epoch=0.587, valid_loss=0.0442]\n",
      "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.587, train_loss_epoch=0.587, valid_loss=0.0442]        \n",
      "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.587, train_loss_epoch=0.587, valid_loss=0.0442]        \n",
      "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.586, train_loss_epoch=0.586, valid_loss=0.0442]        \n",
      "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.586, train_loss_epoch=0.586, valid_loss=0.0442]        \n",
      "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.586, train_loss_epoch=0.586, valid_loss=0.0442]        \n",
      "Epoch 143: 100%|██████████| 1/1 [00:00<00:00, 20.28it/s, v_num=0, train_loss_step=0.586, train_loss_epoch=0.586, valid_loss=0.0442]\n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00, 21.25it/s, v_num=0, train_loss_step=0.585, train_loss_epoch=0.585, valid_loss=0.0442]\n",
      "Epoch 145: 100%|██████████| 1/1 [00:00<00:00, 21.48it/s, v_num=0, train_loss_step=0.585, train_loss_epoch=0.585, valid_loss=0.0442]\n",
      "Epoch 146: 100%|██████████| 1/1 [00:00<00:00, 21.43it/s, v_num=0, train_loss_step=0.585, train_loss_epoch=0.585, valid_loss=0.0442]\n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00, 10.95it/s, v_num=0, train_loss_step=0.584, train_loss_epoch=0.584, valid_loss=0.0442]\n",
      "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.584, train_loss_epoch=0.584, valid_loss=0.0442]        \n",
      "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.584, train_loss_epoch=0.584, valid_loss=0.0442]        \n",
      "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.584, train_loss_epoch=0.584, valid_loss=0.0442]        \n",
      "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.584, train_loss_epoch=0.584, valid_loss=0.0442]        \n",
      "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.583, train_loss_epoch=0.583, valid_loss=0.0442]        \n",
      "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.583, train_loss_epoch=0.583, valid_loss=0.0442]        \n",
      "Epoch 154: 100%|██████████| 1/1 [00:00<00:00, 19.45it/s, v_num=0, train_loss_step=0.583, train_loss_epoch=0.583, valid_loss=0.0442]\n",
      "Epoch 155: 100%|██████████| 1/1 [00:00<00:00, 21.48it/s, v_num=0, train_loss_step=0.583, train_loss_epoch=0.583, valid_loss=0.0442]\n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00, 22.43it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582, valid_loss=0.0442]\n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00, 20.83it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582, valid_loss=0.0442]\n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00, 11.03it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582, valid_loss=0.0442]\n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00, 10.78it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582, valid_loss=0.0442]\n",
      "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582, valid_loss=0.0442]        \n",
      "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582, valid_loss=0.0442]        \n",
      "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582, valid_loss=0.0442]        \n",
      "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.581, train_loss_epoch=0.581, valid_loss=0.0442]        \n",
      "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.581, train_loss_epoch=0.581, valid_loss=0.0442]        \n",
      "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.581, train_loss_epoch=0.581, valid_loss=0.0442]        \n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00, 19.89it/s, v_num=0, train_loss_step=0.581, train_loss_epoch=0.581, valid_loss=0.0442]\n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00, 20.23it/s, v_num=0, train_loss_step=0.581, train_loss_epoch=0.581, valid_loss=0.0442]\n",
      "Epoch 165: 100%|██████████| 1/1 [00:00<00:00, 20.88it/s, v_num=0, train_loss_step=0.580, train_loss_epoch=0.580, valid_loss=0.0442]\n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00, 19.37it/s, v_num=0, train_loss_step=0.580, train_loss_epoch=0.580, valid_loss=0.0442]\n",
      "Epoch 167: 100%|██████████| 1/1 [00:00<00:00, 21.94it/s, v_num=0, train_loss_step=0.580, train_loss_epoch=0.580, valid_loss=0.0442]\n",
      "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.579, train_loss_epoch=0.579, valid_loss=0.0442]        \n",
      "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.579, train_loss_epoch=0.579, valid_loss=0.0442]        \n",
      "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.579, train_loss_epoch=0.579, valid_loss=0.0442]        \n",
      "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.579, train_loss_epoch=0.579, valid_loss=0.0442]        \n",
      "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.578, train_loss_epoch=0.578, valid_loss=0.0442]        \n",
      "Epoch 174: 100%|██████████| 1/1 [00:00<00:00, 20.66it/s, v_num=0, train_loss_step=0.578, train_loss_epoch=0.578, valid_loss=0.0442]\n",
      "Epoch 175: 100%|██████████| 1/1 [00:00<00:00, 23.24it/s, v_num=0, train_loss_step=0.578, train_loss_epoch=0.578, valid_loss=0.0442]\n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00, 20.22it/s, v_num=0, train_loss_step=0.578, train_loss_epoch=0.578, valid_loss=0.0442]\n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00, 11.34it/s, v_num=0, train_loss_step=0.577, train_loss_epoch=0.577, valid_loss=0.0442]\n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00, 11.20it/s, v_num=0, train_loss_step=0.577, train_loss_epoch=0.577, valid_loss=0.0442]\n",
      "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.577, train_loss_epoch=0.577, valid_loss=0.0442]        \n",
      "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.577, train_loss_epoch=0.577, valid_loss=0.0442]        \n",
      "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.576, train_loss_epoch=0.576, valid_loss=0.0442]        \n",
      "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.576, train_loss_epoch=0.576, valid_loss=0.0442]        \n",
      "Epoch 182: 100%|██████████| 1/1 [00:00<00:00, 26.12it/s, v_num=0, train_loss_step=0.576, train_loss_epoch=0.576, valid_loss=0.0442]\n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00, 23.47it/s, v_num=0, train_loss_step=0.576, train_loss_epoch=0.576, valid_loss=0.0442]\n",
      "Epoch 184: 100%|██████████| 1/1 [00:00<00:00, 18.56it/s, v_num=0, train_loss_step=0.575, train_loss_epoch=0.575, valid_loss=0.0442]\n",
      "Epoch 185: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s, v_num=0, train_loss_step=0.575, train_loss_epoch=0.575, valid_loss=0.0442]\n",
      "Epoch 186: 100%|██████████| 1/1 [00:00<00:00, 12.01it/s, v_num=0, train_loss_step=0.575, train_loss_epoch=0.575, valid_loss=0.0442]\n",
      "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574, valid_loss=0.0442]        \n",
      "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574, valid_loss=0.0442]        \n",
      "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574, valid_loss=0.0442]        \n",
      "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573, valid_loss=0.0442]        \n",
      "Epoch 192: 100%|██████████| 1/1 [00:00<00:00, 20.98it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573, valid_loss=0.0442]\n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00, 20.10it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573, valid_loss=0.0442]\n",
      "Epoch 194: 100%|██████████| 1/1 [00:00<00:00, 21.90it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.572, valid_loss=0.0442]\n",
      "Epoch 195: 100%|██████████| 1/1 [00:00<00:00, 22.92it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.572, valid_loss=0.0442]\n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00, 10.97it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571, valid_loss=0.0442]\n",
      "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571, valid_loss=0.0442]        \n",
      "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571, valid_loss=0.0442]        \n",
      "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571, valid_loss=0.0442]        \n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 10.40it/s, v_num=0, train_loss_step=0.570, train_loss_epoch=0.571, valid_loss=0.0442]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=6409)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 28.36it/s]\u001b[A\n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00, 11.85it/s, v_num=0, train_loss_step=0.570, train_loss_epoch=0.570, valid_loss=0.0424]\n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00, 11.60it/s, v_num=0, train_loss_step=0.570, train_loss_epoch=0.570, valid_loss=0.0424]\n",
      "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.570, train_loss_epoch=0.570, valid_loss=0.0424]        \n",
      "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569, valid_loss=0.0424]        \n",
      "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569, valid_loss=0.0424]        \n",
      "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568, valid_loss=0.0424]        \n",
      "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568, valid_loss=0.0424]        \n",
      "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567, valid_loss=0.0424]        \n",
      "Epoch 206: 100%|██████████| 1/1 [00:00<00:00, 22.05it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567, valid_loss=0.0424]\n",
      "Epoch 207: 100%|██████████| 1/1 [00:00<00:00, 21.46it/s, v_num=0, train_loss_step=0.566, train_loss_epoch=0.566, valid_loss=0.0424]\n",
      "Epoch 208: 100%|██████████| 1/1 [00:00<00:00, 20.61it/s, v_num=0, train_loss_step=0.566, train_loss_epoch=0.566, valid_loss=0.0424]\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00, 18.41it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565, valid_loss=0.0424]\n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00, 18.72it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=0.0424]\n",
      "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=0.0424]        \n",
      "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562, valid_loss=0.0424]        \n",
      "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561, valid_loss=0.0424]        \n",
      "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562, valid_loss=0.0424]        \n",
      "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=0.0424]        \n",
      "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=0.0424]        \n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00, 21.40it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=0.0424]\n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00, 21.24it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=0.0424]\n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00, 22.71it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=0.0424]\n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00, 20.89it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=0.0424]\n",
      "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=0.0424]        \n",
      "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=0.0424]        \n",
      "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.0424]        \n",
      "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=0.0424]        \n",
      "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.0424]        \n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00, 20.63it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.0424]\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00, 20.71it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.0424]\n",
      "Epoch 228: 100%|██████████| 1/1 [00:00<00:00, 23.06it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0424]\n",
      "Epoch 229: 100%|██████████| 1/1 [00:00<00:00, 19.95it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.0424]\n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00, 19.52it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0424]\n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00, 10.40it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0424]\n",
      "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0424]        \n",
      "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.0424]        \n",
      "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.0424]        \n",
      "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.0424]        \n",
      "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.0424]        \n",
      "Epoch 235: 100%|██████████| 1/1 [00:00<00:00, 21.71it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.0424]\n",
      "Epoch 236: 100%|██████████| 1/1 [00:00<00:00, 20.02it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.0424]\n",
      "Epoch 237: 100%|██████████| 1/1 [00:00<00:00, 22.82it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.0424]\n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00, 20.11it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.0424]\n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 23.34it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.0424]\n",
      "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.0424]        \n",
      "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.0424]\n",
      "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.0424]        \n",
      "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.0424]        \n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00, 21.39it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0424]\n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00, 19.98it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0424]\n",
      "Epoch 246: 100%|██████████| 1/1 [00:00<00:00, 22.01it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0424]\n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00, 19.81it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0424]\n",
      "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0424]        \n",
      "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0424]        \n",
      "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0424]        \n",
      "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0424]        \n",
      "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0424]        \n",
      "Epoch 253: 100%|██████████| 1/1 [00:00<00:00, 19.82it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0424]\n",
      "Epoch 254: 100%|██████████| 1/1 [00:00<00:00, 22.15it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0424]\n",
      "Epoch 255: 100%|██████████| 1/1 [00:00<00:00, 21.02it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0424]\n",
      "Epoch 256: 100%|██████████| 1/1 [00:00<00:00, 21.11it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0424]\n",
      "Epoch 257: 100%|██████████| 1/1 [00:00<00:00, 10.86it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0424]\n",
      "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0424]        \n",
      "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0424]        \n",
      "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0424]        \n",
      "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0424]        \n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00, 24.40it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0424]\n",
      "Epoch 263: 100%|██████████| 1/1 [00:00<00:00, 23.07it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0424]\n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00, 24.98it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.0424]\n",
      "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.0424]        \n",
      "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.0424]        \n",
      "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.0424]        \n",
      "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.0424]        \n",
      "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0424]        \n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00, 20.47it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0424]\n",
      "Epoch 271: 100%|██████████| 1/1 [00:00<00:00, 25.86it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0424]\n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00, 26.37it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0424]\n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00, 12.07it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0424]\n",
      "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0424]        \n",
      "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0424]        \n",
      "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0424]        \n",
      "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0424]        \n",
      "Epoch 277: 100%|██████████| 1/1 [00:00<00:00, 21.39it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0424]\n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00, 22.90it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0424]\n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00, 21.95it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0424]\n",
      "Epoch 280: 100%|██████████| 1/1 [00:00<00:00, 20.60it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0424]\n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00, 10.56it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0424]\n",
      "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0424]        \n",
      "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0424]        \n",
      "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=0.0424]        \n",
      "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=0.0424]        \n",
      "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=0.0424]        \n",
      "Epoch 287: 100%|██████████| 1/1 [00:00<00:00, 23.05it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=0.0424]\n",
      "Epoch 288: 100%|██████████| 1/1 [00:00<00:00, 22.09it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0424]\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00, 22.43it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0424]\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00, 11.65it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.545, valid_loss=0.0424]\n",
      "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0424]        \n",
      "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0424]        \n",
      "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0424]        \n",
      "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=0.0424]        \n",
      "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=0.0424]        \n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00, 21.33it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.0424]\n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00, 21.03it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.0424]\n",
      "Epoch 297: 100%|██████████| 1/1 [00:00<00:00, 19.97it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=0.0424]\n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00, 22.87it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=0.0424]\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 19.08it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=0.0424]\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 10.70it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.540, valid_loss=0.0424]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 28.67it/s]\u001b[A\n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00, 25.37it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0387]\n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00, 20.07it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.0387]\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00, 24.74it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.0387]\n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00, 10.61it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0387]\n",
      "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0387]        \n",
      "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0387]        \n",
      "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0387]        \n",
      "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0387]        \n",
      "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0387]        \n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00, 26.49it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0387]\n",
      "Epoch 310: 100%|██████████| 1/1 [00:00<00:00, 20.80it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0387]\n",
      "Epoch 311: 100%|██████████| 1/1 [00:00<00:00, 22.80it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.0387]\n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00, 10.92it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.533, valid_loss=0.0387]\n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00, 10.66it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0387]\n",
      "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0387]        \n",
      "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0387]        \n",
      "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=0.0387]        \n",
      "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=0.0387]        \n",
      "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=0.0387]        \n",
      "Epoch 318: 100%|██████████| 1/1 [00:00<00:00, 22.31it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=0.0387]\n",
      "Epoch 319: 100%|██████████| 1/1 [00:00<00:00, 20.25it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0387]\n",
      "Epoch 320: 100%|██████████| 1/1 [00:00<00:00, 23.05it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0387]\n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00, 21.45it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0387]\n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00, 19.65it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0387]\n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00, 10.50it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.530, valid_loss=0.0387]\n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00, 10.30it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0387]\n",
      "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0387]        \n",
      "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0387]        \n",
      "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0387]        \n",
      "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0387]        \n",
      "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.0387]        \n",
      "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.0387]        \n",
      "Epoch 328: 100%|██████████| 1/1 [00:00<00:00, 20.68it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.0387]\n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 22.74it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.0387]\n",
      "Epoch 330: 100%|██████████| 1/1 [00:00<00:00, 20.79it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.0387]\n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00, 12.08it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0387]\n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00, 11.87it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0387]\n",
      "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0387]        \n",
      "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0387]        \n",
      "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0387]        \n",
      "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0387]        \n",
      "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.0387]        \n",
      "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0387]        \n",
      "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0387]        \n",
      "Epoch 338: 100%|██████████| 1/1 [00:00<00:00, 20.89it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0387]\n",
      "Epoch 339: 100%|██████████| 1/1 [00:00<00:00, 25.98it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0387]\n",
      "Epoch 340: 100%|██████████| 1/1 [00:00<00:00, 22.21it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0387]\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00, 21.07it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0387]\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00, 10.99it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.530, valid_loss=0.0387]\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00, 10.77it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0387]\n",
      "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0387]        \n",
      "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.0387]        \n",
      "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0387]        \n",
      "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0387]        \n",
      "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0387]        \n",
      "Epoch 346: 100%|██████████| 1/1 [00:00<00:00, 21.64it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0387]\n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00, 21.92it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0387]\n",
      "Epoch 348: 100%|██████████| 1/1 [00:00<00:00, 19.72it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0387]\n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00, 21.41it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0387]\n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00, 18.51it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0387]\n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00, 19.73it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0387]\n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00, 10.54it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0387]\n",
      "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0387]        \n",
      "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0387]        \n",
      "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0387]        \n",
      "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0387]        \n",
      "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0387]        \n",
      "Epoch 356: 100%|██████████| 1/1 [00:00<00:00, 21.33it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0387]\n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00, 19.69it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0387]\n",
      "Epoch 358: 100%|██████████| 1/1 [00:00<00:00, 20.41it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0387]\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 18.26it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0387]\n",
      "Epoch 360: 100%|██████████| 1/1 [00:00<00:00, 22.16it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0387]\n",
      "Epoch 360: 100%|██████████| 1/1 [00:00<00:00, 11.46it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0387]\n",
      "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0387]        \n",
      "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0387]        \n",
      "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0387]        \n",
      "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0387]        \n",
      "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0387]        \n",
      "Epoch 366: 100%|██████████| 1/1 [00:00<00:00, 20.65it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0387]\n",
      "Epoch 367: 100%|██████████| 1/1 [00:00<00:00, 26.37it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0387]\n",
      "Epoch 368: 100%|██████████| 1/1 [00:00<00:00, 27.68it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0387]\n",
      "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0387]        \n",
      "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0387]        \n",
      "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0387]        \n",
      "Epoch 372: 100%|██████████| 1/1 [00:00<00:00, 22.32it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0387]\n",
      "Epoch 373: 100%|██████████| 1/1 [00:00<00:00, 21.21it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0387]\n",
      "Epoch 374: 100%|██████████| 1/1 [00:00<00:00, 23.29it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0387]\n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00, 12.08it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0387]\n",
      "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0387]        \n",
      "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.0387]        \n",
      "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.0387]        \n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00, 26.41it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0387]\n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00, 27.55it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0387]\n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00, 23.28it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0387]\n",
      "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0387]        \n",
      "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0387]        \n",
      "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0387]        \n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00, 26.78it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0387]\n",
      "Epoch 386: 100%|██████████| 1/1 [00:00<00:00, 26.02it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0387]\n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00, 27.15it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0387]\n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00, 11.45it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0387]\n",
      "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0387]        \n",
      "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0387]        \n",
      "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0387]        \n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00, 22.98it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0387]\n",
      "Epoch 392: 100%|██████████| 1/1 [00:00<00:00, 23.80it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0387]\n",
      "Epoch 393: 100%|██████████| 1/1 [00:00<00:00, 25.62it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.0387]\n",
      "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0387]        \n",
      "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0387]        \n",
      "Epoch 397: 100%|██████████| 1/1 [00:00<00:00, 24.48it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0387]\n",
      "Epoch 398: 100%|██████████| 1/1 [00:00<00:00, 27.36it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0387]\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 12.22it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0387]\n",
      "\u001b[36m(_train_tune pid=6409)\u001b[0m \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=6409)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 30.74it/s]\u001b[A\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00, 23.27it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0395]\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00, 16.97it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0395]\n",
      "Epoch 402: 100%|██████████| 1/1 [00:00<00:00, 25.22it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0395]\n",
      "Epoch 403: 100%|██████████| 1/1 [00:00<00:00, 11.59it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.524, valid_loss=0.0395]\n",
      "Epoch 403: 100%|██████████| 1/1 [00:00<00:00, 11.19it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0395]\n",
      "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0395]        \n",
      "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0395]        \n",
      "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0395]        \n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00, 25.67it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0395]\n",
      "Epoch 408: 100%|██████████| 1/1 [00:00<00:00, 26.01it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0395]\n",
      "Epoch 409: 100%|██████████| 1/1 [00:00<00:00, 25.23it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0395]\n",
      "Epoch 410: 100%|██████████| 1/1 [00:00<00:00, 11.05it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0395]\n",
      "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0395]        \n",
      "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0395]        \n",
      "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0395]        \n",
      "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0395]        \n",
      "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0395]        \n",
      "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0395]        \n",
      "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0395]        \n",
      "Epoch 418: 100%|██████████| 1/1 [00:00<00:00, 21.58it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0395]\n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00, 21.22it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0395]\n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00, 27.15it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0395]\n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00, 12.06it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.520, valid_loss=0.0395]\n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00, 11.64it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0395]\n",
      "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0395]        \n",
      "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0395]        \n",
      "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0395]        \n",
      "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0395]        \n",
      "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0395]        \n",
      "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0395]        \n",
      "Epoch 426: 100%|██████████| 1/1 [00:00<00:00, 19.94it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0395]\n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00, 22.43it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0395]\n",
      "Epoch 428: 100%|██████████| 1/1 [00:00<00:00, 20.65it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0395]\n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00, 23.65it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0395]\n",
      "Epoch 430: 100%|██████████| 1/1 [00:00<00:00, 10.92it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0395]\n",
      "Epoch 430: 100%|██████████| 1/1 [00:00<00:00, 10.64it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0395]\n",
      "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0395]        \n",
      "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0395]        \n",
      "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0395]        \n",
      "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0395]        \n",
      "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0395]        \n",
      "Epoch 436: 100%|██████████| 1/1 [00:00<00:00, 20.02it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0395]\n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00, 20.62it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0395]\n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00, 24.09it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0395]\n",
      "Epoch 439: 100%|██████████| 1/1 [00:00<00:00, 20.26it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0395]\n",
      "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0395]        \n",
      "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0395]        \n",
      "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0395]        \n",
      "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0395]        \n",
      "Epoch 445: 100%|██████████| 1/1 [00:00<00:00, 21.28it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0395]\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00, 19.62it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0395]\n",
      "Epoch 447: 100%|██████████| 1/1 [00:00<00:00, 22.95it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0395]\n",
      "Epoch 448: 100%|██████████| 1/1 [00:00<00:00, 19.02it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0395]\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00, 24.61it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0395]\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00, 11.73it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.518, valid_loss=0.0395]\n",
      "Epoch 449: 100%|██████████| 1/1 [00:00<00:00, 11.17it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0395]\n",
      "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0395]        \n",
      "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0395]        \n",
      "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0395]        \n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00, 23.17it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0395]\n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00, 22.19it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0395]\n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00, 18.53it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0395]\n",
      "Epoch 456: 100%|██████████| 1/1 [00:00<00:00, 20.75it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0395]\n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00, 21.40it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0395]\n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00, 10.96it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0395]\n",
      "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0395]        \n",
      "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0395]        \n",
      "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0395]        \n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00, 21.77it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0395]\n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00, 22.14it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0395]\n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00, 21.67it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0395]\n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00, 22.98it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0395]\n",
      "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0395]        \n",
      "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0395]        \n",
      "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0395]        \n",
      "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0395]        \n",
      "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0395]        \n",
      "Epoch 471: 100%|██████████| 1/1 [00:00<00:00, 19.22it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0395]\n",
      "Epoch 472: 100%|██████████| 1/1 [00:00<00:00, 24.28it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0395]\n",
      "Epoch 473: 100%|██████████| 1/1 [00:00<00:00, 20.11it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0395]\n",
      "Epoch 474: 100%|██████████| 1/1 [00:00<00:00, 20.46it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0395]\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00, 10.94it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.519, valid_loss=0.0395]\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00, 10.67it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0395]\n",
      "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0395]        \n",
      "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0395]        \n",
      "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0395]        \n",
      "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0395]        \n",
      "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0395]        \n",
      "Epoch 480: 100%|██████████| 1/1 [00:00<00:00, 21.25it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0395]\n",
      "Epoch 481: 100%|██████████| 1/1 [00:00<00:00, 19.76it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0395]\n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00, 20.72it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0395]\n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00, 22.16it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0395]\n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00, 10.91it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0395]\n",
      "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0395]        \n",
      "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0395]        \n",
      "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0395]        \n",
      "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0395]        \n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00, 25.08it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0395]\n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00, 19.69it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0395]\n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00, 23.57it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0395]\n",
      "Epoch 491: 100%|██████████| 1/1 [00:00<00:00, 21.01it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0395]\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0395]\n",
      "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0395]        \n",
      "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0395]        \n",
      "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0395]        \n",
      "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0395]        \n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00, 22.45it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0395]\n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00, 21.12it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0395]\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 23.15it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0395]\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 11.72it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0395]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 23.98it/s]\u001b[A\n",
      "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0379]        \n",
      "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0379]        \n",
      "Epoch 502: 100%|██████████| 1/1 [00:00<00:00, 20.76it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0379]\n",
      "Epoch 503: 100%|██████████| 1/1 [00:00<00:00, 21.80it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0379]\n",
      "Epoch 504: 100%|██████████| 1/1 [00:00<00:00, 18.53it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0379]\n",
      "Epoch 505: 100%|██████████| 1/1 [00:00<00:00, 25.51it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0379]\n",
      "Epoch 505: 100%|██████████| 1/1 [00:00<00:00, 11.95it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0379]\n",
      "Epoch 505: 100%|██████████| 1/1 [00:00<00:00, 11.70it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0379]\n",
      "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0379]        \n",
      "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0379]        \n",
      "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0379]        \n",
      "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0379]        \n",
      "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0379]        \n",
      "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0379]        \n",
      "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0379]        \n",
      "Epoch 512: 100%|██████████| 1/1 [00:00<00:00, 20.89it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0379]\n",
      "Epoch 513: 100%|██████████| 1/1 [00:00<00:00, 22.72it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0379]\n",
      "Epoch 514: 100%|██████████| 1/1 [00:00<00:00, 24.26it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0379]\n",
      "Epoch 515: 100%|██████████| 1/1 [00:00<00:00, 21.23it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0379]\n",
      "Epoch 515: 100%|██████████| 1/1 [00:00<00:00, 10.99it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.515, valid_loss=0.0379]\n",
      "Epoch 515: 100%|██████████| 1/1 [00:00<00:00, 10.75it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0379]\n",
      "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0379]        \n",
      "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0379]        \n",
      "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0379]        \n",
      "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0379]        \n",
      "Epoch 521: 100%|██████████| 1/1 [00:00<00:00, 23.38it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0379]\n",
      "Epoch 522: 100%|██████████| 1/1 [00:00<00:00, 20.60it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0379]\n",
      "Epoch 523: 100%|██████████| 1/1 [00:00<00:00, 22.54it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0379]\n",
      "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0379]        \n",
      "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0379]        \n",
      "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0379]        \n",
      "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0379]        \n",
      "Epoch 529: 100%|██████████| 1/1 [00:00<00:00, 20.42it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0379]\n",
      "Epoch 530: 100%|██████████| 1/1 [00:00<00:00, 23.20it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0379]\n",
      "Epoch 531: 100%|██████████| 1/1 [00:00<00:00, 25.64it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0379]\n",
      "Epoch 532: 100%|██████████| 1/1 [00:00<00:00, 11.32it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0379]\n",
      "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0379]        \n",
      "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0379]        \n",
      "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0379]        \n",
      "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0379]        \n",
      "Epoch 537: 100%|██████████| 1/1 [00:00<00:00, 24.76it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0379]\n",
      "Epoch 538: 100%|██████████| 1/1 [00:00<00:00, 21.71it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0379]\n",
      "Epoch 539: 100%|██████████| 1/1 [00:00<00:00, 19.60it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0379]\n",
      "Epoch 540: 100%|██████████| 1/1 [00:00<00:00, 21.28it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0379]\n",
      "Epoch 541: 100%|██████████| 1/1 [00:00<00:00, 22.42it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0379]\n",
      "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0379]        \n",
      "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0379]        \n",
      "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0379]        \n",
      "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0379]        \n",
      "Epoch 547: 100%|██████████| 1/1 [00:00<00:00, 20.87it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0379]\n",
      "Epoch 548: 100%|██████████| 1/1 [00:00<00:00, 20.32it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0379]\n",
      "Epoch 549: 100%|██████████| 1/1 [00:00<00:00, 20.52it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0379]\n",
      "Epoch 550: 100%|██████████| 1/1 [00:00<00:00, 23.43it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0379]\n",
      "Epoch 550: 100%|██████████| 1/1 [00:00<00:00, 11.38it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0379]\n",
      "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0379]        \n",
      "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0379]\n",
      "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0379]        \n",
      "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0379]        \n",
      "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0379]        \n",
      "Epoch 555: 100%|██████████| 1/1 [00:00<00:00, 26.60it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0379]\n",
      "Epoch 556: 100%|██████████| 1/1 [00:00<00:00, 21.04it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0379]\n",
      "Epoch 557: 100%|██████████| 1/1 [00:00<00:00, 26.19it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0379]\n",
      "Epoch 558: 100%|██████████| 1/1 [00:00<00:00, 20.00it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0379]\n",
      "Epoch 558: 100%|██████████| 1/1 [00:00<00:00, 10.52it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0379]\n",
      "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0379]        \n",
      "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0379]        \n",
      "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0379]        \n",
      "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0379]        \n",
      "Epoch 562: 100%|██████████| 1/1 [00:00<00:00, 22.15it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0379]\n",
      "Epoch 563: 100%|██████████| 1/1 [00:00<00:00, 20.24it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0379]\n",
      "Epoch 564: 100%|██████████| 1/1 [00:00<00:00, 22.91it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0379]\n",
      "Epoch 565: 100%|██████████| 1/1 [00:00<00:00, 20.46it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0379]\n",
      "Epoch 566: 100%|██████████| 1/1 [00:00<00:00, 11.07it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.511, valid_loss=0.0379]\n",
      "Epoch 566: 100%|██████████| 1/1 [00:00<00:00, 10.85it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0379]\n",
      "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0379]        \n",
      "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0379]        \n",
      "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0379]        \n",
      "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0379]        \n",
      "Epoch 571: 100%|██████████| 1/1 [00:00<00:00, 23.33it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0379]\n",
      "Epoch 572: 100%|██████████| 1/1 [00:00<00:00, 19.38it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0379]\n",
      "Epoch 573: 100%|██████████| 1/1 [00:00<00:00, 23.99it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0379]\n",
      "Epoch 574: 100%|██████████| 1/1 [00:00<00:00, 22.79it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0379]\n",
      "Epoch 574: 100%|██████████| 1/1 [00:00<00:00, 11.37it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.512, valid_loss=0.0379]\n",
      "Epoch 574: 100%|██████████| 1/1 [00:00<00:00, 11.05it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0379]\n",
      "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0379]        \n",
      "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0379]        \n",
      "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0379]        \n",
      "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0379]        \n",
      "Epoch 580: 100%|██████████| 1/1 [00:00<00:00, 23.90it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0379]\n",
      "Epoch 581: 100%|██████████| 1/1 [00:00<00:00, 18.29it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0379]\n",
      "Epoch 582: 100%|██████████| 1/1 [00:00<00:00, 21.55it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0379]\n",
      "Epoch 583: 100%|██████████| 1/1 [00:00<00:00, 22.44it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0379]\n",
      "Epoch 584: 100%|██████████| 1/1 [00:00<00:00, 22.50it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0379]\n",
      "Epoch 584: 100%|██████████| 1/1 [00:00<00:00, 11.07it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.511, valid_loss=0.0379]\n",
      "Epoch 584: 100%|██████████| 1/1 [00:00<00:00, 10.87it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0379]\n",
      "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0379]        \n",
      "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0379]        \n",
      "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0379]        \n",
      "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0379]        \n",
      "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0379]        \n",
      "Epoch 589: 100%|██████████| 1/1 [00:00<00:00, 22.91it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0379]\n",
      "Epoch 590: 100%|██████████| 1/1 [00:00<00:00, 18.96it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0379]\n",
      "Epoch 591: 100%|██████████| 1/1 [00:00<00:00, 24.41it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0379]\n",
      "Epoch 592: 100%|██████████| 1/1 [00:00<00:00, 19.53it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0379]\n",
      "Epoch 593: 100%|██████████| 1/1 [00:00<00:00, 21.89it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0379]\n",
      "Epoch 593: 100%|██████████| 1/1 [00:00<00:00, 11.31it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.510, valid_loss=0.0379]\n",
      "Epoch 593: 100%|██████████| 1/1 [00:00<00:00, 10.99it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0379]\n",
      "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0379]        \n",
      "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0379]        \n",
      "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0379]        \n",
      "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0379]        \n",
      "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0379]        \n",
      "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 21.52it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0379]\n",
      "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0379]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 26.99it/s]\u001b[A\n",
      "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0371]        \n",
      "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0371]        \n",
      "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0371]        \n",
      "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0371]        \n",
      "Epoch 604: 100%|██████████| 1/1 [00:00<00:00, 23.09it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0371]\n",
      "Epoch 605: 100%|██████████| 1/1 [00:00<00:00, 19.53it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0371]\n",
      "Epoch 606: 100%|██████████| 1/1 [00:00<00:00, 20.58it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0371]\n",
      "Epoch 607: 100%|██████████| 1/1 [00:00<00:00, 20.09it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0371]\n",
      "Epoch 608: 100%|██████████| 1/1 [00:00<00:00, 10.84it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0371]\n",
      "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0371]        \n",
      "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0371]        \n",
      "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0371]        \n",
      "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0371]        \n",
      "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0371]        \n",
      "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0371]        \n",
      "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0371]        \n",
      "Epoch 616: 100%|██████████| 1/1 [00:00<00:00, 24.22it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0371]\n",
      "Epoch 617: 100%|██████████| 1/1 [00:00<00:00, 26.25it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0371]\n",
      "Epoch 618: 100%|██████████| 1/1 [00:00<00:00, 11.13it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0371]\n",
      "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0371]        \n",
      "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0371]        \n",
      "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0371]        \n",
      "Epoch 622: 100%|██████████| 1/1 [00:00<00:00, 24.05it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0371]\n",
      "Epoch 623: 100%|██████████| 1/1 [00:00<00:00, 22.28it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0371]\n",
      "Epoch 624: 100%|██████████| 1/1 [00:00<00:00, 20.52it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0371]\n",
      "Epoch 625: 100%|██████████| 1/1 [00:00<00:00, 18.35it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0371]\n",
      "Epoch 626: 100%|██████████| 1/1 [00:00<00:00, 22.89it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0371]\n",
      "Epoch 626: 100%|██████████| 1/1 [00:00<00:00, 11.64it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0371]\n",
      "Epoch 628:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0371]        \n",
      "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0371]        \n",
      "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0371]        \n",
      "Epoch 631: 100%|██████████| 1/1 [00:00<00:00, 24.61it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0371]\n",
      "Epoch 632: 100%|██████████| 1/1 [00:00<00:00, 20.13it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0371]\n",
      "Epoch 633: 100%|██████████| 1/1 [00:00<00:00, 22.27it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0371]\n",
      "Epoch 634: 100%|██████████| 1/1 [00:00<00:00, 10.85it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0371]\n",
      "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0371]        \n",
      "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0371]        \n",
      "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0371]        \n",
      "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0371]        \n",
      "Epoch 639: 100%|██████████| 1/1 [00:00<00:00, 22.24it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0371]\n",
      "Epoch 640: 100%|██████████| 1/1 [00:00<00:00, 22.14it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0371]\n",
      "Epoch 641: 100%|██████████| 1/1 [00:00<00:00, 21.68it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0371]\n",
      "Epoch 642: 100%|██████████| 1/1 [00:00<00:00, 11.41it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0371]\n",
      "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0371]        \n",
      "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0371]        \n",
      "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0371]        \n",
      "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0371]        \n",
      "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0371]        \n",
      "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0371]        \n",
      "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0371]        \n",
      "Epoch 650: 100%|██████████| 1/1 [00:00<00:00, 22.43it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0371]\n",
      "Epoch 651: 100%|██████████| 1/1 [00:00<00:00, 24.39it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0371]\n",
      "Epoch 652: 100%|██████████| 1/1 [00:00<00:00, 20.46it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0371]\n",
      "Epoch 653: 100%|██████████| 1/1 [00:00<00:00, 11.18it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0371]\n",
      "Epoch 654: 100%|██████████| 1/1 [00:00<00:00, 10.23it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0371]\n",
      "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0371]        \n",
      "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0371]        \n",
      "Epoch 657:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0371]        \n",
      "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0371]        \n",
      "Epoch 659: 100%|██████████| 1/1 [00:00<00:00, 26.03it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0371]\n",
      "Epoch 660: 100%|██████████| 1/1 [00:00<00:00, 25.90it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0371]\n",
      "Epoch 661: 100%|██████████| 1/1 [00:00<00:00, 23.54it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0371]\n",
      "Epoch 662: 100%|██████████| 1/1 [00:00<00:00, 11.16it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0371]\n",
      "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0371]        \n",
      "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0371]        \n",
      "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0371]        \n",
      "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0371]        \n",
      "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0371]        \n",
      "Epoch 667: 100%|██████████| 1/1 [00:00<00:00, 20.73it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0371]\n",
      "Epoch 668: 100%|██████████| 1/1 [00:00<00:00, 21.06it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0371]\n",
      "Epoch 669: 100%|██████████| 1/1 [00:00<00:00, 21.41it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0371]\n",
      "Epoch 670: 100%|██████████| 1/1 [00:00<00:00, 19.97it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0371]\n",
      "Epoch 671: 100%|██████████| 1/1 [00:00<00:00, 10.97it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0371]\n",
      "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0371]        \n",
      "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0371]        \n",
      "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0371]        \n",
      "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0371]        \n",
      "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0371]        \n",
      "Epoch 676: 100%|██████████| 1/1 [00:00<00:00, 23.27it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0371]\n",
      "Epoch 677: 100%|██████████| 1/1 [00:00<00:00, 21.51it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0371]\n",
      "Epoch 678: 100%|██████████| 1/1 [00:00<00:00, 20.43it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0371]\n",
      "Epoch 679: 100%|██████████| 1/1 [00:00<00:00, 22.72it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0371]\n",
      "Epoch 680: 100%|██████████| 1/1 [00:00<00:00, 10.92it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0371]\n",
      "Epoch 680: 100%|██████████| 1/1 [00:00<00:00, 10.61it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0371]\n",
      "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0371]        \n",
      "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0371]        \n",
      "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0371]        \n",
      "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0371]        \n",
      "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0371]        \n",
      "Epoch 686: 100%|██████████| 1/1 [00:00<00:00, 25.60it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0371]\n",
      "Epoch 687: 100%|██████████| 1/1 [00:00<00:00, 23.28it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0371]\n",
      "Epoch 688: 100%|██████████| 1/1 [00:00<00:00, 21.26it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0371]\n",
      "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0371]        \n",
      "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0371]        \n",
      "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0371]        \n",
      "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0371]        \n",
      "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0371]        \n",
      "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0371]        \n",
      "Epoch 695: 100%|██████████| 1/1 [00:00<00:00, 19.57it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0371]\n",
      "Epoch 696: 100%|██████████| 1/1 [00:00<00:00, 21.23it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0371]\n",
      "Epoch 697: 100%|██████████| 1/1 [00:00<00:00, 20.68it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0371]\n",
      "Epoch 698: 100%|██████████| 1/1 [00:00<00:00, 21.67it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0371]\n",
      "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 20.82it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0371]\n",
      "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 11.05it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0371]\n",
      "\u001b[36m(_train_tune pid=6409)\u001b[0m \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 28.25it/s]\u001b[A\n",
      "Epoch 700: 100%|██████████| 1/1 [00:00<00:00, 25.95it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0413]\n",
      "Epoch 701: 100%|██████████| 1/1 [00:00<00:00, 20.91it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0413]\n",
      "Epoch 702: 100%|██████████| 1/1 [00:00<00:00, 25.62it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0413]\n",
      "Epoch 703: 100%|██████████| 1/1 [00:00<00:00, 10.54it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.490, valid_loss=0.0413]\n",
      "Epoch 703: 100%|██████████| 1/1 [00:00<00:00, 10.28it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0413]\n",
      "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0413]        \n",
      "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0413]        \n",
      "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0413]        \n",
      "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0413]        \n",
      "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0413]        \n",
      "Epoch 709: 100%|██████████| 1/1 [00:00<00:00, 21.11it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0413]\n",
      "Epoch 710: 100%|██████████| 1/1 [00:00<00:00, 18.50it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0413]\n",
      "Epoch 711: 100%|██████████| 1/1 [00:00<00:00, 20.37it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0413]\n",
      "Epoch 712: 100%|██████████| 1/1 [00:00<00:00, 20.47it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0413]\n",
      "Epoch 713: 100%|██████████| 1/1 [00:00<00:00, 11.59it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0413]\n",
      "Epoch 713: 100%|██████████| 1/1 [00:00<00:00, 11.31it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0413]\n",
      "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0413]        \n",
      "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0413]        \n",
      "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0413]        \n",
      "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0413]        \n",
      "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0413]        \n",
      "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0413]        \n",
      "Epoch 720: 100%|██████████| 1/1 [00:00<00:00, 25.51it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0413]\n",
      "Epoch 721: 100%|██████████| 1/1 [00:00<00:00, 22.99it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0413]\n",
      "Epoch 722: 100%|██████████| 1/1 [00:00<00:00, 11.38it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.486, valid_loss=0.0413]\n",
      "Epoch 722: 100%|██████████| 1/1 [00:00<00:00, 11.23it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0413]\n",
      "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0413]        \n",
      "Epoch 724:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0413]        \n",
      "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0413]        \n",
      "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0413]        \n",
      "Epoch 727: 100%|██████████| 1/1 [00:00<00:00, 24.91it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0413]\n",
      "Epoch 728: 100%|██████████| 1/1 [00:00<00:00, 20.85it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0413]\n",
      "Epoch 729: 100%|██████████| 1/1 [00:00<00:00, 21.48it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0413]\n",
      "Epoch 730: 100%|██████████| 1/1 [00:00<00:00, 11.69it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0413]\n",
      "Epoch 730: 100%|██████████| 1/1 [00:00<00:00, 11.19it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0413]\n",
      "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0413]        \n",
      "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0413]        \n",
      "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0413]        \n",
      "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0413]        \n",
      "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0413]        \n",
      "Epoch 736: 100%|██████████| 1/1 [00:00<00:00, 22.71it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0413]\n",
      "Epoch 737: 100%|██████████| 1/1 [00:00<00:00, 20.44it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0413]\n",
      "Epoch 738: 100%|██████████| 1/1 [00:00<00:00, 23.48it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0413]\n",
      "Epoch 739: 100%|██████████| 1/1 [00:00<00:00, 18.64it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0413]\n",
      "Epoch 740: 100%|██████████| 1/1 [00:00<00:00, 21.32it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0413]\n",
      "Epoch 741: 100%|██████████| 1/1 [00:00<00:00, 10.90it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0413]\n",
      "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0413]        \n",
      "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0413]        \n",
      "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0413]        \n",
      "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0413]        \n",
      "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.0413]        \n",
      "Epoch 747: 100%|██████████| 1/1 [00:00<00:00, 22.55it/s, v_num=0, train_loss_step=0.475, train_loss_epoch=0.475, valid_loss=0.0413]\n",
      "Epoch 748: 100%|██████████| 1/1 [00:00<00:00, 20.99it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.0413]\n",
      "Epoch 749: 100%|██████████| 1/1 [00:00<00:00, 25.04it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0413]\n",
      "Epoch 750: 100%|██████████| 1/1 [00:00<00:00, 19.60it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0413]\n",
      "Epoch 750: 100%|██████████| 1/1 [00:00<00:00, 10.67it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.505, valid_loss=0.0413]\n",
      "Epoch 750: 100%|██████████| 1/1 [00:00<00:00, 10.47it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0413]\n",
      "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0413]        \n",
      "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0413]        \n",
      "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0413]        \n",
      "Epoch 755: 100%|██████████| 1/1 [00:00<00:00, 20.44it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0413]\n",
      "Epoch 756: 100%|██████████| 1/1 [00:00<00:00, 23.90it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0413]\n",
      "Epoch 757: 100%|██████████| 1/1 [00:00<00:00, 21.01it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0413]\n",
      "Epoch 758: 100%|██████████| 1/1 [00:00<00:00, 24.03it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0413]\n",
      "Epoch 758: 100%|██████████| 1/1 [00:00<00:00, 11.59it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.487, valid_loss=0.0413]\n",
      "Epoch 758: 100%|██████████| 1/1 [00:00<00:00, 11.31it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0413]\n",
      "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0413]        \n",
      "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0413]        \n",
      "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0413]        \n",
      "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0413]        \n",
      "Epoch 763: 100%|██████████| 1/1 [00:00<00:00, 24.17it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0413]\n",
      "Epoch 764: 100%|██████████| 1/1 [00:00<00:00, 22.99it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0413]\n",
      "Epoch 765: 100%|██████████| 1/1 [00:00<00:00, 22.86it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0413]\n",
      "Epoch 766: 100%|██████████| 1/1 [00:00<00:00, 19.91it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0413]\n",
      "Epoch 767: 100%|██████████| 1/1 [00:00<00:00, 11.16it/s, v_num=0, train_loss_step=0.474, train_loss_epoch=0.476, valid_loss=0.0413]\n",
      "Epoch 767: 100%|██████████| 1/1 [00:00<00:00, 10.93it/s, v_num=0, train_loss_step=0.474, train_loss_epoch=0.474, valid_loss=0.0413]\n",
      "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.474, train_loss_epoch=0.474, valid_loss=0.0413]        \n",
      "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.0413]        \n",
      "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.0413]        \n",
      "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473, valid_loss=0.0413]        \n",
      "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0413]        \n",
      "Epoch 772: 100%|██████████| 1/1 [00:00<00:00, 22.61it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0413]\n",
      "Epoch 773:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0413]        \n",
      "Epoch 774: 100%|██████████| 1/1 [00:00<00:00, 22.57it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0413]\n",
      "Epoch 775: 100%|██████████| 1/1 [00:00<00:00, 24.12it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0413]\n",
      "Epoch 776: 100%|██████████| 1/1 [00:00<00:00, 18.37it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0413]\n",
      "Epoch 777: 100%|██████████| 1/1 [00:00<00:00, 20.50it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0413]\n",
      "Epoch 778: 100%|██████████| 1/1 [00:00<00:00, 25.25it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=0.0413]\n",
      "Epoch 778: 100%|██████████| 1/1 [00:00<00:00, 11.79it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=0.0413]\n",
      "Epoch 778: 100%|██████████| 1/1 [00:00<00:00, 11.60it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=0.0413]\n",
      "Epoch 779:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=0.0413]        \n",
      "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0413]        \n",
      "Epoch 781:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0413]        \n",
      "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562, valid_loss=0.0413]        \n",
      "Epoch 783: 100%|██████████| 1/1 [00:00<00:00, 22.06it/s, v_num=0, train_loss_step=0.566, train_loss_epoch=0.566, valid_loss=0.0413]\n",
      "Epoch 784: 100%|██████████| 1/1 [00:00<00:00, 20.40it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=0.0413]\n",
      "Epoch 785: 100%|██████████| 1/1 [00:00<00:00, 21.94it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0413]\n",
      "Epoch 786: 100%|██████████| 1/1 [00:00<00:00, 17.88it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.0413]\n",
      "Epoch 787: 100%|██████████| 1/1 [00:00<00:00, 22.39it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.0413]\n",
      "Epoch 787: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.554, valid_loss=0.0413]\n",
      "Epoch 787: 100%|██████████| 1/1 [00:00<00:00, 11.11it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0413]\n",
      "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0413]        \n",
      "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.0413]        \n",
      "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.0413]        \n",
      "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.0413]        \n",
      "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0413]        \n",
      "Epoch 792: 100%|██████████| 1/1 [00:00<00:00, 21.73it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0413]\n",
      "Epoch 793: 100%|██████████| 1/1 [00:00<00:00, 21.06it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0413]\n",
      "Epoch 794: 100%|██████████| 1/1 [00:00<00:00, 21.07it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.0413]\n",
      "Epoch 795: 100%|██████████| 1/1 [00:00<00:00, 19.94it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0413]\n",
      "Epoch 796: 100%|██████████| 1/1 [00:00<00:00, 24.73it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0413]\n",
      "Epoch 796: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=0.0413]\n",
      "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0413]        \n",
      "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0413]        \n",
      "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 11.44it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.532, valid_loss=0.0413]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=6409)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 25.52it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=6409)\u001b[0m \n",
      "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0317]        \n",
      "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0317]        \n",
      "Epoch 803:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0317]        \n",
      "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0317]        \n",
      "Epoch 805: 100%|██████████| 1/1 [00:00<00:00, 21.26it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0317]\n",
      "Epoch 806: 100%|██████████| 1/1 [00:00<00:00, 20.99it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0317]\n",
      "Epoch 807: 100%|██████████| 1/1 [00:00<00:00, 22.46it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0317]\n",
      "Epoch 808: 100%|██████████| 1/1 [00:00<00:00, 20.82it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0317]\n",
      "Epoch 808: 100%|██████████| 1/1 [00:00<00:00, 11.07it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.521, valid_loss=0.0317]\n",
      "Epoch 808: 100%|██████████| 1/1 [00:00<00:00, 10.54it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0317]\n",
      "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0317]        \n",
      "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0317]        \n",
      "Epoch 811:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0317]        \n",
      "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0317]        \n",
      "Epoch 813: 100%|██████████| 1/1 [00:00<00:00, 20.88it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0317]\n",
      "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0317]        \n",
      "Epoch 814: 100%|██████████| 1/1 [00:00<00:00, 14.72it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0317]\n",
      "Epoch 815: 100%|██████████| 1/1 [00:00<00:00, 22.71it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0317]\n",
      "Epoch 816: 100%|██████████| 1/1 [00:00<00:00, 11.83it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.512, valid_loss=0.0317]\n",
      "Epoch 816: 100%|██████████| 1/1 [00:00<00:00, 11.58it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0317]\n",
      "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0317]        \n",
      "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0317]        \n",
      "Epoch 819:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0317]        \n",
      "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0317]        \n",
      "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0317]        \n",
      "Epoch 821: 100%|██████████| 1/1 [00:00<00:00, 21.57it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0317]\n",
      "Epoch 822: 100%|██████████| 1/1 [00:00<00:00, 18.78it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0317]\n",
      "Epoch 823: 100%|██████████| 1/1 [00:00<00:00, 24.56it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0317]\n",
      "Epoch 824: 100%|██████████| 1/1 [00:00<00:00, 19.23it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0317]\n",
      "Epoch 825: 100%|██████████| 1/1 [00:00<00:00, 10.78it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0317]\n",
      "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0317]        \n",
      "Epoch 827:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0317]        \n",
      "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0317]        \n",
      "Epoch 829:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0317]        \n",
      "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0317]        \n",
      "Epoch 831: 100%|██████████| 1/1 [00:00<00:00, 22.90it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0317]\n",
      "Epoch 832: 100%|██████████| 1/1 [00:00<00:00, 21.66it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0317]\n",
      "Epoch 833: 100%|██████████| 1/1 [00:00<00:00, 18.63it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0317]\n",
      "Epoch 834: 100%|██████████| 1/1 [00:00<00:00, 23.32it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0317]\n",
      "Epoch 834: 100%|██████████| 1/1 [00:00<00:00, 11.50it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0317]\n",
      "Epoch 834: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0317]\n",
      "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0317]        \n",
      "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0317]        \n",
      "Epoch 838:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0317]        \n",
      "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0317]        \n",
      "Epoch 840: 100%|██████████| 1/1 [00:00<00:00, 23.71it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0317]\n",
      "Epoch 841: 100%|██████████| 1/1 [00:00<00:00, 23.48it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0317]\n",
      "Epoch 842: 100%|██████████| 1/1 [00:00<00:00, 20.84it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0317]\n",
      "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0317]        \n",
      "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0317]        \n",
      "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0317]        \n",
      "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0317]        \n",
      "Epoch 848: 100%|██████████| 1/1 [00:00<00:00, 25.40it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0317]\n",
      "Epoch 849: 100%|██████████| 1/1 [00:00<00:00, 21.09it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0317]\n",
      "Epoch 850: 100%|██████████| 1/1 [00:00<00:00, 24.16it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0317]\n",
      "Epoch 851: 100%|██████████| 1/1 [00:00<00:00, 21.34it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0317]\n",
      "Epoch 851: 100%|██████████| 1/1 [00:00<00:00, 11.00it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0317]\n",
      "Epoch 852: 100%|██████████| 1/1 [00:00<00:00, 10.07it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0317]\n",
      "Epoch 853:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0317]        \n",
      "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0317]        \n",
      "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0317]        \n",
      "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0317]        \n",
      "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0317]        \n",
      "Epoch 858: 100%|██████████| 1/1 [00:00<00:00, 21.37it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0317]\n",
      "Epoch 859: 100%|██████████| 1/1 [00:00<00:00, 20.43it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0317]\n",
      "Epoch 860: 100%|██████████| 1/1 [00:00<00:00, 20.10it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0317]\n",
      "Epoch 861: 100%|██████████| 1/1 [00:00<00:00, 23.86it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0317]\n",
      "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0317]        \n",
      "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0317]        \n",
      "Epoch 865:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0317]        \n",
      "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0317]        \n",
      "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0317]        \n",
      "Epoch 868: 100%|██████████| 1/1 [00:00<00:00, 22.20it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0317]\n",
      "Epoch 869: 100%|██████████| 1/1 [00:00<00:00, 20.42it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0317]\n",
      "Epoch 870: 100%|██████████| 1/1 [00:00<00:00, 22.99it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0317]\n",
      "Epoch 871: 100%|██████████| 1/1 [00:00<00:00, 20.96it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0317]\n",
      "Epoch 871: 100%|██████████| 1/1 [00:00<00:00, 11.03it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.496, valid_loss=0.0317]\n",
      "Epoch 871: 100%|██████████| 1/1 [00:00<00:00, 10.64it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0317]\n",
      "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0317]        \n",
      "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0317]        \n",
      "Epoch 874:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0317]        \n",
      "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0317]        \n",
      "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0317]        \n",
      "Epoch 876: 100%|██████████| 1/1 [00:00<00:00, 22.87it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0317]\n",
      "Epoch 877: 100%|██████████| 1/1 [00:00<00:00, 25.97it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0317]\n",
      "Epoch 878: 100%|██████████| 1/1 [00:00<00:00, 21.13it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0317]\n",
      "Epoch 879: 100%|██████████| 1/1 [00:00<00:00, 23.33it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0317]\n",
      "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0317]        \n",
      "Epoch 881:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0317]\n",
      "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0317]        \n",
      "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0317]        \n",
      "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0317]        \n",
      "Epoch 885: 100%|██████████| 1/1 [00:00<00:00, 23.09it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0317]\n",
      "Epoch 886: 100%|██████████| 1/1 [00:00<00:00, 23.43it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0317]\n",
      "Epoch 887: 100%|██████████| 1/1 [00:00<00:00, 19.92it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0317]\n",
      "Epoch 888: 100%|██████████| 1/1 [00:00<00:00, 22.19it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0317]\n",
      "Epoch 888: 100%|██████████| 1/1 [00:00<00:00, 10.88it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0317]\n",
      "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0317]        \n",
      "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0317]        \n",
      "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0317]        \n",
      "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0317]        \n",
      "Epoch 894: 100%|██████████| 1/1 [00:00<00:00, 20.90it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0317]\n",
      "Epoch 895: 100%|██████████| 1/1 [00:00<00:00, 26.65it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0317]\n",
      "Epoch 896: 100%|██████████| 1/1 [00:00<00:00, 19.78it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0317]\n",
      "Epoch 897: 100%|██████████| 1/1 [00:00<00:00, 11.38it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0317]\n",
      "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0317]        \n",
      "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 10.65it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0317]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=6409)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 24.39it/s]\u001b[A\n",
      "Epoch 900: 100%|██████████| 1/1 [00:00<00:00, 21.31it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0361]\n",
      "Epoch 901: 100%|██████████| 1/1 [00:00<00:00, 24.39it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0361]\n",
      "Epoch 902: 100%|██████████| 1/1 [00:00<00:00, 22.97it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0361]\n",
      "Epoch 904:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0361]        \n",
      "Epoch 905:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0361]        \n",
      "Epoch 906:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0361]        \n",
      "Epoch 907:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0361]        \n",
      "Epoch 908: 100%|██████████| 1/1 [00:00<00:00, 23.76it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0361]\n",
      "Epoch 909: 100%|██████████| 1/1 [00:00<00:00, 20.20it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0361]\n",
      "Epoch 910: 100%|██████████| 1/1 [00:00<00:00, 22.74it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0361]\n",
      "Epoch 911: 100%|██████████| 1/1 [00:00<00:00, 21.07it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0361]\n",
      "Epoch 913:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0361]        \n",
      "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0361]        \n",
      "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0361]        \n",
      "Epoch 916:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0361]        \n",
      "Epoch 917: 100%|██████████| 1/1 [00:00<00:00, 22.86it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0361]\n",
      "Epoch 918: 100%|██████████| 1/1 [00:00<00:00, 23.30it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0361]\n",
      "Epoch 919: 100%|██████████| 1/1 [00:00<00:00, 23.21it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0361]\n",
      "Epoch 920: 100%|██████████| 1/1 [00:00<00:00, 11.89it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0361]\n",
      "Epoch 920: 100%|██████████| 1/1 [00:00<00:00, 11.46it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0361]\n",
      "Epoch 921:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0361]        \n",
      "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0361]        \n",
      "Epoch 923:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0361]        \n",
      "Epoch 924:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0361]        \n",
      "Epoch 925: 100%|██████████| 1/1 [00:00<00:00, 22.42it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0361]\n",
      "Epoch 926: 100%|██████████| 1/1 [00:00<00:00, 21.24it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0361]\n",
      "Epoch 927: 100%|██████████| 1/1 [00:00<00:00, 22.05it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0361]\n",
      "Epoch 928: 100%|██████████| 1/1 [00:00<00:00, 20.22it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0361]\n",
      "Epoch 929: 100%|██████████| 1/1 [00:00<00:00, 26.07it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0361]\n",
      "Epoch 931:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0361]        \n",
      "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0361]        \n",
      "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0361]        \n",
      "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0361]        \n",
      "Epoch 935: 100%|██████████| 1/1 [00:00<00:00, 22.44it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0361]\n",
      "Epoch 936: 100%|██████████| 1/1 [00:00<00:00, 20.17it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0361]\n",
      "Epoch 937: 100%|██████████| 1/1 [00:00<00:00, 25.90it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0361]\n",
      "Epoch 939:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0361]        \n",
      "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0361]        \n",
      "Epoch 941:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0361]        \n",
      "Epoch 942: 100%|██████████| 1/1 [00:00<00:00, 25.22it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0361]\n",
      "Epoch 943: 100%|██████████| 1/1 [00:00<00:00, 20.74it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0361]\n",
      "Epoch 944: 100%|██████████| 1/1 [00:00<00:00, 27.32it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0361]\n",
      "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0361]        \n",
      "Epoch 947:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0361]        \n",
      "Epoch 948:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0361]        \n",
      "Epoch 949:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0361]        \n",
      "Epoch 950:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0361]        \n",
      "Epoch 951: 100%|██████████| 1/1 [00:00<00:00, 21.62it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0361]\n",
      "Epoch 952: 100%|██████████| 1/1 [00:00<00:00, 21.65it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0361]\n",
      "Epoch 953: 100%|██████████| 1/1 [00:00<00:00, 22.76it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0361]\n",
      "Epoch 954: 100%|██████████| 1/1 [00:00<00:00, 20.29it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0361]\n",
      "Epoch 955: 100%|██████████| 1/1 [00:00<00:00, 24.19it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0361]\n",
      "Epoch 955: 100%|██████████| 1/1 [00:00<00:00, 11.59it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.489, valid_loss=0.0361]\n",
      "Epoch 955: 100%|██████████| 1/1 [00:00<00:00, 11.33it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0361]\n",
      "Epoch 956:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0361]        \n",
      "Epoch 957:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0361]        \n",
      "Epoch 958:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0361]        \n",
      "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0361]        \n",
      "Epoch 960: 100%|██████████| 1/1 [00:00<00:00, 24.20it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0361]\n",
      "Epoch 961: 100%|██████████| 1/1 [00:00<00:00, 20.99it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0361]\n",
      "Epoch 962: 100%|██████████| 1/1 [00:00<00:00, 25.59it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0361]\n",
      "Epoch 962: 100%|██████████| 1/1 [00:00<00:00, 11.89it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0361]\n",
      "Epoch 962: 100%|██████████| 1/1 [00:00<00:00, 11.37it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0361]\n",
      "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0361]        \n",
      "Epoch 965:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0361]        \n",
      "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0361]        \n",
      "Epoch 967:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0361]        \n",
      "Epoch 968: 100%|██████████| 1/1 [00:00<00:00, 23.11it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0361]\n",
      "Epoch 969: 100%|██████████| 1/1 [00:00<00:00, 22.14it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0361]\n",
      "Epoch 970: 100%|██████████| 1/1 [00:00<00:00, 22.79it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0361]\n",
      "Epoch 971: 100%|██████████| 1/1 [00:00<00:00, 18.65it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0361]\n",
      "Epoch 972: 100%|██████████| 1/1 [00:00<00:00, 22.72it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0361]\n",
      "Epoch 973: 100%|██████████| 1/1 [00:00<00:00, 10.65it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0361]\n",
      "Epoch 974:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0361]        \n",
      "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0361]        \n",
      "Epoch 976:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0361]        \n",
      "Epoch 977:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0361]        \n",
      "Epoch 978: 100%|██████████| 1/1 [00:00<00:00, 21.17it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0361]\n",
      "Epoch 979: 100%|██████████| 1/1 [00:00<00:00, 19.55it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0361]\n",
      "Epoch 980: 100%|██████████| 1/1 [00:00<00:00, 20.28it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0361]\n",
      "Epoch 981: 100%|██████████| 1/1 [00:00<00:00, 19.31it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0361]\n",
      "Epoch 982: 100%|██████████| 1/1 [00:00<00:00, 24.34it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0361]\n",
      "Epoch 982: 100%|██████████| 1/1 [00:00<00:00, 11.67it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.481, valid_loss=0.0361]\n",
      "Epoch 982: 100%|██████████| 1/1 [00:00<00:00, 11.38it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0361]\n",
      "Epoch 983:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0361]        \n",
      "Epoch 984:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0361]        \n",
      "Epoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0361]        \n",
      "Epoch 986:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0361]        \n",
      "Epoch 987: 100%|██████████| 1/1 [00:00<00:00, 22.54it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0361]\n",
      "Epoch 988: 100%|██████████| 1/1 [00:00<00:00, 21.18it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0361]\n",
      "Epoch 989: 100%|██████████| 1/1 [00:00<00:00, 21.53it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0361]\n",
      "Epoch 990: 100%|██████████| 1/1 [00:00<00:00, 20.38it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0361]\n",
      "Epoch 991: 100%|██████████| 1/1 [00:00<00:00, 10.93it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0361]\n",
      "Epoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0361]        \n",
      "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0361]        \n",
      "Epoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.0361]        \n",
      "Epoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.0361]        \n",
      "Epoch 996: 100%|██████████| 1/1 [00:00<00:00, 25.34it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0361]\n",
      "Epoch 997: 100%|██████████| 1/1 [00:00<00:00, 25.92it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0361]\n",
      "Epoch 998: 100%|██████████| 1/1 [00:00<00:00, 24.90it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.0361]\n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 10.77it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.475, valid_loss=0.0361]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=6409)\u001b[0m \n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=6409)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 24.71it/s]\u001b[A\n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00,  6.68it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.0393]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=6409)\u001b[0m `Trainer.fit` stopped: `max_steps=1000` reached.\n",
      "\u001b[36m(_train_tune pid=6843)\u001b[0m /home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=6843)\u001b[0m Seed set to 6\n",
      "\u001b[36m(_train_tune pid=6843)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=6843)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=6843)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=6843)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(_train_tune pid=6843)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]\n",
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=6843)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=6843)\u001b[0m   | Name            | Type          | Params | Mode \n",
      "\u001b[36m(_train_tune pid=6843)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=6843)\u001b[0m 0 | loss            | WMAPE         | 0      | train\n",
      "\u001b[36m(_train_tune pid=6843)\u001b[0m 1 | padder          | ConstantPad1d | 0      | train\n",
      "\u001b[36m(_train_tune pid=6843)\u001b[0m 2 | scaler          | TemporalNorm  | 0      | train\n",
      "\u001b[36m(_train_tune pid=6843)\u001b[0m 3 | hist_encoder    | LSTM          | 41.2 K | train\n",
      "\u001b[36m(_train_tune pid=6843)\u001b[0m 4 | context_adapter | Linear        | 38.9 K | train\n",
      "\u001b[36m(_train_tune pid=6843)\u001b[0m 5 | mlp_decoder     | MLP           | 3.6 K  | train\n",
      "\u001b[36m(_train_tune pid=6843)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=6843)\u001b[0m 83.7 K    Trainable params\n",
      "\u001b[36m(_train_tune pid=6843)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=6843)\u001b[0m 83.7 K    Total params\n",
      "\u001b[36m(_train_tune pid=6843)\u001b[0m 0.335     Total estimated model params size (MB)\n",
      "\u001b[36m(_train_tune pid=6843)\u001b[0m 11        Modules in train mode\n",
      "\u001b[36m(_train_tune pid=6843)\u001b[0m 0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s]\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  7.14it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040]\n",
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040]        \n",
      "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740]        \n",
      "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.839, train_loss_epoch=0.839]         \n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00, 89.74it/s, v_num=0, train_loss_step=0.942, train_loss_epoch=0.942]\n",
      "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040]        \n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00, 70.98it/s, v_num=0, train_loss_step=0.969, train_loss_epoch=1.000]\n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00, 68.03it/s, v_num=0, train_loss_step=0.969, train_loss_epoch=0.969]\n",
      "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.969, train_loss_epoch=0.969]        \n",
      "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060]        \n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00, 75.41it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060]\n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00, 61.97it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.060]\n",
      "Epoch 34: 100%|██████████| 1/1 [00:00<00:00, 58.52it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]\n",
      "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]        \n",
      "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640]        \n",
      "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.964, train_loss_epoch=0.964]        \n",
      "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.981, train_loss_epoch=0.981]        \n",
      "Epoch 55: 100%|██████████| 1/1 [00:00<00:00, 59.06it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590]\n",
      "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590]        \n",
      "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160]        \n",
      "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.975, train_loss_epoch=0.975]        \n",
      "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992]        \n",
      "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.974, train_loss_epoch=0.974]        \n",
      "Epoch 82: 100%|██████████| 1/1 [00:00<00:00, 52.49it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.040]\n",
      "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210]        \n",
      "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]         \n",
      "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988]        \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 72.07it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=1.070] \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=6843)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 48.15it/s]\u001b[A\n",
      "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.307]        \n",
      "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.817, train_loss_epoch=0.817, valid_loss=0.307]         \n",
      "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.954, train_loss_epoch=0.954, valid_loss=0.307]        \n",
      "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.770, train_loss_epoch=0.770, valid_loss=0.307]        \n",
      "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=0.307]         \n",
      "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.974, train_loss_epoch=0.974, valid_loss=0.307]        \n",
      "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.307]        \n",
      "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.908, train_loss_epoch=0.908, valid_loss=0.307]        \n",
      "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.307]        \n",
      "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.768, train_loss_epoch=0.768, valid_loss=0.307]        \n",
      "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.907, train_loss_epoch=0.907, valid_loss=0.307]         \n",
      "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.307]        \n",
      "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.307]        \n",
      "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.307]\n",
      "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.962, train_loss_epoch=0.962, valid_loss=0.307]        \n",
      "Epoch 178: 100%|██████████| 1/1 [00:00<00:00, 65.44it/s, v_num=0, train_loss_step=0.962, train_loss_epoch=0.962, valid_loss=0.307]\n",
      "Epoch 178: 100%|██████████| 1/1 [00:00<00:00, 55.43it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.307]\n",
      "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.912, train_loss_epoch=0.912, valid_loss=0.307]        \n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00, 70.72it/s, v_num=0, train_loss_step=0.912, train_loss_epoch=0.912, valid_loss=0.307]\n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00, 58.12it/s, v_num=0, train_loss_step=0.939, train_loss_epoch=0.912, valid_loss=0.307]\n",
      "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.939, train_loss_epoch=0.939, valid_loss=0.307]        \n",
      "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.307]        \n",
      "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.307]        \n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 56.64it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=0.994, valid_loss=0.307]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=6843)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 43.68it/s]\u001b[A\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00, 63.63it/s, v_num=0, train_loss_step=0.981, train_loss_epoch=0.981, valid_loss=0.331]\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00, 55.05it/s, v_num=0, train_loss_step=0.949, train_loss_epoch=0.981, valid_loss=0.331]\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00, 50.49it/s, v_num=0, train_loss_step=0.949, train_loss_epoch=0.949, valid_loss=0.331]\n",
      "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.949, train_loss_epoch=0.949, valid_loss=0.331]        \n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00, 62.12it/s, v_num=0, train_loss_step=0.967, train_loss_epoch=0.967, valid_loss=0.331]\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00, 66.57it/s, v_num=0, train_loss_step=0.936, train_loss_epoch=0.936, valid_loss=0.331] \n",
      "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.936, train_loss_epoch=0.936, valid_loss=0.331]        \n",
      "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.959, train_loss_epoch=0.959, valid_loss=0.331]        \n",
      "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.331]        \n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00, 54.64it/s, v_num=0, train_loss_step=0.919, train_loss_epoch=1.010, valid_loss=0.331]\n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00, 51.04it/s, v_num=0, train_loss_step=0.919, train_loss_epoch=0.919, valid_loss=0.331]\n",
      "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.919, train_loss_epoch=0.919, valid_loss=0.331]        \n",
      "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.969, train_loss_epoch=0.969, valid_loss=0.331]        \n",
      "Epoch 239: 100%|██████████| 1/1 [00:00<00:00, 87.20it/s, v_num=0, train_loss_step=0.969, train_loss_epoch=0.969, valid_loss=0.331]\n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00, 81.64it/s, v_num=0, train_loss_step=0.983, train_loss_epoch=0.983, valid_loss=0.331]\n",
      "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.834, train_loss_epoch=0.834, valid_loss=0.331]        \n",
      "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.903, train_loss_epoch=0.903, valid_loss=0.331]        \n",
      "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.885, train_loss_epoch=0.885, valid_loss=0.331]         \n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00, 51.51it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.331]\n",
      "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.331]        \n",
      "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.331]        \n",
      "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.748, train_loss_epoch=0.748, valid_loss=0.331]        \n",
      "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.991, valid_loss=0.331]        \n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00, 72.23it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.991, valid_loss=0.331]\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00, 60.45it/s, v_num=0, train_loss_step=0.985, train_loss_epoch=0.985, valid_loss=0.331] \n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00, 43.49it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.331]\n",
      "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.331]        \n",
      "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.801, train_loss_epoch=0.801, valid_loss=0.331]        \n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00, 71.73it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.331]\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 52.05it/s, v_num=0, train_loss_step=0.990, train_loss_epoch=0.963, valid_loss=0.331]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 32.64it/s]\u001b[A\n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00, 36.43it/s, v_num=0, train_loss_step=0.958, train_loss_epoch=0.958, valid_loss=0.317]\n",
      "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.958, train_loss_epoch=0.958, valid_loss=0.317]        \n",
      "Epoch 305: 100%|██████████| 1/1 [00:00<00:00, 73.63it/s, v_num=0, train_loss_step=0.986, train_loss_epoch=0.986, valid_loss=0.317]\n",
      "Epoch 305: 100%|██████████| 1/1 [00:00<00:00, 48.76it/s, v_num=0, train_loss_step=0.953, train_loss_epoch=0.953, valid_loss=0.317]\n",
      "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.953, train_loss_epoch=0.953, valid_loss=0.317]        \n",
      "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.911, train_loss_epoch=0.911, valid_loss=0.317]        \n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00, 27.56it/s, v_num=0, train_loss_step=0.799, train_loss_epoch=0.911, valid_loss=0.317]\n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00, 25.88it/s, v_num=0, train_loss_step=0.799, train_loss_epoch=0.799, valid_loss=0.317]\n",
      "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.799, train_loss_epoch=0.799, valid_loss=0.317]        \n",
      "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.896, train_loss_epoch=0.896, valid_loss=0.317]        \n",
      "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.893, train_loss_epoch=0.893, valid_loss=0.317]        \n",
      "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.317]        \n",
      "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.972, train_loss_epoch=0.972, valid_loss=0.317]        \n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00, 75.92it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=0.317]\n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00, 49.49it/s, v_num=0, train_loss_step=0.811, train_loss_epoch=0.811, valid_loss=0.317]\n",
      "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.811, train_loss_epoch=0.811, valid_loss=0.317]        \n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00, 84.44it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=0.317]\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00, 54.57it/s, v_num=0, train_loss_step=0.859, train_loss_epoch=1.210, valid_loss=0.317]\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00, 52.44it/s, v_num=0, train_loss_step=0.859, train_loss_epoch=0.859, valid_loss=0.317]\n",
      "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.859, train_loss_epoch=0.859, valid_loss=0.317]        \n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00, 63.45it/s, v_num=0, train_loss_step=0.758, train_loss_epoch=0.758, valid_loss=0.317]\n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00, 43.53it/s, v_num=0, train_loss_step=0.952, train_loss_epoch=0.952, valid_loss=0.317]\n",
      "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.952, train_loss_epoch=0.952, valid_loss=0.317]        \n",
      "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.886, train_loss_epoch=0.886, valid_loss=0.317]        \n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00, 75.29it/s, v_num=0, train_loss_step=0.792, train_loss_epoch=0.792, valid_loss=0.317]\n",
      "Epoch 354: 100%|██████████| 1/1 [00:00<00:00, 50.89it/s, v_num=0, train_loss_step=0.781, train_loss_epoch=0.744, valid_loss=0.317]\n",
      "Epoch 354: 100%|██████████| 1/1 [00:00<00:00, 48.31it/s, v_num=0, train_loss_step=0.781, train_loss_epoch=0.781, valid_loss=0.317]\n",
      "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.781, train_loss_epoch=0.781, valid_loss=0.317]        \n",
      "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.801, train_loss_epoch=0.801, valid_loss=0.317]        \n",
      "Epoch 362: 100%|██████████| 1/1 [00:00<00:00, 57.39it/s, v_num=0, train_loss_step=0.780, train_loss_epoch=0.780, valid_loss=0.317]\n",
      "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.925, train_loss_epoch=0.925, valid_loss=0.317]        \n",
      "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.845, train_loss_epoch=0.845, valid_loss=0.317]        \n",
      "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.317]        \n",
      "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.871, train_loss_epoch=0.871, valid_loss=0.317]        \n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00, 52.20it/s, v_num=0, train_loss_step=0.871, train_loss_epoch=0.871, valid_loss=0.317]\n",
      "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.805, train_loss_epoch=0.805, valid_loss=0.317]        \n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00, 72.75it/s, v_num=0, train_loss_step=0.749, train_loss_epoch=0.749, valid_loss=0.317]\n",
      "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.742, train_loss_epoch=0.742, valid_loss=0.317]        \n",
      "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.831, train_loss_epoch=0.831, valid_loss=0.317]        \n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 55.46it/s, v_num=0, train_loss_step=0.860, train_loss_epoch=0.920, valid_loss=0.317]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 33.99it/s]\u001b[A\n",
      "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.860, train_loss_epoch=0.860, valid_loss=0.0725]        \n",
      "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.919, train_loss_epoch=0.919, valid_loss=0.0725]        \n",
      "Epoch 408: 100%|██████████| 1/1 [00:00<00:00, 55.99it/s, v_num=0, train_loss_step=0.859, train_loss_epoch=0.859, valid_loss=0.0725]\n",
      "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.859, train_loss_epoch=0.859, valid_loss=0.0725]        \n",
      "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.812, train_loss_epoch=0.812, valid_loss=0.0725]        \n",
      "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.0725]        \n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00, 54.87it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.0725]\n",
      "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.780, train_loss_epoch=0.780, valid_loss=0.0725]        \n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00, 65.18it/s, v_num=0, train_loss_step=0.789, train_loss_epoch=0.789, valid_loss=0.0725]\n",
      "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.878, train_loss_epoch=0.878, valid_loss=0.0725]        \n",
      "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.781, train_loss_epoch=0.781, valid_loss=0.0725]        \n",
      "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.716, train_loss_epoch=0.716, valid_loss=0.0725]        \n",
      "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.641, train_loss_epoch=0.641, valid_loss=0.0725]        \n",
      "Epoch 451: 100%|██████████| 1/1 [00:00<00:00, 49.51it/s, v_num=0, train_loss_step=0.668, train_loss_epoch=0.668, valid_loss=0.0725]\n",
      "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.707, train_loss_epoch=0.707, valid_loss=0.0725]        \n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00, 53.53it/s, v_num=0, train_loss_step=0.707, train_loss_epoch=0.707, valid_loss=0.0725]\n",
      "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.657, train_loss_epoch=0.657, valid_loss=0.0725]        \n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00, 41.06it/s, v_num=0, train_loss_step=0.851, train_loss_epoch=0.662, valid_loss=0.0725]\n",
      "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.851, train_loss_epoch=0.851, valid_loss=0.0725]        \n",
      "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.851, train_loss_epoch=0.851, valid_loss=0.0725]\n",
      "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.991, valid_loss=0.0725]        \n",
      "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.991, valid_loss=0.0725]\n",
      "Epoch 471: 100%|██████████| 1/1 [00:00<00:00, 43.44it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.0725]\n",
      "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.0725]        \n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00, 52.12it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.0725]\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00, 39.30it/s, v_num=0, train_loss_step=0.972, train_loss_epoch=0.972, valid_loss=0.0725]\n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00, 62.32it/s, v_num=0, train_loss_step=0.930, train_loss_epoch=0.930, valid_loss=0.0725]\n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00, 74.84it/s, v_num=0, train_loss_step=0.791, train_loss_epoch=0.791, valid_loss=0.0725]\n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00, 39.26it/s, v_num=0, train_loss_step=0.690, train_loss_epoch=0.690, valid_loss=0.0725]\n",
      "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.690, train_loss_epoch=0.690, valid_loss=0.0725]        \n",
      "Epoch 493: 100%|██████████| 1/1 [00:00<00:00, 72.62it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984, valid_loss=0.0725]\n",
      "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.878, train_loss_epoch=0.878, valid_loss=0.0725]        \n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 51.07it/s, v_num=0, train_loss_step=0.943, train_loss_epoch=0.644, valid_loss=0.0725]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 32.91it/s]\u001b[A\n",
      "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.943, train_loss_epoch=0.943, valid_loss=0.138]         \n",
      "Epoch 500: 100%|██████████| 1/1 [00:00<00:00, 62.37it/s, v_num=0, train_loss_step=0.943, train_loss_epoch=0.943, valid_loss=0.138]\n",
      "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.876, train_loss_epoch=0.876, valid_loss=0.138]        \n",
      "Epoch 504: 100%|██████████| 1/1 [00:00<00:00, 59.53it/s, v_num=0, train_loss_step=0.876, train_loss_epoch=0.876, valid_loss=0.138]\n",
      "Epoch 508: 100%|██████████| 1/1 [00:00<00:00, 38.57it/s, v_num=0, train_loss_step=0.849, train_loss_epoch=0.757, valid_loss=0.138]\n",
      "Epoch 508: 100%|██████████| 1/1 [00:00<00:00, 36.21it/s, v_num=0, train_loss_step=0.849, train_loss_epoch=0.849, valid_loss=0.138]\n",
      "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.849, train_loss_epoch=0.849, valid_loss=0.138]        \n",
      "Epoch 512: 100%|██████████| 1/1 [00:00<00:00, 59.05it/s, v_num=0, train_loss_step=0.761, train_loss_epoch=0.761, valid_loss=0.138]\n",
      "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.717, train_loss_epoch=0.717, valid_loss=0.138]        \n",
      "Epoch 521: 100%|██████████| 1/1 [00:00<00:00, 58.03it/s, v_num=0, train_loss_step=0.886, train_loss_epoch=0.886, valid_loss=0.138]\n",
      "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.947, train_loss_epoch=0.947, valid_loss=0.138]        \n",
      "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.877, train_loss_epoch=0.877, valid_loss=0.138]        \n",
      "Epoch 530: 100%|██████████| 1/1 [00:00<00:00, 54.86it/s, v_num=0, train_loss_step=0.877, train_loss_epoch=0.877, valid_loss=0.138]\n",
      "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.898, train_loss_epoch=0.898, valid_loss=0.138]        \n",
      "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.750, train_loss_epoch=0.750, valid_loss=0.138]        \n",
      "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.891, train_loss_epoch=0.891, valid_loss=0.138]        \n",
      "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.675, train_loss_epoch=0.675, valid_loss=0.138]        \n",
      "Epoch 551: 100%|██████████| 1/1 [00:00<00:00, 86.34it/s, v_num=0, train_loss_step=0.634, train_loss_epoch=0.634, valid_loss=0.138]\n",
      "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.770, train_loss_epoch=0.770, valid_loss=0.138]        \n",
      "Epoch 560: 100%|██████████| 1/1 [00:00<00:00, 74.89it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.138]\n",
      "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.695, train_loss_epoch=0.695, valid_loss=0.138]        \n",
      "Epoch 569: 100%|██████████| 1/1 [00:00<00:00, 59.97it/s, v_num=0, train_loss_step=0.762, train_loss_epoch=0.762, valid_loss=0.138]\n",
      "Epoch 569: 100%|██████████| 1/1 [00:00<00:00, 45.92it/s, v_num=0, train_loss_step=0.795, train_loss_epoch=0.762, valid_loss=0.138]\n",
      "Epoch 569: 100%|██████████| 1/1 [00:00<00:00, 43.62it/s, v_num=0, train_loss_step=0.795, train_loss_epoch=0.795, valid_loss=0.138]\n",
      "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.795, train_loss_epoch=0.795, valid_loss=0.138]        \n",
      "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.961, train_loss_epoch=0.961, valid_loss=0.138]        \n",
      "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.742, train_loss_epoch=0.742, valid_loss=0.138]        \n",
      "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.637, train_loss_epoch=0.637, valid_loss=0.138]        \n",
      "Epoch 586: 100%|██████████| 1/1 [00:00<00:00, 49.08it/s, v_num=0, train_loss_step=0.857, train_loss_epoch=0.857, valid_loss=0.138]\n",
      "Epoch 586: 100%|██████████| 1/1 [00:00<00:00, 37.56it/s, v_num=0, train_loss_step=0.873, train_loss_epoch=0.873, valid_loss=0.138]\n",
      "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.873, train_loss_epoch=0.873, valid_loss=0.138]        \n",
      "Epoch 590: 100%|██████████| 1/1 [00:00<00:00, 44.03it/s, v_num=0, train_loss_step=0.632, train_loss_epoch=0.632, valid_loss=0.138]\n",
      "Epoch 590: 100%|██████████| 1/1 [00:00<00:00, 35.32it/s, v_num=0, train_loss_step=0.739, train_loss_epoch=0.739, valid_loss=0.138]\n",
      "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.667, train_loss_epoch=0.667, valid_loss=0.138]        \n",
      "Epoch 595: 100%|██████████| 1/1 [00:00<00:00, 68.55it/s, v_num=0, train_loss_step=0.667, train_loss_epoch=0.667, valid_loss=0.138]\n",
      "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 63.12it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582, valid_loss=0.138]\n",
      "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 46.91it/s, v_num=0, train_loss_step=0.723, train_loss_epoch=0.582, valid_loss=0.138]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 29.87it/s]\u001b[A\n",
      "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.604, train_loss_epoch=0.604, valid_loss=0.149]        \n",
      "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.762, train_loss_epoch=0.762, valid_loss=0.149]        \n",
      "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.884, train_loss_epoch=0.884, valid_loss=0.149]        \n",
      "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.620, train_loss_epoch=0.620, valid_loss=0.149]        \n",
      "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.579, train_loss_epoch=0.579, valid_loss=0.149]        \n",
      "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.865, train_loss_epoch=0.865, valid_loss=0.149]        \n",
      "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.149]        \n",
      "Epoch 631: 100%|██████████| 1/1 [00:00<00:00, 41.91it/s, v_num=0, train_loss_step=0.788, train_loss_epoch=0.788, valid_loss=0.149]\n",
      "Epoch 631: 100%|██████████| 1/1 [00:00<00:00, 36.66it/s, v_num=0, train_loss_step=0.718, train_loss_epoch=0.788, valid_loss=0.149]\n",
      "Epoch 631: 100%|██████████| 1/1 [00:00<00:00, 35.37it/s, v_num=0, train_loss_step=0.718, train_loss_epoch=0.718, valid_loss=0.149]\n",
      "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.718, train_loss_epoch=0.718, valid_loss=0.149]        \n",
      "Epoch 636: 100%|██████████| 1/1 [00:00<00:00, 75.63it/s, v_num=0, train_loss_step=0.752, train_loss_epoch=0.752, valid_loss=0.149]\n",
      "Epoch 636: 100%|██████████| 1/1 [00:00<00:00, 47.11it/s, v_num=0, train_loss_step=0.736, train_loss_epoch=0.736, valid_loss=0.149]\n",
      "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.736, train_loss_epoch=0.736, valid_loss=0.149]        \n",
      "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.736, train_loss_epoch=0.736, valid_loss=0.149]\n",
      "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.801, train_loss_epoch=0.801, valid_loss=0.149]        \n",
      "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.149]        \n",
      "Epoch 645: 100%|██████████| 1/1 [00:00<00:00, 56.11it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.149]\n",
      "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.783, train_loss_epoch=0.783, valid_loss=0.149]        \n",
      "Epoch 654: 100%|██████████| 1/1 [00:00<00:00, 61.08it/s, v_num=0, train_loss_step=0.700, train_loss_epoch=0.700, valid_loss=0.149]\n",
      "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.854, train_loss_epoch=0.854, valid_loss=0.149]        \n",
      "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.658, train_loss_epoch=0.658, valid_loss=0.149]        \n",
      "Epoch 663: 100%|██████████| 1/1 [00:00<00:00, 59.88it/s, v_num=0, train_loss_step=0.658, train_loss_epoch=0.658, valid_loss=0.149]\n",
      "Epoch 667: 100%|██████████| 1/1 [00:00<00:00, 43.12it/s, v_num=0, train_loss_step=0.616, train_loss_epoch=0.826, valid_loss=0.149]\n",
      "Epoch 667: 100%|██████████| 1/1 [00:00<00:00, 38.98it/s, v_num=0, train_loss_step=0.616, train_loss_epoch=0.616, valid_loss=0.149]\n",
      "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.616, train_loss_epoch=0.616, valid_loss=0.149]        \n",
      "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.741, train_loss_epoch=0.741, valid_loss=0.149]        \n",
      "Epoch 672: 100%|██████████| 1/1 [00:00<00:00, 54.16it/s, v_num=0, train_loss_step=0.741, train_loss_epoch=0.741, valid_loss=0.149]\n",
      "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.878, train_loss_epoch=0.878, valid_loss=0.149]        \n",
      "Epoch 676: 100%|██████████| 1/1 [00:00<00:00, 52.05it/s, v_num=0, train_loss_step=0.878, train_loss_epoch=0.878, valid_loss=0.149]\n",
      "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.825, train_loss_epoch=0.825, valid_loss=0.149]        \n",
      "Epoch 685: 100%|██████████| 1/1 [00:00<00:00, 71.16it/s, v_num=0, train_loss_step=0.938, train_loss_epoch=0.938, valid_loss=0.149]\n",
      "Epoch 685: 100%|██████████| 1/1 [00:00<00:00, 46.74it/s, v_num=0, train_loss_step=0.755, train_loss_epoch=0.755, valid_loss=0.149]\n",
      "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.755, train_loss_epoch=0.755, valid_loss=0.149]        \n",
      "Epoch 690: 100%|██████████| 1/1 [00:00<00:00, 72.08it/s, v_num=0, train_loss_step=0.782, train_loss_epoch=0.782, valid_loss=0.149]\n",
      "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.657, train_loss_epoch=0.657, valid_loss=0.149]        \n",
      "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.861, train_loss_epoch=0.861, valid_loss=0.149]        \n",
      "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 48.40it/s, v_num=0, train_loss_step=0.698, train_loss_epoch=0.861, valid_loss=0.149]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 32.29it/s]\u001b[A\n",
      "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.700, train_loss_epoch=0.700, valid_loss=0.0743]        \n",
      "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.654, train_loss_epoch=0.654, valid_loss=0.0743]        \n",
      "Epoch 709: 100%|██████████| 1/1 [00:00<00:00, 66.53it/s, v_num=0, train_loss_step=0.762, train_loss_epoch=0.762, valid_loss=0.0743]\n",
      "Epoch 709: 100%|██████████| 1/1 [00:00<00:00, 47.09it/s, v_num=0, train_loss_step=0.657, train_loss_epoch=0.762, valid_loss=0.0743]\n",
      "Epoch 709: 100%|██████████| 1/1 [00:00<00:00, 44.44it/s, v_num=0, train_loss_step=0.657, train_loss_epoch=0.657, valid_loss=0.0743]\n",
      "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.657, train_loss_epoch=0.657, valid_loss=0.0743]        \n",
      "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.631, train_loss_epoch=0.631, valid_loss=0.0743]        \n",
      "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.783, train_loss_epoch=0.783, valid_loss=0.0743]        \n",
      "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.605, train_loss_epoch=0.605, valid_loss=0.0743]        \n",
      "Epoch 726: 100%|██████████| 1/1 [00:00<00:00, 36.94it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.0743]\n",
      "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.0743]        \n",
      "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.591, train_loss_epoch=0.591, valid_loss=0.0743]        \n",
      "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.978, train_loss_epoch=0.978, valid_loss=0.0743]        \n",
      "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.962, train_loss_epoch=0.962, valid_loss=0.0743]        \n",
      "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.709, train_loss_epoch=0.709, valid_loss=0.0743]        \n",
      "Epoch 749: 100%|██████████| 1/1 [00:00<00:00, 57.69it/s, v_num=0, train_loss_step=0.990, train_loss_epoch=0.990, valid_loss=0.0743]\n",
      "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.0743]        \n",
      "Epoch 753: 100%|██████████| 1/1 [00:00<00:00, 52.73it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.0743]\n",
      "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.719, train_loss_epoch=0.719, valid_loss=0.0743]        \n",
      "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.706, train_loss_epoch=0.706, valid_loss=0.0743]        \n",
      "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.0743]        \n",
      "Epoch 770: 100%|██████████| 1/1 [00:00<00:00, 36.69it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=0.0743]\n",
      "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=0.0743]        \n",
      "Epoch 774: 100%|██████████| 1/1 [00:00<00:00, 79.16it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.0743]\n",
      "Epoch 774: 100%|██████████| 1/1 [00:00<00:00, 49.91it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=0.0743]\n",
      "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=0.0743]        \n",
      "Epoch 779: 100%|██████████| 1/1 [00:00<00:00, 68.24it/s, v_num=0, train_loss_step=0.627, train_loss_epoch=0.627, valid_loss=0.0743]\n",
      "Epoch 779: 100%|██████████| 1/1 [00:00<00:00, 46.55it/s, v_num=0, train_loss_step=0.815, train_loss_epoch=0.815, valid_loss=0.0743]\n",
      "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.815, train_loss_epoch=0.815, valid_loss=0.0743]        \n",
      "Epoch 784: 100%|██████████| 1/1 [00:00<00:00, 50.00it/s, v_num=0, train_loss_step=0.768, train_loss_epoch=0.768, valid_loss=0.0743]\n",
      "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.768, train_loss_epoch=0.768, valid_loss=0.0743]        \n",
      "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.825, train_loss_epoch=0.825, valid_loss=0.0743]        \n",
      "Epoch 793: 100%|██████████| 1/1 [00:00<00:00, 71.41it/s, v_num=0, train_loss_step=0.777, train_loss_epoch=0.777, valid_loss=0.0743]\n",
      "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.664, train_loss_epoch=0.664, valid_loss=0.0743]        \n",
      "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 46.71it/s, v_num=0, train_loss_step=0.651, train_loss_epoch=0.865, valid_loss=0.0743]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 33.01it/s]\u001b[A\n",
      "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.651, train_loss_epoch=0.651, valid_loss=0.300]         \n",
      "Epoch 800: 100%|██████████| 1/1 [00:00<00:00, 51.62it/s, v_num=0, train_loss_step=0.651, train_loss_epoch=0.651, valid_loss=0.300]\n",
      "Epoch 800: 100%|██████████| 1/1 [00:00<00:00, 41.71it/s, v_num=0, train_loss_step=0.822, train_loss_epoch=0.651, valid_loss=0.300]\n",
      "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.822, train_loss_epoch=0.822, valid_loss=0.300]        \n",
      "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.822, train_loss_epoch=0.822, valid_loss=0.300]\n",
      "Epoch 805:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.300]        \n",
      "Epoch 809: 100%|██████████| 1/1 [00:00<00:00, 62.05it/s, v_num=0, train_loss_step=0.646, train_loss_epoch=0.646, valid_loss=0.300]\n",
      "Epoch 809: 100%|██████████| 1/1 [00:00<00:00, 42.61it/s, v_num=0, train_loss_step=0.886, train_loss_epoch=0.886, valid_loss=0.300]\n",
      "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.886, train_loss_epoch=0.886, valid_loss=0.300]        \n",
      "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.884, train_loss_epoch=0.884, valid_loss=0.300]        \n",
      "Epoch 818: 100%|██████████| 1/1 [00:00<00:00, 80.72it/s, v_num=0, train_loss_step=0.840, train_loss_epoch=0.840, valid_loss=0.300]\n",
      "Epoch 823:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.300]        \n",
      "Epoch 827:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.649, train_loss_epoch=0.649, valid_loss=0.300]        \n",
      "Epoch 831: 100%|██████████| 1/1 [00:00<00:00, 70.70it/s, v_num=0, train_loss_step=0.783, train_loss_epoch=0.783, valid_loss=0.300]\n",
      "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.779, train_loss_epoch=0.779, valid_loss=0.300]        \n",
      "Epoch 838: 100%|██████████| 1/1 [00:00<00:00, 38.34it/s, v_num=0, train_loss_step=0.653, train_loss_epoch=0.653, valid_loss=0.300]\n",
      "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.653, train_loss_epoch=0.653, valid_loss=0.300]        \n",
      "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.646, train_loss_epoch=0.646, valid_loss=0.300]        \n",
      "Epoch 847: 100%|██████████| 1/1 [00:00<00:00, 70.62it/s, v_num=0, train_loss_step=0.981, train_loss_epoch=0.981, valid_loss=0.300]\n",
      "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.657, train_loss_epoch=0.657, valid_loss=0.300]        \n",
      "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.698, train_loss_epoch=0.698, valid_loss=0.300]        \n",
      "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.747, train_loss_epoch=0.747, valid_loss=0.300]        \n",
      "Epoch 865:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.748, train_loss_epoch=0.748, valid_loss=0.300]        \n",
      "Epoch 869: 100%|██████████| 1/1 [00:00<00:00, 58.12it/s, v_num=0, train_loss_step=0.785, train_loss_epoch=0.785, valid_loss=0.300]\n",
      "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.769, train_loss_epoch=0.769, valid_loss=0.300]        \n",
      "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.836, train_loss_epoch=0.836, valid_loss=0.300]        \n",
      "Epoch 881: 100%|██████████| 1/1 [00:00<00:00, 51.03it/s, v_num=0, train_loss_step=0.793, train_loss_epoch=0.793, valid_loss=0.300]\n",
      "Epoch 886: 100%|██████████| 1/1 [00:00<00:00, 82.31it/s, v_num=0, train_loss_step=0.629, train_loss_epoch=0.629, valid_loss=0.300]\n",
      "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.628, train_loss_epoch=0.628, valid_loss=0.300]        \n",
      "Epoch 896:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.727, train_loss_epoch=0.727, valid_loss=0.300]        \n",
      "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 45.45it/s, v_num=0, train_loss_step=0.388, train_loss_epoch=0.893, valid_loss=0.300]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=6843)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 29.71it/s]\u001b[A\n",
      "Epoch 903:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.788, train_loss_epoch=0.788, valid_loss=0.0518]        \n",
      "Epoch 906: 100%|██████████| 1/1 [00:00<00:00, 36.87it/s, v_num=0, train_loss_step=0.669, train_loss_epoch=0.669, valid_loss=0.0518]\n",
      "Epoch 907:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.669, train_loss_epoch=0.669, valid_loss=0.0518]        \n",
      "Epoch 911:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.782, train_loss_epoch=0.782, valid_loss=0.0518]        \n",
      "Epoch 915: 100%|██████████| 1/1 [00:00<00:00, 62.03it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0518]\n",
      "Epoch 920:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.692, train_loss_epoch=0.692, valid_loss=0.0518]        \n",
      "Epoch 924:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.887, train_loss_epoch=0.887, valid_loss=0.0518]        \n",
      "Epoch 929:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.665, train_loss_epoch=0.665, valid_loss=0.0518]        \n",
      "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.817, train_loss_epoch=0.817, valid_loss=0.0518]        \n",
      "Epoch 937:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.626, train_loss_epoch=0.626, valid_loss=0.0518]        \n",
      "Epoch 941: 100%|██████████| 1/1 [00:00<00:00, 68.74it/s, v_num=0, train_loss_step=0.617, train_loss_epoch=0.617, valid_loss=0.0518]\n",
      "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.671, train_loss_epoch=0.671, valid_loss=0.0518]        \n",
      "Epoch 950: 100%|██████████| 1/1 [00:00<00:00, 57.43it/s, v_num=0, train_loss_step=0.915, train_loss_epoch=0.915, valid_loss=0.0518]\n",
      "Epoch 950: 100%|██████████| 1/1 [00:00<00:00, 40.02it/s, v_num=0, train_loss_step=0.840, train_loss_epoch=0.840, valid_loss=0.0518]\n",
      "Epoch 955:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.709, train_loss_epoch=0.709, valid_loss=0.0518]        \n",
      "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.632, train_loss_epoch=0.632, valid_loss=0.0518]        \n",
      "Epoch 959: 100%|██████████| 1/1 [00:00<00:00, 67.77it/s, v_num=0, train_loss_step=0.632, train_loss_epoch=0.632, valid_loss=0.0518]\n",
      "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.0518]        \n",
      "Epoch 964: 100%|██████████| 1/1 [00:00<00:00, 78.18it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.0518]\n",
      "Epoch 969:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.707, train_loss_epoch=0.707, valid_loss=0.0518]        \n",
      "Epoch 973: 100%|██████████| 1/1 [00:00<00:00, 63.56it/s, v_num=0, train_loss_step=0.653, train_loss_epoch=0.653, valid_loss=0.0518]\n",
      "Epoch 973: 100%|██████████| 1/1 [00:00<00:00, 47.88it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=0.653, valid_loss=0.0518]\n",
      "Epoch 973: 100%|██████████| 1/1 [00:00<00:00, 45.87it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.0518]\n",
      "Epoch 974:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.0518]        \n",
      "Epoch 977: 100%|██████████| 1/1 [00:00<00:00, 39.90it/s, v_num=0, train_loss_step=0.708, train_loss_epoch=0.661, valid_loss=0.0518]\n",
      "Epoch 977: 100%|██████████| 1/1 [00:00<00:00, 37.73it/s, v_num=0, train_loss_step=0.708, train_loss_epoch=0.708, valid_loss=0.0518]\n",
      "Epoch 978:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.708, train_loss_epoch=0.708, valid_loss=0.0518]        \n",
      "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.819, train_loss_epoch=0.819, valid_loss=0.0518]        \n",
      "Epoch 982: 100%|██████████| 1/1 [00:00<00:00, 70.56it/s, v_num=0, train_loss_step=0.819, train_loss_epoch=0.819, valid_loss=0.0518]\n",
      "Epoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.746, train_loss_epoch=0.746, valid_loss=0.0518]        \n",
      "Epoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.778, train_loss_epoch=0.778, valid_loss=0.0518]        \n",
      "Epoch 996: 100%|██████████| 1/1 [00:00<00:00, 56.80it/s, v_num=0, train_loss_step=0.584, train_loss_epoch=0.584, valid_loss=0.0518]\n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 54.64it/s, v_num=0, train_loss_step=0.598, train_loss_epoch=0.606, valid_loss=0.0518]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 33.43it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=6843)\u001b[0m \n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 14.37it/s, v_num=0, train_loss_step=0.598, train_loss_epoch=0.598, valid_loss=0.0719]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=6843)\u001b[0m `Trainer.fit` stopped: `max_steps=1000` reached.\n",
      "\u001b[36m(_train_tune pid=7012)\u001b[0m /home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=7012)\u001b[0m Seed set to 8\n",
      "\u001b[36m(_train_tune pid=7012)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=7012)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=7012)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=7012)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(_train_tune pid=7012)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_train_tune pid=7012)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=7012)\u001b[0m   | Name            | Type          | Params | Mode \n",
      "\u001b[36m(_train_tune pid=7012)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=7012)\u001b[0m 0 | loss            | WMAPE         | 0      | train\n",
      "\u001b[36m(_train_tune pid=7012)\u001b[0m 1 | padder          | ConstantPad1d | 0      | train\n",
      "\u001b[36m(_train_tune pid=7012)\u001b[0m 2 | scaler          | TemporalNorm  | 0      | train\n",
      "\u001b[36m(_train_tune pid=7012)\u001b[0m 3 | hist_encoder    | LSTM          | 162 K  | train\n",
      "\u001b[36m(_train_tune pid=7012)\u001b[0m 4 | context_adapter | Linear        | 773 K  | train\n",
      "\u001b[36m(_train_tune pid=7012)\u001b[0m 5 | mlp_decoder     | MLP           | 3.3 K  | train\n",
      "\u001b[36m(_train_tune pid=7012)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=7012)\u001b[0m 939 K     Trainable params\n",
      "\u001b[36m(_train_tune pid=7012)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=7012)\u001b[0m 939 K     Total params\n",
      "\u001b[36m(_train_tune pid=7012)\u001b[0m 3.758     Total estimated model params size (MB)\n",
      "\u001b[36m(_train_tune pid=7012)\u001b[0m 11        Modules in train mode\n",
      "\u001b[36m(_train_tune pid=7012)\u001b[0m 0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.972, train_loss_epoch=0.972]        \n",
      "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.776, train_loss_epoch=0.776]        \n",
      "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550]        \n",
      "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.910, train_loss_epoch=0.910]        \n",
      "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.836, train_loss_epoch=0.836]        \n",
      "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.916, train_loss_epoch=0.916]        \n",
      "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.942, train_loss_epoch=0.942]        \n",
      "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=0.950]        \n",
      "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=0.950]       \n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00,  8.78it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.950]\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00,  8.74it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.945]\n",
      "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.945]        \n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00, 10.07it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.945]\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00, 10.46it/s, v_num=0, train_loss_step=0.933, train_loss_epoch=0.933]\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00, 10.15it/s, v_num=0, train_loss_step=0.913, train_loss_epoch=0.913]\n",
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.883, train_loss_epoch=0.883]        \n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00,  9.32it/s, v_num=0, train_loss_step=0.860, train_loss_epoch=0.883]\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00,  9.25it/s, v_num=0, train_loss_step=0.860, train_loss_epoch=0.860]\n",
      "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.860, train_loss_epoch=0.860]        \n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00,  9.69it/s, v_num=0, train_loss_step=0.850, train_loss_epoch=0.850]\n",
      "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.850, train_loss_epoch=0.850]        \n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00,  9.74it/s, v_num=0, train_loss_step=0.803, train_loss_epoch=0.803]\n",
      "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.803, train_loss_epoch=0.803]        \n",
      "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.745, train_loss_epoch=0.745]        \n",
      "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.694, train_loss_epoch=0.694]        \n",
      "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.748, train_loss_epoch=0.748]        \n",
      "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.657, train_loss_epoch=0.657]        \n",
      "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.630, train_loss_epoch=0.630]        \n",
      "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.623, train_loss_epoch=0.623]        \n",
      "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.618, train_loss_epoch=0.618]        \n",
      "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.604, train_loss_epoch=0.604]        \n",
      "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.585, train_loss_epoch=0.585]        \n",
      "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.588, train_loss_epoch=0.588]        \n",
      "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.591, train_loss_epoch=0.591]        \n",
      "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.580, train_loss_epoch=0.580]        \n",
      "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582]        \n",
      "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.584, train_loss_epoch=0.584]        \n",
      "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.578, train_loss_epoch=0.578]        \n",
      "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574]        \n",
      "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582]        \n",
      "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.581, train_loss_epoch=0.581]        \n",
      "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573]        \n",
      "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573]        \n",
      "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.575, train_loss_epoch=0.575]        \n",
      "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.572]        \n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00,  8.55it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571]\n",
      "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571]        \n",
      "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573]        \n",
      "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571]        \n",
      "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568]        \n",
      "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569]        \n",
      "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.570, train_loss_epoch=0.570]        \n",
      "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569]        \n",
      "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567]        \n",
      "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567]        \n",
      "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567]        \n",
      "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.566, train_loss_epoch=0.566]        \n",
      "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.566, train_loss_epoch=0.566]        \n",
      "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.566, train_loss_epoch=0.566]        \n",
      "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565]        \n",
      "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564]        \n",
      "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564]        \n",
      "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564]        \n",
      "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562]        \n",
      "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562]        \n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00,  8.74it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562]\n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00,  8.02it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561]\n",
      "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561]        \n",
      "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560]        \n",
      "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560]        \n",
      "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557]        \n",
      "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560]        \n",
      "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562]        \n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s, v_num=0, train_loss_step=0.566, train_loss_epoch=0.566]\n",
      "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.566, train_loss_epoch=0.566]        \n",
      "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568]        \n",
      "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.570, train_loss_epoch=0.570]        \n",
      "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569]        \n",
      "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.566, train_loss_epoch=0.566]        \n",
      "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564]        \n",
      "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563]        \n",
      "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560]        \n",
      "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560]        \n",
      "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561]        \n",
      "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560]        \n",
      "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560]        \n",
      "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561]        \n",
      "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560]        \n",
      "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559]        \n",
      "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558]        \n",
      "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557]        \n",
      "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556]        \n",
      "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556]        \n",
      "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555]        \n",
      "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554]        \n",
      "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552]        \n",
      "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549]        \n",
      "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567]        \n",
      "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549]        \n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.549]\n",
      "Epoch 89: 100%|██████████| 1/1 [00:00<00:00,  7.59it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550]\n",
      "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550]        \n",
      "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548]        \n",
      "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549]        \n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549]\n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547]\n",
      "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547]        \n",
      "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544]        \n",
      "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546]        \n",
      "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548]        \n",
      "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544]        \n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00,  8.31it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544]\n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.544]\n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547]\n",
      "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547]        \n",
      "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549]        \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s, v_num=0, train_loss_step=0.586, train_loss_epoch=0.549]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=7012)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 16.69it/s]\u001b[A\n",
      "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.586, train_loss_epoch=0.586, valid_loss=0.0416]       \n",
      "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.583, train_loss_epoch=0.583, valid_loss=0.0416]        \n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00,  7.66it/s, v_num=0, train_loss_step=0.583, train_loss_epoch=0.583, valid_loss=0.0416]\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00,  7.14it/s, v_num=0, train_loss_step=0.576, train_loss_epoch=0.583, valid_loss=0.0416]\n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00,  7.08it/s, v_num=0, train_loss_step=0.576, train_loss_epoch=0.576, valid_loss=0.0416]\n",
      "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.576, train_loss_epoch=0.576, valid_loss=0.0416]        \n",
      "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.577, train_loss_epoch=0.577, valid_loss=0.0416]        \n",
      "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.577, train_loss_epoch=0.577, valid_loss=0.0416]        \n",
      "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.572, valid_loss=0.0416]        \n",
      "Epoch 105: 100%|██████████| 1/1 [00:00<00:00,  7.60it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.572, valid_loss=0.0416]\n",
      "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569, valid_loss=0.0416]        \n",
      "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.570, train_loss_epoch=0.570, valid_loss=0.0416]        \n",
      "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568, valid_loss=0.0416]        \n",
      "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=0.0416]        \n",
      "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=0.0416]        \n",
      "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565, valid_loss=0.0416]        \n",
      "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=0.0416]        \n",
      "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=0.0416]        \n",
      "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563, valid_loss=0.0416]        \n",
      "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562, valid_loss=0.0416]        \n",
      "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562, valid_loss=0.0416]        \n",
      "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561, valid_loss=0.0416]        \n",
      "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=0.0416]        \n",
      "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561, valid_loss=0.0416]        \n",
      "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561, valid_loss=0.0416]        \n",
      "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=0.0416]        \n",
      "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=0.0416]        \n",
      "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=0.0416]        \n",
      "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=0.0416]        \n",
      "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=0.0416]        \n",
      "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=0.0416]        \n",
      "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=0.0416]        \n",
      "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=0.0416]        \n",
      "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.0416]        \n",
      "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.0416]        \n",
      "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0416]        \n",
      "Epoch 131: 100%|██████████| 1/1 [00:00<00:00,  8.73it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0416]\n",
      "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0416]        \n",
      "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0416]        \n",
      "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.0416]        \n",
      "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.0416]        \n",
      "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.0416]        \n",
      "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.0416]        \n",
      "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.0416]        \n",
      "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.0416]        \n",
      "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.0416]        \n",
      "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0416]        \n",
      "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0416]        \n",
      "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0416]        \n",
      "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0416]        \n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00,  8.00it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0416]\n",
      "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0416]        \n",
      "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0416]        \n",
      "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.0416]        \n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00,  7.66it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.0416]\n",
      "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.0416]        \n",
      "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0416]        \n",
      "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0416]        \n",
      "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=0.0416]        \n",
      "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0416]        \n",
      "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0416]        \n",
      "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0416]        \n",
      "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0416]        \n",
      "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0416]        \n",
      "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.588, train_loss_epoch=0.588, valid_loss=0.0416]        \n",
      "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.594, train_loss_epoch=0.594, valid_loss=0.0416]        \n",
      "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.595, train_loss_epoch=0.595, valid_loss=0.0416]        \n",
      "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.600, train_loss_epoch=0.600, valid_loss=0.0416]        \n",
      "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.601, train_loss_epoch=0.601, valid_loss=0.0416]        \n",
      "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.596, train_loss_epoch=0.596, valid_loss=0.0416]        \n",
      "Epoch 162: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s, v_num=0, train_loss_step=0.586, train_loss_epoch=0.586, valid_loss=0.0416]\n",
      "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.586, train_loss_epoch=0.586, valid_loss=0.0416]        \n",
      "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.577, train_loss_epoch=0.577, valid_loss=0.0416]        \n",
      "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.580, train_loss_epoch=0.580, valid_loss=0.0416]        \n",
      "Epoch 165: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s, v_num=0, train_loss_step=0.580, train_loss_epoch=0.580, valid_loss=0.0416]\n",
      "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582, valid_loss=0.0416]        \n",
      "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.570, train_loss_epoch=0.570, valid_loss=0.0416]        \n",
      "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=0.0416]        \n",
      "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=0.0416]        \n",
      "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565, valid_loss=0.0416]        \n",
      "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=0.0416]        \n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00,  8.31it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=0.0416]\n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00,  7.70it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.560, valid_loss=0.0416]\n",
      "Epoch 172: 100%|██████████| 1/1 [00:00<00:00,  7.66it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=0.0416]\n",
      "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=0.0416]        \n",
      "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562, valid_loss=0.0416]        \n",
      "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.0416]        \n",
      "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=0.0416]        \n",
      "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=0.0416]        \n",
      "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0416]        \n",
      "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.0416]        \n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00,  8.31it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.0416]\n",
      "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0416]        \n",
      "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.0416]        \n",
      "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0416]        \n",
      "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0416]        \n",
      "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0416]        \n",
      "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.0416]        \n",
      "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.0416]        \n",
      "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.0416]        \n",
      "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0416]        \n",
      "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0416]        \n",
      "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0416]        \n",
      "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0416]        \n",
      "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0416]        \n",
      "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0416]        \n",
      "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0416]        \n",
      "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=0.0416]        \n",
      "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=0.0416]        \n",
      "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=0.0416]        \n",
      "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=0.0416]        \n",
      "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0416]        \n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.539, valid_loss=0.0416]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=7012)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 16.83it/s]\u001b[A\n",
      "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0389]        \n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00,  8.82it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0389]\n",
      "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0389]        \n",
      "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563, valid_loss=0.0389]        \n",
      "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.576, train_loss_epoch=0.576, valid_loss=0.0389]        \n",
      "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573, valid_loss=0.0389]        \n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573, valid_loss=0.0389]\n",
      "Epoch 204: 100%|██████████| 1/1 [00:00<00:00,  6.67it/s, v_num=0, train_loss_step=0.578, train_loss_epoch=0.578, valid_loss=0.0389]\n",
      "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.578, train_loss_epoch=0.578, valid_loss=0.0389]        \n",
      "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.586, train_loss_epoch=0.586, valid_loss=0.0389]        \n",
      "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.588, train_loss_epoch=0.588, valid_loss=0.0389]        \n",
      "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.584, train_loss_epoch=0.584, valid_loss=0.0389]        \n",
      "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574, valid_loss=0.0389]        \n",
      "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=0.0389]        \n",
      "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565, valid_loss=0.0389]        \n",
      "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562, valid_loss=0.0389]        \n",
      "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0389]        \n",
      "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0389]        \n",
      "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.0389]        \n",
      "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0389]        \n",
      "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.0389]        \n",
      "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0389]        \n",
      "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.0389]        \n",
      "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.0389]        \n",
      "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561, valid_loss=0.0389]        \n",
      "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0389]        \n",
      "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0389]        \n",
      "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0389]        \n",
      "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0389]        \n",
      "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0389]        \n",
      "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0389]        \n",
      "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0389]        \n",
      "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0389]        \n",
      "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=0.0389]        \n",
      "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0389]        \n",
      "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0389]        \n",
      "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=0.0389]        \n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00,  8.10it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=0.0389]\n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=0.0389]\n",
      "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=0.0389]        \n",
      "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=0.0389]        \n",
      "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=0.0389]        \n",
      "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.0389]        \n",
      "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.0389]        \n",
      "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0389]        \n",
      "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0389]        \n",
      "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0389]        \n",
      "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.0389]        \n",
      "Epoch 242: 100%|██████████| 1/1 [00:00<00:00,  8.11it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.0389]\n",
      "Epoch 243: 100%|██████████| 1/1 [00:00<00:00,  8.80it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0389]\n",
      "Epoch 243: 100%|██████████| 1/1 [00:00<00:00,  8.07it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0389]\n",
      "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0389]        \n",
      "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0389]        \n",
      "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0389]        \n",
      "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0389]        \n",
      "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.0389]        \n",
      "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0389]        \n",
      "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0389]        \n",
      "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.0389]        \n",
      "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0389]        \n",
      "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0389]        \n",
      "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.603, train_loss_epoch=0.603, valid_loss=0.0389]        \n",
      "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.642, train_loss_epoch=0.642, valid_loss=0.0389]        \n",
      "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.637, train_loss_epoch=0.637, valid_loss=0.0389]        \n",
      "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.627, train_loss_epoch=0.627, valid_loss=0.0389]        \n",
      "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.639, train_loss_epoch=0.639, valid_loss=0.0389]        \n",
      "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.643, train_loss_epoch=0.643, valid_loss=0.0389]        \n",
      "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.646, train_loss_epoch=0.646, valid_loss=0.0389]        \n",
      "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.636, train_loss_epoch=0.636, valid_loss=0.0389]        \n",
      "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.618, train_loss_epoch=0.618, valid_loss=0.0389]        \n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s, v_num=0, train_loss_step=0.618, train_loss_epoch=0.618, valid_loss=0.0389]\n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00,  7.66it/s, v_num=0, train_loss_step=0.605, train_loss_epoch=0.618, valid_loss=0.0389]\n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s, v_num=0, train_loss_step=0.605, train_loss_epoch=0.605, valid_loss=0.0389]\n",
      "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.605, train_loss_epoch=0.605, valid_loss=0.0389]        \n",
      "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.605, train_loss_epoch=0.605, valid_loss=0.0389]        \n",
      "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.603, train_loss_epoch=0.603, valid_loss=0.0389]        \n",
      "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.583, train_loss_epoch=0.583, valid_loss=0.0389]        \n",
      "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.572, valid_loss=0.0389]        \n",
      "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.580, train_loss_epoch=0.580, valid_loss=0.0389]        \n",
      "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.570, train_loss_epoch=0.570, valid_loss=0.0389]        \n",
      "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565, valid_loss=0.0389]        \n",
      "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.577, train_loss_epoch=0.577, valid_loss=0.0389]        \n",
      "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569, valid_loss=0.0389]        \n",
      "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=0.0389]        \n",
      "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569, valid_loss=0.0389]        \n",
      "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.566, train_loss_epoch=0.566, valid_loss=0.0389]        \n",
      "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0389]        \n",
      "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=0.0389]        \n",
      "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=0.0389]        \n",
      "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.0389]        \n",
      "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0389]        \n",
      "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=0.0389]        \n",
      "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.0389]        \n",
      "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0389]        \n",
      "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.0389]        \n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.554, valid_loss=0.0389]\n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0389]\n",
      "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0389]        \n",
      "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.0389]        \n",
      "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0389]        \n",
      "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0389]        \n",
      "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0389]        \n",
      "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0389]        \n",
      "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0389]        \n",
      "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0389]        \n",
      "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0389]        \n",
      "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0389]        \n",
      "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=0.0389]        \n",
      "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0389]        \n",
      "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0389]        \n",
      "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0389]        \n",
      "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0389]        \n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0389]\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  6.70it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.548, valid_loss=0.0389]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 16.63it/s]\u001b[A\n",
      "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=0.0443]        \n",
      "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0443]        \n",
      "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0443]        \n",
      "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0443]        \n",
      "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.581, train_loss_epoch=0.581, valid_loss=0.0443]        \n",
      "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562, valid_loss=0.0443]        \n",
      "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563, valid_loss=0.0443]        \n",
      "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0443]        \n",
      "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0443]        \n",
      "Epoch 308: 100%|██████████| 1/1 [00:00<00:00,  8.09it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0443]\n",
      "Epoch 308: 100%|██████████| 1/1 [00:00<00:00,  7.47it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0443]\n",
      "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0443]        \n",
      "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0443]\n",
      "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0443]        \n",
      "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0443]        \n",
      "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=0.0443]        \n",
      "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0443]        \n",
      "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=0.0443]        \n",
      "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=0.0443]        \n",
      "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.0443]        \n",
      "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561, valid_loss=0.0443]        \n",
      "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0443]        \n",
      "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0443]        \n",
      "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.0443]        \n",
      "Epoch 320: 100%|██████████| 1/1 [00:00<00:00,  8.54it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.0443]\n",
      "Epoch 320: 100%|██████████| 1/1 [00:00<00:00,  7.84it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.0443]\n",
      "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.0443]        \n",
      "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.0443]        \n",
      "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0443]        \n",
      "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0443]        \n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00,  7.80it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.547, valid_loss=0.0443]\n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0443]\n",
      "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0443]        \n",
      "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0443]        \n",
      "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0443]        \n",
      "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.0443]        \n",
      "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0443]        \n",
      "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0443]        \n",
      "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0443]        \n",
      "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0443]        \n",
      "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0443]        \n",
      "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0443]        \n",
      "Epoch 334: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0443]\n",
      "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0443]        \n",
      "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0443]        \n",
      "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0443]        \n",
      "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0443]        \n",
      "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0443]        \n",
      "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0443]        \n",
      "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0443]        \n",
      "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0443]        \n",
      "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0443]        \n",
      "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0443]        \n",
      "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=0.0443]        \n",
      "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0443]        \n",
      "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0443]        \n",
      "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0443]        \n",
      "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.0443]        \n",
      "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=0.0443]        \n",
      "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=0.0443]        \n",
      "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.0443]        \n",
      "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0443]        \n",
      "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0443]        \n",
      "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0443]        \n",
      "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=0.0443]        \n",
      "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.0443]        \n",
      "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0443]        \n",
      "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.0443]        \n",
      "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.585, train_loss_epoch=0.585, valid_loss=0.0443]        \n",
      "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582, valid_loss=0.0443]        \n",
      "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.566, train_loss_epoch=0.566, valid_loss=0.0443]        \n",
      "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0443]        \n",
      "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.0443]        \n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.0443]\n",
      "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0443]        \n",
      "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.0443]        \n",
      "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.0443]        \n",
      "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0443]        \n",
      "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0443]        \n",
      "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0443]        \n",
      "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0443]        \n",
      "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0443]        \n",
      "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=0.0443]        \n",
      "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=0.0443]        \n",
      "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0443]        \n",
      "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0443]        \n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0443]\n",
      "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0443]        \n",
      "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0443]        \n",
      "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.0443]        \n",
      "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0443]        \n",
      "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0443]        \n",
      "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0443]        \n",
      "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.0443]        \n",
      "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0443]        \n",
      "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0443]        \n",
      "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=0.0443]        \n",
      "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0443]        \n",
      "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0443]        \n",
      "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561, valid_loss=0.0443]        \n",
      "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0443]        \n",
      "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0443]        \n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00,  8.18it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0443]\n",
      "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0443]        \n",
      "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0443]        \n",
      "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0443]        \n",
      "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0443]        \n",
      "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0443]        \n",
      "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.570, train_loss_epoch=0.570, valid_loss=0.0443]        \n",
      "Epoch 397: 100%|██████████| 1/1 [00:00<00:00,  8.12it/s, v_num=0, train_loss_step=0.570, train_loss_epoch=0.570, valid_loss=0.0443]\n",
      "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568, valid_loss=0.0443]        \n",
      "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.566, train_loss_epoch=0.566, valid_loss=0.0443]        \n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  6.80it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.566, valid_loss=0.0443]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=7012)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 14.05it/s]\u001b[A\n",
      "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=0.0399]        \n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=0.0399]\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.559, valid_loss=0.0399]\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.0399]\n",
      "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.0399]        \n",
      "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0399]        \n",
      "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.0399]        \n",
      "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=0.0399]        \n",
      "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=0.0399]        \n",
      "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.0399]        \n",
      "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0399]        \n",
      "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=0.0399]        \n",
      "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0399]        \n",
      "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=0.0399]        \n",
      "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=0.0399]        \n",
      "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0399]        \n",
      "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0399]        \n",
      "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.0399]        \n",
      "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0399]        \n",
      "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0399]        \n",
      "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0399]        \n",
      "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0399]        \n",
      "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0399]        \n",
      "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=0.0399]        \n",
      "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0399]        \n",
      "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0399]        \n",
      "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0399]        \n",
      "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0399]        \n",
      "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0399]        \n",
      "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0399]        \n",
      "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.0399]        \n",
      "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.0399]        \n",
      "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.0399]        \n",
      "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0399]        \n",
      "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0399]        \n",
      "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.0399]        \n",
      "Epoch 432: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.0399]\n",
      "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0399]        \n",
      "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=0.0399]        \n",
      "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=0.0399]        \n",
      "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=0.0399]        \n",
      "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0399]        \n",
      "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569, valid_loss=0.0399]        \n",
      "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567, valid_loss=0.0399]        \n",
      "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0399]        \n",
      "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0399]        \n",
      "Epoch 441: 100%|██████████| 1/1 [00:00<00:00,  6.43it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.0399]\n",
      "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.0399]        \n",
      "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0399]        \n",
      "Epoch 443: 100%|██████████| 1/1 [00:00<00:00,  6.69it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0399]\n",
      "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0399]        \n",
      "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0399]        \n",
      "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0399]        \n",
      "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0399]        \n",
      "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=0.0399]        \n",
      "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0399]        \n",
      "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=0.0399]        \n",
      "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.0399]        \n",
      "Epoch 451: 100%|██████████| 1/1 [00:00<00:00,  8.51it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.0399]\n",
      "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.0399]        \n",
      "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=0.0399]        \n",
      "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.0399]        \n",
      "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0399]        \n",
      "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0399]        \n",
      "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0399]        \n",
      "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0399]        \n",
      "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0399]        \n",
      "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0399]        \n",
      "Epoch 460: 100%|██████████| 1/1 [00:00<00:00,  8.01it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0399]\n",
      "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0399]        \n",
      "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0399]        \n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0399]\n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.508, valid_loss=0.0399]\n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00,  6.03it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.0399]\n",
      "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.0399]        \n",
      "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0399]        \n",
      "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0399]        \n",
      "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0399]        \n",
      "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0399]        \n",
      "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0399]        \n",
      "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0399]        \n",
      "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0399]        \n",
      "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0399]        \n",
      "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0399]        \n",
      "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0399]        \n",
      "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0399]        \n",
      "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0399]        \n",
      "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0399]        \n",
      "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0399]        \n",
      "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0399]        \n",
      "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0399]        \n",
      "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0399]        \n",
      "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0399]        \n",
      "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0399]        \n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00,  5.98it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.518, valid_loss=0.0399]\n",
      "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0399]        \n",
      "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0399]        \n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0399]\n",
      "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0399]        \n",
      "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0399]        \n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.521, valid_loss=0.0399]\n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00,  6.57it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0399]\n",
      "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0399]        \n",
      "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0399]        \n",
      "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0399]        \n",
      "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0399]        \n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00,  6.88it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.513, valid_loss=0.0399]\n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00,  6.85it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0399]\n",
      "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0399]        \n",
      "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0399]        \n",
      "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0399]        \n",
      "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0399]        \n",
      "Epoch 494: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.505, valid_loss=0.0399]\n",
      "Epoch 494: 100%|██████████| 1/1 [00:00<00:00,  6.21it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0399]\n",
      "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0399]        \n",
      "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0399]        \n",
      "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0399]        \n",
      "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0399]        \n",
      "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0399]        \n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.493, valid_loss=0.0399]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=7012)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 14.00it/s]\u001b[A\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0334]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=7012)\u001b[0m `Trainer.fit` stopped: `max_steps=500` reached.\n",
      "\u001b[36m(_train_tune pid=7309)\u001b[0m /home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=7309)\u001b[0m Seed set to 19\n",
      "\u001b[36m(_train_tune pid=7309)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=7309)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=7309)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=7309)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(_train_tune pid=7309)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_train_tune pid=7309)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=7309)\u001b[0m   | Name            | Type          | Params | Mode \n",
      "\u001b[36m(_train_tune pid=7309)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=7309)\u001b[0m 0 | loss            | WMAPE         | 0      | train\n",
      "\u001b[36m(_train_tune pid=7309)\u001b[0m 1 | padder          | ConstantPad1d | 0      | train\n",
      "\u001b[36m(_train_tune pid=7309)\u001b[0m 2 | scaler          | TemporalNorm  | 0      | train\n",
      "\u001b[36m(_train_tune pid=7309)\u001b[0m 3 | hist_encoder    | LSTM          | 363 K  | train\n",
      "\u001b[36m(_train_tune pid=7309)\u001b[0m 4 | context_adapter | Linear        | 231 K  | train\n",
      "\u001b[36m(_train_tune pid=7309)\u001b[0m 5 | mlp_decoder     | MLP           | 769    | train\n",
      "\u001b[36m(_train_tune pid=7309)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=7309)\u001b[0m 596 K     Trainable params\n",
      "\u001b[36m(_train_tune pid=7309)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=7309)\u001b[0m 596 K     Total params\n",
      "\u001b[36m(_train_tune pid=7309)\u001b[0m 2.385     Total estimated model params size (MB)\n",
      "\u001b[36m(_train_tune pid=7309)\u001b[0m 11        Modules in train mode\n",
      "\u001b[36m(_train_tune pid=7309)\u001b[0m 0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.982, train_loss_epoch=0.982]        \n",
      "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]        \n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  9.25it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  8.69it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.100]\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  8.64it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]\n",
      "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.973, train_loss_epoch=0.973]        \n",
      "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.947, train_loss_epoch=0.947]        \n",
      "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180]        \n",
      "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.916, train_loss_epoch=0.916]        \n",
      "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.919, train_loss_epoch=0.919]       \n",
      "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.899, train_loss_epoch=0.899]        \n",
      "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.876, train_loss_epoch=0.876]        \n",
      "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.814, train_loss_epoch=0.814]        \n",
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.759, train_loss_epoch=0.759]        \n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00,  9.66it/s, v_num=0, train_loss_step=0.759, train_loss_epoch=0.759]\n",
      "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.745, train_loss_epoch=0.745]        \n",
      "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.737, train_loss_epoch=0.737]        \n",
      "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.713, train_loss_epoch=0.713]        \n",
      "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.656, train_loss_epoch=0.656]        \n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00,  7.61it/s, v_num=0, train_loss_step=0.656, train_loss_epoch=0.656]\n",
      "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.620, train_loss_epoch=0.620]        \n",
      "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.635, train_loss_epoch=0.635]        \n",
      "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.591, train_loss_epoch=0.591]        \n",
      "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.603, train_loss_epoch=0.603]        \n",
      "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.604, train_loss_epoch=0.604]        \n",
      "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.589, train_loss_epoch=0.589]        \n",
      "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.588, train_loss_epoch=0.588]        \n",
      "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.593, train_loss_epoch=0.593]        \n",
      "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.575, train_loss_epoch=0.575]        \n",
      "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.583, train_loss_epoch=0.583]        \n",
      "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.581, train_loss_epoch=0.581]        \n",
      "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.570, train_loss_epoch=0.570]        \n",
      "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.575, train_loss_epoch=0.575]        \n",
      "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573]        \n",
      "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567]        \n",
      "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571]        \n",
      "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569]        \n",
      "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564]        \n",
      "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567]        \n",
      "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564]        \n",
      "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561]        \n",
      "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563]        \n",
      "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559]        \n",
      "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556]        \n",
      "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553]        \n",
      "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.577, train_loss_epoch=0.577]        \n",
      "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568]        \n",
      "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556]        \n",
      "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561]        \n",
      "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558]        \n",
      "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554]        \n",
      "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556]        \n",
      "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552]        \n",
      "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553]        \n",
      "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547]        \n",
      "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562]        \n",
      "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554]        \n",
      "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562]        \n",
      "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565]        \n",
      "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563]        \n",
      "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560]        \n",
      "Epoch 59: 100%|██████████| 1/1 [00:00<00:00,  6.13it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560]\n",
      "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558]        \n",
      "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556]        \n",
      "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555]        \n",
      "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555]        \n",
      "Epoch 63: 100%|██████████| 1/1 [00:00<00:00,  6.25it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555]\n",
      "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555]        \n",
      "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555]        \n",
      "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554]        \n",
      "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553]        \n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553]\n",
      "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551]        \n",
      "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550]        \n",
      "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549]        \n",
      "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547]        \n",
      "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546]        \n",
      "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545]        \n",
      "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544]        \n",
      "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547]        \n",
      "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545]        \n",
      "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541]        \n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541]\n",
      "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539]        \n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546]\n",
      "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546]        \n",
      "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.577, train_loss_epoch=0.577]        \n",
      "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545]        \n",
      "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546]        \n",
      "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548]        \n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548]\n",
      "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549]        \n",
      "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546]        \n",
      "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550]        \n",
      "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546]        \n",
      "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552]        \n",
      "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547]        \n",
      "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545]        \n",
      "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543]        \n",
      "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544]        \n",
      "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530]        \n",
      "Epoch 93: 100%|██████████| 1/1 [00:00<00:00,  6.15it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530]\n",
      "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536]        \n",
      "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555]        \n",
      "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538]        \n",
      "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540]        \n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00,  6.08it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540]\n",
      "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537]        \n",
      "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534]        \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  5.63it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.534]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=7309)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 12.75it/s]\u001b[A\n",
      "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0494]       \n",
      "Epoch 100: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0494]\n",
      "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0494]        \n",
      "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.566, train_loss_epoch=0.566, valid_loss=0.0494]        \n",
      "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=0.0494]        \n",
      "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=0.0494]        \n",
      "Epoch 104: 100%|██████████| 1/1 [00:00<00:00,  6.05it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=0.0494]\n",
      "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573, valid_loss=0.0494]        \n",
      "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561, valid_loss=0.0494]        \n",
      "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563, valid_loss=0.0494]        \n",
      "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.566, train_loss_epoch=0.566, valid_loss=0.0494]        \n",
      "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=0.0494]        \n",
      "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=0.0494]        \n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00,  6.04it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=0.0494]\n",
      "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=0.0494]        \n",
      "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0494]        \n",
      "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0494]        \n",
      "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0494]        \n",
      "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0494]        \n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00,  6.03it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0494]\n",
      "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.0494]        \n",
      "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0494]        \n",
      "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0494]        \n",
      "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=0.0494]        \n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=0.0494]\n",
      "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.0494]        \n",
      "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.0494]        \n",
      "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.0494]        \n",
      "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0494]        \n",
      "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.0494]        \n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00,  5.82it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.0494]\n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00,  5.34it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.533, valid_loss=0.0494]\n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00,  5.31it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=0.0494]\n",
      "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=0.0494]        \n",
      "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.0494]        \n",
      "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0494]        \n",
      "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562, valid_loss=0.0494]        \n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562, valid_loss=0.0494]\n",
      "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0494]        \n",
      "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0494]        \n",
      "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0494]        \n",
      "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0494]        \n",
      "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0494]        \n",
      "Epoch 133: 100%|██████████| 1/1 [00:00<00:00,  6.13it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0494]\n",
      "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0494]        \n",
      "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0494]        \n",
      "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0494]        \n",
      "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0494]        \n",
      "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0494]        \n",
      "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0494]        \n",
      "Epoch 139: 100%|██████████| 1/1 [00:00<00:00,  5.97it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0494]\n",
      "Epoch 139: 100%|██████████| 1/1 [00:00<00:00,  5.44it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.515, valid_loss=0.0494]\n",
      "Epoch 139: 100%|██████████| 1/1 [00:00<00:00,  5.42it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0494]\n",
      "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0494]        \n",
      "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0494]\n",
      "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0494]        \n",
      "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0494]        \n",
      "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0494]        \n",
      "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.0494]        \n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.0494]\n",
      "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0494]        \n",
      "Epoch 145: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0494]\n",
      "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0494]        \n",
      "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0494]        \n",
      "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0494]        \n",
      "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=0.0494]        \n",
      "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568, valid_loss=0.0494]        \n",
      "Epoch 150: 100%|██████████| 1/1 [00:00<00:00,  6.06it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568, valid_loss=0.0494]\n",
      "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0494]        \n",
      "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.632, train_loss_epoch=0.632, valid_loss=0.0494]        \n",
      "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.619, train_loss_epoch=0.619, valid_loss=0.0494]        \n",
      "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.581, train_loss_epoch=0.581, valid_loss=0.0494]        \n",
      "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569, valid_loss=0.0494]        \n",
      "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.586, train_loss_epoch=0.586, valid_loss=0.0494]        \n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00,  5.97it/s, v_num=0, train_loss_step=0.586, train_loss_epoch=0.586, valid_loss=0.0494]\n",
      "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.609, train_loss_epoch=0.609, valid_loss=0.0494]        \n",
      "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.576, train_loss_epoch=0.576, valid_loss=0.0494]        \n",
      "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=0.0494]        \n",
      "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=0.0494]        \n",
      "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0494]        \n",
      "Epoch 161: 100%|██████████| 1/1 [00:00<00:00,  5.96it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0494]\n",
      "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568, valid_loss=0.0494]        \n",
      "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.576, train_loss_epoch=0.576, valid_loss=0.0494]        \n",
      "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.570, train_loss_epoch=0.570, valid_loss=0.0494]        \n",
      "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0494]        \n",
      "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=0.0494]        \n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00,  6.05it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=0.0494]\n",
      "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=0.0494]        \n",
      "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.0494]        \n",
      "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0494]        \n",
      "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0494]        \n",
      "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.0494]        \n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00,  5.79it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.0494]\n",
      "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0494]        \n",
      "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=0.0494]        \n",
      "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0494]        \n",
      "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.0494]        \n",
      "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0494]        \n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00,  5.88it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0494]\n",
      "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0494]        \n",
      "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0494]        \n",
      "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0494]        \n",
      "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0494]        \n",
      "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0494]        \n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0494]\n",
      "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0494]        \n",
      "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0494]        \n",
      "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0494]        \n",
      "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0494]        \n",
      "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0494]        \n",
      "Epoch 186: 100%|██████████| 1/1 [00:00<00:00,  6.16it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0494]\n",
      "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0494]        \n",
      "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0494]        \n",
      "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0494]        \n",
      "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0494]        \n",
      "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0494]        \n",
      "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0494]        \n",
      "Epoch 192: 100%|██████████| 1/1 [00:00<00:00,  6.03it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0494]\n",
      "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0494]        \n",
      "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0494]        \n",
      "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0494]        \n",
      "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0494]        \n",
      "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0494]        \n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00,  6.11it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0494]\n",
      "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0494]        \n",
      "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0494]        \n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.516, valid_loss=0.0494]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=7309)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 12.95it/s]\u001b[A\n",
      "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0352]        \n",
      "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0352]        \n",
      "Epoch 201: 100%|██████████| 1/1 [00:00<00:00,  6.04it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0352]\n",
      "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0352]        \n",
      "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0352]        \n",
      "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0352]        \n",
      "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0352]        \n",
      "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0352]        \n",
      "Epoch 206: 100%|██████████| 1/1 [00:00<00:00,  5.91it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0352]\n",
      "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0352]        \n",
      "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0352]        \n",
      "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0352]        \n",
      "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0352]        \n",
      "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0352]        \n",
      "Epoch 211: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0352]\n",
      "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0352]        \n",
      "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0352]        \n",
      "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0352]        \n",
      "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0352]        \n",
      "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0352]        \n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0352]\n",
      "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0352]        \n",
      "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0352]        \n",
      "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0352]        \n",
      "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0352]        \n",
      "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0352]        \n",
      "Epoch 221: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0352]\n",
      "Epoch 221: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0352]\n",
      "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0352]        \n",
      "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0352]        \n",
      "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0352]        \n",
      "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0352]        \n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0352]\n",
      "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0352]        \n",
      "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0352]        \n",
      "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0352]        \n",
      "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0352]        \n",
      "Epoch 229: 100%|██████████| 1/1 [00:00<00:00,  6.01it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0352]\n",
      "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0352]        \n",
      "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0352]        \n",
      "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0352]        \n",
      "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0352]        \n",
      "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0352]        \n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00,  5.53it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.510, valid_loss=0.0352]\n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00,  5.51it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0352]\n",
      "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0352]        \n",
      "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0352]        \n",
      "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0352]        \n",
      "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0352]        \n",
      "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0352]        \n",
      "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0352]        \n",
      "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0352]        \n",
      "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0352]        \n",
      "Epoch 242: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0352]\n",
      "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0352]        \n",
      "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0352]        \n",
      "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0352]        \n",
      "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0352]        \n",
      "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0352]        \n",
      "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0352]        \n",
      "Epoch 248: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0352]\n",
      "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0352]        \n",
      "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0352]        \n",
      "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0352]        \n",
      "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0352]        \n",
      "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0352]        \n",
      "Epoch 253: 100%|██████████| 1/1 [00:00<00:00,  6.15it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0352]\n",
      "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0352]        \n",
      "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0352]        \n",
      "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0352]        \n",
      "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0352]        \n",
      "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0352]        \n",
      "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.637, train_loss_epoch=0.637, valid_loss=0.0352]        \n",
      "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0352]        \n",
      "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0352]        \n",
      "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0352]        \n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00,  6.02it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0352]\n",
      "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0352]        \n",
      "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0352]        \n",
      "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0352]        \n",
      "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0352]        \n",
      "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0352]        \n",
      "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0352]        \n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0352]\n",
      "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0352]        \n",
      "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0352]        \n",
      "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0352]        \n",
      "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0352]        \n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00,  6.25it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0352]\n",
      "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0352]        \n",
      "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0352]        \n",
      "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0352]        \n",
      "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0352]        \n",
      "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0352]        \n",
      "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0352]        \n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0352]\n",
      "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0352]        \n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00,  5.39it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0352]\n",
      "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0352]        \n",
      "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0352]        \n",
      "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0352]        \n",
      "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0352]        \n",
      "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0352]        \n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00,  5.99it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0352]\n",
      "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0352]        \n",
      "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0352]        \n",
      "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0352]        \n",
      "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0352]        \n",
      "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0352]        \n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00,  6.16it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0352]\n",
      "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0352]        \n",
      "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0352]        \n",
      "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0352]        \n",
      "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0352]        \n",
      "Epoch 293: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0352]\n",
      "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0352]        \n",
      "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0352]        \n",
      "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0352]        \n",
      "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0352]        \n",
      "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0352]        \n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00,  6.08it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0352]\n",
      "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0352]        \n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  6.00it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0352]\n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  5.38it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.484, valid_loss=0.0352]\n",
      "\u001b[36m(_train_tune pid=7309)\u001b[0m \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=7309)\u001b[0m \n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=7309)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 12.76it/s]\u001b[A\n",
      "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0372]        \n",
      "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0372]        \n",
      "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.0372]        \n",
      "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471, valid_loss=0.0372]        \n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00,  6.04it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471, valid_loss=0.0372]\n",
      "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=0.0372]        \n",
      "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0372]        \n",
      "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0372]        \n",
      "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.609, train_loss_epoch=0.609, valid_loss=0.0372]        \n",
      "Epoch 307: 100%|██████████| 1/1 [00:00<00:00,  6.23it/s, v_num=0, train_loss_step=0.609, train_loss_epoch=0.609, valid_loss=0.0372]\n",
      "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.589, train_loss_epoch=0.589, valid_loss=0.0372]        \n",
      "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0372]        \n",
      "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0372]        \n",
      "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.0372]        \n",
      "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=0.0372]        \n",
      "Epoch 312: 100%|██████████| 1/1 [00:00<00:00,  6.13it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=0.0372]\n",
      "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.0372]        \n",
      "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=0.0372]        \n",
      "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.0372]        \n",
      "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.0372]        \n",
      "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0372]        \n",
      "Epoch 317: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0372]\n",
      "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0372]        \n",
      "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0372]        \n",
      "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0372]        \n",
      "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0372]        \n",
      "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0372]        \n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0372]\n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00,  5.52it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.491, valid_loss=0.0372]\n",
      "Epoch 322: 100%|██████████| 1/1 [00:00<00:00,  5.49it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0372]\n",
      "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0372]        \n",
      "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0372]        \n",
      "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0372]        \n",
      "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0372]        \n",
      "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0372]        \n",
      "Epoch 327: 100%|██████████| 1/1 [00:00<00:00,  6.01it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0372]\n",
      "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0372]        \n",
      "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0372]        \n",
      "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0372]        \n",
      "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0372]        \n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0372]\n",
      "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0372]        \n",
      "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0372]        \n",
      "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0372]        \n",
      "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0372]        \n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0372]\n",
      "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0372]        \n",
      "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0372]        \n",
      "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0372]        \n",
      "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0372]        \n",
      "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0372]        \n",
      "Epoch 340: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0372]\n",
      "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0372]        \n",
      "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0372]        \n",
      "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0372]        \n",
      "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0372]        \n",
      "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0372]        \n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00,  6.25it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0372]\n",
      "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0372]        \n",
      "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0372]        \n",
      "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0372]        \n",
      "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0372]        \n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0372]\n",
      "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0372]        \n",
      "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0372]        \n",
      "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0372]        \n",
      "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0372]        \n",
      "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0372]        \n",
      "Epoch 354: 100%|██████████| 1/1 [00:00<00:00,  6.03it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0372]\n",
      "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0372]        \n",
      "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0372]        \n",
      "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0372]        \n",
      "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0372]        \n",
      "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0372]        \n",
      "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0372]        \n",
      "Epoch 360: 100%|██████████| 1/1 [00:00<00:00,  6.00it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0372]\n",
      "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0372]        \n",
      "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0372]        \n",
      "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0372]        \n",
      "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0372]        \n",
      "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0372]        \n",
      "Epoch 365: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.506, valid_loss=0.0372]\n",
      "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0372]        \n",
      "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0372]        \n",
      "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0372]        \n",
      "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0372]        \n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0372]\n",
      "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0372]        \n",
      "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0372]        \n",
      "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0372]        \n",
      "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0372]        \n",
      "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0372]        \n",
      "Epoch 374: 100%|██████████| 1/1 [00:00<00:00,  5.82it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0372]\n",
      "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0372]        \n",
      "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0372]        \n",
      "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0372]        \n",
      "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0372]        \n",
      "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0372]        \n",
      "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0372]        \n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00,  6.02it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0372]\n",
      "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0372]        \n",
      "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0372]        \n",
      "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0372]        \n",
      "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0372]        \n",
      "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0372]        \n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00,  6.08it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0372]\n",
      "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0372]        \n",
      "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0372]        \n",
      "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0372]        \n",
      "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0372]        \n",
      "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0372]        \n",
      "Epoch 390: 100%|██████████| 1/1 [00:00<00:00,  5.95it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0372]\n",
      "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0372]        \n",
      "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0372]        \n",
      "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0372]        \n",
      "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0372]        \n",
      "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0372]        \n",
      "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0372]        \n",
      "Epoch 396: 100%|██████████| 1/1 [00:00<00:00,  6.05it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0372]\n",
      "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0372]        \n",
      "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0372]        \n",
      "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0372]        \n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.499, valid_loss=0.0372]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=7309)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 12.57it/s]\u001b[A\n",
      "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563, valid_loss=0.0361]        \n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00,  6.11it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563, valid_loss=0.0361]\n",
      "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0361]        \n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00,  5.60it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0361]\n",
      "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0361]        \n",
      "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0361]        \n",
      "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0361]        \n",
      "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0361]        \n",
      "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0361]        \n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0361]\n",
      "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0361]        \n",
      "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0361]        \n",
      "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0361]        \n",
      "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0361]        \n",
      "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0361]        \n",
      "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0361]        \n",
      "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0361]        \n",
      "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0361]        \n",
      "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.0361]        \n",
      "Epoch 415: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.0361]\n",
      "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.0361]        \n",
      "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=0.0361]        \n",
      "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.0361]        \n",
      "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=0.0361]        \n",
      "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.461, train_loss_epoch=0.461, valid_loss=0.0361]        \n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00,  6.02it/s, v_num=0, train_loss_step=0.461, train_loss_epoch=0.461, valid_loss=0.0361]\n",
      "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.461, train_loss_epoch=0.461, valid_loss=0.0361]        \n",
      "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=0.0361]        \n",
      "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=0.0361]        \n",
      "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.457, train_loss_epoch=0.457, valid_loss=0.0361]        \n",
      "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.453, train_loss_epoch=0.453, valid_loss=0.0361]        \n",
      "Epoch 425: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s, v_num=0, train_loss_step=0.453, train_loss_epoch=0.453, valid_loss=0.0361]\n",
      "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.453, train_loss_epoch=0.453, valid_loss=0.0361]        \n",
      "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.453, train_loss_epoch=0.453, valid_loss=0.0361]        \n",
      "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.458, train_loss_epoch=0.458, valid_loss=0.0361]        \n",
      "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.449, train_loss_epoch=0.449, valid_loss=0.0361]        \n",
      "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.453, train_loss_epoch=0.453, valid_loss=0.0361]        \n",
      "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455, valid_loss=0.0361]        \n",
      "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=0.0361]        \n",
      "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.451, train_loss_epoch=0.451, valid_loss=0.0361]        \n",
      "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.442, train_loss_epoch=0.442, valid_loss=0.0361]        \n",
      "Epoch 434: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s, v_num=0, train_loss_step=0.442, train_loss_epoch=0.442, valid_loss=0.0361]\n",
      "Epoch 434: 100%|██████████| 1/1 [00:00<00:00,  5.51it/s, v_num=0, train_loss_step=0.446, train_loss_epoch=0.442, valid_loss=0.0361]\n",
      "Epoch 434: 100%|██████████| 1/1 [00:00<00:00,  5.48it/s, v_num=0, train_loss_step=0.446, train_loss_epoch=0.446, valid_loss=0.0361]\n",
      "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.446, train_loss_epoch=0.446, valid_loss=0.0361]        \n",
      "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.440, train_loss_epoch=0.440, valid_loss=0.0361]        \n",
      "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.440, train_loss_epoch=0.440, valid_loss=0.0361]        \n",
      "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.437, train_loss_epoch=0.437, valid_loss=0.0361]        \n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00,  6.13it/s, v_num=0, train_loss_step=0.437, train_loss_epoch=0.437, valid_loss=0.0361]\n",
      "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.437, train_loss_epoch=0.437, valid_loss=0.0361]        \n",
      "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.461, train_loss_epoch=0.461, valid_loss=0.0361]        \n",
      "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.453, train_loss_epoch=0.453, valid_loss=0.0361]        \n",
      "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455, valid_loss=0.0361]        \n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00,  6.13it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455, valid_loss=0.0361]\n",
      "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.453, train_loss_epoch=0.453, valid_loss=0.0361]        \n",
      "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452, valid_loss=0.0361]        \n",
      "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.450, train_loss_epoch=0.450, valid_loss=0.0361]        \n",
      "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.457, train_loss_epoch=0.457, valid_loss=0.0361]        \n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00,  6.23it/s, v_num=0, train_loss_step=0.457, train_loss_epoch=0.457, valid_loss=0.0361]\n",
      "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.454, train_loss_epoch=0.454, valid_loss=0.0361]        \n",
      "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.444, train_loss_epoch=0.444, valid_loss=0.0361]        \n",
      "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.444, train_loss_epoch=0.444, valid_loss=0.0361]        \n",
      "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.442, train_loss_epoch=0.442, valid_loss=0.0361]        \n",
      "Epoch 450: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s, v_num=0, train_loss_step=0.442, train_loss_epoch=0.442, valid_loss=0.0361]\n",
      "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.450, train_loss_epoch=0.450, valid_loss=0.0361]        \n",
      "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.449, train_loss_epoch=0.449, valid_loss=0.0361]        \n",
      "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.444, train_loss_epoch=0.444, valid_loss=0.0361]        \n",
      "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.444, train_loss_epoch=0.444, valid_loss=0.0361]        \n",
      "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.441, train_loss_epoch=0.441, valid_loss=0.0361]        \n",
      "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.434, train_loss_epoch=0.434, valid_loss=0.0361]        \n",
      "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.429, train_loss_epoch=0.429, valid_loss=0.0361]        \n",
      "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.428, train_loss_epoch=0.428, valid_loss=0.0361]        \n",
      "Epoch 458: 100%|██████████| 1/1 [00:00<00:00,  6.15it/s, v_num=0, train_loss_step=0.428, train_loss_epoch=0.428, valid_loss=0.0361]\n",
      "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.427, train_loss_epoch=0.427, valid_loss=0.0361]        \n",
      "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.424, train_loss_epoch=0.424, valid_loss=0.0361]        \n",
      "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.422, train_loss_epoch=0.422, valid_loss=0.0361]        \n",
      "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.419, train_loss_epoch=0.419, valid_loss=0.0361]        \n",
      "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.418, train_loss_epoch=0.418, valid_loss=0.0361]        \n",
      "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.415, valid_loss=0.0361]        \n",
      "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.411, train_loss_epoch=0.411, valid_loss=0.0361]        \n",
      "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.409, train_loss_epoch=0.409, valid_loss=0.0361]        \n",
      "Epoch 466: 100%|██████████| 1/1 [00:00<00:00,  6.21it/s, v_num=0, train_loss_step=0.409, train_loss_epoch=0.409, valid_loss=0.0361]\n",
      "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=0.0361]        \n",
      "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.404, train_loss_epoch=0.404, valid_loss=0.0361]        \n",
      "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.401, train_loss_epoch=0.401, valid_loss=0.0361]        \n",
      "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.399, train_loss_epoch=0.399, valid_loss=0.0361]        \n",
      "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396, valid_loss=0.0361]        \n",
      "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.394, train_loss_epoch=0.394, valid_loss=0.0361]        \n",
      "Epoch 472: 100%|██████████| 1/1 [00:00<00:00,  5.87it/s, v_num=0, train_loss_step=0.394, train_loss_epoch=0.394, valid_loss=0.0361]\n",
      "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.393, train_loss_epoch=0.393, valid_loss=0.0361]        \n",
      "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=0.0361]        \n",
      "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.397, train_loss_epoch=0.397, valid_loss=0.0361]        \n",
      "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.390, train_loss_epoch=0.390, valid_loss=0.0361]        \n",
      "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.388, train_loss_epoch=0.388, valid_loss=0.0361]        \n",
      "Epoch 477: 100%|██████████| 1/1 [00:00<00:00,  6.01it/s, v_num=0, train_loss_step=0.388, train_loss_epoch=0.388, valid_loss=0.0361]\n",
      "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.388, train_loss_epoch=0.388, valid_loss=0.0361]        \n",
      "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.385, train_loss_epoch=0.385, valid_loss=0.0361]        \n",
      "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.381, train_loss_epoch=0.381, valid_loss=0.0361]        \n",
      "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.382, train_loss_epoch=0.382, valid_loss=0.0361]        \n",
      "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.381, train_loss_epoch=0.381, valid_loss=0.0361]        \n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00,  5.94it/s, v_num=0, train_loss_step=0.381, train_loss_epoch=0.381, valid_loss=0.0361]\n",
      "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=0.0361]        \n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00,  5.20it/s, v_num=0, train_loss_step=0.376, train_loss_epoch=0.376, valid_loss=0.0361]\n",
      "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.376, train_loss_epoch=0.376, valid_loss=0.0361]        \n",
      "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.376, train_loss_epoch=0.376, valid_loss=0.0361]        \n",
      "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.385, train_loss_epoch=0.385, valid_loss=0.0361]        \n",
      "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.384, train_loss_epoch=0.384, valid_loss=0.0361]        \n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00,  6.08it/s, v_num=0, train_loss_step=0.384, train_loss_epoch=0.384, valid_loss=0.0361]\n",
      "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.389, valid_loss=0.0361]        \n",
      "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.386, train_loss_epoch=0.386, valid_loss=0.0361]        \n",
      "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.383, train_loss_epoch=0.383, valid_loss=0.0361]        \n",
      "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.386, train_loss_epoch=0.386, valid_loss=0.0361]        \n",
      "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.408, train_loss_epoch=0.408, valid_loss=0.0361]        \n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s, v_num=0, train_loss_step=0.408, train_loss_epoch=0.408, valid_loss=0.0361]\n",
      "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=0.0361]        \n",
      "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.421, train_loss_epoch=0.421, valid_loss=0.0361]        \n",
      "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.398, train_loss_epoch=0.398, valid_loss=0.0361]        \n",
      "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.401, train_loss_epoch=0.401, valid_loss=0.0361]        \n",
      "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.390, train_loss_epoch=0.390, valid_loss=0.0361]        \n",
      "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.392, train_loss_epoch=0.392, valid_loss=0.0361]        \n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00,  6.06it/s, v_num=0, train_loss_step=0.392, train_loss_epoch=0.392, valid_loss=0.0361]\n",
      "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.399, train_loss_epoch=0.399, valid_loss=0.0361]        \n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  5.26it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.399, valid_loss=0.0361]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=7309)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 11.67it/s]\u001b[A\n",
      "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=0.0393]        \n",
      "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.456, train_loss_epoch=0.456, valid_loss=0.0393]        \n",
      "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.453, train_loss_epoch=0.453, valid_loss=0.0393]        \n",
      "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.475, train_loss_epoch=0.475, valid_loss=0.0393]        \n",
      "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473, valid_loss=0.0393]        \n",
      "Epoch 504: 100%|██████████| 1/1 [00:00<00:00,  6.04it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473, valid_loss=0.0393]\n",
      "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.459, train_loss_epoch=0.459, valid_loss=0.0393]        \n",
      "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=0.0393]        \n",
      "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.468, valid_loss=0.0393]        \n",
      "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.474, train_loss_epoch=0.474, valid_loss=0.0393]        \n",
      "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=0.0393]        \n",
      "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.0393]        \n",
      "Epoch 510: 100%|██████████| 1/1 [00:00<00:00,  6.05it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.0393]\n",
      "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455, valid_loss=0.0393]        \n",
      "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.0393]        \n",
      "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.446, train_loss_epoch=0.446, valid_loss=0.0393]        \n",
      "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.450, train_loss_epoch=0.450, valid_loss=0.0393]        \n",
      "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0393]        \n",
      "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.475, train_loss_epoch=0.475, valid_loss=0.0393]        \n",
      "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0393]        \n",
      "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0393]        \n",
      "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0393]        \n",
      "Epoch 519: 100%|██████████| 1/1 [00:00<00:00,  6.00it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0393]\n",
      "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0393]        \n",
      "Epoch 520: 100%|██████████| 1/1 [00:00<00:00,  5.75it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0393]\n",
      "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0393]        \n",
      "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0393]        \n",
      "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.0393]        \n",
      "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=0.0393]        \n",
      "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.465, valid_loss=0.0393]        \n",
      "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=0.0393]        \n",
      "Epoch 526: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=0.0393]\n",
      "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=0.0393]        \n",
      "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.459, train_loss_epoch=0.459, valid_loss=0.0393]        \n",
      "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.456, train_loss_epoch=0.456, valid_loss=0.0393]        \n",
      "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.451, train_loss_epoch=0.451, valid_loss=0.0393]        \n",
      "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.448, valid_loss=0.0393]        \n",
      "Epoch 531: 100%|██████████| 1/1 [00:00<00:00,  5.89it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.448, valid_loss=0.0393]\n",
      "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.443, train_loss_epoch=0.443, valid_loss=0.0393]        \n",
      "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.439, train_loss_epoch=0.439, valid_loss=0.0393]        \n",
      "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.436, train_loss_epoch=0.436, valid_loss=0.0393]        \n",
      "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.433, train_loss_epoch=0.433, valid_loss=0.0393]        \n",
      "Epoch 535: 100%|██████████| 1/1 [00:00<00:00,  6.11it/s, v_num=0, train_loss_step=0.433, train_loss_epoch=0.433, valid_loss=0.0393]\n",
      "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.430, train_loss_epoch=0.430, valid_loss=0.0393]        \n",
      "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.427, train_loss_epoch=0.427, valid_loss=0.0393]        \n",
      "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.423, train_loss_epoch=0.423, valid_loss=0.0393]        \n",
      "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.421, train_loss_epoch=0.421, valid_loss=0.0393]        \n",
      "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.423, train_loss_epoch=0.423, valid_loss=0.0393]        \n",
      "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.420, train_loss_epoch=0.420, valid_loss=0.0393]        \n",
      "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.422, train_loss_epoch=0.422, valid_loss=0.0393]        \n",
      "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.423, train_loss_epoch=0.423, valid_loss=0.0393]        \n",
      "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.411, train_loss_epoch=0.411, valid_loss=0.0393]        \n",
      "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.410, train_loss_epoch=0.410, valid_loss=0.0393]        \n",
      "Epoch 545: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s, v_num=0, train_loss_step=0.410, train_loss_epoch=0.410, valid_loss=0.0393]\n",
      "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.402, train_loss_epoch=0.402, valid_loss=0.0393]        \n",
      "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.444, train_loss_epoch=0.444, valid_loss=0.0393]        \n",
      "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=0.0393]        \n",
      "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=0.0393]        \n",
      "Epoch 549: 100%|██████████| 1/1 [00:00<00:00,  5.99it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=0.0393]\n",
      "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.465, valid_loss=0.0393]        \n",
      "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.456, train_loss_epoch=0.456, valid_loss=0.0393]        \n",
      "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=0.0393]        \n",
      "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452, valid_loss=0.0393]        \n",
      "Epoch 553: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452, valid_loss=0.0393]\n",
      "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.459, train_loss_epoch=0.459, valid_loss=0.0393]        \n",
      "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.449, train_loss_epoch=0.449, valid_loss=0.0393]        \n",
      "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.438, train_loss_epoch=0.438, valid_loss=0.0393]        \n",
      "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.437, train_loss_epoch=0.437, valid_loss=0.0393]        \n",
      "Epoch 557: 100%|██████████| 1/1 [00:00<00:00,  6.21it/s, v_num=0, train_loss_step=0.437, train_loss_epoch=0.437, valid_loss=0.0393]\n",
      "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.435, train_loss_epoch=0.435, valid_loss=0.0393]        \n",
      "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.431, train_loss_epoch=0.431, valid_loss=0.0393]        \n",
      "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.432, train_loss_epoch=0.432, valid_loss=0.0393]        \n",
      "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.418, train_loss_epoch=0.418, valid_loss=0.0393]        \n",
      "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=0.0393]        \n",
      "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.427, train_loss_epoch=0.427, valid_loss=0.0393]        \n",
      "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.422, train_loss_epoch=0.422, valid_loss=0.0393]        \n",
      "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.411, train_loss_epoch=0.411, valid_loss=0.0393]        \n",
      "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.433, train_loss_epoch=0.433, valid_loss=0.0393]        \n",
      "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.421, train_loss_epoch=0.421, valid_loss=0.0393]        \n",
      "Epoch 567: 100%|██████████| 1/1 [00:00<00:00,  6.16it/s, v_num=0, train_loss_step=0.421, train_loss_epoch=0.421, valid_loss=0.0393]\n",
      "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.446, train_loss_epoch=0.446, valid_loss=0.0393]        \n",
      "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.424, train_loss_epoch=0.424, valid_loss=0.0393]        \n",
      "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.449, train_loss_epoch=0.449, valid_loss=0.0393]        \n",
      "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=0.0393]        \n",
      "Epoch 571: 100%|██████████| 1/1 [00:00<00:00,  6.16it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=0.0393]\n",
      "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471, valid_loss=0.0393]        \n",
      "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0393]        \n",
      "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.451, train_loss_epoch=0.451, valid_loss=0.0393]        \n",
      "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=0.0393]        \n",
      "Epoch 575: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=0.0393]\n",
      "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.475, train_loss_epoch=0.475, valid_loss=0.0393]        \n",
      "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.0393]        \n",
      "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.461, train_loss_epoch=0.461, valid_loss=0.0393]        \n",
      "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.457, train_loss_epoch=0.457, valid_loss=0.0393]        \n",
      "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.449, train_loss_epoch=0.449, valid_loss=0.0393]        \n",
      "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.438, train_loss_epoch=0.438, valid_loss=0.0393]        \n",
      "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.430, train_loss_epoch=0.430, valid_loss=0.0393]        \n",
      "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.427, train_loss_epoch=0.427, valid_loss=0.0393]        \n",
      "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.427, train_loss_epoch=0.427, valid_loss=0.0393]        \n",
      "Epoch 584: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s, v_num=0, train_loss_step=0.427, train_loss_epoch=0.427, valid_loss=0.0393]\n",
      "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.422, train_loss_epoch=0.422, valid_loss=0.0393]        \n",
      "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.417, train_loss_epoch=0.417, valid_loss=0.0393]        \n",
      "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.412, train_loss_epoch=0.412, valid_loss=0.0393]        \n",
      "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.407, train_loss_epoch=0.407, valid_loss=0.0393]        \n",
      "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.403, train_loss_epoch=0.403, valid_loss=0.0393]        \n",
      "Epoch 589: 100%|██████████| 1/1 [00:00<00:00,  5.95it/s, v_num=0, train_loss_step=0.403, train_loss_epoch=0.403, valid_loss=0.0393]\n",
      "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.400, train_loss_epoch=0.400, valid_loss=0.0393]        \n",
      "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=0.0393]        \n",
      "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.392, train_loss_epoch=0.392, valid_loss=0.0393]        \n",
      "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.415, valid_loss=0.0393]        \n",
      "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.402, train_loss_epoch=0.402, valid_loss=0.0393]        \n",
      "Epoch 594: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s, v_num=0, train_loss_step=0.402, train_loss_epoch=0.402, valid_loss=0.0393]\n",
      "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.389, valid_loss=0.0393]        \n",
      "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.389, valid_loss=0.0393]        \n",
      "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.388, train_loss_epoch=0.388, valid_loss=0.0393]        \n",
      "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.383, train_loss_epoch=0.383, valid_loss=0.0393]        \n",
      "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379, valid_loss=0.0393]        \n",
      "Epoch 599: 100%|██████████| 1/1 [00:00<00:00,  5.63it/s, v_num=0, train_loss_step=0.381, train_loss_epoch=0.379, valid_loss=0.0393]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=7309)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 12.84it/s]\u001b[A\n",
      "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.381, train_loss_epoch=0.381, valid_loss=0.0445]        \n",
      "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.381, train_loss_epoch=0.381, valid_loss=0.0445]        \n",
      "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.385, train_loss_epoch=0.385, valid_loss=0.0445]        \n",
      "Epoch 602: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s, v_num=0, train_loss_step=0.385, train_loss_epoch=0.385, valid_loss=0.0445]\n",
      "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=0.0445]        \n",
      "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.383, train_loss_epoch=0.383, valid_loss=0.0445]        \n",
      "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.378, valid_loss=0.0445]        \n",
      "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.375, train_loss_epoch=0.375, valid_loss=0.0445]        \n",
      "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.370, train_loss_epoch=0.370, valid_loss=0.0445]        \n",
      "Epoch 607: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369, valid_loss=0.0445]\n",
      "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369, valid_loss=0.0445]        \n",
      "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.373, train_loss_epoch=0.373, valid_loss=0.0445]        \n",
      "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.373, train_loss_epoch=0.373, valid_loss=0.0445]        \n",
      "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363, valid_loss=0.0445]        \n",
      "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365, valid_loss=0.0445]        \n",
      "Epoch 612: 100%|██████████| 1/1 [00:00<00:00,  5.85it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365, valid_loss=0.0445]\n",
      "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=0.0445]        \n",
      "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.382, train_loss_epoch=0.382, valid_loss=0.0445]        \n",
      "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452, valid_loss=0.0445]        \n",
      "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.447, train_loss_epoch=0.447, valid_loss=0.0445]        \n",
      "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.408, train_loss_epoch=0.408, valid_loss=0.0445]        \n",
      "Epoch 617: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s, v_num=0, train_loss_step=0.408, train_loss_epoch=0.408, valid_loss=0.0445]\n",
      "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.399, train_loss_epoch=0.399, valid_loss=0.0445]        \n",
      "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.391, train_loss_epoch=0.391, valid_loss=0.0445]        \n",
      "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.392, train_loss_epoch=0.392, valid_loss=0.0445]        \n",
      "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.394, train_loss_epoch=0.394, valid_loss=0.0445]        \n",
      "Epoch 621: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s, v_num=0, train_loss_step=0.394, train_loss_epoch=0.394, valid_loss=0.0445]\n",
      "Epoch 622:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.386, train_loss_epoch=0.386, valid_loss=0.0445]        \n",
      "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.381, train_loss_epoch=0.381, valid_loss=0.0445]        \n",
      "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379, valid_loss=0.0445]        \n",
      "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=0.0445]        \n",
      "Epoch 625: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=0.0445]\n",
      "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.375, train_loss_epoch=0.375, valid_loss=0.0445]        \n",
      "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.375, train_loss_epoch=0.375, valid_loss=0.0445]        \n",
      "Epoch 628:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=0.0445]        \n",
      "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.370, train_loss_epoch=0.370, valid_loss=0.0445]        \n",
      "Epoch 629: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s, v_num=0, train_loss_step=0.370, train_loss_epoch=0.370, valid_loss=0.0445]\n",
      "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.367, train_loss_epoch=0.367, valid_loss=0.0445]        \n",
      "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365, valid_loss=0.0445]        \n",
      "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.364, train_loss_epoch=0.364, valid_loss=0.0445]        \n",
      "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361, valid_loss=0.0445]        \n",
      "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.358, train_loss_epoch=0.358, valid_loss=0.0445]        \n",
      "Epoch 634: 100%|██████████| 1/1 [00:00<00:00,  6.16it/s, v_num=0, train_loss_step=0.358, train_loss_epoch=0.358, valid_loss=0.0445]\n",
      "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=0.0445]        \n",
      "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=0.0445]        \n",
      "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=0.0445]        \n",
      "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=0.0445]        \n",
      "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.345, train_loss_epoch=0.345, valid_loss=0.0445]        \n",
      "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=0.0445]        \n",
      "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.345, train_loss_epoch=0.345, valid_loss=0.0445]        \n",
      "Epoch 641: 100%|██████████| 1/1 [00:00<00:00,  6.32it/s, v_num=0, train_loss_step=0.345, train_loss_epoch=0.345, valid_loss=0.0445]\n",
      "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=0.0445]        \n",
      "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=0.0445]        \n",
      "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=0.0445]        \n",
      "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=0.0445]        \n",
      "Epoch 645: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=0.0445]\n",
      "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=0.0445]        \n",
      "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335, valid_loss=0.0445]        \n",
      "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=0.0445]        \n",
      "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=0.0445]        \n",
      "Epoch 649: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=0.0445]\n",
      "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=0.0445]        \n",
      "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=0.0445]        \n",
      "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=0.0445]        \n",
      "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=0.0445]        \n",
      "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=0.0445]        \n",
      "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=0.0445]        \n",
      "Epoch 655: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=0.0445]\n",
      "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=0.0445]        \n",
      "Epoch 657:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=0.0445]        \n",
      "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=0.0445]        \n",
      "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=0.0445]        \n",
      "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=0.0445]        \n",
      "Epoch 660: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=0.0445]\n",
      "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=0.0445]        \n",
      "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=0.0445]        \n",
      "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.393, train_loss_epoch=0.393, valid_loss=0.0445]        \n",
      "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.382, train_loss_epoch=0.382, valid_loss=0.0445]        \n",
      "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.371, train_loss_epoch=0.371, valid_loss=0.0445]        \n",
      "Epoch 665: 100%|██████████| 1/1 [00:00<00:00,  6.04it/s, v_num=0, train_loss_step=0.371, train_loss_epoch=0.371, valid_loss=0.0445]\n",
      "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.356, train_loss_epoch=0.356, valid_loss=0.0445]        \n",
      "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351, valid_loss=0.0445]        \n",
      "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.340, train_loss_epoch=0.340, valid_loss=0.0445]        \n",
      "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=0.0445]        \n",
      "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.368, train_loss_epoch=0.368, valid_loss=0.0445]        \n",
      "Epoch 670: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s, v_num=0, train_loss_step=0.368, train_loss_epoch=0.368, valid_loss=0.0445]\n",
      "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.359, train_loss_epoch=0.359, valid_loss=0.0445]        \n",
      "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.356, train_loss_epoch=0.356, valid_loss=0.0445]        \n",
      "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351, valid_loss=0.0445]        \n",
      "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346, valid_loss=0.0445]        \n",
      "Epoch 674: 100%|██████████| 1/1 [00:00<00:00,  6.25it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346, valid_loss=0.0445]\n",
      "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=0.0445]        \n",
      "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=0.0445]        \n",
      "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=0.0445]        \n",
      "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=0.0445]        \n",
      "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=0.0445]        \n",
      "Epoch 679: 100%|██████████| 1/1 [00:00<00:00,  6.06it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=0.0445]\n",
      "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=0.0445]        \n",
      "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=0.0445]        \n",
      "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=0.0445]        \n",
      "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=0.0445]        \n",
      "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=0.0445]        \n",
      "Epoch 684: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=0.0445]\n",
      "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=0.0445]        \n",
      "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=0.0445]        \n",
      "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=0.0445]        \n",
      "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=0.0445]        \n",
      "Epoch 688: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=0.0445]\n",
      "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.300, valid_loss=0.0445]        \n",
      "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=0.0445]        \n",
      "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=0.0445]        \n",
      "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=0.0445]        \n",
      "Epoch 692: 100%|██████████| 1/1 [00:00<00:00,  6.27it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=0.0445]\n",
      "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=0.0445]        \n",
      "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=0.0445]        \n",
      "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.288, train_loss_epoch=0.288, valid_loss=0.0445]        \n",
      "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=0.0445]        \n",
      "Epoch 696: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=0.0445]\n",
      "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.284, valid_loss=0.0445]        \n",
      "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.281, train_loss_epoch=0.281, valid_loss=0.0445]        \n",
      "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.279, train_loss_epoch=0.279, valid_loss=0.0445]        \n",
      "Epoch 699: 100%|██████████| 1/1 [00:00<00:00,  5.66it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.279, valid_loss=0.0445]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=7309)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 12.42it/s]\u001b[A\n",
      "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=0.0338]        \n",
      "Epoch 700: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.277, valid_loss=0.0338]\n",
      "Epoch 700: 100%|██████████| 1/1 [00:00<00:00,  5.53it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.275, valid_loss=0.0338]\n",
      "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.275, valid_loss=0.0338]        \n",
      "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.275, valid_loss=0.0338]\n",
      "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.273, train_loss_epoch=0.273, valid_loss=0.0338]        \n",
      "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=0.0338]        \n",
      "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=0.0338]        \n",
      "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.409, train_loss_epoch=0.409, valid_loss=0.0338]        \n",
      "Epoch 705: 100%|██████████| 1/1 [00:00<00:00,  5.94it/s, v_num=0, train_loss_step=0.409, train_loss_epoch=0.409, valid_loss=0.0338]\n",
      "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.433, train_loss_epoch=0.433, valid_loss=0.0338]        \n",
      "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.389, valid_loss=0.0338]        \n",
      "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.393, train_loss_epoch=0.393, valid_loss=0.0338]        \n",
      "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.378, valid_loss=0.0338]        \n",
      "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369, valid_loss=0.0338]        \n",
      "Epoch 710: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369, valid_loss=0.0338]\n",
      "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.370, train_loss_epoch=0.370, valid_loss=0.0338]        \n",
      "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.375, train_loss_epoch=0.375, valid_loss=0.0338]        \n",
      "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.376, train_loss_epoch=0.376, valid_loss=0.0338]        \n",
      "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.380, train_loss_epoch=0.380, valid_loss=0.0338]        \n",
      "Epoch 714: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s, v_num=0, train_loss_step=0.380, train_loss_epoch=0.380, valid_loss=0.0338]\n",
      "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.391, train_loss_epoch=0.391, valid_loss=0.0338]        \n",
      "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.450, train_loss_epoch=0.450, valid_loss=0.0338]        \n",
      "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.378, valid_loss=0.0338]        \n",
      "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379, valid_loss=0.0338]        \n",
      "Epoch 718: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379, valid_loss=0.0338]\n",
      "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.390, train_loss_epoch=0.390, valid_loss=0.0338]        \n",
      "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.378, valid_loss=0.0338]        \n",
      "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.371, train_loss_epoch=0.371, valid_loss=0.0338]        \n",
      "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.373, train_loss_epoch=0.373, valid_loss=0.0338]        \n",
      "Epoch 722: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s, v_num=0, train_loss_step=0.373, train_loss_epoch=0.373, valid_loss=0.0338]\n",
      "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.367, train_loss_epoch=0.367, valid_loss=0.0338]        \n",
      "Epoch 724:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361, valid_loss=0.0338]        \n",
      "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=0.0338]        \n",
      "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=0.0338]        \n",
      "Epoch 726: 100%|██████████| 1/1 [00:00<00:00,  6.11it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=0.0338]\n",
      "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=0.0338]        \n",
      "Epoch 727: 100%|██████████| 1/1 [00:00<00:00,  5.79it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=0.0338]\n",
      "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.356, train_loss_epoch=0.356, valid_loss=0.0338]        \n",
      "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=0.0338]        \n",
      "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=0.0338]        \n",
      "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=0.0338]        \n",
      "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=0.0338]        \n",
      "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=0.0338]        \n",
      "Epoch 733: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=0.0338]\n",
      "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.345, train_loss_epoch=0.345, valid_loss=0.0338]        \n",
      "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.340, train_loss_epoch=0.340, valid_loss=0.0338]        \n",
      "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=0.0338]        \n",
      "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=0.0338]        \n",
      "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=0.0338]        \n",
      "Epoch 738: 100%|██████████| 1/1 [00:00<00:00,  6.08it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=0.0338]\n",
      "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.330, train_loss_epoch=0.330, valid_loss=0.0338]        \n",
      "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=0.0338]        \n",
      "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=0.0338]        \n",
      "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=0.0338]        \n",
      "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=0.0338]        \n",
      "Epoch 743: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=0.0338]\n",
      "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=0.0338]        \n",
      "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=0.0338]        \n",
      "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=0.0338]        \n",
      "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.312, train_loss_epoch=0.312, valid_loss=0.0338]        \n",
      "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=0.0338]        \n",
      "Epoch 748: 100%|██████████| 1/1 [00:00<00:00,  6.25it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=0.0338]\n",
      "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=0.0338]        \n",
      "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=0.0338]        \n",
      "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=0.0338]        \n",
      "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=0.0338]        \n",
      "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.300, valid_loss=0.0338]        \n",
      "Epoch 753: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.300, valid_loss=0.0338]\n",
      "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=0.0338]        \n",
      "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=0.0338]        \n",
      "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=0.0338]        \n",
      "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297, valid_loss=0.0338]        \n",
      "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=0.0338]        \n",
      "Epoch 758: 100%|██████████| 1/1 [00:00<00:00,  6.08it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=0.0338]\n",
      "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=0.0338]        \n",
      "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=0.0338]        \n",
      "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.289, valid_loss=0.0338]        \n",
      "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=0.0338]        \n",
      "Epoch 762: 100%|██████████| 1/1 [00:00<00:00,  6.34it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=0.0338]\n",
      "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.284, valid_loss=0.0338]        \n",
      "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.282, valid_loss=0.0338]        \n",
      "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.280, train_loss_epoch=0.280, valid_loss=0.0338]        \n",
      "Epoch 766:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.278, train_loss_epoch=0.278, valid_loss=0.0338]        \n",
      "Epoch 766: 100%|██████████| 1/1 [00:00<00:00,  6.43it/s, v_num=0, train_loss_step=0.278, train_loss_epoch=0.278, valid_loss=0.0338]\n",
      "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.273, train_loss_epoch=0.273, valid_loss=0.0338]        \n",
      "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.271, train_loss_epoch=0.271, valid_loss=0.0338]        \n",
      "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.270, train_loss_epoch=0.270, valid_loss=0.0338]        \n",
      "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.271, train_loss_epoch=0.271, valid_loss=0.0338]        \n",
      "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.268, train_loss_epoch=0.268, valid_loss=0.0338]        \n",
      "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=0.0338]        \n",
      "Epoch 773:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=0.0338]        \n",
      "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.254, train_loss_epoch=0.254, valid_loss=0.0338]        \n",
      "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.258, train_loss_epoch=0.258, valid_loss=0.0338]        \n",
      "Epoch 775: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s, v_num=0, train_loss_step=0.258, train_loss_epoch=0.258, valid_loss=0.0338]\n",
      "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=0.0338]        \n",
      "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.250, train_loss_epoch=0.250, valid_loss=0.0338]        \n",
      "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.260, train_loss_epoch=0.260, valid_loss=0.0338]        \n",
      "Epoch 779:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.284, valid_loss=0.0338]        \n",
      "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.384, train_loss_epoch=0.384, valid_loss=0.0338]        \n",
      "Epoch 780: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s, v_num=0, train_loss_step=0.384, train_loss_epoch=0.384, valid_loss=0.0338]\n",
      "Epoch 781:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336, valid_loss=0.0338]        \n",
      "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=0.0338]        \n",
      "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363, valid_loss=0.0338]        \n",
      "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.362, train_loss_epoch=0.362, valid_loss=0.0338]        \n",
      "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396, valid_loss=0.0338]        \n",
      "Epoch 785: 100%|██████████| 1/1 [00:00<00:00,  5.83it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396, valid_loss=0.0338]\n",
      "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.410, train_loss_epoch=0.410, valid_loss=0.0338]        \n",
      "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.400, train_loss_epoch=0.400, valid_loss=0.0338]        \n",
      "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.435, train_loss_epoch=0.435, valid_loss=0.0338]        \n",
      "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.416, valid_loss=0.0338]        \n",
      "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.406, train_loss_epoch=0.406, valid_loss=0.0338]        \n",
      "Epoch 790: 100%|██████████| 1/1 [00:00<00:00,  6.01it/s, v_num=0, train_loss_step=0.406, train_loss_epoch=0.406, valid_loss=0.0338]\n",
      "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.400, train_loss_epoch=0.400, valid_loss=0.0338]        \n",
      "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.408, train_loss_epoch=0.408, valid_loss=0.0338]        \n",
      "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.427, train_loss_epoch=0.427, valid_loss=0.0338]        \n",
      "Epoch 794:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.423, train_loss_epoch=0.423, valid_loss=0.0338]        \n",
      "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.447, train_loss_epoch=0.447, valid_loss=0.0338]        \n",
      "Epoch 795: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s, v_num=0, train_loss_step=0.447, train_loss_epoch=0.447, valid_loss=0.0338]\n",
      "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.434, train_loss_epoch=0.434, valid_loss=0.0338]        \n",
      "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.417, train_loss_epoch=0.417, valid_loss=0.0338]        \n",
      "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.415, valid_loss=0.0338]        \n",
      "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.454, train_loss_epoch=0.454, valid_loss=0.0338]        \n",
      "Epoch 799: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=0, train_loss_step=0.420, train_loss_epoch=0.454, valid_loss=0.0338]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=7309)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 12.98it/s]\u001b[A\n",
      "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.420, train_loss_epoch=0.420, valid_loss=0.0451]        \n",
      "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.402, train_loss_epoch=0.402, valid_loss=0.0451]        \n",
      "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.399, train_loss_epoch=0.399, valid_loss=0.0451]        \n",
      "Epoch 803:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.407, train_loss_epoch=0.407, valid_loss=0.0451]        \n",
      "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=0.0451]        \n",
      "Epoch 805:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.397, train_loss_epoch=0.397, valid_loss=0.0451]        \n",
      "Epoch 805: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s, v_num=0, train_loss_step=0.397, train_loss_epoch=0.397, valid_loss=0.0451]\n",
      "Epoch 806:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.383, train_loss_epoch=0.383, valid_loss=0.0451]        \n",
      "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.376, train_loss_epoch=0.376, valid_loss=0.0451]        \n",
      "Epoch 808:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.376, train_loss_epoch=0.376, valid_loss=0.0451]        \n",
      "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.374, train_loss_epoch=0.374, valid_loss=0.0451]        \n",
      "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363, valid_loss=0.0451]        \n",
      "Epoch 811:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361, valid_loss=0.0451]        \n",
      "Epoch 811: 100%|██████████| 1/1 [00:00<00:00,  6.08it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361, valid_loss=0.0451]\n",
      "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.359, train_loss_epoch=0.359, valid_loss=0.0451]        \n",
      "Epoch 813:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.358, train_loss_epoch=0.358, valid_loss=0.0451]        \n",
      "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=0.0451]        \n",
      "Epoch 815:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=0.0451]        \n",
      "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346, valid_loss=0.0451]        \n",
      "Epoch 816: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346, valid_loss=0.0451]\n",
      "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=0.0451]        \n",
      "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=0.0451]        \n",
      "Epoch 819:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=0.0451]        \n",
      "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=0.0451]        \n",
      "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=0.0451]        \n",
      "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=0.0451]        \n",
      "Epoch 823:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336, valid_loss=0.0451]        \n",
      "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332, valid_loss=0.0451]        \n",
      "Epoch 824: 100%|██████████| 1/1 [00:00<00:00,  6.36it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332, valid_loss=0.0451]\n",
      "Epoch 825:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=0.0451]        \n",
      "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=0.0451]        \n",
      "Epoch 827:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=0.0451]        \n",
      "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=0.0451]        \n",
      "Epoch 829:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=0.0451]        \n",
      "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=0.0451]        \n",
      "Epoch 831:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=0.0451]        \n",
      "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=0.0451]        \n",
      "Epoch 832: 100%|██████████| 1/1 [00:00<00:00,  6.36it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=0.0451]\n",
      "Epoch 833:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=0.0451]        \n",
      "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=0.0451]        \n",
      "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=0.0451]        \n",
      "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=0.0451]        \n",
      "Epoch 836: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=0.0451]\n",
      "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=0.0451]        \n",
      "Epoch 838:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=0.0451]        \n",
      "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.305, train_loss_epoch=0.305, valid_loss=0.0451]        \n",
      "Epoch 840:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=0.0451]        \n",
      "Epoch 840: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=0.0451]\n",
      "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=0.0451]        \n",
      "Epoch 842:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=0.0451]        \n",
      "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=0.0451]        \n",
      "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295, valid_loss=0.0451]        \n",
      "Epoch 844: 100%|██████████| 1/1 [00:00<00:00,  5.70it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=0.0451]\n",
      "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=0.0451]        \n",
      "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=0.0451]        \n",
      "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=0.0451]        \n",
      "Epoch 848:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.312, train_loss_epoch=0.312, valid_loss=0.0451]        \n",
      "Epoch 848: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s, v_num=0, train_loss_step=0.312, train_loss_epoch=0.312, valid_loss=0.0451]\n",
      "Epoch 849:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=0.0451]        \n",
      "Epoch 850:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=0.0451]        \n",
      "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=0.0451]        \n",
      "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=0.0451]        \n",
      "Epoch 853:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=0.0451]        \n",
      "Epoch 853: 100%|██████████| 1/1 [00:00<00:00,  6.11it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=0.0451]\n",
      "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=0.0451]        \n",
      "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=0.0451]        \n",
      "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=0.0451]        \n",
      "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=0.0451]        \n",
      "Epoch 857: 100%|██████████| 1/1 [00:00<00:00,  6.34it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=0.0451]\n",
      "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=0.0451]        \n",
      "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.288, train_loss_epoch=0.288, valid_loss=0.0451]        \n",
      "Epoch 860:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.286, valid_loss=0.0451]        \n",
      "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=0.0451]        \n",
      "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.282, valid_loss=0.0451]        \n",
      "Epoch 862: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.282, valid_loss=0.0451]\n",
      "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.284, valid_loss=0.0451]        \n",
      "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=0.0451]        \n",
      "Epoch 865:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=0.0451]        \n",
      "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.286, valid_loss=0.0451]        \n",
      "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=0.0451]        \n",
      "Epoch 867: 100%|██████████| 1/1 [00:00<00:00,  6.01it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=0.0451]\n",
      "Epoch 868:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.282, valid_loss=0.0451]        \n",
      "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.281, train_loss_epoch=0.281, valid_loss=0.0451]        \n",
      "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.280, train_loss_epoch=0.280, valid_loss=0.0451]        \n",
      "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=0.0451]        \n",
      "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=0.0451]        \n",
      "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=0.0451]        \n",
      "Epoch 873: 100%|██████████| 1/1 [00:00<00:00,  5.85it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=0.0451]\n",
      "Epoch 874:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.275, valid_loss=0.0451]        \n",
      "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.269, train_loss_epoch=0.269, valid_loss=0.0451]        \n",
      "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.280, train_loss_epoch=0.280, valid_loss=0.0451]        \n",
      "Epoch 877:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.282, valid_loss=0.0451]        \n",
      "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=0.0451]        \n",
      "Epoch 878: 100%|██████████| 1/1 [00:00<00:00,  5.97it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=0.0451]\n",
      "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=0.0451]        \n",
      "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=0.0451]        \n",
      "Epoch 881:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=0.0451]        \n",
      "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=0.0451]        \n",
      "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=0.0451]        \n",
      "Epoch 883: 100%|██████████| 1/1 [00:00<00:00,  6.15it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=0.0451]\n",
      "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=0.0451]        \n",
      "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.374, train_loss_epoch=0.374, valid_loss=0.0451]        \n",
      "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.356, train_loss_epoch=0.356, valid_loss=0.0451]        \n",
      "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=0.0451]        \n",
      "Epoch 887: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=0.0451]\n",
      "Epoch 888:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.340, train_loss_epoch=0.340, valid_loss=0.0451]        \n",
      "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336, valid_loss=0.0451]        \n",
      "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.340, train_loss_epoch=0.340, valid_loss=0.0451]        \n",
      "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=0.0451]        \n",
      "Epoch 891: 100%|██████████| 1/1 [00:00<00:00,  6.08it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=0.0451]\n",
      "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=0.0451]        \n",
      "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=0.0451]        \n",
      "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=0.0451]        \n",
      "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=0.0451]        \n",
      "Epoch 896:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=0.0451]        \n",
      "Epoch 896: 100%|██████████| 1/1 [00:00<00:00,  5.69it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=0.0451]\n",
      "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=0.0451]        \n",
      "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=0.0451]        \n",
      "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=0.0451]        \n",
      "Epoch 899: 100%|██████████| 1/1 [00:00<00:00,  5.68it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.306, valid_loss=0.0451]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=7309)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 12.91it/s]\u001b[A\n",
      "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=0.0411]        \n",
      "Epoch 901:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=0.0411]        \n",
      "Epoch 902:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=0.0411]        \n",
      "Epoch 903:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.289, valid_loss=0.0411]        \n",
      "Epoch 904:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=0.0411]        \n",
      "Epoch 904: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=0.0411]\n",
      "Epoch 905:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.280, train_loss_epoch=0.280, valid_loss=0.0411]        \n",
      "Epoch 906:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.279, train_loss_epoch=0.279, valid_loss=0.0411]        \n",
      "Epoch 907:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276, valid_loss=0.0411]        \n",
      "Epoch 908:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.273, train_loss_epoch=0.273, valid_loss=0.0411]        \n",
      "Epoch 908: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s, v_num=0, train_loss_step=0.273, train_loss_epoch=0.273, valid_loss=0.0411]\n",
      "Epoch 909:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.269, train_loss_epoch=0.269, valid_loss=0.0411]        \n",
      "Epoch 910:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.266, train_loss_epoch=0.266, valid_loss=0.0411]        \n",
      "Epoch 911:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=0.0411]        \n",
      "Epoch 911: 100%|██████████| 1/1 [00:00<00:00,  6.21it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=0.0411]\n",
      "Epoch 912:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=0.0411]        \n",
      "Epoch 912: 100%|██████████| 1/1 [00:00<00:00,  5.41it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.261, valid_loss=0.0411]\n",
      "Epoch 912: 100%|██████████| 1/1 [00:00<00:00,  5.39it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=0.0411]\n",
      "Epoch 913:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=0.0411]        \n",
      "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.258, train_loss_epoch=0.258, valid_loss=0.0411]        \n",
      "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.256, train_loss_epoch=0.256, valid_loss=0.0411]        \n",
      "Epoch 916:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.260, train_loss_epoch=0.260, valid_loss=0.0411]        \n",
      "Epoch 917:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=0.0411]        \n",
      "Epoch 917: 100%|██████████| 1/1 [00:00<00:00,  5.84it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=0.0411]\n",
      "Epoch 918:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=0.0411]        \n",
      "Epoch 919:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=0.0411]        \n",
      "Epoch 920:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.289, valid_loss=0.0411]        \n",
      "Epoch 921:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.288, train_loss_epoch=0.288, valid_loss=0.0411]        \n",
      "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=0.0411]        \n",
      "Epoch 922: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=0.0411]\n",
      "Epoch 923:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=0.0411]        \n",
      "Epoch 924:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=0.0411]        \n",
      "Epoch 925:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.300, valid_loss=0.0411]        \n",
      "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=0.0411]        \n",
      "Epoch 927:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=0.0411]        \n",
      "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=0.0411]        \n",
      "Epoch 928: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=0.0411]\n",
      "Epoch 929:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=0.0411]        \n",
      "Epoch 929: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=0.0411]\n",
      "Epoch 930:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=0.0411]        \n",
      "Epoch 931:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=0.0411]        \n",
      "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=0.0411]        \n",
      "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.432, train_loss_epoch=0.432, valid_loss=0.0411]        \n",
      "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.422, train_loss_epoch=0.422, valid_loss=0.0411]        \n",
      "Epoch 934: 100%|██████████| 1/1 [00:00<00:00,  6.08it/s, v_num=0, train_loss_step=0.422, train_loss_epoch=0.422, valid_loss=0.0411]\n",
      "Epoch 935:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.407, train_loss_epoch=0.407, valid_loss=0.0411]        \n",
      "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.420, train_loss_epoch=0.420, valid_loss=0.0411]        \n",
      "Epoch 937:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.406, train_loss_epoch=0.406, valid_loss=0.0411]        \n",
      "Epoch 938:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.397, train_loss_epoch=0.397, valid_loss=0.0411]        \n",
      "Epoch 939:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=0.0411]        \n",
      "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.401, train_loss_epoch=0.401, valid_loss=0.0411]        \n",
      "Epoch 940: 100%|██████████| 1/1 [00:00<00:00,  6.21it/s, v_num=0, train_loss_step=0.401, train_loss_epoch=0.401, valid_loss=0.0411]\n",
      "Epoch 941:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.393, train_loss_epoch=0.393, valid_loss=0.0411]        \n",
      "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.392, train_loss_epoch=0.392, valid_loss=0.0411]        \n",
      "Epoch 943:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.391, train_loss_epoch=0.391, valid_loss=0.0411]        \n",
      "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.381, train_loss_epoch=0.381, valid_loss=0.0411]        \n",
      "Epoch 945:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.371, train_loss_epoch=0.371, valid_loss=0.0411]        \n",
      "Epoch 945: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s, v_num=0, train_loss_step=0.371, train_loss_epoch=0.371, valid_loss=0.0411]\n",
      "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.372, valid_loss=0.0411]        \n",
      "Epoch 947:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365, valid_loss=0.0411]        \n",
      "Epoch 948:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=0.0411]        \n",
      "Epoch 949:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=0.0411]        \n",
      "Epoch 950:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=0.0411]        \n",
      "Epoch 950: 100%|██████████| 1/1 [00:00<00:00,  6.25it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=0.0411]\n",
      "Epoch 951:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=0.0411]        \n",
      "Epoch 951: 100%|██████████| 1/1 [00:00<00:00,  5.72it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=0.0411]\n",
      "Epoch 952:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=0.0411]        \n",
      "Epoch 953:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.344, train_loss_epoch=0.344, valid_loss=0.0411]        \n",
      "Epoch 954:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=0.0411]        \n",
      "Epoch 955:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=0.0411]        \n",
      "Epoch 956:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=0.0411]        \n",
      "Epoch 957:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=0.0411]        \n",
      "Epoch 957: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=0.0411]\n",
      "Epoch 957: 100%|██████████| 1/1 [00:00<00:00,  5.45it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.331, valid_loss=0.0411]\n",
      "Epoch 957: 100%|██████████| 1/1 [00:00<00:00,  5.43it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=0.0411]\n",
      "Epoch 958:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=0.0411]        \n",
      "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=0.0411]        \n",
      "Epoch 960:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=0.0411]        \n",
      "Epoch 961:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=0.0411]        \n",
      "Epoch 962:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=0.0411]        \n",
      "Epoch 962: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=0.0411]\n",
      "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=0.0411]        \n",
      "Epoch 963: 100%|██████████| 1/1 [00:00<00:00,  5.38it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=0.0411]\n",
      "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=0.0411]        \n",
      "Epoch 965:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=0.0411]        \n",
      "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=0.0411]        \n",
      "Epoch 967:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351, valid_loss=0.0411]        \n",
      "Epoch 968:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.591, train_loss_epoch=0.591, valid_loss=0.0411]        \n",
      "Epoch 968: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s, v_num=0, train_loss_step=0.591, train_loss_epoch=0.591, valid_loss=0.0411]\n",
      "Epoch 969:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.585, train_loss_epoch=0.585, valid_loss=0.0411]        \n",
      "Epoch 970:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.627, train_loss_epoch=0.627, valid_loss=0.0411]        \n",
      "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.598, train_loss_epoch=0.598, valid_loss=0.0411]        \n",
      "Epoch 972:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.595, train_loss_epoch=0.595, valid_loss=0.0411]        \n",
      "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.598, train_loss_epoch=0.598, valid_loss=0.0411]        \n",
      "Epoch 974:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582, valid_loss=0.0411]        \n",
      "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.576, train_loss_epoch=0.576, valid_loss=0.0411]        \n",
      "Epoch 975: 100%|██████████| 1/1 [00:00<00:00,  5.80it/s, v_num=0, train_loss_step=0.576, train_loss_epoch=0.576, valid_loss=0.0411]\n",
      "Epoch 976:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.578, train_loss_epoch=0.578, valid_loss=0.0411]        \n",
      "Epoch 976: 100%|██████████| 1/1 [00:00<00:00,  5.28it/s, v_num=0, train_loss_step=0.579, train_loss_epoch=0.578, valid_loss=0.0411]\n",
      "Epoch 976: 100%|██████████| 1/1 [00:00<00:00,  5.25it/s, v_num=0, train_loss_step=0.579, train_loss_epoch=0.579, valid_loss=0.0411]\n",
      "Epoch 977:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.579, train_loss_epoch=0.579, valid_loss=0.0411]        \n",
      "Epoch 978:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.575, train_loss_epoch=0.575, valid_loss=0.0411]        \n",
      "Epoch 979:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567, valid_loss=0.0411]        \n",
      "Epoch 980:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=0.0411]        \n",
      "Epoch 981:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=0.0411]        \n",
      "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0411]        \n",
      "Epoch 983:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0411]        \n",
      "Epoch 984:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0411]        \n",
      "Epoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=0.0411]        \n",
      "Epoch 986:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0411]        \n",
      "Epoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=0.0411]        \n",
      "Epoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.0411]        \n",
      "Epoch 988: 100%|██████████| 1/1 [00:00<00:00,  8.82it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.0411]\n",
      "Epoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0411]        \n",
      "Epoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0411]        \n",
      "Epoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0411]        \n",
      "Epoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0411]        \n",
      "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0411]        \n",
      "Epoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=0.0411]        \n",
      "Epoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0411]        \n",
      "Epoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0411]        \n",
      "Epoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0411]        \n",
      "Epoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0411]        \n",
      "Epoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0411]        \n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 10.01it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.535, valid_loss=0.0411]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 20.09it/s]\u001b[A\n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0328]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=7309)\u001b[0m `Trainer.fit` stopped: `max_steps=1000` reached.\n",
      "\u001b[36m(_train_tune pid=7943)\u001b[0m /home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=7943)\u001b[0m Seed set to 11\n",
      "\u001b[36m(_train_tune pid=7943)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=7943)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=7943)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=7943)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(_train_tune pid=7943)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_train_tune pid=7943)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=7943)\u001b[0m   | Name            | Type          | Params | Mode \n",
      "\u001b[36m(_train_tune pid=7943)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=7943)\u001b[0m 0 | loss            | WMAPE         | 0      | train\n",
      "\u001b[36m(_train_tune pid=7943)\u001b[0m 1 | padder          | ConstantPad1d | 0      | train\n",
      "\u001b[36m(_train_tune pid=7943)\u001b[0m 2 | scaler          | TemporalNorm  | 0      | train\n",
      "\u001b[36m(_train_tune pid=7943)\u001b[0m 3 | hist_encoder    | LSTM          | 363 K  | train\n",
      "\u001b[36m(_train_tune pid=7943)\u001b[0m 4 | context_adapter | Linear        | 115 K  | train\n",
      "\u001b[36m(_train_tune pid=7943)\u001b[0m 5 | mlp_decoder     | MLP           | 897    | train\n",
      "\u001b[36m(_train_tune pid=7943)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=7943)\u001b[0m 480 K     Trainable params\n",
      "\u001b[36m(_train_tune pid=7943)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=7943)\u001b[0m 480 K     Total params\n",
      "\u001b[36m(_train_tune pid=7943)\u001b[0m 1.922     Total estimated model params size (MB)\n",
      "\u001b[36m(_train_tune pid=7943)\u001b[0m 11        Modules in train mode\n",
      "\u001b[36m(_train_tune pid=7943)\u001b[0m 0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]\n",
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.750, train_loss_epoch=3.750]        \n",
      "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190]        \n",
      "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580]        \n",
      "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180]        \n",
      "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]        \n",
      "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]        \n",
      "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]        \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 12.22it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.020]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 12.11it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060]\n",
      "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060]       \n",
      "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050]        \n",
      "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050]        \n",
      "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040]        \n",
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]        \n",
      "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.971, train_loss_epoch=0.971]        \n",
      "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.965, train_loss_epoch=0.965]        \n",
      "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.934, train_loss_epoch=0.934]        \n",
      "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040]        \n",
      "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970]        \n",
      "Epoch 21: 100%|██████████| 1/1 [00:00<00:00, 14.69it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.991]\n",
      "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040]        \n",
      "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]        \n",
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00,  8.24it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]\n",
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050]\n",
      "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050]        \n",
      "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]        \n",
      "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]        \n",
      "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260]        \n",
      "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]        \n",
      "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140]        \n",
      "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140]        \n",
      "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]        \n",
      "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180]        \n",
      "Epoch 35: 100%|██████████| 1/1 [00:00<00:00, 14.17it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]\n",
      "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060]        \n",
      "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]        \n",
      "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]        \n",
      "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030]        \n",
      "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]        \n",
      "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]        \n",
      "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]        \n",
      "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]        \n",
      "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00, 11.79it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]\n",
      "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998]        \n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 11.13it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998]\n",
      "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992]        \n",
      "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992]        \n",
      "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996]        \n",
      "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988]        \n",
      "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988]        \n",
      "Epoch 56: 100%|██████████| 1/1 [00:00<00:00, 12.03it/s, v_num=0, train_loss_step=0.980, train_loss_epoch=0.980]\n",
      "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.980, train_loss_epoch=0.980]        \n",
      "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.972, train_loss_epoch=0.972]        \n",
      "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.966, train_loss_epoch=0.966]        \n",
      "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.962, train_loss_epoch=0.962]        \n",
      "Epoch 61: 100%|██████████| 1/1 [00:00<00:00, 12.04it/s, v_num=0, train_loss_step=0.963, train_loss_epoch=0.963]\n",
      "Epoch 61: 100%|██████████| 1/1 [00:00<00:00, 10.90it/s, v_num=0, train_loss_step=0.985, train_loss_epoch=0.985]\n",
      "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.985, train_loss_epoch=0.985]        \n",
      "Epoch 62: 100%|██████████| 1/1 [00:00<00:00,  9.88it/s, v_num=0, train_loss_step=0.985, train_loss_epoch=0.985]\n",
      "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994]        \n",
      "Epoch 63: 100%|██████████| 1/1 [00:00<00:00, 10.25it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994]\n",
      "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.979, train_loss_epoch=0.979]        \n",
      "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.959, train_loss_epoch=0.959]        \n",
      "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.935, train_loss_epoch=0.935]        \n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00, 12.72it/s, v_num=0, train_loss_step=0.920, train_loss_epoch=0.935]\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00, 12.62it/s, v_num=0, train_loss_step=0.920, train_loss_epoch=0.920]\n",
      "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.920, train_loss_epoch=0.920]        \n",
      "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.951, train_loss_epoch=0.951]        \n",
      "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.921, train_loss_epoch=0.921]        \n",
      "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.919, train_loss_epoch=0.919]        \n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00, 13.18it/s, v_num=0, train_loss_step=0.856, train_loss_epoch=0.926]\n",
      "Epoch 72: 100%|██████████| 1/1 [00:00<00:00, 13.06it/s, v_num=0, train_loss_step=0.856, train_loss_epoch=0.856]\n",
      "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.856, train_loss_epoch=0.856]        \n",
      "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.860, train_loss_epoch=0.860]        \n",
      "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040]        \n",
      "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.889, train_loss_epoch=0.889]        \n",
      "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210]        \n",
      "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060]        \n",
      "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.989, train_loss_epoch=0.989]        \n",
      "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]        \n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00, 14.15it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]\n",
      "Epoch 83: 100%|██████████| 1/1 [00:00<00:00, 12.58it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998]\n",
      "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.978, train_loss_epoch=0.978]        \n",
      "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.966, train_loss_epoch=0.966]        \n",
      "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.970, train_loss_epoch=0.970]        \n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00, 12.64it/s, v_num=0, train_loss_step=0.953, train_loss_epoch=0.960]\n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00, 12.55it/s, v_num=0, train_loss_step=0.953, train_loss_epoch=0.953]\n",
      "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.953, train_loss_epoch=0.953]        \n",
      "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.943, train_loss_epoch=0.943]        \n",
      "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.925, train_loss_epoch=0.925]        \n",
      "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.907, train_loss_epoch=0.907]        \n",
      "Epoch 93: 100%|██████████| 1/1 [00:00<00:00, 12.30it/s, v_num=0, train_loss_step=0.905, train_loss_epoch=0.905]\n",
      "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.874, train_loss_epoch=0.874]        \n",
      "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.878, train_loss_epoch=0.878]        \n",
      "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380]        \n",
      "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240]        \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 13.06it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.240]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=7943)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 20.33it/s]\u001b[A\n",
      "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.328]       \n",
      "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.328]        \n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00, 13.30it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.328]\n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.030, valid_loss=0.328]\n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00, 11.95it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.328]\n",
      "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.328]        \n",
      "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.328]        \n",
      "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.328]        \n",
      "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.328]        \n",
      "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.328]        \n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00, 14.07it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.328]\n",
      "Epoch 109: 100%|██████████| 1/1 [00:00<00:00, 11.02it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.328]\n",
      "Epoch 109: 100%|██████████| 1/1 [00:00<00:00, 10.44it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.010, valid_loss=0.328]\n",
      "Epoch 109: 100%|██████████| 1/1 [00:00<00:00, 10.37it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.328]\n",
      "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.328]        \n",
      "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]        \n",
      "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]        \n",
      "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.328]        \n",
      "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.328]        \n",
      "Epoch 114: 100%|██████████| 1/1 [00:00<00:00, 12.93it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.010, valid_loss=0.328]\n",
      "Epoch 114: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]\n",
      "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]        \n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00,  9.67it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.328]\n",
      "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.328]        \n",
      "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]        \n",
      "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]        \n",
      "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]        \n",
      "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.328]        \n",
      "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]        \n",
      "Epoch 122: 100%|██████████| 1/1 [00:00<00:00, 13.10it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]\n",
      "Epoch 122: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]\n",
      "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]        \n",
      "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]        \n",
      "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]        \n",
      "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]        \n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00, 13.63it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]\n",
      "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]        \n",
      "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.328]        \n",
      "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]        \n",
      "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]        \n",
      "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.328]        \n",
      "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.328]        \n",
      "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]        \n",
      "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.328]        \n",
      "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.328]        \n",
      "Epoch 139: 100%|██████████| 1/1 [00:00<00:00, 13.93it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.328]\n",
      "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]        \n",
      "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]        \n",
      "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.328]        \n",
      "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]        \n",
      "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]        \n",
      "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]        \n",
      "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]        \n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00, 14.53it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]\n",
      "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]        \n",
      "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]        \n",
      "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]        \n",
      "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]        \n",
      "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.328]        \n",
      "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.328]        \n",
      "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.328]        \n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00, 13.81it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.328]\n",
      "Epoch 156: 100%|██████████| 1/1 [00:00<00:00, 12.34it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]\n",
      "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]        \n",
      "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.328]        \n",
      "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]        \n",
      "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]        \n",
      "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.328]        \n",
      "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.328]        \n",
      "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]        \n",
      "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.328]        \n",
      "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.328]        \n",
      "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]        \n",
      "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.328]        \n",
      "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.328]        \n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.328]\n",
      "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.328]        \n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00, 10.41it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.328]\n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00,  9.54it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]\n",
      "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]        \n",
      "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]        \n",
      "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.328]        \n",
      "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]        \n",
      "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]        \n",
      "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.328]        \n",
      "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.328]        \n",
      "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.328]        \n",
      "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.328]        \n",
      "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.328]        \n",
      "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]        \n",
      "Epoch 186: 100%|██████████| 1/1 [00:00<00:00, 14.32it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.328]\n",
      "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.328]        \n",
      "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.328]        \n",
      "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.328]        \n",
      "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.328]        \n",
      "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.328]        \n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00, 12.95it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]\n",
      "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.328]        \n",
      "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.328]        \n",
      "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.328]        \n",
      "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.328]        \n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00,  9.47it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.328]\n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00,  8.79it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.999, valid_loss=0.328]\n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00,  8.72it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.328]\n",
      "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.328]        \n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 12.68it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.994, valid_loss=0.328]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=7943)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 19.47it/s]\u001b[A\n",
      "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.332]        \n",
      "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.332]        \n",
      "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.332]        \n",
      "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.332]        \n",
      "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.332]        \n",
      "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.332]        \n",
      "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.332]        \n",
      "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.332]        \n",
      "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.332]        \n",
      "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.332]        \n",
      "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.332]        \n",
      "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.332]        \n",
      "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=0.332]        \n",
      "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.990, train_loss_epoch=0.990, valid_loss=0.332]        \n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00, 12.62it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.332]\n",
      "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.332]        \n",
      "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.987, train_loss_epoch=0.987, valid_loss=0.332]        \n",
      "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.990, train_loss_epoch=0.990, valid_loss=0.332]        \n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00, 12.87it/s, v_num=0, train_loss_step=0.987, train_loss_epoch=0.987, valid_loss=0.332]\n",
      "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.987, train_loss_epoch=0.987, valid_loss=0.332]        \n",
      "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.985, train_loss_epoch=0.985, valid_loss=0.332]        \n",
      "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.976, train_loss_epoch=0.976, valid_loss=0.332]        \n",
      "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.975, train_loss_epoch=0.975, valid_loss=0.332]        \n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00, 12.80it/s, v_num=0, train_loss_step=0.969, train_loss_epoch=0.975, valid_loss=0.332]\n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00, 12.68it/s, v_num=0, train_loss_step=0.969, train_loss_epoch=0.969, valid_loss=0.332]\n",
      "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.969, train_loss_epoch=0.969, valid_loss=0.332]        \n",
      "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.978, train_loss_epoch=0.978, valid_loss=0.332]        \n",
      "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.973, train_loss_epoch=0.973, valid_loss=0.332]        \n",
      "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.332]        \n",
      "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.332]        \n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00, 14.47it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.332]\n",
      "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.332]        \n",
      "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.332]        \n",
      "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.332]        \n",
      "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.332]        \n",
      "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.332]        \n",
      "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.332]        \n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00, 11.29it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.332]\n",
      "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.332]        \n",
      "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.332]        \n",
      "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.332]        \n",
      "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.332]        \n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00, 12.17it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.332]\n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00, 11.28it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.332]\n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00, 10.42it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.332]\n",
      "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.332]        \n",
      "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.332]        \n",
      "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.332]        \n",
      "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.332]        \n",
      "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.332]        \n",
      "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.332]        \n",
      "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.332]        \n",
      "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=0.332]        \n",
      "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.989, train_loss_epoch=0.989, valid_loss=0.332]        \n",
      "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.332]        \n",
      "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=0.332]        \n",
      "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.986, train_loss_epoch=0.986, valid_loss=0.332]        \n",
      "Epoch 259: 100%|██████████| 1/1 [00:00<00:00, 14.18it/s, v_num=0, train_loss_step=0.986, train_loss_epoch=0.986, valid_loss=0.332]\n",
      "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.982, train_loss_epoch=0.982, valid_loss=0.332]        \n",
      "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.332]        \n",
      "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.990, train_loss_epoch=0.990, valid_loss=0.332]        \n",
      "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988, valid_loss=0.332]        \n",
      "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.987, train_loss_epoch=0.987, valid_loss=0.332]        \n",
      "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.986, train_loss_epoch=0.986, valid_loss=0.332]        \n",
      "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.991, valid_loss=0.332]        \n",
      "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.986, train_loss_epoch=0.986, valid_loss=0.332]        \n",
      "Epoch 269: 100%|██████████| 1/1 [00:00<00:00, 12.89it/s, v_num=0, train_loss_step=0.983, train_loss_epoch=0.983, valid_loss=0.332]\n",
      "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.983, train_loss_epoch=0.983, valid_loss=0.332]        \n",
      "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.983, train_loss_epoch=0.983, valid_loss=0.332]        \n",
      "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.991, valid_loss=0.332]        \n",
      "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.975, train_loss_epoch=0.975, valid_loss=0.332]        \n",
      "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.986, train_loss_epoch=0.986, valid_loss=0.332]        \n",
      "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.975, train_loss_epoch=0.975, valid_loss=0.332]        \n",
      "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.983, train_loss_epoch=0.983, valid_loss=0.332]        \n",
      "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.977, train_loss_epoch=0.977, valid_loss=0.332]        \n",
      "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.973, train_loss_epoch=0.973, valid_loss=0.332]        \n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00, 10.84it/s, v_num=0, train_loss_step=0.958, train_loss_epoch=0.958, valid_loss=0.332]\n",
      "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.958, train_loss_epoch=0.958, valid_loss=0.332]        \n",
      "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.948, train_loss_epoch=0.948, valid_loss=0.332]        \n",
      "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.945, valid_loss=0.332]        \n",
      "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.989, train_loss_epoch=0.989, valid_loss=0.332]        \n",
      "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.983, train_loss_epoch=0.983, valid_loss=0.332]        \n",
      "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.332]        \n",
      "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.332]        \n",
      "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.332]        \n",
      "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988, valid_loss=0.332]        \n",
      "Epoch 288: 100%|██████████| 1/1 [00:00<00:00, 14.41it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988, valid_loss=0.332]\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00, 11.70it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.332]\n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00, 10.59it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.332]\n",
      "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.332]        \n",
      "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.332]        \n",
      "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.987, train_loss_epoch=0.987, valid_loss=0.332]        \n",
      "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.989, train_loss_epoch=0.989, valid_loss=0.332]        \n",
      "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984, valid_loss=0.332]        \n",
      "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.332]        \n",
      "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.332]        \n",
      "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.332]        \n",
      "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.332]        \n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  9.93it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.997, valid_loss=0.332]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 20.79it/s]\u001b[A\n",
      "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.332]        \n",
      "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.332]        \n",
      "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.332]        \n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=0.332]\n",
      "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.986, train_loss_epoch=0.986, valid_loss=0.332]        \n",
      "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.989, train_loss_epoch=0.989, valid_loss=0.332]        \n",
      "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984, valid_loss=0.332]        \n",
      "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984, valid_loss=0.332]        \n",
      "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.982, train_loss_epoch=0.982, valid_loss=0.332]        \n",
      "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.332]        \n",
      "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.332]        \n",
      "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.332]        \n",
      "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.989, train_loss_epoch=0.989, valid_loss=0.332]        \n",
      "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.990, train_loss_epoch=0.990, valid_loss=0.332]        \n",
      "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.332]        \n",
      "Epoch 317: 100%|██████████| 1/1 [00:00<00:00, 11.60it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.988, valid_loss=0.332]\n",
      "Epoch 317: 100%|██████████| 1/1 [00:00<00:00, 11.43it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.991, valid_loss=0.332]\n",
      "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.991, valid_loss=0.332]        \n",
      "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.989, train_loss_epoch=0.989, valid_loss=0.332]        \n",
      "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.986, train_loss_epoch=0.986, valid_loss=0.332]        \n",
      "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.989, train_loss_epoch=0.989, valid_loss=0.332]        \n",
      "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.332]        \n",
      "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.332]        \n",
      "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.990, train_loss_epoch=0.990, valid_loss=0.332]        \n",
      "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.987, train_loss_epoch=0.987, valid_loss=0.332]        \n",
      "Epoch 327: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984, valid_loss=0.332]\n",
      "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.977, train_loss_epoch=0.977, valid_loss=0.332]        \n",
      "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.981, train_loss_epoch=0.981, valid_loss=0.332]        \n",
      "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.978, train_loss_epoch=0.978, valid_loss=0.332]        \n",
      "Epoch 332: 100%|██████████| 1/1 [00:00<00:00, 14.60it/s, v_num=0, train_loss_step=0.977, train_loss_epoch=0.977, valid_loss=0.332]\n",
      "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.966, train_loss_epoch=0.966, valid_loss=0.332]        \n",
      "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.966, train_loss_epoch=0.966, valid_loss=0.332]        \n",
      "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.970, train_loss_epoch=0.970, valid_loss=0.332]        \n",
      "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.973, train_loss_epoch=0.973, valid_loss=0.332]        \n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00, 11.84it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984, valid_loss=0.332]\n",
      "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984, valid_loss=0.332]        \n",
      "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984, valid_loss=0.332]        \n",
      "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.976, train_loss_epoch=0.976, valid_loss=0.332]        \n",
      "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.976, train_loss_epoch=0.976, valid_loss=0.332]        \n",
      "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.971, train_loss_epoch=0.971, valid_loss=0.332]        \n",
      "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.981, train_loss_epoch=0.981, valid_loss=0.332]        \n",
      "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.986, train_loss_epoch=0.986, valid_loss=0.332]        \n",
      "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984, valid_loss=0.332]        \n",
      "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.982, train_loss_epoch=0.982, valid_loss=0.332]        \n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00,  9.71it/s, v_num=0, train_loss_step=0.972, train_loss_epoch=0.972, valid_loss=0.332]\n",
      "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.972, train_loss_epoch=0.972, valid_loss=0.332]        \n",
      "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.971, train_loss_epoch=0.971, valid_loss=0.332]        \n",
      "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.976, train_loss_epoch=0.976, valid_loss=0.332]        \n",
      "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.972, train_loss_epoch=0.972, valid_loss=0.332]        \n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00, 12.71it/s, v_num=0, train_loss_step=0.978, train_loss_epoch=0.972, valid_loss=0.332]\n",
      "Epoch 351: 100%|██████████| 1/1 [00:00<00:00, 12.62it/s, v_num=0, train_loss_step=0.978, train_loss_epoch=0.978, valid_loss=0.332]\n",
      "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.978, train_loss_epoch=0.978, valid_loss=0.332]        \n",
      "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.978, train_loss_epoch=0.978, valid_loss=0.332]        \n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00,  8.73it/s, v_num=0, train_loss_step=0.982, train_loss_epoch=0.978, valid_loss=0.332]\n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00,  8.68it/s, v_num=0, train_loss_step=0.982, train_loss_epoch=0.982, valid_loss=0.332]\n",
      "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.982, train_loss_epoch=0.982, valid_loss=0.332]        \n",
      "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.979, train_loss_epoch=0.979, valid_loss=0.332]        \n",
      "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984, valid_loss=0.332]        \n",
      "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.979, train_loss_epoch=0.979, valid_loss=0.332]        \n",
      "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.976, train_loss_epoch=0.976, valid_loss=0.332]        \n",
      "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.970, train_loss_epoch=0.970, valid_loss=0.332]        \n",
      "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.962, train_loss_epoch=0.962, valid_loss=0.332]        \n",
      "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.964, train_loss_epoch=0.964, valid_loss=0.332]        \n",
      "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.965, train_loss_epoch=0.965, valid_loss=0.332]        \n",
      "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.962, train_loss_epoch=0.962, valid_loss=0.332]        \n",
      "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.961, train_loss_epoch=0.961, valid_loss=0.332]        \n",
      "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.960, train_loss_epoch=0.960, valid_loss=0.332]        \n",
      "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.955, train_loss_epoch=0.955, valid_loss=0.332]        \n",
      "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=0.950, valid_loss=0.332]        \n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00,  7.34it/s, v_num=0, train_loss_step=0.953, train_loss_epoch=0.953, valid_loss=0.332]\n",
      "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.953, train_loss_epoch=0.953, valid_loss=0.332]        \n",
      "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.963, train_loss_epoch=0.963, valid_loss=0.332]        \n",
      "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988, valid_loss=0.332]        \n",
      "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.966, train_loss_epoch=0.966, valid_loss=0.332]        \n",
      "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.971, train_loss_epoch=0.971, valid_loss=0.332]        \n",
      "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.956, train_loss_epoch=0.956, valid_loss=0.332]        \n",
      "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984, valid_loss=0.332]        \n",
      "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.986, train_loss_epoch=0.986, valid_loss=0.332]        \n",
      "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.979, train_loss_epoch=0.979, valid_loss=0.332]        \n",
      "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.962, train_loss_epoch=0.962, valid_loss=0.332]        \n",
      "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.332]        \n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00, 11.01it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.332]\n",
      "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984, valid_loss=0.332]        \n",
      "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.977, train_loss_epoch=0.977, valid_loss=0.332]        \n",
      "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.962, train_loss_epoch=0.962, valid_loss=0.332]        \n",
      "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.981, train_loss_epoch=0.981, valid_loss=0.332]        \n",
      "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.954, train_loss_epoch=0.954, valid_loss=0.332]        \n",
      "Epoch 388: 100%|██████████| 1/1 [00:00<00:00, 12.04it/s, v_num=0, train_loss_step=0.952, train_loss_epoch=0.952, valid_loss=0.332]\n",
      "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.952, train_loss_epoch=0.952, valid_loss=0.332]        \n",
      "Epoch 389: 100%|██████████| 1/1 [00:00<00:00,  9.99it/s, v_num=0, train_loss_step=0.952, train_loss_epoch=0.952, valid_loss=0.332]\n",
      "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.949, train_loss_epoch=0.949, valid_loss=0.332]        \n",
      "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.941, train_loss_epoch=0.941, valid_loss=0.332]        \n",
      "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.958, train_loss_epoch=0.958, valid_loss=0.332]        \n",
      "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.962, train_loss_epoch=0.962, valid_loss=0.332]        \n",
      "Epoch 395: 100%|██████████| 1/1 [00:00<00:00, 14.38it/s, v_num=0, train_loss_step=0.954, train_loss_epoch=0.954, valid_loss=0.332]\n",
      "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.949, train_loss_epoch=0.949, valid_loss=0.332]        \n",
      "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=0.950, valid_loss=0.332]        \n",
      "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.942, train_loss_epoch=0.942, valid_loss=0.332]        \n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 10.28it/s, v_num=0, train_loss_step=0.946, train_loss_epoch=0.942, valid_loss=0.332]\n",
      "\u001b[36m(_train_tune pid=7943)\u001b[0m \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=7943)\u001b[0m \n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=7943)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 21.10it/s]\u001b[A\n",
      "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.946, train_loss_epoch=0.946, valid_loss=0.306]        \n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00, 12.84it/s, v_num=0, train_loss_step=0.938, train_loss_epoch=0.953, valid_loss=0.306]\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00, 12.70it/s, v_num=0, train_loss_step=0.938, train_loss_epoch=0.938, valid_loss=0.306]\n",
      "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.938, train_loss_epoch=0.938, valid_loss=0.306]        \n",
      "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.940, train_loss_epoch=0.940, valid_loss=0.306]        \n",
      "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.931, train_loss_epoch=0.931, valid_loss=0.306]        \n",
      "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.936, train_loss_epoch=0.936, valid_loss=0.306]        \n",
      "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.940, train_loss_epoch=0.940, valid_loss=0.306]        \n",
      "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.937, train_loss_epoch=0.937, valid_loss=0.306]        \n",
      "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.912, train_loss_epoch=0.912, valid_loss=0.306]        \n",
      "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.947, train_loss_epoch=0.947, valid_loss=0.306]        \n",
      "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.987, train_loss_epoch=0.987, valid_loss=0.306]        \n",
      "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.960, train_loss_epoch=0.960, valid_loss=0.306]        \n",
      "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.941, train_loss_epoch=0.941, valid_loss=0.306]        \n",
      "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.955, train_loss_epoch=0.955, valid_loss=0.306]        \n",
      "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.981, train_loss_epoch=0.981, valid_loss=0.306]        \n",
      "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.939, train_loss_epoch=0.939, valid_loss=0.306]        \n",
      "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.306]        \n",
      "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.936, train_loss_epoch=0.936, valid_loss=0.306]        \n",
      "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.977, train_loss_epoch=0.977, valid_loss=0.306]        \n",
      "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.975, train_loss_epoch=0.975, valid_loss=0.306]        \n",
      "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.898, train_loss_epoch=0.898, valid_loss=0.306]        \n",
      "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.306]        \n",
      "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.306]        \n",
      "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.306]        \n",
      "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.306]        \n",
      "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.306]        \n",
      "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.306]        \n",
      "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.306]        \n",
      "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.306]        \n",
      "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.306]        \n",
      "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.306]        \n",
      "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.306]        \n",
      "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.306]        \n",
      "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.306]        \n",
      "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.306]        \n",
      "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.306]        \n",
      "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.306]        \n",
      "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.306]        \n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00, 12.41it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.306]\n",
      "Epoch 443: 100%|██████████| 1/1 [00:00<00:00, 10.66it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.306]\n",
      "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.306]        \n",
      "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.306]        \n",
      "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.306]        \n",
      "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.306]        \n",
      "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.306]        \n",
      "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.306]        \n",
      "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.306]        \n",
      "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.306]        \n",
      "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.306]        \n",
      "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.306]        \n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00, 13.41it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.306]\n",
      "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.306]        \n",
      "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.306]        \n",
      "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.306]        \n",
      "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.306]        \n",
      "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.306]        \n",
      "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.306]        \n",
      "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.306]        \n",
      "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.306]        \n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00, 14.68it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.306]\n",
      "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.306]        \n",
      "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.306]        \n",
      "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.306]        \n",
      "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.306]        \n",
      "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.306]        \n",
      "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.306]        \n",
      "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.306]        \n",
      "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.306]        \n",
      "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.306]        \n",
      "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.306]        \n",
      "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.306]        \n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00, 12.62it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.306]\n",
      "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.306]        \n",
      "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.306]        \n",
      "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.306]        \n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00, 12.71it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.306]\n",
      "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.306]        \n",
      "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.306]        \n",
      "Epoch 486: 100%|██████████| 1/1 [00:00<00:00, 14.68it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.306]\n",
      "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.306]        \n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.306]\n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.306]\n",
      "Epoch 488: 100%|██████████| 1/1 [00:00<00:00, 13.04it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.306]\n",
      "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.306]        \n",
      "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.306]        \n",
      "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.306]        \n",
      "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.306]        \n",
      "Epoch 493: 100%|██████████| 1/1 [00:00<00:00, 12.49it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.306]\n",
      "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.306]        \n",
      "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.306]        \n",
      "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.306]        \n",
      "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.306]        \n",
      "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.306]        \n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 10.77it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.306]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=7943)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  9.83it/s]\u001b[A\n",
      "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.333]        \n",
      "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.333]        \n",
      "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.333]        \n",
      "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.333]        \n",
      "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.333]        \n",
      "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.333]        \n",
      "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.333]        \n",
      "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.333]        \n",
      "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.333]        \n",
      "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.333]        \n",
      "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.333]        \n",
      "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.333]        \n",
      "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.333]        \n",
      "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.333]        \n",
      "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.333]        \n",
      "Epoch 517: 100%|██████████| 1/1 [00:00<00:00, 14.76it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.333]\n",
      "Epoch 517: 100%|██████████| 1/1 [00:00<00:00, 13.23it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=1.000, valid_loss=0.333]\n",
      "Epoch 517: 100%|██████████| 1/1 [00:00<00:00, 13.10it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.333]\n",
      "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.333]        \n",
      "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.333]        \n",
      "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.333]        \n",
      "Epoch 521: 100%|██████████| 1/1 [00:00<00:00, 14.24it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.333]\n",
      "Epoch 521: 100%|██████████| 1/1 [00:00<00:00, 12.61it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.333]\n",
      "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.333]        \n",
      "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.333]        \n",
      "Epoch 523: 100%|██████████| 1/1 [00:00<00:00,  9.84it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.333]\n",
      "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.333]        \n",
      "Epoch 524: 100%|██████████| 1/1 [00:00<00:00, 10.15it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.333]\n",
      "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.333]        \n",
      "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.333]        \n",
      "Epoch 526: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.333]\n",
      "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.333]        \n",
      "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.333]        \n",
      "Epoch 529: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.333]\n",
      "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.333]        \n",
      "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.333]        \n",
      "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.333]        \n",
      "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.333]        \n",
      "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.333]        \n",
      "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.333]        \n",
      "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.333]        \n",
      "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.333]\n",
      "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.333]        \n",
      "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.333]        \n",
      "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.333]        \n",
      "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.333]        \n",
      "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.333]        \n",
      "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.333]        \n",
      "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.333]        \n",
      "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.333]        \n",
      "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.333]        \n",
      "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.333]        \n",
      "Epoch 550: 100%|██████████| 1/1 [00:00<00:00, 14.59it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.333]\n",
      "Epoch 551: 100%|██████████| 1/1 [00:00<00:00, 10.58it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.333]\n",
      "Epoch 552: 100%|██████████| 1/1 [00:00<00:00, 11.35it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.333]\n",
      "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.333]        \n",
      "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.333]        \n",
      "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.333]        \n",
      "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.333]        \n",
      "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.333]        \n",
      "Epoch 560: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.333]\n",
      "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.333]        \n",
      "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.333]        \n",
      "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.333]        \n",
      "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.333]        \n",
      "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.333]        \n",
      "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.333]        \n",
      "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.333]        \n",
      "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.333]        \n",
      "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.333]        \n",
      "Epoch 570: 100%|██████████| 1/1 [00:00<00:00, 14.54it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.333]\n",
      "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.333]        \n",
      "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.333]        \n",
      "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.333]        \n",
      "Epoch 574: 100%|██████████| 1/1 [00:00<00:00, 12.81it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=0.998, valid_loss=0.333]\n",
      "Epoch 574: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.333]\n",
      "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.333]        \n",
      "Epoch 576: 100%|██████████| 1/1 [00:00<00:00, 11.94it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.333]\n",
      "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.333]        \n",
      "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.333]        \n",
      "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.333]        \n",
      "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.333]        \n",
      "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.333]        \n",
      "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.333]        \n",
      "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.333]        \n",
      "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.333]        \n",
      "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.333]        \n",
      "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.333]        \n",
      "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.333]        \n",
      "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.333]        \n",
      "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.333]        \n",
      "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.333]        \n",
      "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.333]        \n",
      "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.333]        \n",
      "Epoch 595: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.333]\n",
      "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.333]        \n",
      "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.333]        \n",
      "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 14.80it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.333]\n",
      "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 13.17it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.997, valid_loss=0.333]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 20.98it/s]\u001b[A\n",
      "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.332]        \n",
      "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.332]        \n",
      "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.332]        \n",
      "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.332]        \n",
      "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.332]        \n",
      "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.332]        \n",
      "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.332]        \n",
      "Epoch 606: 100%|██████████| 1/1 [00:00<00:00, 12.36it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.332]\n",
      "Epoch 606: 100%|██████████| 1/1 [00:00<00:00, 12.28it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.332]\n",
      "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.332]        \n",
      "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.332]        \n",
      "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.332]        \n",
      "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.332]        \n",
      "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.332]        \n",
      "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.332]        \n",
      "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.332]        \n",
      "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.332]        \n",
      "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=0.332]        \n",
      "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.332]        \n",
      "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.990, train_loss_epoch=0.990, valid_loss=0.332]        \n",
      "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.991, valid_loss=0.332]        \n",
      "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.990, train_loss_epoch=0.990, valid_loss=0.332]        \n",
      "Epoch 622:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.990, train_loss_epoch=0.990, valid_loss=0.332]        \n",
      "Epoch 623: 100%|██████████| 1/1 [00:00<00:00, 14.76it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.332]\n",
      "Epoch 623: 100%|██████████| 1/1 [00:00<00:00, 13.09it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.332]\n",
      "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.332]        \n",
      "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.332]        \n",
      "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.332]        \n",
      "Epoch 628:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.332]        \n",
      "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.332]        \n",
      "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.332]        \n",
      "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.332]        \n",
      "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.332]        \n",
      "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.332]        \n",
      "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.332]        \n",
      "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.332]        \n",
      "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.332]        \n",
      "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.332]        \n",
      "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.332]        \n",
      "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.332]        \n",
      "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.332]        \n",
      "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.332]        \n",
      "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.332]        \n",
      "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.332]        \n",
      "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.332]        \n",
      "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.332]        \n",
      "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.332]        \n",
      "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.332]        \n",
      "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.332]        \n",
      "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.332]        \n",
      "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.332]        \n",
      "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.332]        \n",
      "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.332]        \n",
      "Epoch 657: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.332]\n",
      "Epoch 658: 100%|██████████| 1/1 [00:00<00:00, 12.37it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.332]\n",
      "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.332]        \n",
      "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.332]        \n",
      "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.332]        \n",
      "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.332]        \n",
      "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.332]        \n",
      "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.332]        \n",
      "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.332]        \n",
      "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.332]        \n",
      "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.332]        \n",
      "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.332]        \n",
      "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.332]        \n",
      "Epoch 671: 100%|██████████| 1/1 [00:00<00:00, 13.93it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.332]\n",
      "Epoch 671: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.997, valid_loss=0.332]\n",
      "Epoch 671: 100%|██████████| 1/1 [00:00<00:00, 12.36it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.332]\n",
      "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.332]        \n",
      "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.332]        \n",
      "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.332]        \n",
      "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.332]        \n",
      "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.332]        \n",
      "Epoch 679: 100%|██████████| 1/1 [00:00<00:00,  9.11it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.997, valid_loss=0.332]\n",
      "Epoch 679: 100%|██████████| 1/1 [00:00<00:00,  9.02it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.332]\n",
      "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.332]        \n",
      "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.332]        \n",
      "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.332]        \n",
      "Epoch 682: 100%|██████████| 1/1 [00:00<00:00,  9.36it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.332]\n",
      "Epoch 683: 100%|██████████| 1/1 [00:00<00:00, 10.34it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.993, valid_loss=0.332]\n",
      "Epoch 683: 100%|██████████| 1/1 [00:00<00:00, 10.26it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.332]\n",
      "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.332]        \n",
      "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.332]        \n",
      "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.332]        \n",
      "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.332]        \n",
      "Epoch 687: 100%|██████████| 1/1 [00:00<00:00,  7.88it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.332]\n",
      "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.332]        \n",
      "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.332]        \n",
      "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.332]        \n",
      "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.332]        \n",
      "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.332]        \n",
      "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.332]        \n",
      "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.332]        \n",
      "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.332]        \n",
      "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.332]        \n",
      "Epoch 697: 100%|██████████| 1/1 [00:00<00:00, 11.70it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.332]\n",
      "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=0.332]        \n",
      "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.992, valid_loss=0.332]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=7943)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 20.63it/s]\u001b[A\n",
      "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.325]        \n",
      "Epoch 701: 100%|██████████| 1/1 [00:00<00:00, 12.39it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.325]\n",
      "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.325]        \n",
      "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.325]        \n",
      "Epoch 703: 100%|██████████| 1/1 [00:00<00:00, 13.18it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.991, valid_loss=0.325]\n",
      "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.325]        \n",
      "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.325]        \n",
      "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.325]        \n",
      "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.325]        \n",
      "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.325]        \n",
      "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.325]        \n",
      "Epoch 711: 100%|██████████| 1/1 [00:00<00:00,  9.38it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.325]\n",
      "Epoch 711: 100%|██████████| 1/1 [00:00<00:00,  8.67it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.325]\n",
      "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.325]        \n",
      "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.325]        \n",
      "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=0.325]        \n",
      "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.991, valid_loss=0.325]        \n",
      "Epoch 716: 100%|██████████| 1/1 [00:00<00:00, 12.69it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.325]\n",
      "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.325]        \n",
      "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.325]\n",
      "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.325]        \n",
      "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.325]        \n",
      "Epoch 721: 100%|██████████| 1/1 [00:00<00:00, 12.72it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.995, valid_loss=0.325]\n",
      "Epoch 721: 100%|██████████| 1/1 [00:00<00:00, 12.60it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.325]\n",
      "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.325]        \n",
      "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.325]        \n",
      "Epoch 724:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.325]        \n",
      "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.325]        \n",
      "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.325]        \n",
      "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=0.325]        \n",
      "Epoch 727: 100%|██████████| 1/1 [00:00<00:00, 13.84it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=0.325]\n",
      "Epoch 728: 100%|██████████| 1/1 [00:00<00:00, 11.02it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=0.325]\n",
      "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.325]        \n",
      "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.325]        \n",
      "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.325]        \n",
      "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.325]        \n",
      "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=0.325]        \n",
      "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.325]        \n",
      "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.325]        \n",
      "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.325]        \n",
      "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.325]        \n",
      "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.990, train_loss_epoch=0.990, valid_loss=0.325]        \n",
      "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.325]        \n",
      "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.325]        \n",
      "Epoch 742: 100%|██████████| 1/1 [00:00<00:00, 11.61it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.325]\n",
      "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.325]        \n",
      "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.325]        \n",
      "Epoch 744: 100%|██████████| 1/1 [00:00<00:00,  9.37it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.325]\n",
      "Epoch 744: 100%|██████████| 1/1 [00:00<00:00,  8.65it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.325]\n",
      "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.325]        \n",
      "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.325]        \n",
      "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.325]        \n",
      "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.325]        \n",
      "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.325]        \n",
      "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.325]        \n",
      "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.325]        \n",
      "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.325]        \n",
      "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.325]        \n",
      "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.325]        \n",
      "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.325]        \n",
      "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.325]        \n",
      "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.325]        \n",
      "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.325]        \n",
      "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=0.325]        \n",
      "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.325]        \n",
      "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.325]        \n",
      "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=0.325]        \n",
      "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.325]        \n",
      "Epoch 766:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.325]        \n",
      "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=0.325]        \n",
      "Epoch 768: 100%|██████████| 1/1 [00:00<00:00, 12.48it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.325]\n",
      "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.325]        \n",
      "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.325]        \n",
      "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.325]        \n",
      "Epoch 773:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.325]        \n",
      "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.325]        \n",
      "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.325]        \n",
      "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.990, train_loss_epoch=0.990, valid_loss=0.325]        \n",
      "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.325]        \n",
      "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.325]        \n",
      "Epoch 779:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.325]        \n",
      "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.325]        \n",
      "Epoch 781:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.325]        \n",
      "Epoch 781: 100%|██████████| 1/1 [00:00<00:00, 12.39it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.325]\n",
      "Epoch 781: 100%|██████████| 1/1 [00:00<00:00, 12.27it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.325]\n",
      "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.325]        \n",
      "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.991, valid_loss=0.325]        \n",
      "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.325]        \n",
      "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.325]        \n",
      "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.325]        \n",
      "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.325]        \n",
      "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.325]        \n",
      "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.325]        \n",
      "Epoch 789: 100%|██████████| 1/1 [00:00<00:00,  7.33it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.325]\n",
      "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.325]        \n",
      "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.325]        \n",
      "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.325]        \n",
      "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.325]        \n",
      "Epoch 794:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.325]        \n",
      "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.325]        \n",
      "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.325]        \n",
      "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.325]        \n",
      "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.325]        \n",
      "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.325]        \n",
      "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 13.00it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.325]\n",
      "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 11.74it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.995, valid_loss=0.325]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 20.80it/s]\u001b[A\n",
      "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.321]        \n",
      "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.321]        \n",
      "Epoch 803:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.321]        \n",
      "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.321]        \n",
      "Epoch 805:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.321]        \n",
      "Epoch 806: 100%|██████████| 1/1 [00:00<00:00, 13.67it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.321]\n",
      "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.321]        \n",
      "Epoch 808: 100%|██████████| 1/1 [00:00<00:00, 14.68it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.321]\n",
      "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.991, valid_loss=0.321]        \n",
      "Epoch 811:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=0.321]        \n",
      "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.321]        \n",
      "Epoch 812: 100%|██████████| 1/1 [00:00<00:00,  7.90it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=0.999, valid_loss=0.321]\n",
      "Epoch 812: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.321]\n",
      "Epoch 813:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.321]        \n",
      "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.321]        \n",
      "Epoch 814: 100%|██████████| 1/1 [00:00<00:00,  9.25it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.321]\n",
      "Epoch 815:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.321]        \n",
      "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.321]        \n",
      "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.321]        \n",
      "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.321]        \n",
      "Epoch 819:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.321]        \n",
      "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.321]        \n",
      "Epoch 821: 100%|██████████| 1/1 [00:00<00:00, 13.05it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.321]\n",
      "Epoch 821: 100%|██████████| 1/1 [00:00<00:00, 11.00it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=0.321]\n",
      "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=0.321]        \n",
      "Epoch 823:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.321]        \n",
      "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.321]        \n",
      "Epoch 825:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.321]        \n",
      "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.321]        \n",
      "Epoch 827:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.321]        \n",
      "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.321]        \n",
      "Epoch 829:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.321]        \n",
      "Epoch 831:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.321]        \n",
      "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.321]        \n",
      "Epoch 833:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=0.321]        \n",
      "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.321]        \n",
      "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.321]        \n",
      "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=0.321]        \n",
      "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.321]        \n",
      "Epoch 838:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=0.321]        \n",
      "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.321]        \n",
      "Epoch 840:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=0.321]        \n",
      "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.321]        \n",
      "Epoch 842:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.991, valid_loss=0.321]        \n",
      "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.321]        \n",
      "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.321]        \n",
      "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.321]        \n",
      "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.321]        \n",
      "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.321]        \n",
      "Epoch 848:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.321]        \n",
      "Epoch 849:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=0.321]        \n",
      "Epoch 850:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.321]        \n",
      "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.321]        \n",
      "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.321]        \n",
      "Epoch 853: 100%|██████████| 1/1 [00:00<00:00, 12.92it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.321]\n",
      "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.321]        \n",
      "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.321]        \n",
      "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.321]        \n",
      "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.321]        \n",
      "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.321]        \n",
      "Epoch 860:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.321]        \n",
      "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.321]        \n",
      "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.321]        \n",
      "Epoch 863: 100%|██████████| 1/1 [00:00<00:00, 12.96it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.995, valid_loss=0.321]\n",
      "Epoch 863: 100%|██████████| 1/1 [00:00<00:00, 12.86it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.321]\n",
      "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.321]        \n",
      "Epoch 865:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.321]        \n",
      "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.321]        \n",
      "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.321]        \n",
      "Epoch 868:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.321]        \n",
      "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.321]        \n",
      "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.321]        \n",
      "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.321]        \n",
      "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.321]        \n",
      "Epoch 873: 100%|██████████| 1/1 [00:00<00:00, 12.97it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.321]\n",
      "Epoch 874:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.321]        \n",
      "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.321]        \n",
      "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.321]        \n",
      "Epoch 877:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.321]        \n",
      "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.991, valid_loss=0.321]        \n",
      "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.321]        \n",
      "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.321]        \n",
      "Epoch 881:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.321]        \n",
      "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=0.321]        \n",
      "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.321]        \n",
      "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.321]        \n",
      "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.321]        \n",
      "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.321]        \n",
      "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.321]        \n",
      "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.321]        \n",
      "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.321]        \n",
      "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=0.321]        \n",
      "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.321]        \n",
      "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.321]        \n",
      "Epoch 894: 100%|██████████| 1/1 [00:00<00:00,  8.51it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.321]\n",
      "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.321]        \n",
      "Epoch 896: 100%|██████████| 1/1 [00:00<00:00, 14.58it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.321]\n",
      "Epoch 896: 100%|██████████| 1/1 [00:00<00:00, 12.93it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.321]\n",
      "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.321]        \n",
      "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.321]        \n",
      "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.321]        \n",
      "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 10.04it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.997, valid_loss=0.321]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=7943)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 12.38it/s]\u001b[A\n",
      "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.322]        \n",
      "Epoch 901:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.322]        \n",
      "Epoch 902:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.322]        \n",
      "Epoch 903:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.322]        \n",
      "Epoch 905:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.322]        \n",
      "Epoch 905: 100%|██████████| 1/1 [00:00<00:00,  9.97it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.322]\n",
      "Epoch 907:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.322]        \n",
      "Epoch 908:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.322]        \n",
      "Epoch 909:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.322]        \n",
      "Epoch 910:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.322]        \n",
      "Epoch 912:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=0.322]        \n",
      "Epoch 912: 100%|██████████| 1/1 [00:00<00:00,  9.36it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=0.322]\n",
      "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.322]        \n",
      "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=0.322]        \n",
      "Epoch 915: 100%|██████████| 1/1 [00:00<00:00, 13.28it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.992, valid_loss=0.322]\n",
      "Epoch 915: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.322]\n",
      "Epoch 916:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.322]        \n",
      "Epoch 916: 100%|██████████| 1/1 [00:00<00:00,  9.65it/s, v_num=0, train_loss_step=0.990, train_loss_epoch=0.990, valid_loss=0.322]\n",
      "Epoch 917:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.990, train_loss_epoch=0.990, valid_loss=0.322]        \n",
      "Epoch 918:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.322]        \n",
      "Epoch 919:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.991, valid_loss=0.322]        \n",
      "Epoch 920:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.322]        \n",
      "Epoch 921:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.322]        \n",
      "Epoch 921: 100%|██████████| 1/1 [00:00<00:00, 12.79it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.322]\n",
      "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.322]        \n",
      "Epoch 923:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=0.322]        \n",
      "Epoch 924:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.991, valid_loss=0.322]        \n",
      "Epoch 925:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.322]        \n",
      "Epoch 927:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.322]        \n",
      "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.322]        \n",
      "Epoch 928: 100%|██████████| 1/1 [00:00<00:00,  8.10it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.993, valid_loss=0.322]\n",
      "Epoch 929:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.991, valid_loss=0.322]        \n",
      "Epoch 931:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.986, train_loss_epoch=0.986, valid_loss=0.322]        \n",
      "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.985, train_loss_epoch=0.985, valid_loss=0.322]        \n",
      "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984, valid_loss=0.322]        \n",
      "Epoch 934: 100%|██████████| 1/1 [00:00<00:00, 14.17it/s, v_num=0, train_loss_step=0.977, train_loss_epoch=0.977, valid_loss=0.322]\n",
      "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.322]        \n",
      "Epoch 937:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.322]        \n",
      "Epoch 938:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.322]        \n",
      "Epoch 939:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.322]        \n",
      "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.322]        \n",
      "Epoch 941: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=0.322]\n",
      "Epoch 941: 100%|██████████| 1/1 [00:00<00:00, 11.65it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.322]\n",
      "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.322]        \n",
      "Epoch 943:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.322]        \n",
      "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.322]        \n",
      "Epoch 945:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.322]        \n",
      "Epoch 946: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.322]\n",
      "Epoch 946: 100%|██████████| 1/1 [00:00<00:00, 13.06it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.322]\n",
      "Epoch 948:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.322]        \n",
      "Epoch 949:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.322]        \n",
      "Epoch 950:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.322]        \n",
      "Epoch 951: 100%|██████████| 1/1 [00:00<00:00, 14.52it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.322]\n",
      "Epoch 951: 100%|██████████| 1/1 [00:00<00:00, 13.08it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=0.995, valid_loss=0.322]\n",
      "Epoch 952:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.322]        \n",
      "Epoch 953:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.322]        \n",
      "Epoch 954:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.322]        \n",
      "Epoch 955:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.322]        \n",
      "Epoch 957:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.322]        \n",
      "Epoch 958:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.322]        \n",
      "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.322]        \n",
      "Epoch 960:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.322]        \n",
      "Epoch 961:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.322]        \n",
      "Epoch 962: 100%|██████████| 1/1 [00:00<00:00, 13.12it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.322]\n",
      "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.322]        \n",
      "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.322]        \n",
      "Epoch 965:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.322]        \n",
      "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.322]        \n",
      "Epoch 968:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.322]        \n",
      "Epoch 969:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.322]        \n",
      "Epoch 970:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.322]        \n",
      "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.322]        \n",
      "Epoch 972:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.322]        \n",
      "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.322]        \n",
      "Epoch 974:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.322]        \n",
      "Epoch 976:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.322]        \n",
      "Epoch 976: 100%|██████████| 1/1 [00:00<00:00, 10.84it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.322]\n",
      "Epoch 978:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.322]        \n",
      "Epoch 979:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.322]        \n",
      "Epoch 980:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.322]        \n",
      "Epoch 981:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.322]        \n",
      "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.322]        \n",
      "Epoch 983:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.322]        \n",
      "Epoch 984: 100%|██████████| 1/1 [00:00<00:00, 13.08it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.322]\n",
      "Epoch 984: 100%|██████████| 1/1 [00:00<00:00, 12.93it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.322]\n",
      "Epoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.322]        \n",
      "Epoch 986:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.322]        \n",
      "Epoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.322]        \n",
      "Epoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.322]        \n",
      "Epoch 989: 100%|██████████| 1/1 [00:00<00:00, 11.98it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.322]\n",
      "Epoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.322]        \n",
      "Epoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.322]        \n",
      "Epoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.322]        \n",
      "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.322]        \n",
      "Epoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.322]        \n",
      "Epoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.322]        \n",
      "Epoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.322]        \n",
      "Epoch 996: 100%|██████████| 1/1 [00:00<00:00, 12.72it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.322]\n",
      "Epoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.322]        \n",
      "Epoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.322]        \n",
      "Epoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.322]        \n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 11.21it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.322]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=7943)\u001b[0m `Trainer.fit` stopped: `max_steps=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=7943)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 21.18it/s]\u001b[A\n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00,  6.80it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.333]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=8340)\u001b[0m /home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=8340)\u001b[0m Seed set to 9\n",
      "\u001b[36m(_train_tune pid=8340)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=8340)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=8340)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=8340)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(_train_tune pid=8340)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_train_tune pid=8340)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=8340)\u001b[0m   | Name            | Type          | Params | Mode \n",
      "\u001b[36m(_train_tune pid=8340)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=8340)\u001b[0m 0 | loss            | WMAPE         | 0      | train\n",
      "\u001b[36m(_train_tune pid=8340)\u001b[0m 1 | padder          | ConstantPad1d | 0      | train\n",
      "\u001b[36m(_train_tune pid=8340)\u001b[0m 2 | scaler          | TemporalNorm  | 0      | train\n",
      "\u001b[36m(_train_tune pid=8340)\u001b[0m 3 | hist_encoder    | LSTM          | 363 K  | train\n",
      "\u001b[36m(_train_tune pid=8340)\u001b[0m 4 | context_adapter | Linear        | 231 K  | train\n",
      "\u001b[36m(_train_tune pid=8340)\u001b[0m 5 | mlp_decoder     | MLP           | 3.1 K  | train\n",
      "\u001b[36m(_train_tune pid=8340)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=8340)\u001b[0m 598 K     Trainable params\n",
      "\u001b[36m(_train_tune pid=8340)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=8340)\u001b[0m 598 K     Total params\n",
      "\u001b[36m(_train_tune pid=8340)\u001b[0m 2.394     Total estimated model params size (MB)\n",
      "\u001b[36m(_train_tune pid=8340)\u001b[0m 11        Modules in train mode\n",
      "\u001b[36m(_train_tune pid=8340)\u001b[0m 0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Sanity Checking DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  2.86it/s]\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.100, train_loss_epoch=5.100]        \n",
      "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.170, train_loss_epoch=5.170]        \n",
      "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140]        \n",
      "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.180, train_loss_epoch=3.180]        \n",
      "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.40, train_loss_epoch=11.40]        \n",
      "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.610, train_loss_epoch=2.610]        \n",
      "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350]        \n",
      "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540]        \n",
      "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.070, train_loss_epoch=3.070]       \n",
      "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050]        \n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00,  8.92it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050]\n",
      "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270]        \n",
      "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070]        \n",
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080]        \n",
      "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440]        \n",
      "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.100, train_loss_epoch=2.100]        \n",
      "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360]        \n",
      "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230]        \n",
      "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330]        \n",
      "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060]        \n",
      "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180]        \n",
      "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]        \n",
      "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050]        \n",
      "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]        \n",
      "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]        \n",
      "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]        \n",
      "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050]        \n",
      "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030]        \n",
      "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060]        \n",
      "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]        \n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]\n",
      "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]        \n",
      "Epoch 31: 100%|██████████| 1/1 [00:00<00:00,  9.83it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]\n",
      "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]        \n",
      "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]        \n",
      "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]        \n",
      "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]        \n",
      "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]        \n",
      "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]        \n",
      "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]        \n",
      "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00,  9.52it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]\n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00,  8.84it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]\n",
      "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 40: 100%|██████████| 1/1 [00:00<00:00,  9.91it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]\n",
      "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]        \n",
      "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00,  8.69it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]\n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00,  8.63it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]\n",
      "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00,  8.10it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]\n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00,  7.19it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]\n",
      "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999]        \n",
      "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999]        \n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999]\n",
      "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999]        \n",
      "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999]        \n",
      "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999]        \n",
      "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999]        \n",
      "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999]        \n",
      "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999]        \n",
      "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999]        \n",
      "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999]        \n",
      "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999]        \n",
      "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999]        \n",
      "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999]        \n",
      "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999]        \n",
      "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998]        \n",
      "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998]        \n",
      "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998]        \n",
      "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998]        \n",
      "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998]        \n",
      "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998]        \n",
      "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998]        \n",
      "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998]        \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  6.92it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=8340)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 18.73it/s]\u001b[A\n",
      "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.331]       \n",
      "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.331]        \n",
      "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.331]        \n",
      "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.331]        \n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00,  8.57it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.331]\n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00,  7.80it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.331]\n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.331]\n",
      "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.331]        \n",
      "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.331]        \n",
      "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.331]        \n",
      "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.331]        \n",
      "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.331]        \n",
      "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.331]        \n",
      "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.331]        \n",
      "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996, valid_loss=0.331]        \n",
      "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.331]        \n",
      "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.331]        \n",
      "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.331]        \n",
      "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.331]        \n",
      "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.331]        \n",
      "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.331]        \n",
      "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.331]        \n",
      "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.331]        \n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.331]\n",
      "Epoch 120: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.331]\n",
      "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.331]        \n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00,  9.09it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.331]\n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.331]\n",
      "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993, valid_loss=0.331]        \n",
      "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=0.331]        \n",
      "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=0.331]        \n",
      "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.991, valid_loss=0.331]        \n",
      "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.991, valid_loss=0.331]        \n",
      "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.990, train_loss_epoch=0.990, valid_loss=0.331]        \n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s, v_num=0, train_loss_step=0.990, train_loss_epoch=0.990, valid_loss=0.331]\n",
      "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.990, train_loss_epoch=0.990, valid_loss=0.331]        \n",
      "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.989, train_loss_epoch=0.989, valid_loss=0.331]        \n",
      "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.989, train_loss_epoch=0.989, valid_loss=0.331]        \n",
      "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988, valid_loss=0.331]        \n",
      "Epoch 131: 100%|██████████| 1/1 [00:00<00:00,  8.91it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988, valid_loss=0.331]\n",
      "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.987, train_loss_epoch=0.987, valid_loss=0.331]        \n",
      "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.987, train_loss_epoch=0.987, valid_loss=0.331]        \n",
      "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.986, train_loss_epoch=0.986, valid_loss=0.331]        \n",
      "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.985, train_loss_epoch=0.985, valid_loss=0.331]        \n",
      "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984, valid_loss=0.331]        \n",
      "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.982, train_loss_epoch=0.982, valid_loss=0.331]        \n",
      "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.981, train_loss_epoch=0.981, valid_loss=0.331]        \n",
      "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.980, train_loss_epoch=0.980, valid_loss=0.331]        \n",
      "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.979, train_loss_epoch=0.979, valid_loss=0.331]        \n",
      "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.978, train_loss_epoch=0.978, valid_loss=0.331]        \n",
      "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.976, train_loss_epoch=0.976, valid_loss=0.331]        \n",
      "Epoch 142: 100%|██████████| 1/1 [00:00<00:00,  9.88it/s, v_num=0, train_loss_step=0.976, train_loss_epoch=0.976, valid_loss=0.331]\n",
      "Epoch 142: 100%|██████████| 1/1 [00:00<00:00,  9.07it/s, v_num=0, train_loss_step=0.975, train_loss_epoch=0.975, valid_loss=0.331]\n",
      "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.975, train_loss_epoch=0.975, valid_loss=0.331]        \n",
      "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.972, train_loss_epoch=0.972, valid_loss=0.331]        \n",
      "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.971, train_loss_epoch=0.971, valid_loss=0.331]        \n",
      "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.968, train_loss_epoch=0.968, valid_loss=0.331]        \n",
      "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.967, train_loss_epoch=0.967, valid_loss=0.331]        \n",
      "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.964, train_loss_epoch=0.964, valid_loss=0.331]        \n",
      "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.960, train_loss_epoch=0.960, valid_loss=0.331]        \n",
      "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.957, train_loss_epoch=0.957, valid_loss=0.331]        \n",
      "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.953, train_loss_epoch=0.953, valid_loss=0.331]        \n",
      "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.954, train_loss_epoch=0.954, valid_loss=0.331]        \n",
      "Epoch 152: 100%|██████████| 1/1 [00:00<00:00,  9.06it/s, v_num=0, train_loss_step=0.962, train_loss_epoch=0.954, valid_loss=0.331]\n",
      "Epoch 152: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s, v_num=0, train_loss_step=0.962, train_loss_epoch=0.962, valid_loss=0.331]\n",
      "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.962, train_loss_epoch=0.962, valid_loss=0.331]        \n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00,  9.75it/s, v_num=0, train_loss_step=0.962, train_loss_epoch=0.962, valid_loss=0.331]\n",
      "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.951, train_loss_epoch=0.951, valid_loss=0.331]        \n",
      "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.944, train_loss_epoch=0.944, valid_loss=0.331]        \n",
      "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.944, train_loss_epoch=0.944, valid_loss=0.331]        \n",
      "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.958, train_loss_epoch=0.958, valid_loss=0.331]        \n",
      "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.978, train_loss_epoch=0.978, valid_loss=0.331]        \n",
      "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.945, valid_loss=0.331]        \n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00,  9.66it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.945, valid_loss=0.331]\n",
      "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.945, valid_loss=0.331]        \n",
      "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.937, train_loss_epoch=0.937, valid_loss=0.331]        \n",
      "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.937, train_loss_epoch=0.937, valid_loss=0.331]        \n",
      "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.930, train_loss_epoch=0.930, valid_loss=0.331]        \n",
      "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.930, train_loss_epoch=0.930, valid_loss=0.331]        \n",
      "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.925, train_loss_epoch=0.925, valid_loss=0.331]        \n",
      "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.918, train_loss_epoch=0.918, valid_loss=0.331]        \n",
      "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.908, train_loss_epoch=0.908, valid_loss=0.331]        \n",
      "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.905, train_loss_epoch=0.905, valid_loss=0.331]        \n",
      "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.901, train_loss_epoch=0.901, valid_loss=0.331]        \n",
      "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.896, train_loss_epoch=0.896, valid_loss=0.331]        \n",
      "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.900, train_loss_epoch=0.900, valid_loss=0.331]        \n",
      "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=0.914, valid_loss=0.331]        \n",
      "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.917, train_loss_epoch=0.917, valid_loss=0.331]        \n",
      "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.899, train_loss_epoch=0.899, valid_loss=0.331]        \n",
      "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.868, train_loss_epoch=0.868, valid_loss=0.331]        \n",
      "Epoch 175: 100%|██████████| 1/1 [00:00<00:00,  8.69it/s, v_num=0, train_loss_step=0.871, train_loss_epoch=0.871, valid_loss=0.331]\n",
      "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.871, train_loss_epoch=0.871, valid_loss=0.331]        \n",
      "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.871, train_loss_epoch=0.871, valid_loss=0.331]        \n",
      "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.905, train_loss_epoch=0.905, valid_loss=0.331]        \n",
      "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.331]        \n",
      "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.961, train_loss_epoch=0.961, valid_loss=0.331]        \n",
      "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.882, train_loss_epoch=0.882, valid_loss=0.331]        \n",
      "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.937, train_loss_epoch=0.937, valid_loss=0.331]        \n",
      "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.881, train_loss_epoch=0.881, valid_loss=0.331]        \n",
      "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.893, train_loss_epoch=0.893, valid_loss=0.331]        \n",
      "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.881, train_loss_epoch=0.881, valid_loss=0.331]        \n",
      "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.878, train_loss_epoch=0.878, valid_loss=0.331]        \n",
      "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.863, train_loss_epoch=0.863, valid_loss=0.331]        \n",
      "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.859, train_loss_epoch=0.859, valid_loss=0.331]        \n",
      "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.844, train_loss_epoch=0.844, valid_loss=0.331]        \n",
      "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.826, train_loss_epoch=0.826, valid_loss=0.331]        \n",
      "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.825, train_loss_epoch=0.825, valid_loss=0.331]        \n",
      "Epoch 191: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s, v_num=0, train_loss_step=0.823, train_loss_epoch=0.825, valid_loss=0.331]\n",
      "Epoch 191: 100%|██████████| 1/1 [00:00<00:00,  6.06it/s, v_num=0, train_loss_step=0.823, train_loss_epoch=0.823, valid_loss=0.331]\n",
      "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.823, train_loss_epoch=0.823, valid_loss=0.331]        \n",
      "Epoch 192: 100%|██████████| 1/1 [00:00<00:00,  9.72it/s, v_num=0, train_loss_step=0.823, train_loss_epoch=0.823, valid_loss=0.331]\n",
      "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.834, train_loss_epoch=0.834, valid_loss=0.331]        \n",
      "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.847, train_loss_epoch=0.847, valid_loss=0.331]        \n",
      "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.912, train_loss_epoch=0.912, valid_loss=0.331]        \n",
      "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.873, train_loss_epoch=0.873, valid_loss=0.331]        \n",
      "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.812, train_loss_epoch=0.812, valid_loss=0.331]        \n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00,  9.77it/s, v_num=0, train_loss_step=0.812, train_loss_epoch=0.812, valid_loss=0.331]\n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00,  9.06it/s, v_num=0, train_loss_step=0.804, train_loss_epoch=0.812, valid_loss=0.331]\n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00,  8.97it/s, v_num=0, train_loss_step=0.804, train_loss_epoch=0.804, valid_loss=0.331]\n",
      "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.804, train_loss_epoch=0.804, valid_loss=0.331]        \n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00,  9.66it/s, v_num=0, train_loss_step=0.804, train_loss_epoch=0.804, valid_loss=0.331]\n",
      "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.850, train_loss_epoch=0.850, valid_loss=0.331]        \n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  9.19it/s, v_num=0, train_loss_step=0.848, train_loss_epoch=0.850, valid_loss=0.331]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 15.88it/s]\u001b[A\n",
      "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.848, train_loss_epoch=0.848, valid_loss=0.246]        \n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00,  8.87it/s, v_num=0, train_loss_step=0.848, train_loss_epoch=0.848, valid_loss=0.246]\n",
      "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.803, train_loss_epoch=0.803, valid_loss=0.246]        \n",
      "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.809, train_loss_epoch=0.809, valid_loss=0.246]        \n",
      "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.820, train_loss_epoch=0.820, valid_loss=0.246]        \n",
      "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.790, train_loss_epoch=0.790, valid_loss=0.246]        \n",
      "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.785, train_loss_epoch=0.785, valid_loss=0.246]        \n",
      "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.783, train_loss_epoch=0.783, valid_loss=0.246]        \n",
      "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.803, train_loss_epoch=0.803, valid_loss=0.246]        \n",
      "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.788, train_loss_epoch=0.788, valid_loss=0.246]        \n",
      "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.736, train_loss_epoch=0.736, valid_loss=0.246]        \n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00,  9.07it/s, v_num=0, train_loss_step=0.736, train_loss_epoch=0.736, valid_loss=0.246]\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00,  8.29it/s, v_num=0, train_loss_step=0.747, train_loss_epoch=0.736, valid_loss=0.246]\n",
      "Epoch 209: 100%|██████████| 1/1 [00:00<00:00,  8.21it/s, v_num=0, train_loss_step=0.747, train_loss_epoch=0.747, valid_loss=0.246]\n",
      "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.747, train_loss_epoch=0.747, valid_loss=0.246]        \n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00,  9.87it/s, v_num=0, train_loss_step=0.747, train_loss_epoch=0.747, valid_loss=0.246]\n",
      "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.755, train_loss_epoch=0.755, valid_loss=0.246]        \n",
      "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.789, train_loss_epoch=0.789, valid_loss=0.246]        \n",
      "Epoch 212: 100%|██████████| 1/1 [00:00<00:00,  9.04it/s, v_num=0, train_loss_step=0.833, train_loss_epoch=0.789, valid_loss=0.246]\n",
      "Epoch 212: 100%|██████████| 1/1 [00:00<00:00,  8.98it/s, v_num=0, train_loss_step=0.833, train_loss_epoch=0.833, valid_loss=0.246]\n",
      "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.833, train_loss_epoch=0.833, valid_loss=0.246]        \n",
      "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.816, train_loss_epoch=0.816, valid_loss=0.246]        \n",
      "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.770, train_loss_epoch=0.770, valid_loss=0.246]        \n",
      "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.731, train_loss_epoch=0.731, valid_loss=0.246]        \n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00,  7.59it/s, v_num=0, train_loss_step=0.731, train_loss_epoch=0.731, valid_loss=0.246]\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00,  7.23it/s, v_num=0, train_loss_step=0.781, train_loss_epoch=0.731, valid_loss=0.246]\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=0, train_loss_step=0.781, train_loss_epoch=0.781, valid_loss=0.246]\n",
      "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.781, train_loss_epoch=0.781, valid_loss=0.246]        \n",
      "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.753, train_loss_epoch=0.753, valid_loss=0.246]        \n",
      "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.723, train_loss_epoch=0.723, valid_loss=0.246]        \n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00,  9.02it/s, v_num=0, train_loss_step=0.714, train_loss_epoch=0.743, valid_loss=0.246]\n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00,  8.95it/s, v_num=0, train_loss_step=0.714, train_loss_epoch=0.714, valid_loss=0.246]\n",
      "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.714, train_loss_epoch=0.714, valid_loss=0.246]        \n",
      "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.712, train_loss_epoch=0.712, valid_loss=0.246]        \n",
      "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.694, train_loss_epoch=0.694, valid_loss=0.246]        \n",
      "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.687, train_loss_epoch=0.687, valid_loss=0.246]        \n",
      "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.682, train_loss_epoch=0.682, valid_loss=0.246]        \n",
      "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.672, train_loss_epoch=0.672, valid_loss=0.246]        \n",
      "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.673, train_loss_epoch=0.673, valid_loss=0.246]        \n",
      "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.683, train_loss_epoch=0.683, valid_loss=0.246]        \n",
      "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.661, train_loss_epoch=0.661, valid_loss=0.246]        \n",
      "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.662, train_loss_epoch=0.662, valid_loss=0.246]        \n",
      "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.683, train_loss_epoch=0.683, valid_loss=0.246]        \n",
      "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.744, train_loss_epoch=0.744, valid_loss=0.246]        \n",
      "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.769, train_loss_epoch=0.769, valid_loss=0.246]        \n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00,  8.21it/s, v_num=0, train_loss_step=0.769, train_loss_epoch=0.769, valid_loss=0.246]\n",
      "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.676, train_loss_epoch=0.676, valid_loss=0.246]        \n",
      "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.709, train_loss_epoch=0.709, valid_loss=0.246]        \n",
      "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.730, train_loss_epoch=0.730, valid_loss=0.246]        \n",
      "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.673, train_loss_epoch=0.673, valid_loss=0.246]        \n",
      "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.699, train_loss_epoch=0.699, valid_loss=0.246]        \n",
      "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.692, train_loss_epoch=0.692, valid_loss=0.246]        \n",
      "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.667, train_loss_epoch=0.667, valid_loss=0.246]        \n",
      "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.650, train_loss_epoch=0.650, valid_loss=0.246]        \n",
      "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.653, train_loss_epoch=0.653, valid_loss=0.246]        \n",
      "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.627, train_loss_epoch=0.627, valid_loss=0.246]        \n",
      "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.627, train_loss_epoch=0.627, valid_loss=0.246]        \n",
      "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.617, train_loss_epoch=0.617, valid_loss=0.246]        \n",
      "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.614, train_loss_epoch=0.614, valid_loss=0.246]        \n",
      "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.616, train_loss_epoch=0.616, valid_loss=0.246]        \n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00,  9.75it/s, v_num=0, train_loss_step=0.616, train_loss_epoch=0.616, valid_loss=0.246]\n",
      "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.606, train_loss_epoch=0.606, valid_loss=0.246]        \n",
      "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.644, train_loss_epoch=0.644, valid_loss=0.246]        \n",
      "Epoch 249: 100%|██████████| 1/1 [00:00<00:00,  9.10it/s, v_num=0, train_loss_step=0.625, train_loss_epoch=0.644, valid_loss=0.246]\n",
      "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.625, train_loss_epoch=0.625, valid_loss=0.246]        \n",
      "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.614, train_loss_epoch=0.614, valid_loss=0.246]        \n",
      "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.621, train_loss_epoch=0.621, valid_loss=0.246]        \n",
      "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.634, train_loss_epoch=0.634, valid_loss=0.246]        \n",
      "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.655, train_loss_epoch=0.655, valid_loss=0.246]        \n",
      "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.616, train_loss_epoch=0.616, valid_loss=0.246]        \n",
      "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.613, train_loss_epoch=0.613, valid_loss=0.246]        \n",
      "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.633, train_loss_epoch=0.633, valid_loss=0.246]        \n",
      "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.610, train_loss_epoch=0.610, valid_loss=0.246]        \n",
      "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.604, train_loss_epoch=0.604, valid_loss=0.246]        \n",
      "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.616, train_loss_epoch=0.616, valid_loss=0.246]        \n",
      "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.597, train_loss_epoch=0.597, valid_loss=0.246]        \n",
      "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.609, train_loss_epoch=0.609, valid_loss=0.246]        \n",
      "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.598, train_loss_epoch=0.598, valid_loss=0.246]        \n",
      "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.587, train_loss_epoch=0.587, valid_loss=0.246]        \n",
      "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.595, train_loss_epoch=0.595, valid_loss=0.246]        \n",
      "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.596, train_loss_epoch=0.596, valid_loss=0.246]        \n",
      "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.580, train_loss_epoch=0.580, valid_loss=0.246]        \n",
      "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.580, train_loss_epoch=0.580, valid_loss=0.246]        \n",
      "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.592, train_loss_epoch=0.592, valid_loss=0.246]        \n",
      "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.579, train_loss_epoch=0.579, valid_loss=0.246]        \n",
      "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569, valid_loss=0.246]        \n",
      "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.580, train_loss_epoch=0.580, valid_loss=0.246]        \n",
      "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567, valid_loss=0.246]        \n",
      "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568, valid_loss=0.246]        \n",
      "Epoch 274: 100%|██████████| 1/1 [00:00<00:00,  9.33it/s, v_num=0, train_loss_step=0.635, train_loss_epoch=0.568, valid_loss=0.246]\n",
      "Epoch 274: 100%|██████████| 1/1 [00:00<00:00,  9.27it/s, v_num=0, train_loss_step=0.635, train_loss_epoch=0.635, valid_loss=0.246]\n",
      "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.635, train_loss_epoch=0.635, valid_loss=0.246]        \n",
      "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.606, train_loss_epoch=0.606, valid_loss=0.246]        \n",
      "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.632, train_loss_epoch=0.632, valid_loss=0.246]        \n",
      "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.602, train_loss_epoch=0.602, valid_loss=0.246]        \n",
      "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.601, train_loss_epoch=0.601, valid_loss=0.246]        \n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s, v_num=0, train_loss_step=0.601, train_loss_epoch=0.601, valid_loss=0.246]\n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00,  7.88it/s, v_num=0, train_loss_step=0.601, train_loss_epoch=0.601, valid_loss=0.246]\n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00,  7.81it/s, v_num=0, train_loss_step=0.601, train_loss_epoch=0.601, valid_loss=0.246]\n",
      "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.601, train_loss_epoch=0.601, valid_loss=0.246]        \n",
      "Epoch 280: 100%|██████████| 1/1 [00:00<00:00,  8.24it/s, v_num=0, train_loss_step=0.585, train_loss_epoch=0.601, valid_loss=0.246]\n",
      "Epoch 280: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s, v_num=0, train_loss_step=0.585, train_loss_epoch=0.585, valid_loss=0.246]\n",
      "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.585, train_loss_epoch=0.585, valid_loss=0.246]        \n",
      "Epoch 281: 100%|██████████| 1/1 [00:00<00:00,  9.67it/s, v_num=0, train_loss_step=0.585, train_loss_epoch=0.585, valid_loss=0.246]\n",
      "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.592, train_loss_epoch=0.592, valid_loss=0.246]        \n",
      "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.596, train_loss_epoch=0.596, valid_loss=0.246]        \n",
      "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574, valid_loss=0.246]        \n",
      "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571, valid_loss=0.246]        \n",
      "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.587, train_loss_epoch=0.587, valid_loss=0.246]        \n",
      "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574, valid_loss=0.246]        \n",
      "Epoch 287: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.574, valid_loss=0.246]\n",
      "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=0.246]        \n",
      "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=0.246]        \n",
      "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563, valid_loss=0.246]        \n",
      "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.246]        \n",
      "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.246]        \n",
      "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.246]        \n",
      "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.246]        \n",
      "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=0.246]        \n",
      "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.246]        \n",
      "Epoch 297: 100%|██████████| 1/1 [00:00<00:00,  9.52it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.246]\n",
      "Epoch 297: 100%|██████████| 1/1 [00:00<00:00,  8.78it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573, valid_loss=0.246]\n",
      "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573, valid_loss=0.246]        \n",
      "Epoch 298: 100%|██████████| 1/1 [00:00<00:00,  9.83it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573, valid_loss=0.246]\n",
      "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573, valid_loss=0.246]        \n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  8.14it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.573, valid_loss=0.246]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 18.31it/s]\u001b[A\n",
      "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0463]        \n",
      "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=0.0463]        \n",
      "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.0463]        \n",
      "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.0463]        \n",
      "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0463]        \n",
      "Epoch 304: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0463]\n",
      "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0463]        \n",
      "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=0.0463]        \n",
      "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.0463]        \n",
      "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0463]        \n",
      "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.0463]        \n",
      "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.0463]        \n",
      "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.0463]        \n",
      "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=0.0463]        \n",
      "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0463]        \n",
      "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.0463]        \n",
      "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0463]        \n",
      "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=0.0463]        \n",
      "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0463]        \n",
      "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0463]        \n",
      "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0463]        \n",
      "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0463]        \n",
      "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0463]        \n",
      "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0463]        \n",
      "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.0463]        \n",
      "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0463]        \n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00,  9.12it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.0463]\n",
      "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.0463]        \n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00,  9.84it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0463]\n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00,  9.02it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.0463]\n",
      "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.0463]        \n",
      "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0463]        \n",
      "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0463]        \n",
      "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.0463]        \n",
      "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0463]        \n",
      "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.0463]        \n",
      "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=0.0463]        \n",
      "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0463]        \n",
      "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0463]        \n",
      "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0463]        \n",
      "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0463]        \n",
      "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0463]        \n",
      "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0463]        \n",
      "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0463]        \n",
      "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0463]        \n",
      "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0463]        \n",
      "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0463]        \n",
      "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0463]        \n",
      "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0463]        \n",
      "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=0.0463]        \n",
      "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0463]        \n",
      "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0463]        \n",
      "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0463]        \n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00,  9.79it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0463]\n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00,  9.87it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0463]\n",
      "Epoch 350: 100%|██████████| 1/1 [00:00<00:00,  9.06it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0463]\n",
      "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0463]        \n",
      "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0463]        \n",
      "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=0.0463]        \n",
      "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=0.0463]        \n",
      "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0463]        \n",
      "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0463]        \n",
      "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0463]        \n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00,  6.30it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0463]\n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00,  6.01it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.508, valid_loss=0.0463]\n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00,  5.98it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0463]\n",
      "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0463]        \n",
      "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0463]        \n",
      "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0463]        \n",
      "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0463]        \n",
      "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0463]        \n",
      "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0463]        \n",
      "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0463]        \n",
      "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=0.0463]        \n",
      "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0463]        \n",
      "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.0463]        \n",
      "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0463]        \n",
      "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=0.0463]        \n",
      "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.584, train_loss_epoch=0.584, valid_loss=0.0463]        \n",
      "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0463]        \n",
      "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.0463]        \n",
      "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=0.0463]        \n",
      "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.0463]        \n",
      "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0463]        \n",
      "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.0463]        \n",
      "Epoch 376: 100%|██████████| 1/1 [00:00<00:00,  9.96it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.0463]\n",
      "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0463]        \n",
      "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.0463]        \n",
      "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0463]        \n",
      "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.0463]        \n",
      "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0463]        \n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00,  7.81it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0463]\n",
      "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0463]        \n",
      "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0463]        \n",
      "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0463]        \n",
      "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0463]        \n",
      "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0463]        \n",
      "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0463]        \n",
      "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0463]        \n",
      "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0463]        \n",
      "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0463]        \n",
      "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0463]        \n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00,  8.37it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0463]\n",
      "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0463]        \n",
      "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0463]        \n",
      "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0463]        \n",
      "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0463]        \n",
      "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0463]        \n",
      "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0463]        \n",
      "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0463]        \n",
      "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0463]        \n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  9.32it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0463]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 19.63it/s]\u001b[A\n",
      "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0482]        \n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00,  8.41it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0482]\n",
      "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0482]        \n",
      "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0482]        \n",
      "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0482]        \n",
      "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0482]        \n",
      "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0482]        \n",
      "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0482]        \n",
      "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0482]        \n",
      "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0482]        \n",
      "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0482]        \n",
      "Epoch 409: 100%|██████████| 1/1 [00:00<00:00, 10.02it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0482]\n",
      "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0482]        \n",
      "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0482]        \n",
      "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0482]        \n",
      "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0482]        \n",
      "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0482]        \n",
      "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0482]        \n",
      "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0482]        \n",
      "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0482]        \n",
      "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0482]        \n",
      "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0482]        \n",
      "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0482]        \n",
      "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0482]        \n",
      "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0482]        \n",
      "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0482]        \n",
      "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0482]        \n",
      "Epoch 424: 100%|██████████| 1/1 [00:00<00:00,  8.82it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0482]\n",
      "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0482]        \n",
      "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0482]        \n",
      "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0482]        \n",
      "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0482]        \n",
      "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0482]        \n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00,  9.66it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0482]\n",
      "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0482]        \n",
      "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0482]        \n",
      "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0482]        \n",
      "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0482]        \n",
      "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0482]        \n",
      "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0482]        \n",
      "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0482]        \n",
      "Epoch 436: 100%|██████████| 1/1 [00:00<00:00,  9.76it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0482]\n",
      "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0482]        \n",
      "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0482]        \n",
      "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0482]        \n",
      "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0482]        \n",
      "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0482]        \n",
      "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0482]        \n",
      "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0482]        \n",
      "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0482]        \n",
      "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0482]        \n",
      "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0482]        \n",
      "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0482]        \n",
      "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0482]        \n",
      "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0482]        \n",
      "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0482]        \n",
      "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0482]        \n",
      "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0482]        \n",
      "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0482]        \n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00,  8.53it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0482]\n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0482]\n",
      "Epoch 453: 100%|██████████| 1/1 [00:00<00:00,  7.59it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0482]\n",
      "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0482]        \n",
      "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0482]        \n",
      "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0482]        \n",
      "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0482]        \n",
      "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0482]        \n",
      "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0482]        \n",
      "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0482]        \n",
      "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0482]        \n",
      "Epoch 461: 100%|██████████| 1/1 [00:00<00:00,  8.57it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0482]\n",
      "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0482]        \n",
      "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0482]        \n",
      "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0482]        \n",
      "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.604, train_loss_epoch=0.604, valid_loss=0.0482]        \n",
      "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.578, train_loss_epoch=0.578, valid_loss=0.0482]        \n",
      "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.0482]        \n",
      "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.604, train_loss_epoch=0.604, valid_loss=0.0482]        \n",
      "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0482]        \n",
      "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0482]        \n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00,  7.84it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0482]\n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.514, valid_loss=0.0482]\n",
      "Epoch 470: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562, valid_loss=0.0482]\n",
      "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562, valid_loss=0.0482]        \n",
      "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0482]        \n",
      "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0482]        \n",
      "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0482]        \n",
      "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0482]        \n",
      "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0482]        \n",
      "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0482]        \n",
      "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0482]        \n",
      "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0482]        \n",
      "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0482]        \n",
      "Epoch 480: 100%|██████████| 1/1 [00:00<00:00,  9.73it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0482]\n",
      "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0482]        \n",
      "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0482]        \n",
      "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0482]        \n",
      "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0482]        \n",
      "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0482]        \n",
      "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0482]        \n",
      "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0482]        \n",
      "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0482]        \n",
      "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0482]        \n",
      "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0482]        \n",
      "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0482]        \n",
      "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0482]        \n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00,  8.87it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0482]\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00,  8.29it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.497, valid_loss=0.0482]\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00,  8.23it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0482]\n",
      "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0482]        \n",
      "Epoch 493: 100%|██████████| 1/1 [00:00<00:00,  9.80it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0482]\n",
      "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0482]        \n",
      "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0482]        \n",
      "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0482]        \n",
      "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0482]        \n",
      "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0482]        \n",
      "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0482]        \n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  9.04it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0482]\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  8.43it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.492, valid_loss=0.0482]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 19.14it/s]\u001b[A\n",
      "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0464]        \n",
      "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0464]        \n",
      "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0464]        \n",
      "Epoch 502: 100%|██████████| 1/1 [00:00<00:00,  8.55it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.499, valid_loss=0.0464]\n",
      "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0464]        \n",
      "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0464]\n",
      "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0464]        \n",
      "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0464]        \n",
      "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0464]        \n",
      "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0464]        \n",
      "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0464]        \n",
      "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0464]        \n",
      "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0464]        \n",
      "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0464]        \n",
      "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0464]        \n",
      "Epoch 512: 100%|██████████| 1/1 [00:00<00:00,  9.03it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0464]\n",
      "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0464]        \n",
      "Epoch 513: 100%|██████████| 1/1 [00:00<00:00,  9.11it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.495, valid_loss=0.0464]\n",
      "Epoch 513: 100%|██████████| 1/1 [00:00<00:00,  9.03it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0464]\n",
      "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0464]        \n",
      "Epoch 514: 100%|██████████| 1/1 [00:00<00:00,  9.84it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0464]\n",
      "Epoch 514: 100%|██████████| 1/1 [00:00<00:00,  9.04it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0464]\n",
      "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0464]        \n",
      "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0464]\n",
      "Epoch 515: 100%|██████████| 1/1 [00:00<00:00,  9.68it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0464]\n",
      "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0464]        \n",
      "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0464]        \n",
      "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0464]        \n",
      "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0464]        \n",
      "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0464]        \n",
      "Epoch 520: 100%|██████████| 1/1 [00:00<00:00,  9.00it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0464]\n",
      "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0464]        \n",
      "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0464]        \n",
      "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0464]        \n",
      "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0464]        \n",
      "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0464]        \n",
      "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0464]        \n",
      "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0464]        \n",
      "Epoch 527: 100%|██████████| 1/1 [00:00<00:00,  9.51it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0464]\n",
      "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0464]        \n",
      "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0464]        \n",
      "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0464]        \n",
      "Epoch 530: 100%|██████████| 1/1 [00:00<00:00,  9.06it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.495, valid_loss=0.0464]\n",
      "Epoch 530: 100%|██████████| 1/1 [00:00<00:00,  8.97it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0464]\n",
      "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0464]        \n",
      "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0464]        \n",
      "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0464]        \n",
      "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0464]        \n",
      "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0464]        \n",
      "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0464]        \n",
      "Epoch 536: 100%|██████████| 1/1 [00:00<00:00,  9.70it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0464]\n",
      "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0464]        \n",
      "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0464]        \n",
      "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0464]        \n",
      "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0464]        \n",
      "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0464]        \n",
      "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0464]        \n",
      "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0464]        \n",
      "Epoch 543: 100%|██████████| 1/1 [00:00<00:00,  9.04it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0464]\n",
      "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0464]        \n",
      "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0464]        \n",
      "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0464]        \n",
      "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0464]        \n",
      "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0464]        \n",
      "Epoch 548: 100%|██████████| 1/1 [00:00<00:00,  8.86it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0464]\n",
      "Epoch 548: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0464]\n",
      "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0464]        \n",
      "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0464]        \n",
      "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0464]        \n",
      "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0464]        \n",
      "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0464]        \n",
      "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0464]        \n",
      "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0464]        \n",
      "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0464]        \n",
      "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0464]        \n",
      "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0464]        \n",
      "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0464]        \n",
      "Epoch 559: 100%|██████████| 1/1 [00:00<00:00,  8.33it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0464]\n",
      "Epoch 559: 100%|██████████| 1/1 [00:00<00:00,  7.76it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0464]\n",
      "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0464]        \n",
      "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0464]        \n",
      "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0464]        \n",
      "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0464]        \n",
      "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0464]        \n",
      "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0464]        \n",
      "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0464]        \n",
      "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0464]        \n",
      "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0464]        \n",
      "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0464]        \n",
      "Epoch 569: 100%|██████████| 1/1 [00:00<00:00,  9.53it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0464]\n",
      "Epoch 569: 100%|██████████| 1/1 [00:00<00:00,  8.78it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0464]\n",
      "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0464]        \n",
      "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0464]        \n",
      "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0464]        \n",
      "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0464]        \n",
      "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0464]        \n",
      "Epoch 574: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0464]\n",
      "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0464]        \n",
      "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0464]        \n",
      "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0464]        \n",
      "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0464]        \n",
      "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0464]        \n",
      "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0464]        \n",
      "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0464]        \n",
      "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0464]        \n",
      "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0464]        \n",
      "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0464]        \n",
      "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0464]        \n",
      "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0464]        \n",
      "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0464]        \n",
      "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0464]        \n",
      "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0464]        \n",
      "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0464]        \n",
      "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0464]        \n",
      "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0464]        \n",
      "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0464]        \n",
      "Epoch 593: 100%|██████████| 1/1 [00:00<00:00,  8.68it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.495, valid_loss=0.0464]\n",
      "Epoch 593: 100%|██████████| 1/1 [00:00<00:00,  8.62it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0464]\n",
      "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0464]        \n",
      "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0464]        \n",
      "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0464]        \n",
      "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0464]        \n",
      "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0464]        \n",
      "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0464]        \n",
      "Epoch 599: 100%|██████████| 1/1 [00:00<00:00,  9.15it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.492, valid_loss=0.0464]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=8340)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 20.05it/s]\u001b[A\n",
      "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0402]        \n",
      "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0402]        \n",
      "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0402]        \n",
      "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0402]        \n",
      "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0402]        \n",
      "Epoch 604: 100%|██████████| 1/1 [00:00<00:00,  8.28it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0402]\n",
      "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0402]        \n",
      "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0402]        \n",
      "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0402]        \n",
      "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0402]        \n",
      "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0402]        \n",
      "Epoch 609: 100%|██████████| 1/1 [00:00<00:00,  8.31it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0402]\n",
      "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0402]        \n",
      "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0402]        \n",
      "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0402]        \n",
      "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0402]        \n",
      "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0402]        \n",
      "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0402]        \n",
      "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0402]        \n",
      "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0402]        \n",
      "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0402]        \n",
      "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0402]        \n",
      "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0402]        \n",
      "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0402]        \n",
      "Epoch 622:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0402]        \n",
      "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0402]        \n",
      "Epoch 623: 100%|██████████| 1/1 [00:00<00:00,  8.78it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0402]\n",
      "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0402]        \n",
      "Epoch 624: 100%|██████████| 1/1 [00:00<00:00,  9.53it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0402]\n",
      "Epoch 624: 100%|██████████| 1/1 [00:00<00:00,  8.84it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.501, valid_loss=0.0402]\n",
      "Epoch 624: 100%|██████████| 1/1 [00:00<00:00,  8.75it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0402]\n",
      "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0402]        \n",
      "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0402]        \n",
      "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0402]        \n",
      "Epoch 628:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0402]        \n",
      "Epoch 628: 100%|██████████| 1/1 [00:00<00:00,  8.75it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.500, valid_loss=0.0402]\n",
      "Epoch 628: 100%|██████████| 1/1 [00:00<00:00,  8.69it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0402]\n",
      "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0402]        \n",
      "Epoch 629: 100%|██████████| 1/1 [00:00<00:00,  8.60it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0402]\n",
      "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0402]        \n",
      "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0402]        \n",
      "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0402]        \n",
      "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0402]        \n",
      "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0402]        \n",
      "Epoch 634: 100%|██████████| 1/1 [00:00<00:00,  9.64it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0402]\n",
      "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0402]        \n",
      "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0402]        \n",
      "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0402]        \n",
      "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0402]        \n",
      "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0402]        \n",
      "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0402]        \n",
      "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0402]        \n",
      "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0402]        \n",
      "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0402]        \n",
      "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0402]        \n",
      "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0402]        \n",
      "Epoch 645: 100%|██████████| 1/1 [00:00<00:00,  8.35it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0402]\n",
      "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0402]        \n",
      "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0402]        \n",
      "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0402]        \n",
      "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0402]        \n",
      "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0402]        \n",
      "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0402]        \n",
      "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0402]        \n",
      "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0402]        \n",
      "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0402]        \n",
      "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0402]        \n",
      "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0402]        \n",
      "Epoch 657:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0402]        \n",
      "Epoch 657: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0402]\n",
      "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0402]        \n",
      "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0402]        \n",
      "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0402]        \n",
      "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0402]        \n",
      "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0402]        \n",
      "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0402]        \n",
      "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0402]        \n",
      "Epoch 664: 100%|██████████| 1/1 [00:00<00:00,  8.32it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0402]\n",
      "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0402]        \n",
      "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0402]        \n",
      "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0402]        \n",
      "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0402]        \n",
      "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0402]        \n",
      "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0402]        \n",
      "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0402]        \n",
      "Epoch 671: 100%|██████████| 1/1 [00:00<00:00,  9.69it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0402]\n",
      "Epoch 671: 100%|██████████| 1/1 [00:00<00:00,  8.98it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.487, valid_loss=0.0402]\n",
      "Epoch 671: 100%|██████████| 1/1 [00:00<00:00,  8.94it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0402]\n",
      "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0402]        \n",
      "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0402]        \n",
      "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0402]        \n",
      "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0402]        \n",
      "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0402]        \n",
      "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0402]        \n",
      "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0402]        \n",
      "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0402]        \n",
      "Epoch 679: 100%|██████████| 1/1 [00:00<00:00,  9.64it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0402]\n",
      "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0402]        \n",
      "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0402]        \n",
      "Epoch 681: 100%|██████████| 1/1 [00:00<00:00,  9.72it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0402]\n",
      "Epoch 681: 100%|██████████| 1/1 [00:00<00:00,  8.94it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0402]\n",
      "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0402]        \n",
      "Epoch 682: 100%|██████████| 1/1 [00:00<00:00,  9.72it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0402]\n",
      "Epoch 682: 100%|██████████| 1/1 [00:00<00:00,  8.95it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0402]\n",
      "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0402]        \n",
      "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0402]        \n",
      "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0402]        \n",
      "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0402]        \n",
      "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0402]        \n",
      "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0402]        \n",
      "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0402]        \n",
      "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0402]        \n",
      "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0402]        \n",
      "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0402]        \n",
      "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0402]        \n",
      "Epoch 693: 100%|██████████| 1/1 [00:00<00:00,  9.43it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0402]\n",
      "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0402]        \n",
      "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0402]        \n",
      "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0402]        \n",
      "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0402]        \n",
      "Epoch 697: 100%|██████████| 1/1 [00:00<00:00,  8.10it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.498, valid_loss=0.0402]\n",
      "Epoch 697: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0402]\n",
      "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0402]        \n",
      "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0402]        \n",
      "Epoch 699: 100%|██████████| 1/1 [00:00<00:00,  8.94it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.494, valid_loss=0.0402]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=8340)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 19.36it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=8340)\u001b[0m \n",
      "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0449]        \n",
      "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0449]        \n",
      "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0449]        \n",
      "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0449]        \n",
      "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0449]        \n",
      "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0449]        \n",
      "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0449]        \n",
      "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0449]        \n",
      "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0449]        \n",
      "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0449]        \n",
      "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0449]        \n",
      "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0449]        \n",
      "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0449]        \n",
      "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0449]        \n",
      "Epoch 713: 100%|██████████| 1/1 [00:00<00:00,  9.73it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0449]\n",
      "Epoch 713: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.484, valid_loss=0.0449]\n",
      "Epoch 713: 100%|██████████| 1/1 [00:00<00:00,  8.96it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0449]\n",
      "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0449]        \n",
      "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0449]        \n",
      "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0449]        \n",
      "Epoch 716: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0449]\n",
      "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0449]        \n",
      "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0449]        \n",
      "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0449]        \n",
      "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0449]        \n",
      "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0449]        \n",
      "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0449]        \n",
      "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0449]        \n",
      "Epoch 724:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0449]        \n",
      "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0449]        \n",
      "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0449]        \n",
      "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0449]        \n",
      "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0449]        \n",
      "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0449]        \n",
      "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0449]        \n",
      "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0449]        \n",
      "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0449]        \n",
      "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0449]        \n",
      "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0449]        \n",
      "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0449]        \n",
      "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0449]        \n",
      "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0449]        \n",
      "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0449]        \n",
      "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0449]        \n",
      "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0449]        \n",
      "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0449]        \n",
      "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0449]        \n",
      "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0449]        \n",
      "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0449]        \n",
      "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0449]        \n",
      "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0449]        \n",
      "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0449]        \n",
      "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0449]        \n",
      "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0449]        \n",
      "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0449]        \n",
      "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0449]        \n",
      "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0449]        \n",
      "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0449]        \n",
      "Epoch 753: 100%|██████████| 1/1 [00:00<00:00,  8.67it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0449]\n",
      "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0449]        \n",
      "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0449]        \n",
      "Epoch 755: 100%|██████████| 1/1 [00:00<00:00,  8.06it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0449]\n",
      "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0449]        \n",
      "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0449]        \n",
      "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0449]        \n",
      "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0449]        \n",
      "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0449]        \n",
      "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0449]        \n",
      "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0449]        \n",
      "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0449]        \n",
      "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0449]        \n",
      "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0449]        \n",
      "Epoch 765: 100%|██████████| 1/1 [00:00<00:00,  9.44it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0449]\n",
      "Epoch 766:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0449]        \n",
      "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0449]        \n",
      "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0449]        \n",
      "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0449]        \n",
      "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0449]        \n",
      "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0449]        \n",
      "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0449]        \n",
      "Epoch 772: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0449]\n",
      "Epoch 773:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0449]        \n",
      "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0449]        \n",
      "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0449]        \n",
      "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0449]        \n",
      "Epoch 776: 100%|██████████| 1/1 [00:00<00:00,  8.82it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0449]\n",
      "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0449]        \n",
      "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0449]        \n",
      "Epoch 779:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0449]        \n",
      "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0449]        \n",
      "Epoch 781:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0449]        \n",
      "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0449]        \n",
      "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0449]        \n",
      "Epoch 783: 100%|██████████| 1/1 [00:00<00:00,  9.76it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0449]\n",
      "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0449]        \n",
      "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0449]        \n",
      "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0449]        \n",
      "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0449]        \n",
      "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0449]        \n",
      "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0449]        \n",
      "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0449]        \n",
      "Epoch 790: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0449]\n",
      "Epoch 790: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.478, valid_loss=0.0449]\n",
      "Epoch 790: 100%|██████████| 1/1 [00:00<00:00,  6.16it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.0449]\n",
      "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.0449]        \n",
      "Epoch 791: 100%|██████████| 1/1 [00:00<00:00,  9.73it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.0449]\n",
      "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.0449]        \n",
      "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0449]        \n",
      "Epoch 794:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0449]        \n",
      "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0449]        \n",
      "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0449]        \n",
      "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0449]        \n",
      "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0449]        \n",
      "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0449]        \n",
      "Epoch 799: 100%|██████████| 1/1 [00:00<00:00,  9.59it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0449]\n",
      "Epoch 799: 100%|██████████| 1/1 [00:00<00:00,  8.90it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.494, valid_loss=0.0449]\n",
      "\u001b[36m(_train_tune pid=8340)\u001b[0m \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=8340)\u001b[0m \n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=8340)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 19.00it/s]\u001b[A\n",
      "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0408]        \n",
      "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0408]        \n",
      "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0408]        \n",
      "Epoch 803:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0408]        \n",
      "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0408]        \n",
      "Epoch 805:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0408]        \n",
      "Epoch 806:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0408]        \n",
      "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0408]        \n",
      "Epoch 808:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0408]        \n",
      "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0408]        \n",
      "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0408]        \n",
      "Epoch 811:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0408]        \n",
      "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0408]        \n",
      "Epoch 813:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0408]        \n",
      "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0408]        \n",
      "Epoch 815:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0408]        \n",
      "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0408]        \n",
      "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0408]        \n",
      "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0408]        \n",
      "Epoch 819:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0408]        \n",
      "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0408]        \n",
      "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0408]        \n",
      "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0408]        \n",
      "Epoch 823:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0408]        \n",
      "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0408]        \n",
      "Epoch 824: 100%|██████████| 1/1 [00:00<00:00,  8.82it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0408]\n",
      "Epoch 825:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0408]        \n",
      "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0408]        \n",
      "Epoch 827:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0408]        \n",
      "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0408]        \n",
      "Epoch 829:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0408]        \n",
      "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0408]        \n",
      "Epoch 831:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0408]        \n",
      "Epoch 831: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0408]\n",
      "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0408]        \n",
      "Epoch 833:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0408]        \n",
      "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0408]        \n",
      "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0408]        \n",
      "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0408]        \n",
      "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0408]        \n",
      "Epoch 838:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0408]        \n",
      "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0408]        \n",
      "Epoch 840:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0408]        \n",
      "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0408]        \n",
      "Epoch 842:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0408]        \n",
      "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0408]        \n",
      "Epoch 843: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0408]\n",
      "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0408]        \n",
      "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0408]        \n",
      "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0408]        \n",
      "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0408]        \n",
      "Epoch 848:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0408]        \n",
      "Epoch 849:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0408]        \n",
      "Epoch 850:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0408]        \n",
      "Epoch 850: 100%|██████████| 1/1 [00:00<00:00,  9.69it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0408]\n",
      "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0408]        \n",
      "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0408]        \n",
      "Epoch 853:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0408]        \n",
      "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0408]        \n",
      "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0408]        \n",
      "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0408]        \n",
      "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0408]        \n",
      "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0408]        \n",
      "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0408]        \n",
      "Epoch 859: 100%|██████████| 1/1 [00:00<00:00,  9.59it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0408]\n",
      "Epoch 859: 100%|██████████| 1/1 [00:00<00:00,  8.79it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0408]\n",
      "Epoch 860:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0408]        \n",
      "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0408]        \n",
      "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0408]        \n",
      "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0408]        \n",
      "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0408]        \n",
      "Epoch 865:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0408]        \n",
      "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0408]        \n",
      "Epoch 866: 100%|██████████| 1/1 [00:00<00:00,  7.95it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0408]\n",
      "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0408]        \n",
      "Epoch 868:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0408]        \n",
      "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0408]        \n",
      "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0408]        \n",
      "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0408]        \n",
      "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0408]        \n",
      "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0408]        \n",
      "Epoch 873: 100%|██████████| 1/1 [00:00<00:00,  9.28it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0408]\n",
      "Epoch 873: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0408]\n",
      "Epoch 874:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0408]        \n",
      "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0408]        \n",
      "Epoch 875: 100%|██████████| 1/1 [00:00<00:00,  9.98it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0408]\n",
      "Epoch 875: 100%|██████████| 1/1 [00:00<00:00,  9.60it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.479, valid_loss=0.0408]\n",
      "Epoch 875: 100%|██████████| 1/1 [00:00<00:00,  9.54it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0408]\n",
      "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0408]        \n",
      "Epoch 877:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0408]        \n",
      "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0408]        \n",
      "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0408]        \n",
      "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0408]        \n",
      "Epoch 881:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0408]        \n",
      "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0408]        \n",
      "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0408]        \n",
      "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0408]        \n",
      "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0408]        \n",
      "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0408]        \n",
      "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0408]        \n",
      "Epoch 888:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0408]        \n",
      "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0408]        \n",
      "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0408]        \n",
      "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0408]        \n",
      "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0408]        \n",
      "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0408]        \n",
      "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0408]        \n",
      "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0408]        \n",
      "Epoch 896:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0408]        \n",
      "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0408]        \n",
      "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0408]        \n",
      "Epoch 898: 100%|██████████| 1/1 [00:00<00:00,  8.83it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0408]\n",
      "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0408]        \n",
      "Epoch 899: 100%|██████████| 1/1 [00:00<00:00,  8.79it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.484, valid_loss=0.0408]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 19.46it/s]\u001b[A\n",
      "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0349]        \n",
      "Epoch 901:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0349]        \n",
      "Epoch 902:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0349]        \n",
      "Epoch 903:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0349]        \n",
      "Epoch 904:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0349]        \n",
      "Epoch 905:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0349]        \n",
      "Epoch 906:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0349]        \n",
      "Epoch 907:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0349]        \n",
      "Epoch 908:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0349]        \n",
      "Epoch 909:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0349]        \n",
      "Epoch 910:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0349]        \n",
      "Epoch 911:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0349]        \n",
      "Epoch 912:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0349]        \n",
      "Epoch 913:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0349]        \n",
      "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0349]        \n",
      "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.0349]        \n",
      "Epoch 916:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=0.0349]        \n",
      "Epoch 917:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0349]        \n",
      "Epoch 918:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0349]        \n",
      "Epoch 919:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0349]        \n",
      "Epoch 920:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0349]        \n",
      "Epoch 921:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0349]        \n",
      "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0349]        \n",
      "Epoch 923:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0349]        \n",
      "Epoch 924:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0349]        \n",
      "Epoch 925:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0349]        \n",
      "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0349]        \n",
      "Epoch 927:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0349]        \n",
      "Epoch 927: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0349]\n",
      "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0349]        \n",
      "Epoch 929:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0349]        \n",
      "Epoch 930:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0349]        \n",
      "Epoch 931:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0349]        \n",
      "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0349]        \n",
      "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0349]        \n",
      "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0349]        \n",
      "Epoch 935:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0349]        \n",
      "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0349]        \n",
      "Epoch 937:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0349]        \n",
      "Epoch 938:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0349]        \n",
      "Epoch 939:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0349]        \n",
      "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0349]        \n",
      "Epoch 940: 100%|██████████| 1/1 [00:00<00:00,  8.62it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.486, valid_loss=0.0349]\n",
      "Epoch 941:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0349]        \n",
      "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0349]        \n",
      "Epoch 943:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0349]        \n",
      "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0349]        \n",
      "Epoch 945:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0349]        \n",
      "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0349]        \n",
      "Epoch 947:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0349]        \n",
      "Epoch 948:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0349]        \n",
      "Epoch 949:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0349]        \n",
      "Epoch 950:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0349]        \n",
      "Epoch 951:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0349]        \n",
      "Epoch 952:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0349]        \n",
      "Epoch 953:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0349]        \n",
      "Epoch 954:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0349]        \n",
      "Epoch 955:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0349]        \n",
      "Epoch 956:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0349]        \n",
      "Epoch 957:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0349]        \n",
      "Epoch 958:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0349]        \n",
      "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0349]        \n",
      "Epoch 960:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0349]        \n",
      "Epoch 960: 100%|██████████| 1/1 [00:00<00:00,  7.68it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0349]\n",
      "Epoch 961:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0349]        \n",
      "Epoch 962:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0349]        \n",
      "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0349]        \n",
      "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0349]        \n",
      "Epoch 965:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0349]        \n",
      "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0349]        \n",
      "Epoch 967:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0349]        \n",
      "Epoch 968:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0349]        \n",
      "Epoch 969:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0349]        \n",
      "Epoch 970:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0349]        \n",
      "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0349]        \n",
      "Epoch 972:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0349]        \n",
      "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0349]        \n",
      "Epoch 974:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0349]        \n",
      "Epoch 974: 100%|██████████| 1/1 [00:00<00:00,  9.09it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0349]\n",
      "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0349]        \n",
      "Epoch 976:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0349]        \n",
      "Epoch 977:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0349]        \n",
      "Epoch 978:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0349]        \n",
      "Epoch 979:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0349]        \n",
      "Epoch 979: 100%|██████████| 1/1 [00:00<00:00,  9.63it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0349]\n",
      "Epoch 980:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0349]        \n",
      "Epoch 981:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0349]        \n",
      "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0349]        \n",
      "Epoch 982: 100%|██████████| 1/1 [00:00<00:00,  9.68it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0349]\n",
      "Epoch 982: 100%|██████████| 1/1 [00:00<00:00,  8.91it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0349]\n",
      "Epoch 983:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0349]        \n",
      "Epoch 984:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0349]        \n",
      "Epoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0349]        \n",
      "Epoch 986:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0349]        \n",
      "Epoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0349]        \n",
      "Epoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0349]        \n",
      "Epoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0349]        \n",
      "Epoch 989: 100%|██████████| 1/1 [00:00<00:00,  9.21it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0349]\n",
      "Epoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0349]        \n",
      "Epoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0349]        \n",
      "Epoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0349]        \n",
      "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0349]        \n",
      "Epoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0349]        \n",
      "Epoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0349]        \n",
      "Epoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0349]        \n",
      "Epoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0349]        \n",
      "Epoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0349]        \n",
      "Epoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0349]        \n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00,  8.76it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.487, valid_loss=0.0349]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=8340)\u001b[0m `Trainer.fit` stopped: `max_steps=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=8340)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 11.10it/s]\u001b[A\n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00,  4.63it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0398]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=9004)\u001b[0m /home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=9004)\u001b[0m Seed set to 17\n",
      "\u001b[36m(_train_tune pid=9004)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=9004)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=9004)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=9004)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(_train_tune pid=9004)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=9004)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=9004)\u001b[0m   | Name            | Type          | Params | Mode \n",
      "\u001b[36m(_train_tune pid=9004)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=9004)\u001b[0m 0 | loss            | WMAPE         | 0      | train\n",
      "\u001b[36m(_train_tune pid=9004)\u001b[0m 1 | padder          | ConstantPad1d | 0      | train\n",
      "\u001b[36m(_train_tune pid=9004)\u001b[0m 2 | scaler          | TemporalNorm  | 0      | train\n",
      "\u001b[36m(_train_tune pid=9004)\u001b[0m 3 | hist_encoder    | LSTM          | 31.0 K | train\n",
      "\u001b[36m(_train_tune pid=9004)\u001b[0m 4 | context_adapter | Linear        | 19.6 K | train\n",
      "\u001b[36m(_train_tune pid=9004)\u001b[0m 5 | mlp_decoder     | MLP           | 449    | train\n",
      "\u001b[36m(_train_tune pid=9004)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=9004)\u001b[0m 51.1 K    Trainable params\n",
      "\u001b[36m(_train_tune pid=9004)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=9004)\u001b[0m 51.1 K    Total params\n",
      "\u001b[36m(_train_tune pid=9004)\u001b[0m 0.204     Total estimated model params size (MB)\n",
      "\u001b[36m(_train_tune pid=9004)\u001b[0m 11        Modules in train mode\n",
      "\u001b[36m(_train_tune pid=9004)\u001b[0m 0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 66.19it/s, v_num=0, train_loss_step=0.851, train_loss_epoch=0.851]\n",
      "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.677, train_loss_epoch=0.677]       \n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00, 64.53it/s, v_num=0, train_loss_step=0.598, train_loss_epoch=0.582]\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00, 61.89it/s, v_num=0, train_loss_step=0.598, train_loss_epoch=0.598]\n",
      "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.598, train_loss_epoch=0.598]        \n",
      "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.572]        \n",
      "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560]        \n",
      "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562]        \n",
      "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557]        \n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00, 72.56it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550]\n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00, 57.89it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550]\n",
      "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550]        \n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00, 53.24it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.569]\n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00, 49.26it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567]\n",
      "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567]        \n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00, 83.02it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552]\n",
      "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537]        \n",
      "Epoch 61: 100%|██████████| 1/1 [00:00<00:00, 55.24it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529]\n",
      "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529]        \n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00, 73.35it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524]\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00, 62.46it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.524]\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00, 59.05it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531]\n",
      "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531]        \n",
      "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527]        \n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00, 73.79it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519]\n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00, 56.73it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519]\n",
      "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513]        \n",
      "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510]        \n",
      "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506]        \n",
      "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501]        \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 81.29it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501]\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 63.23it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.501]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 115.08it/s]\u001b[A\n",
      "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.043]        \n",
      "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.043]        \n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00, 52.48it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.043]\n",
      "Epoch 108: 100%|██████████| 1/1 [00:00<00:00, 46.60it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.043]\n",
      "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.043]        \n",
      "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.043]        \n",
      "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.043]        \n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00, 46.27it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.043]\n",
      "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.043]        \n",
      "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.043]        \n",
      "Epoch 134: 100%|██████████| 1/1 [00:00<00:00, 77.62it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.043]\n",
      "Epoch 134: 100%|██████████| 1/1 [00:00<00:00, 58.91it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.043]\n",
      "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.043]        \n",
      "Epoch 140: 100%|██████████| 1/1 [00:00<00:00, 76.97it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.043]\n",
      "Epoch 140: 100%|██████████| 1/1 [00:00<00:00, 62.30it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.478, valid_loss=0.043]\n",
      "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.043]        \n",
      "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.043]\n",
      "Epoch 146: 100%|██████████| 1/1 [00:00<00:00, 71.46it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473, valid_loss=0.043]\n",
      "Epoch 146: 100%|██████████| 1/1 [00:00<00:00, 57.45it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.043]\n",
      "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.043]        \n",
      "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.043]        \n",
      "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.043]\n",
      "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.043]        \n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00, 78.38it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.043]\n",
      "Epoch 161: 100%|██████████| 1/1 [00:00<00:00, 43.79it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.043]\n",
      "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.043]        \n",
      "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.043]        \n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00, 55.06it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.043]\n",
      "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.043]        \n",
      "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.043]        \n",
      "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=0.043]        \n",
      "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.043]        \n",
      "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.475, train_loss_epoch=0.475, valid_loss=0.043]        \n",
      "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.043]        \n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00, 55.80it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.043]\n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00, 49.59it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.043]\n",
      "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.043]        \n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 57.10it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.503, valid_loss=0.043]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 106.35it/s]\u001b[A\n",
      "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0537]        \n",
      "Epoch 206: 100%|██████████| 1/1 [00:00<00:00, 55.40it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.0537]\n",
      "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.0537]        \n",
      "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.454, train_loss_epoch=0.454, valid_loss=0.0537]        \n",
      "Epoch 211: 100%|██████████| 1/1 [00:00<00:00, 42.63it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.465, valid_loss=0.0537]\n",
      "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0537]        \n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00, 77.34it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0537]\n",
      "Epoch 222: 100%|██████████| 1/1 [00:00<00:00, 57.72it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0537]\n",
      "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0537]        \n",
      "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0537]        \n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00, 61.05it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.449, valid_loss=0.0537]\n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00, 57.78it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455, valid_loss=0.0537]\n",
      "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455, valid_loss=0.0537]        \n",
      "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.459, train_loss_epoch=0.459, valid_loss=0.0537]        \n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00, 65.11it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0537]\n",
      "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0537]        \n",
      "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=0.0537]        \n",
      "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.0537]        \n",
      "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0537]        \n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00, 51.43it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0537]\n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00, 49.69it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.530, valid_loss=0.0537]\n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00, 46.97it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0537]\n",
      "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0537]        \n",
      "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0537]        \n",
      "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.0537]        \n",
      "Epoch 279: 100%|██████████| 1/1 [00:00<00:00, 56.08it/s, v_num=0, train_loss_step=0.441, train_loss_epoch=0.441, valid_loss=0.0537]\n",
      "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.441, train_loss_epoch=0.441, valid_loss=0.0537]        \n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00, 50.11it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.417, valid_loss=0.0537]\n",
      "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.416, valid_loss=0.0537]        \n",
      "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0537]        \n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00, 67.87it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0537]\n",
      "Epoch 295: 100%|██████████| 1/1 [00:00<00:00, 52.09it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0537]\n",
      "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0537]        \n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 49.80it/s, v_num=0, train_loss_step=0.458, train_loss_epoch=0.464, valid_loss=0.0537]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 100.91it/s]\u001b[A\n",
      "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.458, train_loss_epoch=0.458, valid_loss=0.0323]        \n",
      "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.443, train_loss_epoch=0.443, valid_loss=0.0323]        \n",
      "Epoch 310: 100%|██████████| 1/1 [00:00<00:00, 76.36it/s, v_num=0, train_loss_step=0.414, train_loss_epoch=0.414, valid_loss=0.0323]\n",
      "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.441, train_loss_epoch=0.441, valid_loss=0.0323]        \n",
      "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.438, train_loss_epoch=0.438, valid_loss=0.0323]        \n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00, 66.03it/s, v_num=0, train_loss_step=0.438, train_loss_epoch=0.438, valid_loss=0.0323]\n",
      "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0323]        \n",
      "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.443, train_loss_epoch=0.443, valid_loss=0.0323]        \n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00, 88.08it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=0.0323]\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00, 65.51it/s, v_num=0, train_loss_step=0.400, train_loss_epoch=0.405, valid_loss=0.0323]\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00, 61.95it/s, v_num=0, train_loss_step=0.400, train_loss_epoch=0.400, valid_loss=0.0323]\n",
      "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.400, train_loss_epoch=0.400, valid_loss=0.0323]        \n",
      "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.415, valid_loss=0.0323]        \n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00, 53.09it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369, valid_loss=0.0323]\n",
      "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369, valid_loss=0.0323]        \n",
      "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354, valid_loss=0.0323]        \n",
      "Epoch 355: 100%|██████████| 1/1 [00:00<00:00, 55.04it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.340, valid_loss=0.0323]\n",
      "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=0.0323]        \n",
      "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.420, train_loss_epoch=0.420, valid_loss=0.0323]        \n",
      "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.414, train_loss_epoch=0.414, valid_loss=0.0323]        \n",
      "Epoch 370: 100%|██████████| 1/1 [00:00<00:00, 72.79it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=0.0323]\n",
      "Epoch 370: 100%|██████████| 1/1 [00:00<00:00, 57.41it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.0323]\n",
      "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.0323]        \n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00, 46.91it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.0323]\n",
      "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.0323]        \n",
      "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.0323]        \n",
      "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.577, train_loss_epoch=0.577, valid_loss=0.0323]        \n",
      "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.442, train_loss_epoch=0.442, valid_loss=0.0323]        \n",
      "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.429, train_loss_epoch=0.429, valid_loss=0.0323]        \n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 59.26it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.423, valid_loss=0.0323]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 111.17it/s]\u001b[A\n",
      "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.422, train_loss_epoch=0.422, valid_loss=0.0422]        \n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00, 75.45it/s, v_num=0, train_loss_step=0.401, train_loss_epoch=0.401, valid_loss=0.0422]\n",
      "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.456, train_loss_epoch=0.456, valid_loss=0.0422]        \n",
      "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.434, train_loss_epoch=0.434, valid_loss=0.0422]        \n",
      "Epoch 423: 100%|██████████| 1/1 [00:00<00:00, 64.96it/s, v_num=0, train_loss_step=0.406, train_loss_epoch=0.406, valid_loss=0.0422]\n",
      "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.406, train_loss_epoch=0.406, valid_loss=0.0422]        \n",
      "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.387, train_loss_epoch=0.387, valid_loss=0.0422]        \n",
      "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=0.0422]        \n",
      "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=0.0422]        \n",
      "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336, valid_loss=0.0422]        \n",
      "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336, valid_loss=0.0422]        \n",
      "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=0.0422]        \n",
      "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=0.0422]        \n",
      "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=0.0422]        \n",
      "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297, valid_loss=0.0422]        \n",
      "Epoch 476: 100%|██████████| 1/1 [00:00<00:00, 85.32it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=0.0422]\n",
      "Epoch 476: 100%|██████████| 1/1 [00:00<00:00, 62.42it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=0.0422]\n",
      "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=0.0422]        \n",
      "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=0.0422]        \n",
      "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=0.0422]        \n",
      "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=0.0422]        \n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00, 62.13it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=0.0422]\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00, 53.25it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.314, valid_loss=0.0422]\n",
      "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=0.0422]        \n",
      "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=0.0422]        \n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 60.52it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.330, valid_loss=0.0422]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 94.15it/s]\u001b[A\n",
      "Epoch 502: 100%|██████████| 1/1 [00:00<00:00, 79.29it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=0.0417]\n",
      "Epoch 507: 100%|██████████| 1/1 [00:00<00:00, 60.55it/s, v_num=0, train_loss_step=0.342, train_loss_epoch=0.342, valid_loss=0.0417]\n",
      "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.342, train_loss_epoch=0.342, valid_loss=0.0417]        \n",
      "Epoch 513: 100%|██████████| 1/1 [00:00<00:00, 61.29it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=0.0417]\n",
      "Epoch 513: 100%|██████████| 1/1 [00:00<00:00, 50.70it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=0.0417]\n",
      "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=0.0417]        \n",
      "Epoch 518: 100%|██████████| 1/1 [00:00<00:00, 62.65it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=0.0417]\n",
      "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=0.0417]        \n",
      "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.279, train_loss_epoch=0.279, valid_loss=0.0417]        \n",
      "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=0.0417]        \n",
      "Epoch 533: 100%|██████████| 1/1 [00:00<00:00, 44.61it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.272, valid_loss=0.0417]\n",
      "Epoch 533: 100%|██████████| 1/1 [00:00<00:00, 42.52it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=0.0417]\n",
      "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=0.0417]        \n",
      "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.260, train_loss_epoch=0.260, valid_loss=0.0417]        \n",
      "Epoch 544: 100%|██████████| 1/1 [00:00<00:00, 61.22it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=0.0417]\n",
      "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=0.0417]        \n",
      "Epoch 550: 100%|██████████| 1/1 [00:00<00:00, 66.55it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259, valid_loss=0.0417]\n",
      "Epoch 550: 100%|██████████| 1/1 [00:00<00:00, 56.01it/s, v_num=0, train_loss_step=0.256, train_loss_epoch=0.259, valid_loss=0.0417]\n",
      "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.256, train_loss_epoch=0.256, valid_loss=0.0417]        \n",
      "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.378, valid_loss=0.0417]        \n",
      "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=0.0417]        \n",
      "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=0.0417]        \n",
      "Epoch 566: 100%|██████████| 1/1 [00:00<00:00, 51.49it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.319, valid_loss=0.0417]\n",
      "Epoch 566: 100%|██████████| 1/1 [00:00<00:00, 48.79it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=0.0417]\n",
      "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=0.0417]        \n",
      "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295, valid_loss=0.0417]        \n",
      "Epoch 572: 100%|██████████| 1/1 [00:00<00:00, 71.48it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295, valid_loss=0.0417]\n",
      "Epoch 572: 100%|██████████| 1/1 [00:00<00:00, 59.47it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.295, valid_loss=0.0417]\n",
      "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=0.0417]        \n",
      "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.282, valid_loss=0.0417]        \n",
      "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.280, train_loss_epoch=0.280, valid_loss=0.0417]        \n",
      "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.266, train_loss_epoch=0.266, valid_loss=0.0417]        \n",
      "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.249, train_loss_epoch=0.249, valid_loss=0.0417]        \n",
      "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 58.76it/s, v_num=0, train_loss_step=0.238, train_loss_epoch=0.238, valid_loss=0.0417]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=9004)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 97.22it/s]\u001b[A\n",
      "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.243, train_loss_epoch=0.243, valid_loss=0.038]         \n",
      "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.232, train_loss_epoch=0.232, valid_loss=0.038]        \n",
      "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=0.038]        \n",
      "Epoch 620: 100%|██████████| 1/1 [00:00<00:00, 61.09it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=0.038]\n",
      "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=0.038]        \n",
      "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=0.038]        \n",
      "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=0.038]        \n",
      "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204, valid_loss=0.038]        \n",
      "Epoch 641: 100%|██████████| 1/1 [00:00<00:00, 53.78it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=0.038]\n",
      "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=0.038]        \n",
      "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196, valid_loss=0.038]        \n",
      "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=0.038]        \n",
      "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=0.038]        \n",
      "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.240, train_loss_epoch=0.240, valid_loss=0.038]        \n",
      "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.444, train_loss_epoch=0.444, valid_loss=0.038]        \n",
      "Epoch 667: 100%|██████████| 1/1 [00:00<00:00, 74.97it/s, v_num=0, train_loss_step=0.444, train_loss_epoch=0.444, valid_loss=0.038]\n",
      "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.584, train_loss_epoch=0.584, valid_loss=0.038]        \n",
      "Epoch 677: 100%|██████████| 1/1 [00:00<00:00, 69.26it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567, valid_loss=0.038]\n",
      "Epoch 677: 100%|██████████| 1/1 [00:00<00:00, 57.94it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.567, valid_loss=0.038]\n",
      "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.038]        \n",
      "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.038]        \n",
      "Epoch 688: 100%|██████████| 1/1 [00:00<00:00, 56.19it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.038]\n",
      "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.038]        \n",
      "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.474, train_loss_epoch=0.474, valid_loss=0.038]        \n",
      "Epoch 693: 100%|██████████| 1/1 [00:00<00:00, 53.37it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.474, valid_loss=0.038]\n",
      "Epoch 693: 100%|██████████| 1/1 [00:00<00:00, 49.40it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=0.038]\n",
      "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=0.038]        \n",
      "Epoch 697: 100%|██████████| 1/1 [00:00<00:00, 41.23it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=0.038]\n",
      "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=0.038]        \n",
      "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 61.42it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.457, valid_loss=0.038]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 106.39it/s]\u001b[A\n",
      "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.450, train_loss_epoch=0.450, valid_loss=0.0411]        \n",
      "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.448, valid_loss=0.0411]        \n",
      "Epoch 712: 100%|██████████| 1/1 [00:00<00:00, 77.81it/s, v_num=0, train_loss_step=0.429, train_loss_epoch=0.429, valid_loss=0.0411]\n",
      "Epoch 712: 100%|██████████| 1/1 [00:00<00:00, 47.85it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=0.0411]\n",
      "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=0.0411]        \n",
      "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.420, train_loss_epoch=0.420, valid_loss=0.0411]        \n",
      "Epoch 723: 100%|██████████| 1/1 [00:00<00:00, 78.65it/s, v_num=0, train_loss_step=0.421, train_loss_epoch=0.421, valid_loss=0.0411]\n",
      "Epoch 723: 100%|██████████| 1/1 [00:00<00:00, 61.52it/s, v_num=0, train_loss_step=0.440, train_loss_epoch=0.421, valid_loss=0.0411]\n",
      "Epoch 723: 100%|██████████| 1/1 [00:00<00:00, 58.81it/s, v_num=0, train_loss_step=0.440, train_loss_epoch=0.440, valid_loss=0.0411]\n",
      "Epoch 724:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.440, train_loss_epoch=0.440, valid_loss=0.0411]        \n",
      "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.612, train_loss_epoch=0.612, valid_loss=0.0411]        \n",
      "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.444, train_loss_epoch=0.444, valid_loss=0.0411]        \n",
      "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.434, train_loss_epoch=0.434, valid_loss=0.0411]        \n",
      "Epoch 743: 100%|██████████| 1/1 [00:00<00:00, 58.11it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.415, valid_loss=0.0411]\n",
      "Epoch 743: 100%|██████████| 1/1 [00:00<00:00, 50.02it/s, v_num=0, train_loss_step=0.412, train_loss_epoch=0.412, valid_loss=0.0411]\n",
      "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.412, train_loss_epoch=0.412, valid_loss=0.0411]        \n",
      "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396, valid_loss=0.0411]        \n",
      "Epoch 753: 100%|██████████| 1/1 [00:00<00:00, 62.37it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.378, valid_loss=0.0411]\n",
      "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.378, valid_loss=0.0411]        \n",
      "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.392, train_loss_epoch=0.392, valid_loss=0.0411]        \n",
      "Epoch 763: 100%|██████████| 1/1 [00:00<00:00, 57.66it/s, v_num=0, train_loss_step=0.383, train_loss_epoch=0.383, valid_loss=0.0411]\n",
      "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.383, train_loss_epoch=0.383, valid_loss=0.0411]        \n",
      "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.368, train_loss_epoch=0.368, valid_loss=0.0411]        \n",
      "Epoch 774: 100%|██████████| 1/1 [00:00<00:00, 69.46it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=0.0411]\n",
      "Epoch 774: 100%|██████████| 1/1 [00:00<00:00, 57.55it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=0.0411]\n",
      "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=0.0411]        \n",
      "Epoch 780: 100%|██████████| 1/1 [00:00<00:00, 61.88it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=0.0411]\n",
      "Epoch 781:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=0.0411]        \n",
      "Epoch 785: 100%|██████████| 1/1 [00:00<00:00, 78.12it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=0.0411]\n",
      "Epoch 785: 100%|██████████| 1/1 [00:00<00:00, 60.31it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.337, valid_loss=0.0411]\n",
      "Epoch 785: 100%|██████████| 1/1 [00:00<00:00, 57.74it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=0.0411]\n",
      "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=0.0411]        \n",
      "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.389, valid_loss=0.0411]        \n",
      "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565, valid_loss=0.0411]        \n",
      "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 65.67it/s, v_num=0, train_loss_step=0.474, train_loss_epoch=0.499, valid_loss=0.0411]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 123.43it/s]\u001b[A\n",
      "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.465, valid_loss=0.0411]        \n",
      "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.465, valid_loss=0.0411]\n",
      "Epoch 806:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.441, train_loss_epoch=0.441, valid_loss=0.0411]        \n",
      "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=0.0411]        \n",
      "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.416, valid_loss=0.0411]        \n",
      "Epoch 822: 100%|██████████| 1/1 [00:00<00:00, 80.38it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=0.0411]\n",
      "Epoch 822: 100%|██████████| 1/1 [00:00<00:00, 59.81it/s, v_num=0, train_loss_step=0.398, train_loss_epoch=0.398, valid_loss=0.0411]\n",
      "Epoch 823:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.398, train_loss_epoch=0.398, valid_loss=0.0411]        \n",
      "Epoch 828: 100%|██████████| 1/1 [00:00<00:00, 61.90it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.389, valid_loss=0.0411]\n",
      "Epoch 829:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.389, valid_loss=0.0411]        \n",
      "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=0.0411]        \n",
      "Epoch 840:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=0.0411]        \n",
      "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=0.0411]        \n",
      "Epoch 845: 100%|██████████| 1/1 [00:00<00:00, 70.07it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=0.0411]\n",
      "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363, valid_loss=0.0411]        \n",
      "Epoch 856: 100%|██████████| 1/1 [00:00<00:00, 62.59it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.349, valid_loss=0.0411]\n",
      "Epoch 856: 100%|██████████| 1/1 [00:00<00:00, 59.92it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346, valid_loss=0.0411]\n",
      "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346, valid_loss=0.0411]        \n",
      "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=0.0411]        \n",
      "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=0.0411]        \n",
      "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=0.0411]        \n",
      "Epoch 877: 100%|██████████| 1/1 [00:00<00:00, 69.82it/s, v_num=0, train_loss_step=0.340, train_loss_epoch=0.340, valid_loss=0.0411]\n",
      "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=0.0411]        \n",
      "Epoch 888:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=0.0411]        \n",
      "Epoch 893: 100%|██████████| 1/1 [00:00<00:00, 77.08it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335, valid_loss=0.0411]\n",
      "Epoch 893: 100%|██████████| 1/1 [00:00<00:00, 59.68it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=0.0411]\n",
      "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=0.0411]        \n",
      "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=0.0411]        \n",
      "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 54.55it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.324, valid_loss=0.0411]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 101.20it/s]\u001b[A\n",
      "Epoch 903:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=0.0448]        \n",
      "Epoch 909:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.289, valid_loss=0.0448]        \n",
      "Epoch 913: 100%|██████████| 1/1 [00:00<00:00, 62.51it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.282, valid_loss=0.0448]\n",
      "Epoch 913: 100%|██████████| 1/1 [00:00<00:00, 50.83it/s, v_num=0, train_loss_step=0.279, train_loss_epoch=0.279, valid_loss=0.0448]\n",
      "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.279, train_loss_epoch=0.279, valid_loss=0.0448]        \n",
      "Epoch 919:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=0.0448]        \n",
      "Epoch 924: 100%|██████████| 1/1 [00:00<00:00, 72.60it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=0.0448]\n",
      "Epoch 930:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=0.0448]        \n",
      "Epoch 935:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.268, train_loss_epoch=0.268, valid_loss=0.0448]        \n",
      "Epoch 941:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=0.0448]        \n",
      "Epoch 946: 100%|██████████| 1/1 [00:00<00:00, 81.66it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=0.0448]\n",
      "Epoch 946: 100%|██████████| 1/1 [00:00<00:00, 63.41it/s, v_num=0, train_loss_step=0.251, train_loss_epoch=0.252, valid_loss=0.0448]\n",
      "Epoch 947:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.251, train_loss_epoch=0.251, valid_loss=0.0448]        \n",
      "Epoch 952:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.248, train_loss_epoch=0.248, valid_loss=0.0448]        \n",
      "Epoch 957: 100%|██████████| 1/1 [00:00<00:00, 67.20it/s, v_num=0, train_loss_step=0.271, train_loss_epoch=0.271, valid_loss=0.0448]\n",
      "Epoch 957: 100%|██████████| 1/1 [00:00<00:00, 52.81it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=0.0448]\n",
      "Epoch 958:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=0.0448]        \n",
      "Epoch 963: 100%|██████████| 1/1 [00:00<00:00, 82.43it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.257, valid_loss=0.0448]\n",
      "Epoch 963: 100%|██████████| 1/1 [00:00<00:00, 64.07it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.257, valid_loss=0.0448]\n",
      "Epoch 963: 100%|██████████| 1/1 [00:00<00:00, 61.15it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.282, valid_loss=0.0448]\n",
      "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.282, valid_loss=0.0448]        \n",
      "Epoch 968:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=0.0448]        \n",
      "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.421, train_loss_epoch=0.421, valid_loss=0.0448]        \n",
      "Epoch 973: 100%|██████████| 1/1 [00:00<00:00, 63.24it/s, v_num=0, train_loss_step=0.421, train_loss_epoch=0.421, valid_loss=0.0448]\n",
      "Epoch 973: 100%|██████████| 1/1 [00:00<00:00, 53.23it/s, v_num=0, train_loss_step=0.410, train_loss_epoch=0.410, valid_loss=0.0448]\n",
      "Epoch 974:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.410, train_loss_epoch=0.410, valid_loss=0.0448]        \n",
      "Epoch 979:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.393, train_loss_epoch=0.393, valid_loss=0.0448]        \n",
      "Epoch 984:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=0.0448]        \n",
      "Epoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452, valid_loss=0.0448]        \n",
      "Epoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.436, train_loss_epoch=0.436, valid_loss=0.0448]        \n",
      "Epoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.436, train_loss_epoch=0.436, valid_loss=0.0448]\n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 54.29it/s, v_num=0, train_loss_step=0.420, train_loss_epoch=0.421, valid_loss=0.0448]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 78.07it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=9004)\u001b[0m \n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 21.21it/s, v_num=0, train_loss_step=0.420, train_loss_epoch=0.421, valid_loss=0.0521]\n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 20.66it/s, v_num=0, train_loss_step=0.420, train_loss_epoch=0.420, valid_loss=0.0521]\n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 19.66it/s, v_num=0, train_loss_step=0.420, train_loss_epoch=0.420, valid_loss=0.0521]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=9004)\u001b[0m `Trainer.fit` stopped: `max_steps=1000` reached.\n",
      "\u001b[36m(_train_tune pid=9194)\u001b[0m /home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=9194)\u001b[0m Seed set to 15\n",
      "\u001b[36m(_train_tune pid=9194)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=9194)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=9194)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=9194)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(_train_tune pid=9194)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_train_tune pid=9194)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=9194)\u001b[0m   | Name            | Type          | Params | Mode \n",
      "\u001b[36m(_train_tune pid=9194)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=9194)\u001b[0m 0 | loss            | WMAPE         | 0      | train\n",
      "\u001b[36m(_train_tune pid=9194)\u001b[0m 1 | padder          | ConstantPad1d | 0      | train\n",
      "\u001b[36m(_train_tune pid=9194)\u001b[0m 2 | scaler          | TemporalNorm  | 0      | train\n",
      "\u001b[36m(_train_tune pid=9194)\u001b[0m 3 | hist_encoder    | LSTM          | 41.2 K | train\n",
      "\u001b[36m(_train_tune pid=9194)\u001b[0m 4 | context_adapter | Linear        | 388 K  | train\n",
      "\u001b[36m(_train_tune pid=9194)\u001b[0m 5 | mlp_decoder     | MLP           | 26.6 K | train\n",
      "\u001b[36m(_train_tune pid=9194)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=9194)\u001b[0m 456 K     Trainable params\n",
      "\u001b[36m(_train_tune pid=9194)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=9194)\u001b[0m 456 K     Total params\n",
      "\u001b[36m(_train_tune pid=9194)\u001b[0m 1.827     Total estimated model params size (MB)\n",
      "\u001b[36m(_train_tune pid=9194)\u001b[0m 11        Modules in train mode\n",
      "\u001b[36m(_train_tune pid=9194)\u001b[0m 0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]        \n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 69.28it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 62.74it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993]\n",
      "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]        \n",
      "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00, 47.81it/s, v_num=0, train_loss_step=0.962, train_loss_epoch=0.962]\n",
      "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.962, train_loss_epoch=0.962]        \n",
      "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.982, train_loss_epoch=0.982]        \n",
      "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.925, train_loss_epoch=0.925]        \n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00, 72.28it/s, v_num=0, train_loss_step=0.856, train_loss_epoch=0.856]\n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00, 53.10it/s, v_num=0, train_loss_step=0.875, train_loss_epoch=0.875]\n",
      "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.792, train_loss_epoch=0.792]        \n",
      "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.925, train_loss_epoch=0.925]        \n",
      "Epoch 52: 100%|██████████| 1/1 [00:00<00:00, 64.49it/s, v_num=0, train_loss_step=0.836, train_loss_epoch=0.716]\n",
      "Epoch 52: 100%|██████████| 1/1 [00:00<00:00, 57.92it/s, v_num=0, train_loss_step=0.836, train_loss_epoch=0.836]\n",
      "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.836, train_loss_epoch=0.836]        \n",
      "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.726, train_loss_epoch=0.726]        \n",
      "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.629, train_loss_epoch=0.629]         \n",
      "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.711, train_loss_epoch=0.711]        \n",
      "Epoch 73: 100%|██████████| 1/1 [00:00<00:00, 60.57it/s, v_num=0, train_loss_step=0.962, train_loss_epoch=0.962] \n",
      "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.962, train_loss_epoch=0.962]        \n",
      "Epoch 79: 100%|██████████| 1/1 [00:00<00:00, 95.31it/s, v_num=0, train_loss_step=0.873, train_loss_epoch=0.873] \n",
      "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.728, train_loss_epoch=0.728]         \n",
      "Epoch 90: 100%|██████████| 1/1 [00:00<00:00, 56.06it/s, v_num=0, train_loss_step=0.714, train_loss_epoch=0.714]\n",
      "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.714, train_loss_epoch=0.714]        \n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00, 72.02it/s, v_num=0, train_loss_step=0.616, train_loss_epoch=0.616]\n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00, 53.59it/s, v_num=0, train_loss_step=0.720, train_loss_epoch=0.720]\n",
      "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.720, train_loss_epoch=0.720]        \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 57.64it/s, v_num=0, train_loss_step=0.664, train_loss_epoch=0.675]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 43.46it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=9194)\u001b[0m \n",
      "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569, valid_loss=0.129]        \n",
      "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.129]        \n",
      "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.881, train_loss_epoch=0.881, valid_loss=0.129]        \n",
      "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.675, train_loss_epoch=0.675, valid_loss=0.129]         \n",
      "Epoch 126: 100%|██████████| 1/1 [00:00<00:00, 57.18it/s, v_num=0, train_loss_step=0.693, train_loss_epoch=0.652, valid_loss=0.129] \n",
      "Epoch 126: 100%|██████████| 1/1 [00:00<00:00, 53.88it/s, v_num=0, train_loss_step=0.693, train_loss_epoch=0.693, valid_loss=0.129]\n",
      "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.693, train_loss_epoch=0.693, valid_loss=0.129]        \n",
      "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.721, train_loss_epoch=0.721, valid_loss=0.129]        \n",
      "Epoch 132: 100%|██████████| 1/1 [00:00<00:00, 92.84it/s, v_num=0, train_loss_step=0.721, train_loss_epoch=0.721, valid_loss=0.129]\n",
      "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=0.129]        \n",
      "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.129]        \n",
      "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.613, train_loss_epoch=0.613, valid_loss=0.129]         \n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00, 64.23it/s, v_num=0, train_loss_step=0.613, train_loss_epoch=0.613, valid_loss=0.129]\n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00, 53.29it/s, v_num=0, train_loss_step=0.641, train_loss_epoch=0.613, valid_loss=0.129]\n",
      "Epoch 148: 100%|██████████| 1/1 [00:00<00:00, 50.57it/s, v_num=0, train_loss_step=0.641, train_loss_epoch=0.641, valid_loss=0.129]\n",
      "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.641, train_loss_epoch=0.641, valid_loss=0.129]        \n",
      "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.678, train_loss_epoch=0.678, valid_loss=0.129]        \n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00, 57.71it/s, v_num=0, train_loss_step=0.579, train_loss_epoch=0.579, valid_loss=0.129]\n",
      "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.579, train_loss_epoch=0.579, valid_loss=0.129]        \n",
      "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.475, train_loss_epoch=0.475, valid_loss=0.129]         \n",
      "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.965, train_loss_epoch=0.965, valid_loss=0.129]        \n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00, 94.76it/s, v_num=0, train_loss_step=0.660, train_loss_epoch=0.660, valid_loss=0.129]\n",
      "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.632, train_loss_epoch=0.632, valid_loss=0.129]        \n",
      "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.751, train_loss_epoch=0.751, valid_loss=0.129]        \n",
      "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.747, train_loss_epoch=0.747, valid_loss=0.129]        \n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00, 78.79it/s, v_num=0, train_loss_step=0.888, train_loss_epoch=0.888, valid_loss=0.129]\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 56.11it/s, v_num=0, train_loss_step=0.724, train_loss_epoch=0.764, valid_loss=0.129]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 36.13it/s]\u001b[A\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 16.93it/s, v_num=0, train_loss_step=0.724, train_loss_epoch=0.764, valid_loss=0.0592]\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 16.58it/s, v_num=0, train_loss_step=0.724, train_loss_epoch=0.724, valid_loss=0.0592]\n",
      "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.724, train_loss_epoch=0.724, valid_loss=0.0592]        \n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00, 80.60it/s, v_num=0, train_loss_step=0.760, train_loss_epoch=0.760, valid_loss=0.0592]\n",
      "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.813, train_loss_epoch=0.813, valid_loss=0.0592]        \n",
      "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.0592]        \n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00, 77.65it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.0592]\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00, 59.74it/s, v_num=0, train_loss_step=0.857, train_loss_epoch=1.000, valid_loss=0.0592]\n",
      "Epoch 216: 100%|██████████| 1/1 [00:00<00:00, 57.05it/s, v_num=0, train_loss_step=0.857, train_loss_epoch=0.857, valid_loss=0.0592]\n",
      "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.857, train_loss_epoch=0.857, valid_loss=0.0592]        \n",
      "Epoch 222: 100%|██████████| 1/1 [00:00<00:00, 80.35it/s, v_num=0, train_loss_step=0.691, train_loss_epoch=0.691, valid_loss=0.0592] \n",
      "Epoch 222: 100%|██████████| 1/1 [00:00<00:00, 59.15it/s, v_num=0, train_loss_step=0.813, train_loss_epoch=0.691, valid_loss=0.0592]\n",
      "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.813, train_loss_epoch=0.813, valid_loss=0.0592]        \n",
      "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.813, train_loss_epoch=0.813, valid_loss=0.0592]\n",
      "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.644, train_loss_epoch=0.644, valid_loss=0.0592]        \n",
      "Epoch 228: 100%|██████████| 1/1 [00:00<00:00, 97.05it/s, v_num=0, train_loss_step=0.644, train_loss_epoch=0.644, valid_loss=0.0592]\n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00, 74.78it/s, v_num=0, train_loss_step=0.374, train_loss_epoch=0.374, valid_loss=0.0592]\n",
      "Epoch 233: 100%|██████████| 1/1 [00:00<00:00, 53.02it/s, v_num=0, train_loss_step=0.586, train_loss_epoch=0.586, valid_loss=0.0592]\n",
      "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.586, train_loss_epoch=0.586, valid_loss=0.0592]        \n",
      "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.677, train_loss_epoch=0.677, valid_loss=0.0592]        \n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00, 73.73it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0592]\n",
      "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.0592]        \n",
      "Epoch 253: 100%|██████████| 1/1 [00:00<00:00, 48.41it/s, v_num=0, train_loss_step=0.853, train_loss_epoch=0.853, valid_loss=0.0592]\n",
      "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.853, train_loss_epoch=0.853, valid_loss=0.0592]        \n",
      "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.771, train_loss_epoch=0.771, valid_loss=0.0592]        \n",
      "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.691, train_loss_epoch=0.691, valid_loss=0.0592]        \n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00, 70.84it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=0.0592]\n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00, 52.74it/s, v_num=0, train_loss_step=0.660, train_loss_epoch=0.660, valid_loss=0.0592]\n",
      "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.660, train_loss_epoch=0.660, valid_loss=0.0592]        \n",
      "Epoch 273: 100%|██████████| 1/1 [00:00<00:00, 61.68it/s, v_num=0, train_loss_step=0.853, train_loss_epoch=0.853, valid_loss=0.0592]\n",
      "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.786, train_loss_epoch=0.786, valid_loss=0.0592]        \n",
      "Epoch 278: 100%|██████████| 1/1 [00:00<00:00, 67.31it/s, v_num=0, train_loss_step=0.786, train_loss_epoch=0.786, valid_loss=0.0592]\n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00, 68.51it/s, v_num=0, train_loss_step=0.617, train_loss_epoch=0.617, valid_loss=0.0592]\n",
      "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.376, train_loss_epoch=0.376, valid_loss=0.0592]        \n",
      "Epoch 293: 100%|██████████| 1/1 [00:00<00:00, 100.87it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.945, valid_loss=0.0592]\n",
      "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.941, train_loss_epoch=0.941, valid_loss=0.0592]         \n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 54.72it/s, v_num=0, train_loss_step=0.678, train_loss_epoch=0.941, valid_loss=0.0592]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 38.29it/s]\u001b[A\n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00, 58.75it/s, v_num=0, train_loss_step=0.676, train_loss_epoch=0.676, valid_loss=0.0438]\n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00, 46.69it/s, v_num=0, train_loss_step=0.625, train_loss_epoch=0.625, valid_loss=0.0438]\n",
      "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.625, train_loss_epoch=0.625, valid_loss=0.0438]        \n",
      "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.613, train_loss_epoch=0.613, valid_loss=0.0438]        \n",
      "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.763, train_loss_epoch=0.763, valid_loss=0.0438]        \n",
      "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.422, train_loss_epoch=0.422, valid_loss=0.0438]        \n",
      "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.661, train_loss_epoch=0.661, valid_loss=0.0438]        \n",
      "Epoch 321: 100%|██████████| 1/1 [00:00<00:00, 64.36it/s, v_num=0, train_loss_step=0.661, train_loss_epoch=0.661, valid_loss=0.0438]\n",
      "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.0438]        \n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00, 71.17it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.0438]\n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00, 55.70it/s, v_num=0, train_loss_step=0.712, train_loss_epoch=1.020, valid_loss=0.0438]\n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00, 52.98it/s, v_num=0, train_loss_step=0.712, train_loss_epoch=0.712, valid_loss=0.0438]\n",
      "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.712, train_loss_epoch=0.712, valid_loss=0.0438]        \n",
      "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.378, valid_loss=0.0438]        \n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00, 90.46it/s, v_num=0, train_loss_step=0.475, train_loss_epoch=0.475, valid_loss=0.0438]\n",
      "Epoch 336: 100%|██████████| 1/1 [00:00<00:00, 61.15it/s, v_num=0, train_loss_step=0.724, train_loss_epoch=0.724, valid_loss=0.0438]\n",
      "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.724, train_loss_epoch=0.724, valid_loss=0.0438]        \n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00, 87.20it/s, v_num=0, train_loss_step=0.672, train_loss_epoch=0.672, valid_loss=0.0438]\n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00, 42.41it/s, v_num=0, train_loss_step=0.613, train_loss_epoch=0.625, valid_loss=0.0438]\n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00, 39.87it/s, v_num=0, train_loss_step=0.613, train_loss_epoch=0.613, valid_loss=0.0438]\n",
      "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.613, train_loss_epoch=0.613, valid_loss=0.0438]        \n",
      "Epoch 352: 100%|██████████| 1/1 [00:00<00:00, 47.12it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.945, valid_loss=0.0438]\n",
      "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.945, valid_loss=0.0438]        \n",
      "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.0438]        \n",
      "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.644, train_loss_epoch=0.644, valid_loss=0.0438]        \n",
      "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.706, train_loss_epoch=0.706, valid_loss=0.0438]        \n",
      "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.746, train_loss_epoch=0.746, valid_loss=0.0438]         \n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00, 53.00it/s, v_num=0, train_loss_step=0.644, train_loss_epoch=0.644, valid_loss=0.0438]\n",
      "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.644, train_loss_epoch=0.644, valid_loss=0.0438]        \n",
      "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.775, train_loss_epoch=0.775, valid_loss=0.0438]        \n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00, 91.04it/s, v_num=0, train_loss_step=0.775, train_loss_epoch=0.775, valid_loss=0.0438]\n",
      "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.779, train_loss_epoch=0.779, valid_loss=0.0438]        \n",
      "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.664, train_loss_epoch=0.664, valid_loss=0.0438]        \n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 60.66it/s, v_num=0, train_loss_step=0.842, train_loss_epoch=0.664, valid_loss=0.0438]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 41.07it/s]\u001b[A\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00, 69.15it/s, v_num=0, train_loss_step=0.760, train_loss_epoch=0.760, valid_loss=0.0363]\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00, 51.21it/s, v_num=0, train_loss_step=0.683, train_loss_epoch=0.760, valid_loss=0.0363]\n",
      "Epoch 401: 100%|██████████| 1/1 [00:00<00:00, 48.87it/s, v_num=0, train_loss_step=0.683, train_loss_epoch=0.683, valid_loss=0.0363]\n",
      "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.683, train_loss_epoch=0.683, valid_loss=0.0363]        \n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00, 55.68it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.454, valid_loss=0.0363]\n",
      "Epoch 406: 100%|██████████| 1/1 [00:00<00:00, 47.74it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.0363]\n",
      "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.0363]        \n",
      "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.673, train_loss_epoch=0.673, valid_loss=0.0363]        \n",
      "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.776, train_loss_epoch=0.776, valid_loss=0.0363]        \n",
      "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.623, train_loss_epoch=0.623, valid_loss=0.0363]        \n",
      "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561, valid_loss=0.0363]        \n",
      "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.646, train_loss_epoch=0.646, valid_loss=0.0363]         \n",
      "Epoch 430: 100%|██████████| 1/1 [00:00<00:00, 49.42it/s, v_num=0, train_loss_step=0.644, train_loss_epoch=0.644, valid_loss=0.0363]\n",
      "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.644, train_loss_epoch=0.644, valid_loss=0.0363]        \n",
      "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.427, train_loss_epoch=0.427, valid_loss=0.0363]        \n",
      "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.613, train_loss_epoch=0.613, valid_loss=0.0363]        \n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00, 71.18it/s, v_num=0, train_loss_step=0.710, train_loss_epoch=0.710, valid_loss=0.0363]\n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00, 53.11it/s, v_num=0, train_loss_step=0.615, train_loss_epoch=0.710, valid_loss=0.0363]\n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00, 50.11it/s, v_num=0, train_loss_step=0.615, train_loss_epoch=0.615, valid_loss=0.0363]\n",
      "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.615, train_loss_epoch=0.615, valid_loss=0.0363]        \n",
      "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.655, train_loss_epoch=0.655, valid_loss=0.0363]        \n",
      "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.698, train_loss_epoch=0.698, valid_loss=0.0363]        \n",
      "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0363]        \n",
      "Epoch 463: 100%|██████████| 1/1 [00:00<00:00, 86.98it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.416, valid_loss=0.0363]\n",
      "Epoch 468: 100%|██████████| 1/1 [00:00<00:00, 46.35it/s, v_num=0, train_loss_step=0.658, train_loss_epoch=0.658, valid_loss=0.0363]\n",
      "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.658, train_loss_epoch=0.658, valid_loss=0.0363]        \n",
      "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.837, train_loss_epoch=0.837, valid_loss=0.0363]        \n",
      "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.831, train_loss_epoch=0.831, valid_loss=0.0363]        \n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00, 85.08it/s, v_num=0, train_loss_step=0.831, train_loss_epoch=0.831, valid_loss=0.0363]\n",
      "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.678, train_loss_epoch=0.678, valid_loss=0.0363]        \n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00, 74.76it/s, v_num=0, train_loss_step=0.660, train_loss_epoch=0.660, valid_loss=0.0363]\n",
      "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.631, train_loss_epoch=0.631, valid_loss=0.0363]        \n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 56.66it/s, v_num=0, train_loss_step=0.749, train_loss_epoch=0.627, valid_loss=0.0363]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=9194)\u001b[0m `Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=9194)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 41.08it/s]\u001b[A\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 16.93it/s, v_num=0, train_loss_step=0.749, train_loss_epoch=0.749, valid_loss=0.0889]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=9316)\u001b[0m /home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=9316)\u001b[0m Seed set to 13\n",
      "\u001b[36m(_train_tune pid=9316)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=9316)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=9316)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=9316)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(_train_tune pid=9316)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=9316)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=9316)\u001b[0m   | Name            | Type          | Params | Mode \n",
      "\u001b[36m(_train_tune pid=9316)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=9316)\u001b[0m 0 | loss            | WMAPE         | 0      | train\n",
      "\u001b[36m(_train_tune pid=9316)\u001b[0m 1 | padder          | ConstantPad1d | 0      | train\n",
      "\u001b[36m(_train_tune pid=9316)\u001b[0m 2 | scaler          | TemporalNorm  | 0      | train\n",
      "\u001b[36m(_train_tune pid=9316)\u001b[0m 3 | hist_encoder    | LSTM          | 51.4 K | train\n",
      "\u001b[36m(_train_tune pid=9316)\u001b[0m 4 | context_adapter | Linear        | 196 K  | train\n",
      "\u001b[36m(_train_tune pid=9316)\u001b[0m 5 | mlp_decoder     | MLP           | 3.3 K  | train\n",
      "\u001b[36m(_train_tune pid=9316)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=9316)\u001b[0m 251 K     Trainable params\n",
      "\u001b[36m(_train_tune pid=9316)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=9316)\u001b[0m 251 K     Total params\n",
      "\u001b[36m(_train_tune pid=9316)\u001b[0m 1.004     Total estimated model params size (MB)\n",
      "\u001b[36m(_train_tune pid=9316)\u001b[0m 11        Modules in train mode\n",
      "\u001b[36m(_train_tune pid=9316)\u001b[0m 0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060]        \n",
      "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]         \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 85.23it/s, v_num=0, train_loss_step=0.976, train_loss_epoch=1.000]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 81.47it/s, v_num=0, train_loss_step=0.976, train_loss_epoch=0.976]\n",
      "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.976, train_loss_epoch=0.976]       \n",
      "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.940, train_loss_epoch=0.940]         \n",
      "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050]         \n",
      "Epoch 27: 100%|██████████| 1/1 [00:00<00:00, 56.69it/s, v_num=0, train_loss_step=0.932, train_loss_epoch=1.050]\n",
      "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.932, train_loss_epoch=0.932]        \n",
      "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.788, train_loss_epoch=0.788]        \n",
      "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.705, train_loss_epoch=0.705]         \n",
      "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.892, train_loss_epoch=0.892]         \n",
      "Epoch 55: 100%|██████████| 1/1 [00:00<00:00, 86.88it/s, v_num=0, train_loss_step=0.830, train_loss_epoch=0.830] \n",
      "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.830, train_loss_epoch=0.830]        \n",
      "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060]         \n",
      "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060]\n",
      "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.799, train_loss_epoch=0.799]         \n",
      "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.768, train_loss_epoch=0.768]         \n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00, 108.51it/s, v_num=0, train_loss_step=0.768, train_loss_epoch=0.768]\n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00, 97.14it/s, v_num=0, train_loss_step=0.684, train_loss_epoch=0.684] \n",
      "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.684, train_loss_epoch=0.684]        \n",
      "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.686, train_loss_epoch=0.686]         \n",
      "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.691, train_loss_epoch=0.691]        \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 74.00it/s, v_num=0, train_loss_step=0.672, train_loss_epoch=0.691]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 82.62it/s]\u001b[A\n",
      "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.631, train_loss_epoch=0.631, valid_loss=0.116]         \n",
      "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.848, train_loss_epoch=0.848, valid_loss=0.116]         \n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00, 107.71it/s, v_num=0, train_loss_step=0.769, train_loss_epoch=0.769, valid_loss=0.116]\n",
      "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.769, train_loss_epoch=0.769, valid_loss=0.116]         \n",
      "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.635, train_loss_epoch=0.635, valid_loss=0.116]         \n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00, 73.94it/s, v_num=0, train_loss_step=0.786, train_loss_epoch=0.786, valid_loss=0.116]\n",
      "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.786, train_loss_epoch=0.786, valid_loss=0.116]        \n",
      "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.674, train_loss_epoch=0.674, valid_loss=0.116]         \n",
      "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.386, train_loss_epoch=0.386, valid_loss=0.116]         \n",
      "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351, valid_loss=0.116]         \n",
      "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.707, train_loss_epoch=0.707, valid_loss=0.116]         \n",
      "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.938, train_loss_epoch=0.938, valid_loss=0.116]         \n",
      "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.676, train_loss_epoch=0.676, valid_loss=0.116]         \n",
      "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.650, train_loss_epoch=0.650, valid_loss=0.116]         \n",
      "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.675, train_loss_epoch=0.675, valid_loss=0.116]         \n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 100.51it/s, v_num=0, train_loss_step=0.643, train_loss_epoch=0.657, valid_loss=0.116]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 81.92it/s]\u001b[A\n",
      "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.797, train_loss_epoch=0.797, valid_loss=0.182]         \n",
      "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.681, train_loss_epoch=0.681, valid_loss=0.182]         \n",
      "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.782, train_loss_epoch=0.782, valid_loss=0.182]         \n",
      "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.677, train_loss_epoch=0.677, valid_loss=0.182]         \n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00, 92.95it/s, v_num=0, train_loss_step=0.677, train_loss_epoch=0.677, valid_loss=0.182]\n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00, 80.60it/s, v_num=0, train_loss_step=0.728, train_loss_epoch=0.677, valid_loss=0.182]\n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00, 59.23it/s, v_num=0, train_loss_step=0.728, train_loss_epoch=0.728, valid_loss=0.182]\n",
      "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.728, train_loss_epoch=0.728, valid_loss=0.182]        \n",
      "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.182]         \n",
      "Epoch 235: 100%|██████████| 1/1 [00:00<00:00, 101.82it/s, v_num=0, train_loss_step=0.763, train_loss_epoch=0.763, valid_loss=0.182]\n",
      "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.763, train_loss_epoch=0.763, valid_loss=0.182]         \n",
      "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.673, train_loss_epoch=0.673, valid_loss=0.182]         \n",
      "Epoch 253: 100%|██████████| 1/1 [00:00<00:00, 108.13it/s, v_num=0, train_loss_step=0.725, train_loss_epoch=0.725, valid_loss=0.182]\n",
      "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.725, train_loss_epoch=0.725, valid_loss=0.182]         \n",
      "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.440, train_loss_epoch=0.440, valid_loss=0.182]         \n",
      "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.566, train_loss_epoch=0.566, valid_loss=0.182]         \n",
      "Epoch 271: 100%|██████████| 1/1 [00:00<00:00, 117.51it/s, v_num=0, train_loss_step=0.566, train_loss_epoch=0.566, valid_loss=0.182]\n",
      "Epoch 271: 100%|██████████| 1/1 [00:00<00:00, 107.88it/s, v_num=0, train_loss_step=0.656, train_loss_epoch=0.656, valid_loss=0.182]\n",
      "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.656, train_loss_epoch=0.656, valid_loss=0.182]         \n",
      "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.660, train_loss_epoch=0.660, valid_loss=0.182]         \n",
      "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.750, train_loss_epoch=0.750, valid_loss=0.182]         \n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 126.61it/s, v_num=0, train_loss_step=0.667, train_loss_epoch=0.820, valid_loss=0.182]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=9316)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 91.65it/s]\u001b[A\n",
      "Epoch 308: 100%|██████████| 1/1 [00:00<00:00, 131.62it/s, v_num=0, train_loss_step=0.685, train_loss_epoch=0.685, valid_loss=0.108]\n",
      "Epoch 308: 100%|██████████| 1/1 [00:00<00:00, 115.77it/s, v_num=0, train_loss_step=0.754, train_loss_epoch=0.754, valid_loss=0.108]\n",
      "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.754, train_loss_epoch=0.754, valid_loss=0.108]         \n",
      "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.661, train_loss_epoch=0.661, valid_loss=0.108]         \n",
      "Epoch 328: 100%|██████████| 1/1 [00:00<00:00, 104.39it/s, v_num=0, train_loss_step=0.627, train_loss_epoch=0.627, valid_loss=0.108]\n",
      "Epoch 328: 100%|██████████| 1/1 [00:00<00:00, 96.42it/s, v_num=0, train_loss_step=0.711, train_loss_epoch=0.711, valid_loss=0.108] \n",
      "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.711, train_loss_epoch=0.711, valid_loss=0.108]        \n",
      "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.616, train_loss_epoch=0.616, valid_loss=0.108]         \n",
      "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.877, train_loss_epoch=0.877, valid_loss=0.108]         \n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00, 124.52it/s, v_num=0, train_loss_step=0.618, train_loss_epoch=0.618, valid_loss=0.108]\n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00, 113.66it/s, v_num=0, train_loss_step=0.618, train_loss_epoch=0.618, valid_loss=0.108]\n",
      "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.618, train_loss_epoch=0.618, valid_loss=0.108]         \n",
      "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.651, train_loss_epoch=0.651, valid_loss=0.108]         \n",
      "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.662, train_loss_epoch=0.662, valid_loss=0.108]         \n",
      "Epoch 377: 100%|██████████| 1/1 [00:00<00:00, 117.63it/s, v_num=0, train_loss_step=0.662, train_loss_epoch=0.662, valid_loss=0.108]\n",
      "Epoch 377: 100%|██████████| 1/1 [00:00<00:00, 105.80it/s, v_num=0, train_loss_step=0.665, train_loss_epoch=0.665, valid_loss=0.108]\n",
      "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.665, train_loss_epoch=0.665, valid_loss=0.108]         \n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00, 108.96it/s, v_num=0, train_loss_step=0.832, train_loss_epoch=0.832, valid_loss=0.108]\n",
      "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.832, train_loss_epoch=0.832, valid_loss=0.108]         \n",
      "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.664, train_loss_epoch=0.664, valid_loss=0.108]         \n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 108.26it/s, v_num=0, train_loss_step=0.712, train_loss_epoch=0.432, valid_loss=0.108]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 86.27it/s]\u001b[A\n",
      "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.804, train_loss_epoch=0.804, valid_loss=0.0471]        \n",
      "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.817, train_loss_epoch=0.817, valid_loss=0.0471]         \n",
      "Epoch 411: 100%|██████████| 1/1 [00:00<00:00, 113.43it/s, v_num=0, train_loss_step=0.754, train_loss_epoch=0.817, valid_loss=0.0471]\n",
      "Epoch 411: 100%|██████████| 1/1 [00:00<00:00, 101.28it/s, v_num=0, train_loss_step=0.754, train_loss_epoch=0.754, valid_loss=0.0471]\n",
      "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.754, train_loss_epoch=0.754, valid_loss=0.0471]         \n",
      "Epoch 421: 100%|██████████| 1/1 [00:00<00:00, 86.49it/s, v_num=0, train_loss_step=0.632, train_loss_epoch=0.632, valid_loss=0.0471] \n",
      "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.632, train_loss_epoch=0.632, valid_loss=0.0471]        \n",
      "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.796, train_loss_epoch=0.796, valid_loss=0.0471]         \n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00, 99.20it/s, v_num=0, train_loss_step=0.782, train_loss_epoch=0.782, valid_loss=0.0471] \n",
      "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.782, train_loss_epoch=0.782, valid_loss=0.0471]        \n",
      "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.772, train_loss_epoch=0.772, valid_loss=0.0471]         \n",
      "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.692, train_loss_epoch=0.692, valid_loss=0.0471]         \n",
      "Epoch 465: 100%|██████████| 1/1 [00:00<00:00, 102.80it/s, v_num=0, train_loss_step=0.444, train_loss_epoch=0.444, valid_loss=0.0471]\n",
      "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.444, train_loss_epoch=0.444, valid_loss=0.0471]         \n",
      "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.803, train_loss_epoch=0.803, valid_loss=0.0471]         \n",
      "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.940, train_loss_epoch=0.940, valid_loss=0.0471]         \n",
      "Epoch 480: 100%|██████████| 1/1 [00:00<00:00, 88.68it/s, v_num=0, train_loss_step=0.752, train_loss_epoch=0.752, valid_loss=0.0471]\n",
      "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.752, train_loss_epoch=0.752, valid_loss=0.0471]        \n",
      "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.752, train_loss_epoch=0.752, valid_loss=0.0471]\n",
      "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.605, train_loss_epoch=0.605, valid_loss=0.0471]         \n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00, 80.43it/s, v_num=0, train_loss_step=0.637, train_loss_epoch=0.605, valid_loss=0.0471]\n",
      "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.637, train_loss_epoch=0.637, valid_loss=0.0471]        \n",
      "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.637, train_loss_epoch=0.637, valid_loss=0.0471]\n",
      "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.769, train_loss_epoch=0.769, valid_loss=0.0471]         \n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 104.82it/s, v_num=0, train_loss_step=0.645, train_loss_epoch=0.974, valid_loss=0.0471]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 89.78it/s]\u001b[A\n",
      "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.758, train_loss_epoch=0.758, valid_loss=0.0503]         \n",
      "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.752, train_loss_epoch=0.752, valid_loss=0.0503]         \n",
      "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.797, train_loss_epoch=0.797, valid_loss=0.0503]         \n",
      "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.710, train_loss_epoch=0.710, valid_loss=0.0503]         \n",
      "Epoch 529: 100%|██████████| 1/1 [00:00<00:00, 84.16it/s, v_num=0, train_loss_step=0.710, train_loss_epoch=0.710, valid_loss=0.0503]\n",
      "Epoch 529: 100%|██████████| 1/1 [00:00<00:00, 77.99it/s, v_num=0, train_loss_step=0.622, train_loss_epoch=0.622, valid_loss=0.0503]\n",
      "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.622, train_loss_epoch=0.622, valid_loss=0.0503]        \n",
      "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.807, train_loss_epoch=0.807, valid_loss=0.0503]         \n",
      "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.683, train_loss_epoch=0.683, valid_loss=0.0503]         \n",
      "Epoch 558: 100%|██████████| 1/1 [00:00<00:00, 76.67it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=0.0503] \n",
      "Epoch 558: 100%|██████████| 1/1 [00:00<00:00, 70.86it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=0.0503]\n",
      "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=0.0503]        \n",
      "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.801, train_loss_epoch=0.801, valid_loss=0.0503]         \n",
      "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.974, train_loss_epoch=0.974, valid_loss=0.0503]        \n",
      "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.807, train_loss_epoch=0.807, valid_loss=0.0503]         \n",
      "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0503]         \n",
      "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.793, train_loss_epoch=0.793, valid_loss=0.0503]         \n",
      "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 111.66it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.635, valid_loss=0.0503]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 79.70it/s]\u001b[A\n",
      "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.642, train_loss_epoch=0.642, valid_loss=0.0534]         \n",
      "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.696, train_loss_epoch=0.696, valid_loss=0.0534]         \n",
      "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.621, train_loss_epoch=0.621, valid_loss=0.0534]         \n",
      "Epoch 625: 100%|██████████| 1/1 [00:00<00:00, 120.40it/s, v_num=0, train_loss_step=0.621, train_loss_epoch=0.621, valid_loss=0.0534]\n",
      "Epoch 625: 100%|██████████| 1/1 [00:00<00:00, 111.08it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.991, valid_loss=0.0534]\n",
      "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.991, valid_loss=0.0534]         \n",
      "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.630, train_loss_epoch=0.630, valid_loss=0.0534]         \n",
      "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.630, train_loss_epoch=0.630, valid_loss=0.0534]         \n",
      "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.427, train_loss_epoch=0.427, valid_loss=0.0534]         \n",
      "Epoch 661: 100%|██████████| 1/1 [00:00<00:00, 91.19it/s, v_num=0, train_loss_step=0.623, train_loss_epoch=0.623, valid_loss=0.0534] \n",
      "Epoch 661: 100%|██████████| 1/1 [00:00<00:00, 83.50it/s, v_num=0, train_loss_step=0.782, train_loss_epoch=0.782, valid_loss=0.0534]\n",
      "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.782, train_loss_epoch=0.782, valid_loss=0.0534]        \n",
      "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.738, train_loss_epoch=0.738, valid_loss=0.0534]         \n",
      "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.610, train_loss_epoch=0.610, valid_loss=0.0534]         \n",
      "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.681, train_loss_epoch=0.681, valid_loss=0.0534]         \n",
      "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.655, train_loss_epoch=0.655, valid_loss=0.0534]         \n",
      "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 118.53it/s, v_num=0, train_loss_step=0.649, train_loss_epoch=0.661, valid_loss=0.0534]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 90.43it/s]\u001b[A\n",
      "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.616, train_loss_epoch=0.616, valid_loss=0.0505]         \n",
      "Epoch 715: 100%|██████████| 1/1 [00:00<00:00, 104.05it/s, v_num=0, train_loss_step=0.874, train_loss_epoch=0.874, valid_loss=0.0505]\n",
      "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.874, train_loss_epoch=0.874, valid_loss=0.0505]         \n",
      "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.609, train_loss_epoch=0.609, valid_loss=0.0505]         \n",
      "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.597, train_loss_epoch=0.597, valid_loss=0.0505]         \n",
      "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.617, train_loss_epoch=0.617, valid_loss=0.0505]         \n",
      "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.723, train_loss_epoch=0.723, valid_loss=0.0505]         \n",
      "Epoch 763: 100%|██████████| 1/1 [00:00<00:00, 81.31it/s, v_num=0, train_loss_step=0.615, train_loss_epoch=0.615, valid_loss=0.0505] \n",
      "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.615, train_loss_epoch=0.615, valid_loss=0.0505]        \n",
      "Epoch 773:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.629, train_loss_epoch=0.629, valid_loss=0.0505]         \n",
      "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.584, train_loss_epoch=0.584, valid_loss=0.0505]         \n",
      "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.762, train_loss_epoch=0.762, valid_loss=0.0505]         \n",
      "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 123.30it/s, v_num=0, train_loss_step=0.976, train_loss_epoch=0.678, valid_loss=0.0505]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=9316)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 68.64it/s]\u001b[A\n",
      "Epoch 808:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.736, train_loss_epoch=0.736, valid_loss=0.0373]         \n",
      "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=0.914, valid_loss=0.0373]         \n",
      "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.829, train_loss_epoch=0.829, valid_loss=0.0373]         \n",
      "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.598, train_loss_epoch=0.598, valid_loss=0.0373]         \n",
      "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.623, train_loss_epoch=0.623, valid_loss=0.0373]         \n",
      "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.689, train_loss_epoch=0.689, valid_loss=0.0373]         \n",
      "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0373]         \n",
      "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.700, train_loss_epoch=0.700, valid_loss=0.0373]         \n",
      "Epoch 872: 100%|██████████| 1/1 [00:00<00:00, 89.30it/s, v_num=0, train_loss_step=0.670, train_loss_epoch=0.700, valid_loss=0.0373]\n",
      "Epoch 872: 100%|██████████| 1/1 [00:00<00:00, 83.23it/s, v_num=0, train_loss_step=0.670, train_loss_epoch=0.670, valid_loss=0.0373]\n",
      "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.670, train_loss_epoch=0.670, valid_loss=0.0373]        \n",
      "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.644, train_loss_epoch=0.644, valid_loss=0.0373]         \n",
      "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.587, train_loss_epoch=0.587, valid_loss=0.0373]         \n",
      "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 111.76it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.590, valid_loss=0.0373]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 87.57it/s]\u001b[A\n",
      "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0492]         \n",
      "Epoch 909:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.654, train_loss_epoch=0.654, valid_loss=0.0492]         \n",
      "Epoch 916:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.748, train_loss_epoch=0.748, valid_loss=0.0492]         \n",
      "Epoch 916: 100%|██████████| 1/1 [00:00<00:00, 108.07it/s, v_num=0, train_loss_step=0.649, train_loss_epoch=0.649, valid_loss=0.0492]\n",
      "Epoch 917:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.649, train_loss_epoch=0.649, valid_loss=0.0492]         \n",
      "Epoch 927:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.374, train_loss_epoch=0.374, valid_loss=0.0492]         \n",
      "Epoch 937:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.624, train_loss_epoch=0.624, valid_loss=0.0492]         \n",
      "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0492]         \n",
      "Epoch 946: 100%|██████████| 1/1 [00:00<00:00, 106.48it/s, v_num=0, train_loss_step=0.657, train_loss_epoch=0.657, valid_loss=0.0492]\n",
      "Epoch 947:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.657, train_loss_epoch=0.657, valid_loss=0.0492]         \n",
      "Epoch 956:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.720, train_loss_epoch=0.720, valid_loss=0.0492]         \n",
      "Epoch 965:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.657, train_loss_epoch=0.657, valid_loss=0.0492]         \n",
      "Epoch 974: 100%|██████████| 1/1 [00:00<00:00, 115.73it/s, v_num=0, train_loss_step=0.669, train_loss_epoch=0.832, valid_loss=0.0492]\n",
      "Epoch 974: 100%|██████████| 1/1 [00:00<00:00, 107.97it/s, v_num=0, train_loss_step=0.669, train_loss_epoch=0.669, valid_loss=0.0492]\n",
      "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.669, train_loss_epoch=0.669, valid_loss=0.0492]         \n",
      "Epoch 983: 100%|██████████| 1/1 [00:00<00:00, 95.55it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.389, valid_loss=0.0492] \n",
      "Epoch 984:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.389, valid_loss=0.0492]        \n",
      "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.806, train_loss_epoch=0.806, valid_loss=0.0492]         \n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 122.14it/s, v_num=0, train_loss_step=0.587, train_loss_epoch=0.538, valid_loss=0.0492]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 88.99it/s]\u001b[A\n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 32.92it/s, v_num=0, train_loss_step=0.587, train_loss_epoch=0.587, valid_loss=0.175]  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=9316)\u001b[0m `Trainer.fit` stopped: `max_steps=1000` reached.\n",
      "\u001b[36m(_train_tune pid=9441)\u001b[0m /home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=9441)\u001b[0m Seed set to 1\n",
      "\u001b[36m(_train_tune pid=9441)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=9441)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=9441)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=9441)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(_train_tune pid=9441)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_train_tune pid=9441)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=9441)\u001b[0m   | Name            | Type          | Params | Mode \n",
      "\u001b[36m(_train_tune pid=9441)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=9441)\u001b[0m 0 | loss            | WMAPE         | 0      | train\n",
      "\u001b[36m(_train_tune pid=9441)\u001b[0m 1 | padder          | ConstantPad1d | 0      | train\n",
      "\u001b[36m(_train_tune pid=9441)\u001b[0m 2 | scaler          | TemporalNorm  | 0      | train\n",
      "\u001b[36m(_train_tune pid=9441)\u001b[0m 3 | hist_encoder    | LSTM          | 484 K  | train\n",
      "\u001b[36m(_train_tune pid=9441)\u001b[0m 4 | context_adapter | Linear        | 154 K  | train\n",
      "\u001b[36m(_train_tune pid=9441)\u001b[0m 5 | mlp_decoder     | MLP           | 769    | train\n",
      "\u001b[36m(_train_tune pid=9441)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=9441)\u001b[0m 639 K     Trainable params\n",
      "\u001b[36m(_train_tune pid=9441)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=9441)\u001b[0m 639 K     Total params\n",
      "\u001b[36m(_train_tune pid=9441)\u001b[0m 2.558     Total estimated model params size (MB)\n",
      "\u001b[36m(_train_tune pid=9441)\u001b[0m 11        Modules in train mode\n",
      "\u001b[36m(_train_tune pid=9441)\u001b[0m 0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00,  8.37it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00,  8.17it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=1.000]\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00,  8.12it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997]\n",
      "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997]        \n",
      "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.921, train_loss_epoch=0.921]        \n",
      "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.846, train_loss_epoch=0.846]        \n",
      "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590]        \n",
      "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330]        \n",
      "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050]        \n",
      "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.927, train_loss_epoch=0.927]        \n",
      "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.908, train_loss_epoch=0.908]        \n",
      "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.906, train_loss_epoch=0.906]       \n",
      "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.902, train_loss_epoch=0.902]        \n",
      "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.872, train_loss_epoch=0.872]        \n",
      "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.906, train_loss_epoch=0.906]        \n",
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.836, train_loss_epoch=0.836]        \n",
      "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.875, train_loss_epoch=0.875]        \n",
      "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.817, train_loss_epoch=0.817]        \n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s, v_num=0, train_loss_step=0.817, train_loss_epoch=0.817]\n",
      "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.807, train_loss_epoch=0.807]        \n",
      "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.752, train_loss_epoch=0.752]        \n",
      "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.797, train_loss_epoch=0.797]        \n",
      "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.861, train_loss_epoch=0.861]        \n",
      "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.867, train_loss_epoch=0.867]        \n",
      "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.854, train_loss_epoch=0.854]        \n",
      "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.812, train_loss_epoch=0.812]        \n",
      "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.780, train_loss_epoch=0.780]        \n",
      "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.749, train_loss_epoch=0.749]        \n",
      "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.889, train_loss_epoch=0.889]        \n",
      "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.793, train_loss_epoch=0.793]        \n",
      "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.723, train_loss_epoch=0.723]        \n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00,  8.78it/s, v_num=0, train_loss_step=0.729, train_loss_epoch=0.729]\n",
      "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.729, train_loss_epoch=0.729]        \n",
      "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.700, train_loss_epoch=0.700]        \n",
      "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.682, train_loss_epoch=0.682]        \n",
      "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.716, train_loss_epoch=0.716]        \n",
      "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.610, train_loss_epoch=0.610]        \n",
      "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.721, train_loss_epoch=0.721]        \n",
      "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.588, train_loss_epoch=0.588]        \n",
      "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.600, train_loss_epoch=0.600]        \n",
      "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.675, train_loss_epoch=0.675]        \n",
      "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.628, train_loss_epoch=0.628]        \n",
      "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.660, train_loss_epoch=0.660]        \n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00,  9.39it/s, v_num=0, train_loss_step=0.712, train_loss_epoch=0.660]\n",
      "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.712, train_loss_epoch=0.712]        \n",
      "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.712, train_loss_epoch=0.712]        \n",
      "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.707, train_loss_epoch=0.707]        \n",
      "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.681, train_loss_epoch=0.681]        \n",
      "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.683, train_loss_epoch=0.683]        \n",
      "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.657, train_loss_epoch=0.657]        \n",
      "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.675, train_loss_epoch=0.675]        \n",
      "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.651, train_loss_epoch=0.651]        \n",
      "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.662, train_loss_epoch=0.662]        \n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00,  8.93it/s, v_num=0, train_loss_step=0.662, train_loss_epoch=0.662]\n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00,  8.59it/s, v_num=0, train_loss_step=0.641, train_loss_epoch=0.662]\n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00,  8.52it/s, v_num=0, train_loss_step=0.641, train_loss_epoch=0.641]\n",
      "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.641, train_loss_epoch=0.641]        \n",
      "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.685, train_loss_epoch=0.685]        \n",
      "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.690, train_loss_epoch=0.690]        \n",
      "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.663, train_loss_epoch=0.663]        \n",
      "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.657, train_loss_epoch=0.657]        \n",
      "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.638, train_loss_epoch=0.638]        \n",
      "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.695, train_loss_epoch=0.695]        \n",
      "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.589, train_loss_epoch=0.589]        \n",
      "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.622, train_loss_epoch=0.622]        \n",
      "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.708, train_loss_epoch=0.708]        \n",
      "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.700, train_loss_epoch=0.700]        \n",
      "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.682, train_loss_epoch=0.682]        \n",
      "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.669, train_loss_epoch=0.669]        \n",
      "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.657, train_loss_epoch=0.657]        \n",
      "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.685, train_loss_epoch=0.685]        \n",
      "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.641, train_loss_epoch=0.641]        \n",
      "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.642, train_loss_epoch=0.642]        \n",
      "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.705, train_loss_epoch=0.705]        \n",
      "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.721, train_loss_epoch=0.721]        \n",
      "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.696, train_loss_epoch=0.696]        \n",
      "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.630, train_loss_epoch=0.630]        \n",
      "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.675, train_loss_epoch=0.675]        \n",
      "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.701, train_loss_epoch=0.701]        \n",
      "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.641, train_loss_epoch=0.641]        \n",
      "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.592, train_loss_epoch=0.592]        \n",
      "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573]        \n",
      "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.717, train_loss_epoch=0.717]        \n",
      "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.604, train_loss_epoch=0.604]        \n",
      "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.716, train_loss_epoch=0.716]        \n",
      "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.687, train_loss_epoch=0.687]        \n",
      "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.696, train_loss_epoch=0.696]        \n",
      "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.645, train_loss_epoch=0.645]        \n",
      "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.652, train_loss_epoch=0.652]        \n",
      "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.634, train_loss_epoch=0.634]        \n",
      "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.689, train_loss_epoch=0.689]        \n",
      "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.630, train_loss_epoch=0.630]        \n",
      "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.718, train_loss_epoch=0.718]        \n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00,  8.38it/s, v_num=0, train_loss_step=0.718, train_loss_epoch=0.718]\n",
      "Epoch 85: 100%|██████████| 1/1 [00:00<00:00,  8.16it/s, v_num=0, train_loss_step=0.604, train_loss_epoch=0.604]\n",
      "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.604, train_loss_epoch=0.604]        \n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00,  9.82it/s, v_num=0, train_loss_step=0.604, train_loss_epoch=0.604]\n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00,  9.46it/s, v_num=0, train_loss_step=0.622, train_loss_epoch=0.622]\n",
      "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.622, train_loss_epoch=0.622]        \n",
      "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554]        \n",
      "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.702, train_loss_epoch=0.702]        \n",
      "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.668, train_loss_epoch=0.668]        \n",
      "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.596, train_loss_epoch=0.596]        \n",
      "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.646, train_loss_epoch=0.646]        \n",
      "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.690, train_loss_epoch=0.690]        \n",
      "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.668, train_loss_epoch=0.668]        \n",
      "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571]        \n",
      "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542]        \n",
      "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557]        \n",
      "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.613, train_loss_epoch=0.613]        \n",
      "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532]        \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  8.49it/s, v_num=0, train_loss_step=0.600, train_loss_epoch=0.532]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=9441)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  8.48it/s]\u001b[A\n",
      "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.600, train_loss_epoch=0.600, valid_loss=0.0324]       \n",
      "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.598, train_loss_epoch=0.598, valid_loss=0.0324]        \n",
      "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.713, train_loss_epoch=0.713, valid_loss=0.0324]        \n",
      "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.660, train_loss_epoch=0.660, valid_loss=0.0324]        \n",
      "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.685, train_loss_epoch=0.685, valid_loss=0.0324]        \n",
      "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.676, train_loss_epoch=0.676, valid_loss=0.0324]        \n",
      "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.688, train_loss_epoch=0.688, valid_loss=0.0324]        \n",
      "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.659, train_loss_epoch=0.659, valid_loss=0.0324]        \n",
      "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.671, train_loss_epoch=0.671, valid_loss=0.0324]        \n",
      "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.667, train_loss_epoch=0.667, valid_loss=0.0324]        \n",
      "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.668, train_loss_epoch=0.668, valid_loss=0.0324]        \n",
      "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.623, train_loss_epoch=0.623, valid_loss=0.0324]        \n",
      "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.663, train_loss_epoch=0.663, valid_loss=0.0324]        \n",
      "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.646, train_loss_epoch=0.646, valid_loss=0.0324]        \n",
      "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.644, train_loss_epoch=0.644, valid_loss=0.0324]        \n",
      "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.664, train_loss_epoch=0.664, valid_loss=0.0324]        \n",
      "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.617, train_loss_epoch=0.617, valid_loss=0.0324]        \n",
      "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.636, train_loss_epoch=0.636, valid_loss=0.0324]        \n",
      "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.612, train_loss_epoch=0.612, valid_loss=0.0324]        \n",
      "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.666, train_loss_epoch=0.666, valid_loss=0.0324]        \n",
      "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.621, train_loss_epoch=0.621, valid_loss=0.0324]        \n",
      "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.640, train_loss_epoch=0.640, valid_loss=0.0324]        \n",
      "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.657, train_loss_epoch=0.657, valid_loss=0.0324]        \n",
      "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.590, train_loss_epoch=0.590, valid_loss=0.0324]        \n",
      "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.619, train_loss_epoch=0.619, valid_loss=0.0324]        \n",
      "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.608, train_loss_epoch=0.608, valid_loss=0.0324]        \n",
      "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=0.0324]        \n",
      "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.0324]        \n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00,  8.57it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.0324]\n",
      "Epoch 127: 100%|██████████| 1/1 [00:00<00:00,  8.32it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.0324]\n",
      "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.0324]        \n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00,  9.74it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.0324]\n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00,  9.39it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.537, valid_loss=0.0324]\n",
      "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.0324]        \n",
      "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.692, train_loss_epoch=0.692, valid_loss=0.0324]        \n",
      "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.642, train_loss_epoch=0.642, valid_loss=0.0324]        \n",
      "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.673, train_loss_epoch=0.673, valid_loss=0.0324]        \n",
      "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.666, train_loss_epoch=0.666, valid_loss=0.0324]        \n",
      "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.628, train_loss_epoch=0.628, valid_loss=0.0324]        \n",
      "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.649, train_loss_epoch=0.649, valid_loss=0.0324]        \n",
      "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.648, train_loss_epoch=0.648, valid_loss=0.0324]        \n",
      "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.677, train_loss_epoch=0.677, valid_loss=0.0324]        \n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00,  8.04it/s, v_num=0, train_loss_step=0.624, train_loss_epoch=0.624, valid_loss=0.0324]\n",
      "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.624, train_loss_epoch=0.624, valid_loss=0.0324]        \n",
      "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.607, train_loss_epoch=0.607, valid_loss=0.0324]        \n",
      "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582, valid_loss=0.0324]        \n",
      "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.683, train_loss_epoch=0.683, valid_loss=0.0324]        \n",
      "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.622, train_loss_epoch=0.622, valid_loss=0.0324]        \n",
      "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.686, train_loss_epoch=0.686, valid_loss=0.0324]        \n",
      "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0324]        \n",
      "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.598, train_loss_epoch=0.598, valid_loss=0.0324]        \n",
      "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.658, train_loss_epoch=0.658, valid_loss=0.0324]        \n",
      "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0324]        \n",
      "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0324]        \n",
      "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.635, train_loss_epoch=0.635, valid_loss=0.0324]        \n",
      "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.632, train_loss_epoch=0.632, valid_loss=0.0324]        \n",
      "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.0324]        \n",
      "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.649, train_loss_epoch=0.649, valid_loss=0.0324]        \n",
      "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.682, train_loss_epoch=0.682, valid_loss=0.0324]        \n",
      "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.651, train_loss_epoch=0.651, valid_loss=0.0324]        \n",
      "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.586, train_loss_epoch=0.586, valid_loss=0.0324]        \n",
      "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.645, train_loss_epoch=0.645, valid_loss=0.0324]        \n",
      "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.654, train_loss_epoch=0.654, valid_loss=0.0324]        \n",
      "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.665, train_loss_epoch=0.665, valid_loss=0.0324]        \n",
      "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582, valid_loss=0.0324]        \n",
      "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.643, train_loss_epoch=0.643, valid_loss=0.0324]        \n",
      "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.641, train_loss_epoch=0.641, valid_loss=0.0324]        \n",
      "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.618, train_loss_epoch=0.618, valid_loss=0.0324]        \n",
      "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0324]        \n",
      "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.625, train_loss_epoch=0.625, valid_loss=0.0324]        \n",
      "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.637, train_loss_epoch=0.637, valid_loss=0.0324]        \n",
      "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.604, train_loss_epoch=0.604, valid_loss=0.0324]        \n",
      "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0324]        \n",
      "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.643, train_loss_epoch=0.643, valid_loss=0.0324]        \n",
      "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563, valid_loss=0.0324]        \n",
      "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0324]        \n",
      "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.621, train_loss_epoch=0.621, valid_loss=0.0324]        \n",
      "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.607, train_loss_epoch=0.607, valid_loss=0.0324]        \n",
      "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.615, train_loss_epoch=0.615, valid_loss=0.0324]        \n",
      "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.617, train_loss_epoch=0.617, valid_loss=0.0324]        \n",
      "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.618, train_loss_epoch=0.618, valid_loss=0.0324]        \n",
      "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0324]        \n",
      "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.642, train_loss_epoch=0.642, valid_loss=0.0324]        \n",
      "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582, valid_loss=0.0324]        \n",
      "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.617, train_loss_epoch=0.617, valid_loss=0.0324]        \n",
      "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.622, train_loss_epoch=0.622, valid_loss=0.0324]        \n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s, v_num=0, train_loss_step=0.622, train_loss_epoch=0.622, valid_loss=0.0324]\n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00,  7.28it/s, v_num=0, train_loss_step=0.621, train_loss_epoch=0.621, valid_loss=0.0324]\n",
      "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.621, train_loss_epoch=0.621, valid_loss=0.0324]        \n",
      "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.660, train_loss_epoch=0.660, valid_loss=0.0324]        \n",
      "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.628, train_loss_epoch=0.628, valid_loss=0.0324]        \n",
      "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.632, train_loss_epoch=0.632, valid_loss=0.0324]        \n",
      "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573, valid_loss=0.0324]        \n",
      "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.664, train_loss_epoch=0.664, valid_loss=0.0324]        \n",
      "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.720, train_loss_epoch=0.720, valid_loss=0.0324]        \n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00,  9.53it/s, v_num=0, train_loss_step=0.720, train_loss_epoch=0.720, valid_loss=0.0324]\n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00,  9.19it/s, v_num=0, train_loss_step=0.587, train_loss_epoch=0.587, valid_loss=0.0324]\n",
      "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.587, train_loss_epoch=0.587, valid_loss=0.0324]        \n",
      "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.706, train_loss_epoch=0.706, valid_loss=0.0324]        \n",
      "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.654, train_loss_epoch=0.654, valid_loss=0.0324]        \n",
      "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.701, train_loss_epoch=0.701, valid_loss=0.0324]        \n",
      "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.590, train_loss_epoch=0.590, valid_loss=0.0324]        \n",
      "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.583, train_loss_epoch=0.583, valid_loss=0.0324]        \n",
      "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.669, train_loss_epoch=0.669, valid_loss=0.0324]        \n",
      "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0324]        \n",
      "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.673, train_loss_epoch=0.673, valid_loss=0.0324]        \n",
      "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.600, train_loss_epoch=0.600, valid_loss=0.0324]        \n",
      "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.657, train_loss_epoch=0.657, valid_loss=0.0324]        \n",
      "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=0.0324]        \n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  7.76it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.558, valid_loss=0.0324]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=9441)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 13.27it/s]\u001b[A\n",
      "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562, valid_loss=0.0533]        \n",
      "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0533]        \n",
      "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0533]        \n",
      "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.668, train_loss_epoch=0.668, valid_loss=0.0533]        \n",
      "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0533]        \n",
      "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.639, train_loss_epoch=0.639, valid_loss=0.0533]        \n",
      "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.632, train_loss_epoch=0.632, valid_loss=0.0533]        \n",
      "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.657, train_loss_epoch=0.657, valid_loss=0.0533]        \n",
      "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.641, train_loss_epoch=0.641, valid_loss=0.0533]        \n",
      "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.624, train_loss_epoch=0.624, valid_loss=0.0533]        \n",
      "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.634, train_loss_epoch=0.634, valid_loss=0.0533]        \n",
      "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.635, train_loss_epoch=0.635, valid_loss=0.0533]        \n",
      "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.624, train_loss_epoch=0.624, valid_loss=0.0533]        \n",
      "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.656, train_loss_epoch=0.656, valid_loss=0.0533]        \n",
      "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.629, train_loss_epoch=0.629, valid_loss=0.0533]        \n",
      "Epoch 214: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s, v_num=0, train_loss_step=0.629, train_loss_epoch=0.629, valid_loss=0.0533]\n",
      "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.595, train_loss_epoch=0.595, valid_loss=0.0533]        \n",
      "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=0.0533]        \n",
      "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.633, train_loss_epoch=0.633, valid_loss=0.0533]        \n",
      "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568, valid_loss=0.0533]        \n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s, v_num=0, train_loss_step=0.632, train_loss_epoch=0.516, valid_loss=0.0533]\n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00,  8.94it/s, v_num=0, train_loss_step=0.632, train_loss_epoch=0.632, valid_loss=0.0533]\n",
      "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.632, train_loss_epoch=0.632, valid_loss=0.0533]        \n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00,  9.61it/s, v_num=0, train_loss_step=0.632, train_loss_epoch=0.632, valid_loss=0.0533]\n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00,  9.30it/s, v_num=0, train_loss_step=0.630, train_loss_epoch=0.630, valid_loss=0.0533]\n",
      "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.630, train_loss_epoch=0.630, valid_loss=0.0533]        \n",
      "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.623, train_loss_epoch=0.623, valid_loss=0.0533]        \n",
      "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.620, train_loss_epoch=0.620, valid_loss=0.0533]        \n",
      "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.604, train_loss_epoch=0.604, valid_loss=0.0533]        \n",
      "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.608, train_loss_epoch=0.608, valid_loss=0.0533]        \n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00,  9.08it/s, v_num=0, train_loss_step=0.598, train_loss_epoch=0.608, valid_loss=0.0533]\n",
      "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.598, train_loss_epoch=0.598, valid_loss=0.0533]        \n",
      "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.599, train_loss_epoch=0.599, valid_loss=0.0533]        \n",
      "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.605, train_loss_epoch=0.605, valid_loss=0.0533]        \n",
      "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0533]        \n",
      "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.606, train_loss_epoch=0.606, valid_loss=0.0533]        \n",
      "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0533]        \n",
      "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.591, train_loss_epoch=0.591, valid_loss=0.0533]        \n",
      "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.592, train_loss_epoch=0.592, valid_loss=0.0533]        \n",
      "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0533]        \n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0533]\n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00,  8.68it/s, v_num=0, train_loss_step=0.577, train_loss_epoch=0.502, valid_loss=0.0533]\n",
      "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.577, train_loss_epoch=0.577, valid_loss=0.0533]        \n",
      "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0533]        \n",
      "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.616, train_loss_epoch=0.616, valid_loss=0.0533]        \n",
      "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=0.0533]        \n",
      "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0533]        \n",
      "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.616, train_loss_epoch=0.616, valid_loss=0.0533]        \n",
      "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0533]        \n",
      "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.601, train_loss_epoch=0.601, valid_loss=0.0533]        \n",
      "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0533]        \n",
      "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0533]        \n",
      "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.597, train_loss_epoch=0.597, valid_loss=0.0533]        \n",
      "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.0533]        \n",
      "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0533]        \n",
      "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0533]        \n",
      "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.605, train_loss_epoch=0.605, valid_loss=0.0533]        \n",
      "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0533]        \n",
      "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0533]        \n",
      "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0533]        \n",
      "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0533]        \n",
      "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0533]        \n",
      "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568, valid_loss=0.0533]        \n",
      "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.0533]        \n",
      "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0533]        \n",
      "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0533]        \n",
      "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.421, train_loss_epoch=0.421, valid_loss=0.0533]        \n",
      "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0533]        \n",
      "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=0.0533]        \n",
      "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.416, valid_loss=0.0533]        \n",
      "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0533]        \n",
      "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.423, train_loss_epoch=0.423, valid_loss=0.0533]        \n",
      "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.475, train_loss_epoch=0.475, valid_loss=0.0533]        \n",
      "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.585, train_loss_epoch=0.585, valid_loss=0.0533]        \n",
      "Epoch 266: 100%|██████████| 1/1 [00:00<00:00,  8.40it/s, v_num=0, train_loss_step=0.585, train_loss_epoch=0.585, valid_loss=0.0533]\n",
      "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.957, train_loss_epoch=0.957, valid_loss=0.0533]        \n",
      "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.589, train_loss_epoch=0.589, valid_loss=0.0533]        \n",
      "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.612, train_loss_epoch=0.612, valid_loss=0.0533]        \n",
      "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.623, train_loss_epoch=0.623, valid_loss=0.0533]        \n",
      "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0533]        \n",
      "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.0533]        \n",
      "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.586, train_loss_epoch=0.586, valid_loss=0.0533]        \n",
      "Epoch 273: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s, v_num=0, train_loss_step=0.586, train_loss_epoch=0.586, valid_loss=0.0533]\n",
      "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.572, valid_loss=0.0533]        \n",
      "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.597, train_loss_epoch=0.597, valid_loss=0.0533]        \n",
      "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582, valid_loss=0.0533]        \n",
      "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574, valid_loss=0.0533]        \n",
      "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567, valid_loss=0.0533]        \n",
      "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.0533]        \n",
      "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0533]        \n",
      "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.0533]        \n",
      "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0533]        \n",
      "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.453, train_loss_epoch=0.453, valid_loss=0.0533]        \n",
      "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.0533]        \n",
      "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0533]        \n",
      "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0533]        \n",
      "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=0.0533]        \n",
      "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0533]        \n",
      "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.441, train_loss_epoch=0.441, valid_loss=0.0533]        \n",
      "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0533]        \n",
      "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0533]        \n",
      "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.439, train_loss_epoch=0.439, valid_loss=0.0533]        \n",
      "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.609, train_loss_epoch=0.609, valid_loss=0.0533]        \n",
      "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=0.0533]        \n",
      "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0533]        \n",
      "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.0533]        \n",
      "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.811, train_loss_epoch=0.811, valid_loss=0.0533]        \n",
      "Epoch 297: 100%|██████████| 1/1 [00:00<00:00,  5.99it/s, v_num=0, train_loss_step=0.811, train_loss_epoch=0.811, valid_loss=0.0533]\n",
      "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.804, train_loss_epoch=0.804, valid_loss=0.0533]        \n",
      "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.0533]        \n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=0, train_loss_step=0.727, train_loss_epoch=1.090, valid_loss=0.0533]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=9441)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  9.41it/s]\u001b[A\n",
      "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.727, train_loss_epoch=0.727, valid_loss=0.200]         \n",
      "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.751, train_loss_epoch=0.751, valid_loss=0.200]        \n",
      "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.746, train_loss_epoch=0.746, valid_loss=0.200]        \n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00,  9.43it/s, v_num=0, train_loss_step=0.758, train_loss_epoch=0.758, valid_loss=0.200]\n",
      "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.758, train_loss_epoch=0.758, valid_loss=0.200]        \n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00,  9.53it/s, v_num=0, train_loss_step=0.758, train_loss_epoch=0.758, valid_loss=0.200]\n",
      "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.724, train_loss_epoch=0.724, valid_loss=0.200]        \n",
      "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.699, train_loss_epoch=0.699, valid_loss=0.200]        \n",
      "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.697, train_loss_epoch=0.697, valid_loss=0.200]        \n",
      "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.718, train_loss_epoch=0.718, valid_loss=0.200]        \n",
      "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.707, train_loss_epoch=0.707, valid_loss=0.200]        \n",
      "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.691, train_loss_epoch=0.691, valid_loss=0.200]        \n",
      "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.678, train_loss_epoch=0.678, valid_loss=0.200]        \n",
      "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.676, train_loss_epoch=0.676, valid_loss=0.200]        \n",
      "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.677, train_loss_epoch=0.677, valid_loss=0.200]        \n",
      "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.677, train_loss_epoch=0.677, valid_loss=0.200]        \n",
      "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.659, train_loss_epoch=0.659, valid_loss=0.200]        \n",
      "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.651, train_loss_epoch=0.651, valid_loss=0.200]        \n",
      "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.660, train_loss_epoch=0.660, valid_loss=0.200]        \n",
      "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.642, train_loss_epoch=0.642, valid_loss=0.200]        \n",
      "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.629, train_loss_epoch=0.629, valid_loss=0.200]        \n",
      "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.650, train_loss_epoch=0.650, valid_loss=0.200]        \n",
      "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.612, train_loss_epoch=0.612, valid_loss=0.200]        \n",
      "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.629, train_loss_epoch=0.629, valid_loss=0.200]        \n",
      "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.627, train_loss_epoch=0.627, valid_loss=0.200]        \n",
      "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.649, train_loss_epoch=0.649, valid_loss=0.200]        \n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00,  9.09it/s, v_num=0, train_loss_step=0.628, train_loss_epoch=0.628, valid_loss=0.200]\n",
      "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.628, train_loss_epoch=0.628, valid_loss=0.200]        \n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00,  9.77it/s, v_num=0, train_loss_step=0.628, train_loss_epoch=0.628, valid_loss=0.200]\n",
      "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.610, train_loss_epoch=0.610, valid_loss=0.200]        \n",
      "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.577, train_loss_epoch=0.577, valid_loss=0.200]        \n",
      "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.611, train_loss_epoch=0.611, valid_loss=0.200]        \n",
      "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.650, train_loss_epoch=0.650, valid_loss=0.200]        \n",
      "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.706, train_loss_epoch=0.706, valid_loss=0.200]        \n",
      "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.712, train_loss_epoch=0.712, valid_loss=0.200]        \n",
      "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.853, train_loss_epoch=0.853, valid_loss=0.200]        \n",
      "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.695, train_loss_epoch=0.695, valid_loss=0.200]        \n",
      "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.755, train_loss_epoch=0.755, valid_loss=0.200]        \n",
      "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.791, train_loss_epoch=0.791, valid_loss=0.200]        \n",
      "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.680, train_loss_epoch=0.680, valid_loss=0.200]        \n",
      "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.692, train_loss_epoch=0.692, valid_loss=0.200]        \n",
      "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.646, train_loss_epoch=0.646, valid_loss=0.200]        \n",
      "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.680, train_loss_epoch=0.680, valid_loss=0.200]        \n",
      "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.654, train_loss_epoch=0.654, valid_loss=0.200]        \n",
      "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.643, train_loss_epoch=0.643, valid_loss=0.200]        \n",
      "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.628, train_loss_epoch=0.628, valid_loss=0.200]        \n",
      "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.642, train_loss_epoch=0.642, valid_loss=0.200]        \n",
      "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.644, train_loss_epoch=0.644, valid_loss=0.200]        \n",
      "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.635, train_loss_epoch=0.635, valid_loss=0.200]        \n",
      "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.626, train_loss_epoch=0.626, valid_loss=0.200]        \n",
      "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.590, train_loss_epoch=0.590, valid_loss=0.200]        \n",
      "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.632, train_loss_epoch=0.632, valid_loss=0.200]        \n",
      "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.626, train_loss_epoch=0.626, valid_loss=0.200]        \n",
      "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565, valid_loss=0.200]        \n",
      "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.610, train_loss_epoch=0.610, valid_loss=0.200]        \n",
      "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.200]        \n",
      "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.626, train_loss_epoch=0.626, valid_loss=0.200]        \n",
      "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.608, train_loss_epoch=0.608, valid_loss=0.200]        \n",
      "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.604, train_loss_epoch=0.604, valid_loss=0.200]        \n",
      "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.200]        \n",
      "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.615, train_loss_epoch=0.615, valid_loss=0.200]        \n",
      "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.633, train_loss_epoch=0.633, valid_loss=0.200]        \n",
      "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.595, train_loss_epoch=0.595, valid_loss=0.200]        \n",
      "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=0.200]        \n",
      "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568, valid_loss=0.200]        \n",
      "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.587, train_loss_epoch=0.587, valid_loss=0.200]        \n",
      "Epoch 361: 100%|██████████| 1/1 [00:00<00:00,  9.56it/s, v_num=0, train_loss_step=0.587, train_loss_epoch=0.587, valid_loss=0.200]\n",
      "Epoch 361: 100%|██████████| 1/1 [00:00<00:00,  9.20it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.587, valid_loss=0.200]\n",
      "Epoch 361: 100%|██████████| 1/1 [00:00<00:00,  9.14it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.200]\n",
      "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.200]        \n",
      "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582, valid_loss=0.200]        \n",
      "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.200]        \n",
      "Epoch 364: 100%|██████████| 1/1 [00:00<00:00,  9.44it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.506, valid_loss=0.200]\n",
      "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.200]        \n",
      "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569, valid_loss=0.200]        \n",
      "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.200]        \n",
      "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567, valid_loss=0.200]        \n",
      "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.474, train_loss_epoch=0.474, valid_loss=0.200]        \n",
      "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.435, train_loss_epoch=0.435, valid_loss=0.200]        \n",
      "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.591, train_loss_epoch=0.591, valid_loss=0.200]        \n",
      "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.422, train_loss_epoch=0.422, valid_loss=0.200]        \n",
      "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=0.200]        \n",
      "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.447, train_loss_epoch=0.447, valid_loss=0.200]        \n",
      "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.419, train_loss_epoch=0.419, valid_loss=0.200]        \n",
      "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.200]        \n",
      "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.200]        \n",
      "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.731, train_loss_epoch=0.731, valid_loss=0.200]        \n",
      "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.716, train_loss_epoch=0.716, valid_loss=0.200]        \n",
      "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.649, train_loss_epoch=0.649, valid_loss=0.200]        \n",
      "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.586, train_loss_epoch=0.586, valid_loss=0.200]        \n",
      "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.788, train_loss_epoch=0.788, valid_loss=0.200]        \n",
      "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.763, train_loss_epoch=0.763, valid_loss=0.200]        \n",
      "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.695, train_loss_epoch=0.695, valid_loss=0.200]        \n",
      "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.691, train_loss_epoch=0.691, valid_loss=0.200]        \n",
      "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.711, train_loss_epoch=0.711, valid_loss=0.200]        \n",
      "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.709, train_loss_epoch=0.709, valid_loss=0.200]        \n",
      "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.697, train_loss_epoch=0.697, valid_loss=0.200]        \n",
      "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.676, train_loss_epoch=0.676, valid_loss=0.200]        \n",
      "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.664, train_loss_epoch=0.664, valid_loss=0.200]        \n",
      "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.640, train_loss_epoch=0.640, valid_loss=0.200]        \n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00,  9.12it/s, v_num=0, train_loss_step=0.620, train_loss_epoch=0.640, valid_loss=0.200]\n",
      "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.620, train_loss_epoch=0.620, valid_loss=0.200]        \n",
      "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.631, train_loss_epoch=0.631, valid_loss=0.200]        \n",
      "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.672, train_loss_epoch=0.672, valid_loss=0.200]        \n",
      "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.653, train_loss_epoch=0.653, valid_loss=0.200]        \n",
      "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.656, train_loss_epoch=0.656, valid_loss=0.200]        \n",
      "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.590, train_loss_epoch=0.590, valid_loss=0.200]        \n",
      "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.566, train_loss_epoch=0.566, valid_loss=0.200]        \n",
      "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.580, train_loss_epoch=0.580, valid_loss=0.200]        \n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  8.61it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.580, valid_loss=0.200]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 14.21it/s]\u001b[A\n",
      "                                                                      \u001b[A\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0361]\n",
      "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0361]        \n",
      "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.663, train_loss_epoch=0.663, valid_loss=0.0361]        \n",
      "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.609, train_loss_epoch=0.609, valid_loss=0.0361]        \n",
      "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.585, train_loss_epoch=0.585, valid_loss=0.0361]        \n",
      "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.0361]        \n",
      "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0361]        \n",
      "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=0.0361]        \n",
      "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.607, train_loss_epoch=0.607, valid_loss=0.0361]        \n",
      "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.645, train_loss_epoch=0.645, valid_loss=0.0361]        \n",
      "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0361]        \n",
      "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0361]        \n",
      "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.621, train_loss_epoch=0.621, valid_loss=0.0361]        \n",
      "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0361]        \n",
      "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.0361]        \n",
      "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.590, train_loss_epoch=0.590, valid_loss=0.0361]        \n",
      "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=0.0361]        \n",
      "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.605, train_loss_epoch=0.605, valid_loss=0.0361]        \n",
      "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.575, train_loss_epoch=0.575, valid_loss=0.0361]        \n",
      "Epoch 418: 100%|██████████| 1/1 [00:00<00:00,  9.19it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.513, valid_loss=0.0361]\n",
      "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=0.0361]        \n",
      "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0361]        \n",
      "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.0361]        \n",
      "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0361]        \n",
      "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0361]        \n",
      "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.597, train_loss_epoch=0.597, valid_loss=0.0361]        \n",
      "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.443, train_loss_epoch=0.443, valid_loss=0.0361]        \n",
      "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.596, train_loss_epoch=0.596, valid_loss=0.0361]        \n",
      "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.638, train_loss_epoch=0.638, valid_loss=0.0361]        \n",
      "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.635, train_loss_epoch=0.635, valid_loss=0.0361]        \n",
      "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.576, train_loss_epoch=0.576, valid_loss=0.0361]        \n",
      "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.682, train_loss_epoch=0.682, valid_loss=0.0361]        \n",
      "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.691, train_loss_epoch=0.691, valid_loss=0.0361]        \n",
      "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.653, train_loss_epoch=0.653, valid_loss=0.0361]        \n",
      "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.709, train_loss_epoch=0.709, valid_loss=0.0361]        \n",
      "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0361]        \n",
      "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.612, train_loss_epoch=0.612, valid_loss=0.0361]        \n",
      "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.642, train_loss_epoch=0.642, valid_loss=0.0361]        \n",
      "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.0361]        \n",
      "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.657, train_loss_epoch=0.657, valid_loss=0.0361]        \n",
      "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.634, train_loss_epoch=0.634, valid_loss=0.0361]        \n",
      "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0361]        \n",
      "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.612, train_loss_epoch=0.612, valid_loss=0.0361]        \n",
      "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0361]        \n",
      "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.618, train_loss_epoch=0.618, valid_loss=0.0361]        \n",
      "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.614, train_loss_epoch=0.614, valid_loss=0.0361]        \n",
      "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.610, train_loss_epoch=0.610, valid_loss=0.0361]        \n",
      "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.602, train_loss_epoch=0.602, valid_loss=0.0361]        \n",
      "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0361]        \n",
      "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.615, train_loss_epoch=0.615, valid_loss=0.0361]        \n",
      "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.635, train_loss_epoch=0.635, valid_loss=0.0361]        \n",
      "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.609, train_loss_epoch=0.609, valid_loss=0.0361]        \n",
      "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.579, train_loss_epoch=0.579, valid_loss=0.0361]        \n",
      "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0361]        \n",
      "Epoch 452: 100%|██████████| 1/1 [00:00<00:00,  8.44it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0361]\n",
      "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0361]        \n",
      "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0361]        \n",
      "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.629, train_loss_epoch=0.629, valid_loss=0.0361]        \n",
      "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0361]        \n",
      "Epoch 456: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0361]\n",
      "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.0361]        \n",
      "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.593, train_loss_epoch=0.593, valid_loss=0.0361]        \n",
      "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0361]        \n",
      "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.454, train_loss_epoch=0.454, valid_loss=0.0361]        \n",
      "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.606, train_loss_epoch=0.606, valid_loss=0.0361]        \n",
      "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574, valid_loss=0.0361]        \n",
      "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565, valid_loss=0.0361]        \n",
      "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571, valid_loss=0.0361]        \n",
      "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0361]        \n",
      "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0361]        \n",
      "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0361]        \n",
      "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567, valid_loss=0.0361]        \n",
      "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0361]        \n",
      "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0361]        \n",
      "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.588, train_loss_epoch=0.588, valid_loss=0.0361]        \n",
      "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.592, train_loss_epoch=0.592, valid_loss=0.0361]        \n",
      "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.0361]        \n",
      "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.454, train_loss_epoch=0.454, valid_loss=0.0361]        \n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00,  9.16it/s, v_num=0, train_loss_step=0.591, train_loss_epoch=0.591, valid_loss=0.0361]\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00,  8.80it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0361]\n",
      "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0361]        \n",
      "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.601, train_loss_epoch=0.601, valid_loss=0.0361]        \n",
      "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.603, train_loss_epoch=0.603, valid_loss=0.0361]        \n",
      "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471, valid_loss=0.0361]        \n",
      "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=0.0361]        \n",
      "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.585, train_loss_epoch=0.585, valid_loss=0.0361]        \n",
      "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.447, train_loss_epoch=0.447, valid_loss=0.0361]        \n",
      "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.435, train_loss_epoch=0.435, valid_loss=0.0361]        \n",
      "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0361]        \n",
      "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.427, train_loss_epoch=0.427, valid_loss=0.0361]        \n",
      "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0361]        \n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00,  9.68it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.448, valid_loss=0.0361]\n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00,  9.25it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=0.0361]\n",
      "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=0.0361]        \n",
      "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=0.0361]        \n",
      "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.421, train_loss_epoch=0.421, valid_loss=0.0361]        \n",
      "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.449, train_loss_epoch=0.449, valid_loss=0.0361]        \n",
      "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.451, train_loss_epoch=0.451, valid_loss=0.0361]        \n",
      "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.403, train_loss_epoch=0.403, valid_loss=0.0361]        \n",
      "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0361]        \n",
      "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.413, train_loss_epoch=0.413, valid_loss=0.0361]        \n",
      "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0361]        \n",
      "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0361]        \n",
      "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.0361]        \n",
      "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0361]        \n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  8.87it/s, v_num=0, train_loss_step=0.411, train_loss_epoch=0.515, valid_loss=0.0361]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=9441)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 14.36it/s]\u001b[A\n",
      "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.411, train_loss_epoch=0.411, valid_loss=0.0325]        \n",
      "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.389, valid_loss=0.0325]        \n",
      "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.394, train_loss_epoch=0.394, valid_loss=0.0325]        \n",
      "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.400, train_loss_epoch=0.400, valid_loss=0.0325]        \n",
      "Epoch 503: 100%|██████████| 1/1 [00:00<00:00,  9.35it/s, v_num=0, train_loss_step=0.385, train_loss_epoch=0.385, valid_loss=0.0325]\n",
      "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.385, train_loss_epoch=0.385, valid_loss=0.0325]        \n",
      "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.399, train_loss_epoch=0.399, valid_loss=0.0325]        \n",
      "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.619, train_loss_epoch=0.619, valid_loss=0.0325]        \n",
      "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.635, train_loss_epoch=0.635, valid_loss=0.0325]        \n",
      "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.619, train_loss_epoch=0.619, valid_loss=0.0325]        \n",
      "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=0.0325]        \n",
      "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.587, train_loss_epoch=0.587, valid_loss=0.0325]        \n",
      "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0325]        \n",
      "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0325]        \n",
      "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0325]        \n",
      "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573, valid_loss=0.0325]        \n",
      "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.0325]        \n",
      "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0325]        \n",
      "Epoch 516: 100%|██████████| 1/1 [00:00<00:00,  9.27it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0325]\n",
      "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.0325]        \n",
      "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.590, train_loss_epoch=0.590, valid_loss=0.0325]        \n",
      "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455, valid_loss=0.0325]        \n",
      "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571, valid_loss=0.0325]        \n",
      "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0325]        \n",
      "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561, valid_loss=0.0325]        \n",
      "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=0.0325]        \n",
      "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0325]        \n",
      "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0325]        \n",
      "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.0325]        \n",
      "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=0.0325]        \n",
      "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0325]        \n",
      "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0325]        \n",
      "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.465, valid_loss=0.0325]        \n",
      "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0325]        \n",
      "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=0.0325]        \n",
      "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0325]        \n",
      "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0325]        \n",
      "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0325]        \n",
      "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452, valid_loss=0.0325]        \n",
      "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.457, train_loss_epoch=0.457, valid_loss=0.0325]        \n",
      "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.465, valid_loss=0.0325]        \n",
      "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.422, train_loss_epoch=0.422, valid_loss=0.0325]        \n",
      "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.436, train_loss_epoch=0.436, valid_loss=0.0325]        \n",
      "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0325]        \n",
      "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0325]        \n",
      "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0325]        \n",
      "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.420, train_loss_epoch=0.420, valid_loss=0.0325]        \n",
      "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.399, train_loss_epoch=0.399, valid_loss=0.0325]        \n",
      "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=0.0325]        \n",
      "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573, valid_loss=0.0325]        \n",
      "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571, valid_loss=0.0325]        \n",
      "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.600, train_loss_epoch=0.600, valid_loss=0.0325]        \n",
      "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=0.0325]        \n",
      "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.579, train_loss_epoch=0.579, valid_loss=0.0325]        \n",
      "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.590, train_loss_epoch=0.590, valid_loss=0.0325]        \n",
      "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.606, train_loss_epoch=0.606, valid_loss=0.0325]        \n",
      "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.613, train_loss_epoch=0.613, valid_loss=0.0325]        \n",
      "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.581, train_loss_epoch=0.581, valid_loss=0.0325]        \n",
      "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.577, train_loss_epoch=0.577, valid_loss=0.0325]        \n",
      "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0325]        \n",
      "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.580, train_loss_epoch=0.580, valid_loss=0.0325]        \n",
      "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.616, train_loss_epoch=0.616, valid_loss=0.0325]        \n",
      "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0325]        \n",
      "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.584, train_loss_epoch=0.584, valid_loss=0.0325]        \n",
      "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0325]        \n",
      "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0325]        \n",
      "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.645, train_loss_epoch=0.645, valid_loss=0.0325]        \n",
      "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0325]        \n",
      "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0325]        \n",
      "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.613, train_loss_epoch=0.613, valid_loss=0.0325]        \n",
      "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.580, train_loss_epoch=0.580, valid_loss=0.0325]        \n",
      "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0325]        \n",
      "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0325]        \n",
      "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=0.0325]        \n",
      "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.577, train_loss_epoch=0.577, valid_loss=0.0325]        \n",
      "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0325]        \n",
      "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.0325]        \n",
      "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.0325]        \n",
      "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0325]        \n",
      "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0325]        \n",
      "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.451, train_loss_epoch=0.451, valid_loss=0.0325]        \n",
      "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.434, train_loss_epoch=0.434, valid_loss=0.0325]        \n",
      "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0325]        \n",
      "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.0325]        \n",
      "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0325]        \n",
      "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=0.0325]        \n",
      "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.430, train_loss_epoch=0.430, valid_loss=0.0325]        \n",
      "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0325]        \n",
      "Epoch 585: 100%|██████████| 1/1 [00:00<00:00,  9.35it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0325]\n",
      "Epoch 585: 100%|██████████| 1/1 [00:00<00:00,  9.08it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0325]\n",
      "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0325]        \n",
      "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.474, train_loss_epoch=0.474, valid_loss=0.0325]        \n",
      "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.0325]        \n",
      "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0325]        \n",
      "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.474, train_loss_epoch=0.474, valid_loss=0.0325]        \n",
      "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0325]        \n",
      "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0325]        \n",
      "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=0.0325]        \n",
      "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.468, valid_loss=0.0325]        \n",
      "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=0.0325]        \n",
      "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.392, train_loss_epoch=0.392, valid_loss=0.0325]        \n",
      "Epoch 596: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s, v_num=0, train_loss_step=0.392, train_loss_epoch=0.392, valid_loss=0.0325]\n",
      "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.0325]        \n",
      "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0325]        \n",
      "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=0.0325]        \n",
      "Epoch 599: 100%|██████████| 1/1 [00:00<00:00,  7.58it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.377, valid_loss=0.0325]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\u001b[A\n",
      "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0459]        \n",
      "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.454, train_loss_epoch=0.454, valid_loss=0.0459]        \n",
      "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.416, valid_loss=0.0459]        \n",
      "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.0459]        \n",
      "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0459]        \n",
      "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0459]        \n",
      "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0459]        \n",
      "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.401, train_loss_epoch=0.401, valid_loss=0.0459]        \n",
      "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.438, train_loss_epoch=0.438, valid_loss=0.0459]        \n",
      "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=0.0459]        \n",
      "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.428, train_loss_epoch=0.428, valid_loss=0.0459]        \n",
      "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471, valid_loss=0.0459]        \n",
      "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.413, train_loss_epoch=0.413, valid_loss=0.0459]        \n",
      "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351, valid_loss=0.0459]        \n",
      "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.388, train_loss_epoch=0.388, valid_loss=0.0459]        \n",
      "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.411, train_loss_epoch=0.411, valid_loss=0.0459]        \n",
      "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.435, train_loss_epoch=0.435, valid_loss=0.0459]        \n",
      "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.400, train_loss_epoch=0.400, valid_loss=0.0459]        \n",
      "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.362, train_loss_epoch=0.362, valid_loss=0.0459]        \n",
      "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=0.0459]        \n",
      "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.418, train_loss_epoch=0.418, valid_loss=0.0459]        \n",
      "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.456, train_loss_epoch=0.456, valid_loss=0.0459]        \n",
      "Epoch 622:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=0.0459]        \n",
      "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.330, train_loss_epoch=0.330, valid_loss=0.0459]        \n",
      "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.381, train_loss_epoch=0.381, valid_loss=0.0459]        \n",
      "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0459]        \n",
      "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369, valid_loss=0.0459]        \n",
      "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.423, train_loss_epoch=0.423, valid_loss=0.0459]        \n",
      "Epoch 628:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=0.0459]        \n",
      "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.392, train_loss_epoch=0.392, valid_loss=0.0459]        \n",
      "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=0.0459]        \n",
      "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.436, train_loss_epoch=0.436, valid_loss=0.0459]        \n",
      "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=0.0459]        \n",
      "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396, valid_loss=0.0459]        \n",
      "Epoch 633: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s, v_num=0, train_loss_step=0.388, train_loss_epoch=0.396, valid_loss=0.0459]\n",
      "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.388, train_loss_epoch=0.388, valid_loss=0.0459]        \n",
      "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.388, train_loss_epoch=0.388, valid_loss=0.0459]        \n",
      "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.375, train_loss_epoch=0.375, valid_loss=0.0459]        \n",
      "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=0.0459]        \n",
      "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=0.0459]        \n",
      "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=0.0459]        \n",
      "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.390, train_loss_epoch=0.390, valid_loss=0.0459]        \n",
      "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.359, train_loss_epoch=0.359, valid_loss=0.0459]        \n",
      "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.289, valid_loss=0.0459]        \n",
      "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=0.0459]        \n",
      "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=0.0459]        \n",
      "Epoch 644: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=0, train_loss_step=0.408, train_loss_epoch=0.408, valid_loss=0.0459]\n",
      "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.408, train_loss_epoch=0.408, valid_loss=0.0459]        \n",
      "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=0.0459]        \n",
      "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.459, train_loss_epoch=0.459, valid_loss=0.0459]        \n",
      "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.383, train_loss_epoch=0.383, valid_loss=0.0459]        \n",
      "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.438, train_loss_epoch=0.438, valid_loss=0.0459]        \n",
      "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=0.0459]        \n",
      "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=0.0459]        \n",
      "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.427, train_loss_epoch=0.427, valid_loss=0.0459]        \n",
      "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=0.0459]        \n",
      "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=0.0459]        \n",
      "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.414, train_loss_epoch=0.414, valid_loss=0.0459]        \n",
      "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=0.0459]        \n",
      "Epoch 657:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365, valid_loss=0.0459]        \n",
      "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=0.0459]        \n",
      "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.358, train_loss_epoch=0.358, valid_loss=0.0459]        \n",
      "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.378, valid_loss=0.0459]        \n",
      "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.358, train_loss_epoch=0.358, valid_loss=0.0459]        \n",
      "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351, valid_loss=0.0459]        \n",
      "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=0.0459]        \n",
      "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.267, train_loss_epoch=0.267, valid_loss=0.0459]        \n",
      "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.378, valid_loss=0.0459]        \n",
      "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=0.0459]        \n",
      "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.312, train_loss_epoch=0.312, valid_loss=0.0459]        \n",
      "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363, valid_loss=0.0459]        \n",
      "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.383, train_loss_epoch=0.383, valid_loss=0.0459]        \n",
      "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295, valid_loss=0.0459]        \n",
      "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=0.0459]        \n",
      "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=0.0459]        \n",
      "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.258, train_loss_epoch=0.258, valid_loss=0.0459]        \n",
      "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.362, train_loss_epoch=0.362, valid_loss=0.0459]        \n",
      "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.271, train_loss_epoch=0.271, valid_loss=0.0459]        \n",
      "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=0.0459]        \n",
      "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=0.0459]        \n",
      "Epoch 677: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s, v_num=0, train_loss_step=0.238, train_loss_epoch=0.325, valid_loss=0.0459]\n",
      "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.238, train_loss_epoch=0.238, valid_loss=0.0459]        \n",
      "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=0.0459]        \n",
      "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=0.0459]        \n",
      "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=0.0459]        \n",
      "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332, valid_loss=0.0459]        \n",
      "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=0.0459]        \n",
      "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.246, train_loss_epoch=0.246, valid_loss=0.0459]        \n",
      "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=0.0459]        \n",
      "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.225, train_loss_epoch=0.225, valid_loss=0.0459]        \n",
      "Epoch 687: 100%|██████████| 1/1 [00:00<00:00,  9.57it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=0.0459]\n",
      "Epoch 687: 100%|██████████| 1/1 [00:00<00:00,  9.19it/s, v_num=0, train_loss_step=0.231, train_loss_epoch=0.231, valid_loss=0.0459]\n",
      "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.231, train_loss_epoch=0.231, valid_loss=0.0459]        \n",
      "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259, valid_loss=0.0459]        \n",
      "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.258, train_loss_epoch=0.258, valid_loss=0.0459]        \n",
      "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=0.0459]        \n",
      "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.249, train_loss_epoch=0.249, valid_loss=0.0459]        \n",
      "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217, valid_loss=0.0459]        \n",
      "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.376, train_loss_epoch=0.376, valid_loss=0.0459]        \n",
      "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.232, train_loss_epoch=0.232, valid_loss=0.0459]        \n",
      "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295, valid_loss=0.0459]        \n",
      "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=0.0459]        \n",
      "Epoch 697: 100%|██████████| 1/1 [00:00<00:00,  9.31it/s, v_num=0, train_loss_step=0.254, train_loss_epoch=0.339, valid_loss=0.0459]\n",
      "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.254, train_loss_epoch=0.254, valid_loss=0.0459]        \n",
      "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=0.0459]        \n",
      "Epoch 699: 100%|██████████| 1/1 [00:00<00:00,  6.77it/s, v_num=0, train_loss_step=0.279, train_loss_epoch=0.277, valid_loss=0.0459]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=9441)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\u001b[A\n",
      "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.279, train_loss_epoch=0.279, valid_loss=0.0293]        \n",
      "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.234, train_loss_epoch=0.234, valid_loss=0.0293]        \n",
      "Epoch 701: 100%|██████████| 1/1 [00:00<00:00,  9.06it/s, v_num=0, train_loss_step=0.234, train_loss_epoch=0.234, valid_loss=0.0293]\n",
      "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.239, valid_loss=0.0293]        \n",
      "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.300, valid_loss=0.0293]        \n",
      "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=0.0293]        \n",
      "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=0.0293]        \n",
      "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=0.0293]        \n",
      "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=0.0293]        \n",
      "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=0.0293]        \n",
      "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.214, valid_loss=0.0293]        \n",
      "Epoch 709: 100%|██████████| 1/1 [00:00<00:00,  8.86it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.214, valid_loss=0.0293]\n",
      "Epoch 709: 100%|██████████| 1/1 [00:00<00:00,  8.59it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=0.0293]\n",
      "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=0.0293]        \n",
      "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.260, train_loss_epoch=0.260, valid_loss=0.0293]        \n",
      "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.312, train_loss_epoch=0.312, valid_loss=0.0293]        \n",
      "Epoch 712: 100%|██████████| 1/1 [00:00<00:00,  8.96it/s, v_num=0, train_loss_step=0.210, train_loss_epoch=0.312, valid_loss=0.0293]\n",
      "Epoch 712: 100%|██████████| 1/1 [00:00<00:00,  8.91it/s, v_num=0, train_loss_step=0.210, train_loss_epoch=0.210, valid_loss=0.0293]\n",
      "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.210, train_loss_epoch=0.210, valid_loss=0.0293]        \n",
      "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206, valid_loss=0.0293]        \n",
      "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.223, valid_loss=0.0293]        \n",
      "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=0.0293]        \n",
      "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204, valid_loss=0.0293]        \n",
      "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=0.0293]        \n",
      "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=0.0293]        \n",
      "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.210, train_loss_epoch=0.210, valid_loss=0.0293]        \n",
      "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.269, train_loss_epoch=0.269, valid_loss=0.0293]        \n",
      "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=0.0293]        \n",
      "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.200, train_loss_epoch=0.200, valid_loss=0.0293]        \n",
      "Epoch 724:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.232, train_loss_epoch=0.232, valid_loss=0.0293]        \n",
      "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=0.0293]        \n",
      "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=0.0293]        \n",
      "Epoch 726: 100%|██████████| 1/1 [00:00<00:00,  8.77it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=0.0293]\n",
      "Epoch 726: 100%|██████████| 1/1 [00:00<00:00,  8.50it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.261, valid_loss=0.0293]\n",
      "Epoch 726: 100%|██████████| 1/1 [00:00<00:00,  8.45it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.207, valid_loss=0.0293]\n",
      "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.207, valid_loss=0.0293]        \n",
      "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=0.0293]        \n",
      "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=0.0293]        \n",
      "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=0.0293]        \n",
      "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.288, train_loss_epoch=0.288, valid_loss=0.0293]        \n",
      "Epoch 731: 100%|██████████| 1/1 [00:00<00:00,  8.06it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193, valid_loss=0.0293]\n",
      "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193, valid_loss=0.0293]        \n",
      "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=0.0293]        \n",
      "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=0.0293]        \n",
      "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=0.0293]        \n",
      "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=0.0293]        \n",
      "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=0.0293]        \n",
      "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=0.0293]        \n",
      "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190, valid_loss=0.0293]        \n",
      "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.280, train_loss_epoch=0.280, valid_loss=0.0293]        \n",
      "Epoch 740: 100%|██████████| 1/1 [00:00<00:00,  9.58it/s, v_num=0, train_loss_step=0.280, train_loss_epoch=0.280, valid_loss=0.0293]\n",
      "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.250, train_loss_epoch=0.250, valid_loss=0.0293]        \n",
      "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=0.0293]        \n",
      "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=0.0293]        \n",
      "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=0.0293]        \n",
      "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.258, train_loss_epoch=0.258, valid_loss=0.0293]        \n",
      "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.232, train_loss_epoch=0.232, valid_loss=0.0293]        \n",
      "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=0.0293]        \n",
      "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=0.0293]        \n",
      "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=0.0293]        \n",
      "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.227, train_loss_epoch=0.227, valid_loss=0.0293]        \n",
      "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=0.0293]        \n",
      "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276, valid_loss=0.0293]        \n",
      "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=0.0293]        \n",
      "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=0.0293]        \n",
      "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.198, valid_loss=0.0293]        \n",
      "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.280, train_loss_epoch=0.280, valid_loss=0.0293]        \n",
      "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=0.0293]        \n",
      "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.275, valid_loss=0.0293]        \n",
      "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.223, valid_loss=0.0293]        \n",
      "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.267, train_loss_epoch=0.267, valid_loss=0.0293]        \n",
      "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.270, train_loss_epoch=0.270, valid_loss=0.0293]        \n",
      "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=0.0293]        \n",
      "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190, valid_loss=0.0293]        \n",
      "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.226, train_loss_epoch=0.226, valid_loss=0.0293]        \n",
      "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.257, valid_loss=0.0293]        \n",
      "Epoch 766:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=0.0293]        \n",
      "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=0.0293]        \n",
      "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=0.0293]        \n",
      "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=0.0293]        \n",
      "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.286, valid_loss=0.0293]        \n",
      "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=0.0293]        \n",
      "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=0.0293]        \n",
      "Epoch 773:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.249, train_loss_epoch=0.249, valid_loss=0.0293]        \n",
      "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=0.0293]        \n",
      "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=0.0293]        \n",
      "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=0.0293]        \n",
      "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=0.0293]        \n",
      "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.257, valid_loss=0.0293]        \n",
      "Epoch 779:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.232, train_loss_epoch=0.232, valid_loss=0.0293]        \n",
      "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.200, train_loss_epoch=0.200, valid_loss=0.0293]        \n",
      "Epoch 781:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=0.0293]        \n",
      "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.225, train_loss_epoch=0.225, valid_loss=0.0293]        \n",
      "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=0.0293]        \n",
      "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.269, train_loss_epoch=0.269, valid_loss=0.0293]        \n",
      "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=0.0293]        \n",
      "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.275, valid_loss=0.0293]        \n",
      "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.239, valid_loss=0.0293]        \n",
      "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.210, train_loss_epoch=0.210, valid_loss=0.0293]        \n",
      "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.250, train_loss_epoch=0.250, valid_loss=0.0293]        \n",
      "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=0.0293]        \n",
      "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.278, train_loss_epoch=0.278, valid_loss=0.0293]        \n",
      "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=0.0293]        \n",
      "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.231, train_loss_epoch=0.231, valid_loss=0.0293]        \n",
      "Epoch 794:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.258, train_loss_epoch=0.258, valid_loss=0.0293]        \n",
      "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=0.0293]        \n",
      "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=0.0293]        \n",
      "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=0.0293]        \n",
      "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=0.0293]        \n",
      "Epoch 798: 100%|██████████| 1/1 [00:00<00:00,  6.27it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=0.0293]\n",
      "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.170, valid_loss=0.0293]        \n",
      "Epoch 799: 100%|██████████| 1/1 [00:00<00:00,  8.76it/s, v_num=0, train_loss_step=0.240, train_loss_epoch=0.170, valid_loss=0.0293]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 13.82it/s]\u001b[A\n",
      "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.240, train_loss_epoch=0.240, valid_loss=0.0391]        \n",
      "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=0.0391]        \n",
      "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=0.0391]        \n",
      "Epoch 803:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.260, train_loss_epoch=0.260, valid_loss=0.0391]        \n",
      "Epoch 803: 100%|██████████| 1/1 [00:00<00:00,  9.18it/s, v_num=0, train_loss_step=0.260, train_loss_epoch=0.260, valid_loss=0.0391]\n",
      "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=0.0391]        \n",
      "Epoch 805:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.159, train_loss_epoch=0.159, valid_loss=0.0391]        \n",
      "Epoch 805: 100%|██████████| 1/1 [00:00<00:00,  9.05it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.159, valid_loss=0.0391]\n",
      "Epoch 805: 100%|██████████| 1/1 [00:00<00:00,  9.00it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=0.0391]\n",
      "Epoch 806:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=0.0391]        \n",
      "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.207, valid_loss=0.0391]        \n",
      "Epoch 808:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.236, train_loss_epoch=0.236, valid_loss=0.0391]        \n",
      "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.223, valid_loss=0.0391]        \n",
      "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=0.0391]        \n",
      "Epoch 811:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.187, train_loss_epoch=0.187, valid_loss=0.0391]        \n",
      "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=0.0391]        \n",
      "Epoch 813:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=0.0391]        \n",
      "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=0.0391]        \n",
      "Epoch 814: 100%|██████████| 1/1 [00:00<00:00,  5.86it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=0.0391]\n",
      "Epoch 815:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=0.0391]        \n",
      "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216, valid_loss=0.0391]        \n",
      "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=0.0391]        \n",
      "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=0.0391]        \n",
      "Epoch 819:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.231, train_loss_epoch=0.231, valid_loss=0.0391]        \n",
      "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.240, train_loss_epoch=0.240, valid_loss=0.0391]        \n",
      "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=0.0391]        \n",
      "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=0.0391]        \n",
      "Epoch 823:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.243, train_loss_epoch=0.243, valid_loss=0.0391]        \n",
      "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.175, train_loss_epoch=0.175, valid_loss=0.0391]        \n",
      "Epoch 825:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.225, train_loss_epoch=0.225, valid_loss=0.0391]        \n",
      "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.227, train_loss_epoch=0.227, valid_loss=0.0391]        \n",
      "Epoch 827:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.170, valid_loss=0.0391]        \n",
      "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.232, train_loss_epoch=0.232, valid_loss=0.0391]        \n",
      "Epoch 829:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.170, valid_loss=0.0391]        \n",
      "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.157, train_loss_epoch=0.157, valid_loss=0.0391]        \n",
      "Epoch 831:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=0.0391]        \n",
      "Epoch 831: 100%|██████████| 1/1 [00:00<00:00,  8.67it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=0.0391]\n",
      "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=0.0391]        \n",
      "Epoch 833:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=0.0391]        \n",
      "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.149, train_loss_epoch=0.149, valid_loss=0.0391]        \n",
      "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.247, train_loss_epoch=0.247, valid_loss=0.0391]        \n",
      "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.180, train_loss_epoch=0.180, valid_loss=0.0391]        \n",
      "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.155, train_loss_epoch=0.155, valid_loss=0.0391]        \n",
      "Epoch 838:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.158, train_loss_epoch=0.158, valid_loss=0.0391]        \n",
      "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.181, train_loss_epoch=0.181, valid_loss=0.0391]        \n",
      "Epoch 840:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.146, train_loss_epoch=0.146, valid_loss=0.0391]        \n",
      "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=0.0391]        \n",
      "Epoch 842:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217, valid_loss=0.0391]        \n",
      "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.231, train_loss_epoch=0.231, valid_loss=0.0391]        \n",
      "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.232, train_loss_epoch=0.232, valid_loss=0.0391]        \n",
      "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=0.0391]        \n",
      "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.174, valid_loss=0.0391]        \n",
      "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.158, train_loss_epoch=0.158, valid_loss=0.0391]        \n",
      "Epoch 848:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.222, train_loss_epoch=0.222, valid_loss=0.0391]        \n",
      "Epoch 849:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=0.0391]        \n",
      "Epoch 850:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.207, valid_loss=0.0391]        \n",
      "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=0.0391]        \n",
      "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=0.0391]        \n",
      "Epoch 853:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.154, train_loss_epoch=0.154, valid_loss=0.0391]        \n",
      "Epoch 853: 100%|██████████| 1/1 [00:00<00:00,  9.19it/s, v_num=0, train_loss_step=0.154, train_loss_epoch=0.154, valid_loss=0.0391]\n",
      "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.225, train_loss_epoch=0.225, valid_loss=0.0391]        \n",
      "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=0.0391]        \n",
      "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.152, train_loss_epoch=0.152, valid_loss=0.0391]        \n",
      "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=0.0391]        \n",
      "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.160, train_loss_epoch=0.160, valid_loss=0.0391]        \n",
      "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=0.0391]        \n",
      "Epoch 860:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216, valid_loss=0.0391]        \n",
      "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.156, train_loss_epoch=0.156, valid_loss=0.0391]        \n",
      "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.207, valid_loss=0.0391]        \n",
      "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.270, train_loss_epoch=0.270, valid_loss=0.0391]        \n",
      "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=0.0391]        \n",
      "Epoch 865:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=0.0391]        \n",
      "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=0.0391]        \n",
      "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.234, train_loss_epoch=0.234, valid_loss=0.0391]        \n",
      "Epoch 868:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=0.0391]        \n",
      "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.160, train_loss_epoch=0.160, valid_loss=0.0391]        \n",
      "Epoch 869: 100%|██████████| 1/1 [00:00<00:00,  9.10it/s, v_num=0, train_loss_step=0.224, train_loss_epoch=0.160, valid_loss=0.0391]\n",
      "Epoch 869: 100%|██████████| 1/1 [00:00<00:00,  9.04it/s, v_num=0, train_loss_step=0.224, train_loss_epoch=0.224, valid_loss=0.0391]\n",
      "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.224, train_loss_epoch=0.224, valid_loss=0.0391]        \n",
      "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=0.0391]        \n",
      "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.152, train_loss_epoch=0.152, valid_loss=0.0391]        \n",
      "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=0.0391]        \n",
      "Epoch 874:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.161, train_loss_epoch=0.161, valid_loss=0.0391]        \n",
      "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.210, train_loss_epoch=0.210, valid_loss=0.0391]        \n",
      "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.175, train_loss_epoch=0.175, valid_loss=0.0391]        \n",
      "Epoch 877:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.164, train_loss_epoch=0.164, valid_loss=0.0391]        \n",
      "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.229, train_loss_epoch=0.229, valid_loss=0.0391]        \n",
      "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=0.0391]        \n",
      "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.241, train_loss_epoch=0.241, valid_loss=0.0391]        \n",
      "Epoch 881:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.207, valid_loss=0.0391]        \n",
      "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.207, valid_loss=0.0391]        \n",
      "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.198, valid_loss=0.0391]        \n",
      "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=0.0391]        \n",
      "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.153, train_loss_epoch=0.153, valid_loss=0.0391]        \n",
      "Epoch 885: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=0, train_loss_step=0.153, train_loss_epoch=0.153, valid_loss=0.0391]\n",
      "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=0.0391]        \n",
      "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.237, train_loss_epoch=0.237, valid_loss=0.0391]        \n",
      "Epoch 888:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=0.0391]        \n",
      "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.148, train_loss_epoch=0.148, valid_loss=0.0391]        \n",
      "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=0.0391]        \n",
      "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=0.0391]        \n",
      "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=0.0391]        \n",
      "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=0.0391]        \n",
      "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.160, train_loss_epoch=0.160, valid_loss=0.0391]        \n",
      "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=0.0391]        \n",
      "Epoch 896:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=0.0391]        \n",
      "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.221, train_loss_epoch=0.221, valid_loss=0.0391]        \n",
      "Epoch 897: 100%|██████████| 1/1 [00:00<00:00,  9.80it/s, v_num=0, train_loss_step=0.221, train_loss_epoch=0.221, valid_loss=0.0391]\n",
      "Epoch 897: 100%|██████████| 1/1 [00:00<00:00,  9.42it/s, v_num=0, train_loss_step=0.180, train_loss_epoch=0.221, valid_loss=0.0391]\n",
      "Epoch 897: 100%|██████████| 1/1 [00:00<00:00,  9.36it/s, v_num=0, train_loss_step=0.180, train_loss_epoch=0.180, valid_loss=0.0391]\n",
      "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.180, train_loss_epoch=0.180, valid_loss=0.0391]        \n",
      "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.180, train_loss_epoch=0.180, valid_loss=0.0391]        \n",
      "Epoch 899: 100%|██████████| 1/1 [00:00<00:00,  8.45it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.180, valid_loss=0.0391]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=9441)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s]\u001b[A\n",
      "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.170, valid_loss=0.0388]        \n",
      "Epoch 901:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=0.0388]        \n",
      "Epoch 901: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=0.0388]\n",
      "Epoch 902:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.141, train_loss_epoch=0.141, valid_loss=0.0388]        \n",
      "Epoch 903:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.200, train_loss_epoch=0.200, valid_loss=0.0388]        \n",
      "Epoch 904:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.144, train_loss_epoch=0.144, valid_loss=0.0388]        \n",
      "Epoch 905:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.179, train_loss_epoch=0.179, valid_loss=0.0388]        \n",
      "Epoch 906:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=0.0388]        \n",
      "Epoch 907:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=0.0388]        \n",
      "Epoch 908:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=0.0388]        \n",
      "Epoch 909:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=0.0388]        \n",
      "Epoch 910:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=0.0388]        \n",
      "Epoch 911:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=0.0388]        \n",
      "Epoch 912:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=0.0388]        \n",
      "Epoch 913:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.183, train_loss_epoch=0.183, valid_loss=0.0388]        \n",
      "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.159, train_loss_epoch=0.159, valid_loss=0.0388]        \n",
      "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=0.0388]        \n",
      "Epoch 916:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.183, train_loss_epoch=0.183, valid_loss=0.0388]        \n",
      "Epoch 917:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196, valid_loss=0.0388]        \n",
      "Epoch 918:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.155, train_loss_epoch=0.155, valid_loss=0.0388]        \n",
      "Epoch 919:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.179, train_loss_epoch=0.179, valid_loss=0.0388]        \n",
      "Epoch 920:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.175, train_loss_epoch=0.175, valid_loss=0.0388]        \n",
      "Epoch 921:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.146, train_loss_epoch=0.146, valid_loss=0.0388]        \n",
      "Epoch 921: 100%|██████████| 1/1 [00:00<00:00,  9.04it/s, v_num=0, train_loss_step=0.144, train_loss_epoch=0.146, valid_loss=0.0388]\n",
      "Epoch 921: 100%|██████████| 1/1 [00:00<00:00,  8.98it/s, v_num=0, train_loss_step=0.144, train_loss_epoch=0.144, valid_loss=0.0388]\n",
      "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.144, train_loss_epoch=0.144, valid_loss=0.0388]        \n",
      "Epoch 923:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.134, train_loss_epoch=0.134, valid_loss=0.0388]        \n",
      "Epoch 924:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=0.0388]        \n",
      "Epoch 925:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=0.0388]        \n",
      "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=0.0388]        \n",
      "Epoch 927:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.151, train_loss_epoch=0.151, valid_loss=0.0388]        \n",
      "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=0.0388]        \n",
      "Epoch 929:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.161, train_loss_epoch=0.161, valid_loss=0.0388]        \n",
      "Epoch 930:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.176, train_loss_epoch=0.176, valid_loss=0.0388]        \n",
      "Epoch 931:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=0.0388]        \n",
      "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216, valid_loss=0.0388]        \n",
      "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.145, train_loss_epoch=0.145, valid_loss=0.0388]        \n",
      "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=0.0388]        \n",
      "Epoch 935:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.142, train_loss_epoch=0.142, valid_loss=0.0388]        \n",
      "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=0.0388]        \n",
      "Epoch 937:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.180, train_loss_epoch=0.180, valid_loss=0.0388]        \n",
      "Epoch 938:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190, valid_loss=0.0388]        \n",
      "Epoch 939:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.180, train_loss_epoch=0.180, valid_loss=0.0388]        \n",
      "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.175, train_loss_epoch=0.175, valid_loss=0.0388]        \n",
      "Epoch 941:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=0.0388]        \n",
      "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.135, train_loss_epoch=0.135, valid_loss=0.0388]        \n",
      "Epoch 943:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=0.0388]        \n",
      "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.180, train_loss_epoch=0.180, valid_loss=0.0388]        \n",
      "Epoch 945:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.144, train_loss_epoch=0.144, valid_loss=0.0388]        \n",
      "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=0.0388]        \n",
      "Epoch 947:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=0.0388]        \n",
      "Epoch 948:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.144, train_loss_epoch=0.144, valid_loss=0.0388]        \n",
      "Epoch 949:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.151, train_loss_epoch=0.151, valid_loss=0.0388]        \n",
      "Epoch 950:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217, valid_loss=0.0388]        \n",
      "Epoch 951:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.176, train_loss_epoch=0.176, valid_loss=0.0388]        \n",
      "Epoch 951: 100%|██████████| 1/1 [00:00<00:00,  7.84it/s, v_num=0, train_loss_step=0.176, train_loss_epoch=0.176, valid_loss=0.0388]\n",
      "Epoch 952:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.151, train_loss_epoch=0.151, valid_loss=0.0388]        \n",
      "Epoch 953:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.187, train_loss_epoch=0.187, valid_loss=0.0388]        \n",
      "Epoch 954:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.145, train_loss_epoch=0.145, valid_loss=0.0388]        \n",
      "Epoch 955:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.145, train_loss_epoch=0.145, valid_loss=0.0388]        \n",
      "Epoch 956:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=0.0388]        \n",
      "Epoch 957:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=0.0388]        \n",
      "Epoch 958:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.133, train_loss_epoch=0.133, valid_loss=0.0388]        \n",
      "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.179, train_loss_epoch=0.179, valid_loss=0.0388]        \n",
      "Epoch 960:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.144, train_loss_epoch=0.144, valid_loss=0.0388]        \n",
      "Epoch 961:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.176, train_loss_epoch=0.176, valid_loss=0.0388]        \n",
      "Epoch 962:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.133, train_loss_epoch=0.133, valid_loss=0.0388]        \n",
      "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.200, train_loss_epoch=0.200, valid_loss=0.0388]        \n",
      "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.135, train_loss_epoch=0.135, valid_loss=0.0388]        \n",
      "Epoch 965:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.172, train_loss_epoch=0.172, valid_loss=0.0388]        \n",
      "Epoch 965: 100%|██████████| 1/1 [00:00<00:00,  7.14it/s, v_num=0, train_loss_step=0.172, train_loss_epoch=0.172, valid_loss=0.0388]\n",
      "Epoch 965: 100%|██████████| 1/1 [00:00<00:00,  6.72it/s, v_num=0, train_loss_step=0.136, train_loss_epoch=0.136, valid_loss=0.0388]\n",
      "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.136, train_loss_epoch=0.136, valid_loss=0.0388]        \n",
      "Epoch 967:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.135, train_loss_epoch=0.135, valid_loss=0.0388]        \n",
      "Epoch 968:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.130, train_loss_epoch=0.130, valid_loss=0.0388]        \n",
      "Epoch 969:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=0.0388]        \n",
      "Epoch 970:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.128, train_loss_epoch=0.128, valid_loss=0.0388]        \n",
      "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.126, train_loss_epoch=0.126, valid_loss=0.0388]        \n",
      "Epoch 972:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=0.0388]        \n",
      "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.137, train_loss_epoch=0.137, valid_loss=0.0388]        \n",
      "Epoch 973: 100%|██████████| 1/1 [00:00<00:00,  9.75it/s, v_num=0, train_loss_step=0.137, train_loss_epoch=0.137, valid_loss=0.0388]\n",
      "Epoch 974:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=0.0388]        \n",
      "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=0.0388]        \n",
      "Epoch 976:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=0.0388]        \n",
      "Epoch 977:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.124, train_loss_epoch=0.124, valid_loss=0.0388]        \n",
      "Epoch 978:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.153, train_loss_epoch=0.153, valid_loss=0.0388]        \n",
      "Epoch 979:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=0.0388]        \n",
      "Epoch 980:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=0.0388]        \n",
      "Epoch 981:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=0.0388]        \n",
      "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.121, train_loss_epoch=0.121, valid_loss=0.0388]        \n",
      "Epoch 983:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.161, train_loss_epoch=0.161, valid_loss=0.0388]        \n",
      "Epoch 984:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=0.0388]        \n",
      "Epoch 984: 100%|██████████| 1/1 [00:00<00:00,  9.53it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=0.0388]\n",
      "Epoch 984: 100%|██████████| 1/1 [00:00<00:00,  9.20it/s, v_num=0, train_loss_step=0.164, train_loss_epoch=0.163, valid_loss=0.0388]\n",
      "Epoch 984: 100%|██████████| 1/1 [00:00<00:00,  9.14it/s, v_num=0, train_loss_step=0.164, train_loss_epoch=0.164, valid_loss=0.0388]\n",
      "Epoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.164, train_loss_epoch=0.164, valid_loss=0.0388]        \n",
      "Epoch 986:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.124, train_loss_epoch=0.124, valid_loss=0.0388]        \n",
      "Epoch 987: 100%|██████████| 1/1 [00:00<00:00,  8.82it/s, v_num=0, train_loss_step=0.125, train_loss_epoch=0.125, valid_loss=0.0388]\n",
      "Epoch 987: 100%|██████████| 1/1 [00:00<00:00,  8.58it/s, v_num=0, train_loss_step=0.124, train_loss_epoch=0.124, valid_loss=0.0388]\n",
      "Epoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.124, train_loss_epoch=0.124, valid_loss=0.0388]        \n",
      "Epoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.123, train_loss_epoch=0.123, valid_loss=0.0388]        \n",
      "Epoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=0.0388]        \n",
      "Epoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.164, train_loss_epoch=0.164, valid_loss=0.0388]        \n",
      "Epoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=0.0388]        \n",
      "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=0.0388]        \n",
      "Epoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.183, train_loss_epoch=0.183, valid_loss=0.0388]        \n",
      "Epoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.150, train_loss_epoch=0.150, valid_loss=0.0388]        \n",
      "Epoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.128, train_loss_epoch=0.128, valid_loss=0.0388]        \n",
      "Epoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.161, train_loss_epoch=0.161, valid_loss=0.0388]        \n",
      "Epoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.139, train_loss_epoch=0.139, valid_loss=0.0388]        \n",
      "Epoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.132, train_loss_epoch=0.132, valid_loss=0.0388]        \n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00,  9.20it/s, v_num=0, train_loss_step=0.137, train_loss_epoch=0.132, valid_loss=0.0388]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=9441)\u001b[0m `Trainer.fit` stopped: `max_steps=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=9441)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  8.28it/s]\u001b[A\n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00,  4.16it/s, v_num=0, train_loss_step=0.137, train_loss_epoch=0.137, valid_loss=0.040] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=10134)\u001b[0m /home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m Seed set to 2\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]\n",
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=10134)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m   | Name            | Type          | Params | Mode \n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m 0 | loss            | WMAPE         | 0      | train\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m 1 | padder          | ConstantPad1d | 0      | train\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m 2 | scaler          | TemporalNorm  | 0      | train\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m 3 | hist_encoder    | LSTM          | 484 K  | train\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m 4 | context_adapter | Linear        | 77.4 K | train\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m 5 | mlp_decoder     | MLP           | 897    | train\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m 562 K     Trainable params\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m 562 K     Total params\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m 2.249     Total estimated model params size (MB)\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m 11        Modules in train mode\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m 0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]        \n",
      "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740]        \n",
      "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998]        \n",
      "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030]        \n",
      "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340]        \n",
      "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080]        \n",
      "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030]        \n",
      "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160]        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-22 08:43:57,434\tERROR tune_controller.py:1331 -- Trial task failed for trial _train_tune_eaea9_00020\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/_private/worker.py\", line 2755, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/_private/worker.py\", line 906, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=10134, ip=172.23.111.25, actor_id=d347bc3f6032db9d1493ba4801000000, repr=_train_tune)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/air/_internal/util.py\", line 107, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 250, in _trainable_func\n",
      "    output = fn()\n",
      "             ^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/tune/trainable/util.py\", line 130, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/neuralforecast/common/_base_auto.py\", line 214, in _train_tune\n",
      "    _ = self._fit_model(\n",
      "        ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/neuralforecast/common/_base_auto.py\", line 362, in _fit_model\n",
      "    model = model.fit(\n",
      "            ^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/neuralforecast/common/_base_recurrent.py\", line 537, in fit\n",
      "    return self._fit(\n",
      "           ^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/neuralforecast/common/_base_model.py\", line 370, in _fit\n",
      "    trainer.fit(model, datamodule=datamodule)\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 539, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 575, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 982, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 1026, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py\", line 216, in run\n",
      "    self.advance()\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py\", line 455, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 150, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 320, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 192, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 270, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 171, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/core/module.py\", line 1302, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py\", line 154, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py\", line 239, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py\", line 123, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 137, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 487, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 91, in _use_grad\n",
      "    ret = func(self, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/torch/optim/adam.py\", line 202, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py\", line 109, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 146, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 131, in closure\n",
      "    step_output = self._step_fn()\n",
      "                  ^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 319, in _training_step\n",
      "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 323, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py\", line 391, in training_step\n",
      "    return self.lightning_module.training_step(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/neuralforecast/common/_base_recurrent.py\", line 350, in training_step\n",
      "    raise Exception(\"Loss is NaN, training stopped.\")\n",
      "Exception: Loss is NaN, training stopped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220]        \n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m Model Parameters \"alias\":                     None\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m \"batch_size\":                32\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m \"callbacks\":                 [<ray.tune.integration.pytorch_lightning.TuneReportCallback object at 0x7f86e298fbd0>, <pytorch_lightning.callbacks.progress.tqdm_progress.TQDMProgressBar object at 0x7f843e7597d0>, <pytorch_lightning.callbacks.model_summary.ModelSummary object at 0x7f843e759790>]\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m \"context_size\":              5\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m \"dataloader_kwargs\":         None\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m \"decoder_hidden_size\":       128\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m \"decoder_layers\":            2\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m \"drop_last_loader\":          False\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m \"early_stop_patience_steps\": -1\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m \"encoder_bias\":              True\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m \"encoder_dropout\":           0.0\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m \"encoder_hidden_size\":       200\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m \"encoder_n_layers\":          2\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m \"futr_exog_list\":            None\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m \"h\":                         77\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m \"hist_exog_list\":            None\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m \"inference_input_size\":      -77\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m \"input_size\":                4928\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m \"learning_rate\":             0.03999093120064948\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m \"loss\":                      WMAPE()\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m \"lr_scheduler\":              None\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m \"lr_scheduler_kwargs\":       None\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m \"max_steps\":                 500\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m \"num_lr_decays\":             -1\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m \"num_workers_loader\":        0\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m \"optimizer\":                 None\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m \"optimizer_kwargs\":          None\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m \"random_seed\":               2\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m \"scaler_type\":               robust\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m \"stat_exog_list\":            None\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m \"val_check_steps\":           100\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m \"valid_batch_size\":          None\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m \"valid_loss\":                WMAPE()\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m insample_y tensor(0, device='cuda:0')\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m outsample_y tensor(0, device='cuda:0')\n",
      "\u001b[36m(_train_tune pid=10134)\u001b[0m output tensor(250404, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=10234)\u001b[0m /home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=10234)\u001b[0m Seed set to 2\n",
      "\u001b[36m(_train_tune pid=10234)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=10234)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=10234)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=10234)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(_train_tune pid=10234)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=10234)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=10234)\u001b[0m   | Name            | Type          | Params | Mode \n",
      "\u001b[36m(_train_tune pid=10234)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=10234)\u001b[0m 0 | loss            | WMAPE         | 0      | train\n",
      "\u001b[36m(_train_tune pid=10234)\u001b[0m 1 | padder          | ConstantPad1d | 0      | train\n",
      "\u001b[36m(_train_tune pid=10234)\u001b[0m 2 | scaler          | TemporalNorm  | 0      | train\n",
      "\u001b[36m(_train_tune pid=10234)\u001b[0m 3 | hist_encoder    | LSTM          | 122 K  | train\n",
      "\u001b[36m(_train_tune pid=10234)\u001b[0m 4 | context_adapter | Linear        | 388 K  | train\n",
      "\u001b[36m(_train_tune pid=10234)\u001b[0m 5 | mlp_decoder     | MLP           | 13.3 K | train\n",
      "\u001b[36m(_train_tune pid=10234)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=10234)\u001b[0m 524 K     Trainable params\n",
      "\u001b[36m(_train_tune pid=10234)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=10234)\u001b[0m 524 K     Total params\n",
      "\u001b[36m(_train_tune pid=10234)\u001b[0m 2.097     Total estimated model params size (MB)\n",
      "\u001b[36m(_train_tune pid=10234)\u001b[0m 11        Modules in train mode\n",
      "\u001b[36m(_train_tune pid=10234)\u001b[0m 0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 36.60it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 20.56it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999]\n",
      "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999]        \n",
      "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998]        \n",
      "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996]        \n",
      "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994]       \n",
      "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.990, train_loss_epoch=0.990]        \n",
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.985, train_loss_epoch=0.985]        \n",
      "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.978, train_loss_epoch=0.978]        \n",
      "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.967, train_loss_epoch=0.967]        \n",
      "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.951, train_loss_epoch=0.951]        \n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00, 40.61it/s, v_num=0, train_loss_step=0.929, train_loss_epoch=0.929]\n",
      "Epoch 24: 100%|██████████| 1/1 [00:00<00:00, 31.68it/s, v_num=0, train_loss_step=0.897, train_loss_epoch=0.897]\n",
      "Epoch 26: 100%|██████████| 1/1 [00:00<00:00, 33.86it/s, v_num=0, train_loss_step=0.854, train_loss_epoch=0.854]\n",
      "Epoch 28: 100%|██████████| 1/1 [00:00<00:00, 39.59it/s, v_num=0, train_loss_step=0.797, train_loss_epoch=0.797]\n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00, 33.58it/s, v_num=0, train_loss_step=0.735, train_loss_epoch=0.735]\n",
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00, 20.73it/s, v_num=0, train_loss_step=0.709, train_loss_epoch=0.735]\n",
      "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.709, train_loss_epoch=0.709]        \n",
      "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.709, train_loss_epoch=0.709]\n",
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00, 19.31it/s, v_num=0, train_loss_step=0.701, train_loss_epoch=0.697]\n",
      "Epoch 32: 100%|██████████| 1/1 [00:00<00:00, 18.54it/s, v_num=0, train_loss_step=0.701, train_loss_epoch=0.701]\n",
      "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.701, train_loss_epoch=0.701]        \n",
      "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.724, train_loss_epoch=0.724]        \n",
      "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.708, train_loss_epoch=0.708]        \n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00, 27.16it/s, v_num=0, train_loss_step=0.691, train_loss_epoch=0.691]\n",
      "Epoch 38: 100%|██████████| 1/1 [00:00<00:00, 17.96it/s, v_num=0, train_loss_step=0.675, train_loss_epoch=0.675]\n",
      "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.675, train_loss_epoch=0.675]        \n",
      "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.658, train_loss_epoch=0.658]        \n",
      "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.655, train_loss_epoch=0.655]        \n",
      "Epoch 44: 100%|██████████| 1/1 [00:00<00:00, 19.25it/s, v_num=0, train_loss_step=0.652, train_loss_epoch=0.652]\n",
      "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.652, train_loss_epoch=0.652]        \n",
      "Epoch 46: 100%|██████████| 1/1 [00:00<00:00, 18.78it/s, v_num=0, train_loss_step=0.643, train_loss_epoch=0.643]\n",
      "Epoch 48: 100%|██████████| 1/1 [00:00<00:00, 20.71it/s, v_num=0, train_loss_step=0.629, train_loss_epoch=0.636]\n",
      "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.629, train_loss_epoch=0.629]        \n",
      "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.629, train_loss_epoch=0.629]\n",
      "Epoch 50: 100%|██████████| 1/1 [00:00<00:00, 19.04it/s, v_num=0, train_loss_step=0.618, train_loss_epoch=0.618]\n",
      "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.618, train_loss_epoch=0.618]        \n",
      "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.616, train_loss_epoch=0.616]        \n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00, 25.56it/s, v_num=0, train_loss_step=0.615, train_loss_epoch=0.615]\n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00, 18.05it/s, v_num=0, train_loss_step=0.611, train_loss_epoch=0.615]\n",
      "Epoch 54: 100%|██████████| 1/1 [00:00<00:00, 17.34it/s, v_num=0, train_loss_step=0.611, train_loss_epoch=0.611]\n",
      "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.611, train_loss_epoch=0.611]        \n",
      "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.605, train_loss_epoch=0.605]        \n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00, 27.36it/s, v_num=0, train_loss_step=0.605, train_loss_epoch=0.605]\n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00, 18.72it/s, v_num=0, train_loss_step=0.604, train_loss_epoch=0.605]\n",
      "Epoch 58: 100%|██████████| 1/1 [00:00<00:00, 17.93it/s, v_num=0, train_loss_step=0.604, train_loss_epoch=0.604]\n",
      "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.604, train_loss_epoch=0.604]        \n",
      "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.599, train_loss_epoch=0.599]        \n",
      "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.595, train_loss_epoch=0.595]        \n",
      "Epoch 64: 100%|██████████| 1/1 [00:00<00:00, 19.86it/s, v_num=0, train_loss_step=0.596, train_loss_epoch=0.596]\n",
      "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.596, train_loss_epoch=0.596]        \n",
      "Epoch 66: 100%|██████████| 1/1 [00:00<00:00, 18.76it/s, v_num=0, train_loss_step=0.594, train_loss_epoch=0.595]\n",
      "Epoch 66: 100%|██████████| 1/1 [00:00<00:00, 18.12it/s, v_num=0, train_loss_step=0.594, train_loss_epoch=0.594]\n",
      "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.594, train_loss_epoch=0.594]        \n",
      "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.592, train_loss_epoch=0.592]        \n",
      "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.592, train_loss_epoch=0.592]        \n",
      "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.591, train_loss_epoch=0.591]        \n",
      "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.591, train_loss_epoch=0.591]        \n",
      "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.589, train_loss_epoch=0.589]        \n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00, 31.54it/s, v_num=0, train_loss_step=0.589, train_loss_epoch=0.589]\n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00, 19.30it/s, v_num=0, train_loss_step=0.589, train_loss_epoch=0.589]\n",
      "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.589, train_loss_epoch=0.589]        \n",
      "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.587, train_loss_epoch=0.587]        \n",
      "Epoch 84: 100%|██████████| 1/1 [00:00<00:00, 18.74it/s, v_num=0, train_loss_step=0.587, train_loss_epoch=0.587]\n",
      "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.587, train_loss_epoch=0.587]        \n",
      "Epoch 86: 100%|██████████| 1/1 [00:00<00:00, 19.13it/s, v_num=0, train_loss_step=0.586, train_loss_epoch=0.586]\n",
      "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.586, train_loss_epoch=0.586]        \n",
      "Epoch 88: 100%|██████████| 1/1 [00:00<00:00, 25.98it/s, v_num=0, train_loss_step=0.586, train_loss_epoch=0.586]\n",
      "Epoch 90: 100%|██████████| 1/1 [00:00<00:00, 30.83it/s, v_num=0, train_loss_step=0.586, train_loss_epoch=0.586]\n",
      "Epoch 92: 100%|██████████| 1/1 [00:00<00:00, 28.75it/s, v_num=0, train_loss_step=0.585, train_loss_epoch=0.585]\n",
      "Epoch 94: 100%|██████████| 1/1 [00:00<00:00, 29.94it/s, v_num=0, train_loss_step=0.584, train_loss_epoch=0.584]\n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00, 42.74it/s, v_num=0, train_loss_step=0.584, train_loss_epoch=0.584]\n",
      "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.583, train_loss_epoch=0.583]        \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 20.52it/s, v_num=0, train_loss_step=0.583, train_loss_epoch=0.583]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 40.70it/s]\u001b[A\n",
      "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.583, train_loss_epoch=0.583, valid_loss=0.0453]       \n",
      "Epoch 101: 100%|██████████| 1/1 [00:00<00:00, 19.35it/s, v_num=0, train_loss_step=0.583, train_loss_epoch=0.583, valid_loss=0.0453]\n",
      "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.583, train_loss_epoch=0.583, valid_loss=0.0453]        \n",
      "Epoch 103: 100%|██████████| 1/1 [00:00<00:00, 21.59it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582, valid_loss=0.0453]\n",
      "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582, valid_loss=0.0453]        \n",
      "Epoch 105: 100%|██████████| 1/1 [00:00<00:00, 20.55it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582, valid_loss=0.0453]\n",
      "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582, valid_loss=0.0453]        \n",
      "Epoch 107: 100%|██████████| 1/1 [00:00<00:00, 26.93it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582, valid_loss=0.0453]\n",
      "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.581, train_loss_epoch=0.581, valid_loss=0.0453]        \n",
      "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.581, train_loss_epoch=0.581, valid_loss=0.0453]        \n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00, 18.27it/s, v_num=0, train_loss_step=0.580, train_loss_epoch=0.580, valid_loss=0.0453]\n",
      "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.580, train_loss_epoch=0.580, valid_loss=0.0453]        \n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00, 25.08it/s, v_num=0, train_loss_step=0.580, train_loss_epoch=0.580, valid_loss=0.0453]\n",
      "Epoch 117: 100%|██████████| 1/1 [00:00<00:00, 41.17it/s, v_num=0, train_loss_step=0.580, train_loss_epoch=0.580, valid_loss=0.0453]\n",
      "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.579, train_loss_epoch=0.579, valid_loss=0.0453]        \n",
      "Epoch 119: 100%|██████████| 1/1 [00:00<00:00, 26.71it/s, v_num=0, train_loss_step=0.579, train_loss_epoch=0.579, valid_loss=0.0453]\n",
      "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.579, train_loss_epoch=0.579, valid_loss=0.0453]        \n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00, 31.41it/s, v_num=0, train_loss_step=0.579, train_loss_epoch=0.579, valid_loss=0.0453]\n",
      "Epoch 123: 100%|██████████| 1/1 [00:00<00:00, 41.23it/s, v_num=0, train_loss_step=0.579, train_loss_epoch=0.579, valid_loss=0.0453]\n",
      "Epoch 125: 100%|██████████| 1/1 [00:00<00:00, 20.26it/s, v_num=0, train_loss_step=0.578, train_loss_epoch=0.578, valid_loss=0.0453]\n",
      "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.578, train_loss_epoch=0.578, valid_loss=0.0453]        \n",
      "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.578, train_loss_epoch=0.578, valid_loss=0.0453]        \n",
      "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.577, train_loss_epoch=0.577, valid_loss=0.0453]        \n",
      "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.577, train_loss_epoch=0.577, valid_loss=0.0453]        \n",
      "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.577, train_loss_epoch=0.577, valid_loss=0.0453]        \n",
      "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.576, train_loss_epoch=0.576, valid_loss=0.0453]        \n",
      "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.576, train_loss_epoch=0.576, valid_loss=0.0453]        \n",
      "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.575, train_loss_epoch=0.575, valid_loss=0.0453]        \n",
      "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.575, train_loss_epoch=0.575, valid_loss=0.0453]        \n",
      "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.575, train_loss_epoch=0.575, valid_loss=0.0453]        \n",
      "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574, valid_loss=0.0453]        \n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00, 13.66it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574, valid_loss=0.0453]\n",
      "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574, valid_loss=0.0453]        \n",
      "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574, valid_loss=0.0453]        \n",
      "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573, valid_loss=0.0453]        \n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00, 27.04it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573, valid_loss=0.0453]\n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00, 17.79it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573, valid_loss=0.0453]\n",
      "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573, valid_loss=0.0453]        \n",
      "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573, valid_loss=0.0453]        \n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00, 30.72it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.572, valid_loss=0.0453]\n",
      "Epoch 157: 100%|██████████| 1/1 [00:00<00:00, 19.46it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.572, valid_loss=0.0453]\n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00, 29.05it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.572, valid_loss=0.0453]\n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00, 19.10it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.572, valid_loss=0.0453]\n",
      "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.572, valid_loss=0.0453]        \n",
      "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571, valid_loss=0.0453]        \n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00, 19.40it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571, valid_loss=0.0453]\n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00, 18.02it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571, valid_loss=0.0453]\n",
      "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571, valid_loss=0.0453]        \n",
      "Epoch 165: 100%|██████████| 1/1 [00:00<00:00, 19.41it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571, valid_loss=0.0453]\n",
      "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571, valid_loss=0.0453]        \n",
      "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.570, train_loss_epoch=0.570, valid_loss=0.0453]        \n",
      "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.570, train_loss_epoch=0.570, valid_loss=0.0453]        \n",
      "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569, valid_loss=0.0453]        \n",
      "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569, valid_loss=0.0453]        \n",
      "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568, valid_loss=0.0453]        \n",
      "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568, valid_loss=0.0453]        \n",
      "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568, valid_loss=0.0453]        \n",
      "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567, valid_loss=0.0453]        \n",
      "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.566, train_loss_epoch=0.566, valid_loss=0.0453]        \n",
      "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.566, train_loss_epoch=0.566, valid_loss=0.0453]        \n",
      "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.566, train_loss_epoch=0.566, valid_loss=0.0453]\n",
      "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565, valid_loss=0.0453]        \n",
      "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565, valid_loss=0.0453]        \n",
      "Epoch 191: 100%|██████████| 1/1 [00:00<00:00, 18.19it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=0.0453]\n",
      "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=0.0453]        \n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00, 19.59it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563, valid_loss=0.0453]\n",
      "Epoch 193: 100%|██████████| 1/1 [00:00<00:00, 18.86it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563, valid_loss=0.0453]\n",
      "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563, valid_loss=0.0453]        \n",
      "Epoch 195: 100%|██████████| 1/1 [00:00<00:00, 19.67it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562, valid_loss=0.0453]\n",
      "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562, valid_loss=0.0453]        \n",
      "Epoch 197: 100%|██████████| 1/1 [00:00<00:00, 19.52it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=0.0453]\n",
      "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=0.0453]        \n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 18.17it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.559, valid_loss=0.0453]\n",
      "\u001b[36m(_train_tune pid=10234)\u001b[0m \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=10234)\u001b[0m \n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=10234)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 41.26it/s]\u001b[A\n",
      "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.0408]        \n",
      "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.0408]        \n",
      "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=0.0408]        \n",
      "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562, valid_loss=0.0408]        \n",
      "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.0408]        \n",
      "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563, valid_loss=0.0408]        \n",
      "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0408]        \n",
      "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561, valid_loss=0.0408]        \n",
      "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=0.0408]        \n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00, 19.82it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=0.0408]\n",
      "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=0.0408]        \n",
      "Epoch 220: 100%|██████████| 1/1 [00:00<00:00, 19.75it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=0.0408]\n",
      "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=0.0408]        \n",
      "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=0.0408]        \n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00, 30.68it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=0.0408]\n",
      "Epoch 224: 100%|██████████| 1/1 [00:00<00:00, 18.85it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=0.0408]\n",
      "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=0.0408]        \n",
      "Epoch 226: 100%|██████████| 1/1 [00:00<00:00, 19.36it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0408]\n",
      "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0408]        \n",
      "Epoch 228: 100%|██████████| 1/1 [00:00<00:00, 27.65it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0408]\n",
      "Epoch 228: 100%|██████████| 1/1 [00:00<00:00, 18.52it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.0408]\n",
      "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.0408]        \n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00, 19.35it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.0408]\n",
      "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.0408]        \n",
      "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0408]        \n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00, 20.10it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.0408]\n",
      "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.0408]        \n",
      "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0408]        \n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00, 19.74it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0408]\n",
      "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0408]        \n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00, 19.23it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=0.0408]\n",
      "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=0.0408]        \n",
      "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0408]        \n",
      "Epoch 244: 100%|██████████| 1/1 [00:00<00:00, 19.60it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0408]\n",
      "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0408]        \n",
      "Epoch 246: 100%|██████████| 1/1 [00:00<00:00, 18.85it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0408]\n",
      "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0408]        \n",
      "Epoch 248: 100%|██████████| 1/1 [00:00<00:00, 19.28it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0408]\n",
      "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0408]        \n",
      "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0408]        \n",
      "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.0408]        \n",
      "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.0408]        \n",
      "Epoch 256: 100%|██████████| 1/1 [00:00<00:00, 19.54it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0408]\n",
      "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0408]        \n",
      "Epoch 258: 100%|██████████| 1/1 [00:00<00:00, 19.22it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0408]\n",
      "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0408]        \n",
      "Epoch 260: 100%|██████████| 1/1 [00:00<00:00, 19.22it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561, valid_loss=0.0408]\n",
      "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561, valid_loss=0.0408]        \n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00, 27.08it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0408]\n",
      "Epoch 262: 100%|██████████| 1/1 [00:00<00:00, 18.38it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0408]\n",
      "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0408]        \n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00, 18.36it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0408]\n",
      "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0408]        \n",
      "Epoch 266: 100%|██████████| 1/1 [00:00<00:00, 18.70it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0408]\n",
      "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0408]        \n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00, 19.91it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0408]\n",
      "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0408]        \n",
      "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.0408]        \n",
      "Epoch 272: 100%|██████████| 1/1 [00:00<00:00, 19.53it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0408]\n",
      "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0408]        \n",
      "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0408]        \n",
      "Epoch 276: 100%|██████████| 1/1 [00:00<00:00, 19.20it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=0.0408]\n",
      "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=0.0408]        \n",
      "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=0.0408]        \n",
      "Epoch 280: 100%|██████████| 1/1 [00:00<00:00, 19.67it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0408]\n",
      "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0408]        \n",
      "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0408]        \n",
      "Epoch 284: 100%|██████████| 1/1 [00:00<00:00, 18.67it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0408]\n",
      "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0408]        \n",
      "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0408]        \n",
      "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0408]        \n",
      "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0408]        \n",
      "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0408]        \n",
      "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.0408]        \n",
      "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.0408]        \n",
      "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0408]        \n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 20.38it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0408]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 43.10it/s]\u001b[A\n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00, 32.59it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0369]\n",
      "Epoch 300: 100%|██████████| 1/1 [00:00<00:00, 20.93it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0369]\n",
      "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0369]        \n",
      "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0369]\n",
      "Epoch 302: 100%|██████████| 1/1 [00:00<00:00, 21.31it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0369]\n",
      "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0369]        \n",
      "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0369]        \n",
      "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=0.0369]        \n",
      "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=0.0369]        \n",
      "Epoch 309: 100%|██████████| 1/1 [00:00<00:00, 41.89it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=0.0369]\n",
      "Epoch 311: 100%|██████████| 1/1 [00:00<00:00, 31.30it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0369]\n",
      "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0369]        \n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00, 32.39it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0369]\n",
      "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0369]        \n",
      "Epoch 319: 100%|██████████| 1/1 [00:00<00:00, 33.39it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0369]\n",
      "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.0369]        \n",
      "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.0369]        \n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00, 31.19it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.0369]\n",
      "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0369]        \n",
      "Epoch 327: 100%|██████████| 1/1 [00:00<00:00, 39.88it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0369]\n",
      "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0369]        \n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 29.86it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0369]\n",
      "Epoch 331: 100%|██████████| 1/1 [00:00<00:00, 33.73it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0369]\n",
      "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0369]        \n",
      "Epoch 333: 100%|██████████| 1/1 [00:00<00:00, 38.00it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0369]\n",
      "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0369]        \n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00, 28.70it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0369]\n",
      "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0369]        \n",
      "Epoch 337: 100%|██████████| 1/1 [00:00<00:00, 29.92it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0369]\n",
      "Epoch 339: 100%|██████████| 1/1 [00:00<00:00, 33.05it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0369]\n",
      "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0369]        \n",
      "Epoch 341: 100%|██████████| 1/1 [00:00<00:00, 27.36it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0369]\n",
      "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0369]        \n",
      "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0369]        \n",
      "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0369]        \n",
      "Epoch 347: 100%|██████████| 1/1 [00:00<00:00, 32.64it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0369]\n",
      "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0369]        \n",
      "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0369]        \n",
      "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0369]        \n",
      "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0369]        \n",
      "Epoch 355: 100%|██████████| 1/1 [00:00<00:00, 32.54it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0369]\n",
      "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0369]        \n",
      "Epoch 357: 100%|██████████| 1/1 [00:00<00:00, 32.52it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0369]\n",
      "Epoch 359: 100%|██████████| 1/1 [00:00<00:00, 30.06it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0369]\n",
      "Epoch 361: 100%|██████████| 1/1 [00:00<00:00, 31.44it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0369]\n",
      "Epoch 363: 100%|██████████| 1/1 [00:00<00:00, 29.85it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0369]\n",
      "Epoch 365: 100%|██████████| 1/1 [00:00<00:00, 38.69it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0369]\n",
      "Epoch 367: 100%|██████████| 1/1 [00:00<00:00, 32.22it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0369]\n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00, 30.53it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0369]\n",
      "Epoch 371: 100%|██████████| 1/1 [00:00<00:00, 28.11it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0369]\n",
      "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0369]        \n",
      "Epoch 373: 100%|██████████| 1/1 [00:00<00:00, 29.81it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0369]\n",
      "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0369]        \n",
      "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0369]        \n",
      "Epoch 379: 100%|██████████| 1/1 [00:00<00:00, 37.98it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0369]\n",
      "Epoch 381: 100%|██████████| 1/1 [00:00<00:00, 32.18it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0369]\n",
      "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0369]        \n",
      "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=0.0369]        \n",
      "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.0369]        \n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00, 27.78it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.0369]\n",
      "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=0.0369]        \n",
      "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.0369]        \n",
      "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.0369]        \n",
      "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0369]        \n",
      "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0369]        \n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 34.28it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=0.0369]\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 21.04it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.543, valid_loss=0.0369]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 45.58it/s]\u001b[A\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00, 32.89it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0374]\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00, 19.99it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.0374]\n",
      "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.0374]        \n",
      "Epoch 402: 100%|██████████| 1/1 [00:00<00:00, 26.69it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0374]\n",
      "Epoch 402: 100%|██████████| 1/1 [00:00<00:00, 18.93it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.544, valid_loss=0.0374]\n",
      "Epoch 402: 100%|██████████| 1/1 [00:00<00:00, 18.37it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=0.0374]\n",
      "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=0.0374]        \n",
      "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=0.0374]        \n",
      "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0374]        \n",
      "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.0374]        \n",
      "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0374]        \n",
      "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0374]        \n",
      "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0374]        \n",
      "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0374]        \n",
      "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.0374]        \n",
      "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0374]        \n",
      "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=0.0374]        \n",
      "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0374]        \n",
      "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0374]        \n",
      "Epoch 428: 100%|██████████| 1/1 [00:00<00:00, 17.01it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.529, valid_loss=0.0374]\n",
      "Epoch 428: 100%|██████████| 1/1 [00:00<00:00, 16.31it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.0374]\n",
      "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.0374]        \n",
      "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.0374]\n",
      "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0374]        \n",
      "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0374]        \n",
      "Epoch 432: 100%|██████████| 1/1 [00:00<00:00,  3.85it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0374]\n",
      "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0374]        \n",
      "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0374]        \n",
      "Epoch 436: 100%|██████████| 1/1 [00:00<00:00, 19.00it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0374]\n",
      "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0374]        \n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00, 20.71it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.523, valid_loss=0.0374]\n",
      "Epoch 438: 100%|██████████| 1/1 [00:00<00:00, 20.07it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0374]\n",
      "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0374]        \n",
      "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0374]        \n",
      "Epoch 442: 100%|██████████| 1/1 [00:00<00:00, 18.57it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0374]\n",
      "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0374]        \n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00, 26.39it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0374]\n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00, 17.86it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0374]\n",
      "Epoch 446: 100%|██████████| 1/1 [00:00<00:00, 20.01it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0374]\n",
      "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0374]        \n",
      "Epoch 448: 100%|██████████| 1/1 [00:00<00:00, 19.14it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0374]\n",
      "Epoch 448: 100%|██████████| 1/1 [00:00<00:00, 18.58it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0374]\n",
      "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0374]        \n",
      "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0374]        \n",
      "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0374]        \n",
      "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0374]        \n",
      "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0374]        \n",
      "Epoch 458: 100%|██████████| 1/1 [00:00<00:00, 22.32it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0374]\n",
      "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0374]        \n",
      "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0374]        \n",
      "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0374]        \n",
      "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=0.0374]        \n",
      "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0374]        \n",
      "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0374]        \n",
      "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0374]\n",
      "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.0374]        \n",
      "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.0374]        \n",
      "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0374]        \n",
      "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.0374]        \n",
      "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.0374]        \n",
      "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0374]        \n",
      "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0374]        \n",
      "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0374]        \n",
      "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0374]        \n",
      "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0374]        \n",
      "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0374]        \n",
      "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0374]        \n",
      "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0374]        \n",
      "Epoch 497: 100%|██████████| 1/1 [00:00<00:00, 42.80it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0374]\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 42.55it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0374]\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 23.38it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0374]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 46.89it/s]\u001b[A\n",
      "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0358]        \n",
      "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0358]        \n",
      "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0358]        \n",
      "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0358]        \n",
      "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0358]        \n",
      "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0358]        \n",
      "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0358]        \n",
      "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0358]        \n",
      "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0358]        \n",
      "Epoch 518: 100%|██████████| 1/1 [00:00<00:00, 16.52it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.513, valid_loss=0.0358]\n",
      "Epoch 518: 100%|██████████| 1/1 [00:00<00:00, 15.09it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0358]\n",
      "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0358]        \n",
      "Epoch 520: 100%|██████████| 1/1 [00:00<00:00, 30.73it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0358]\n",
      "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0358]        \n",
      "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0358]        \n",
      "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0358]        \n",
      "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0358]        \n",
      "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0358]        \n",
      "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0358]        \n",
      "Epoch 533: 100%|██████████| 1/1 [00:00<00:00, 31.01it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0358]\n",
      "Epoch 535: 100%|██████████| 1/1 [00:00<00:00, 43.49it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0358]\n",
      "Epoch 537: 100%|██████████| 1/1 [00:00<00:00, 31.96it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0358]\n",
      "Epoch 537: 100%|██████████| 1/1 [00:00<00:00, 20.95it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0358]\n",
      "Epoch 537: 100%|██████████| 1/1 [00:00<00:00, 19.86it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0358]\n",
      "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0358]        \n",
      "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0358]        \n",
      "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0358]        \n",
      "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0358]        \n",
      "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0358]        \n",
      "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0358]        \n",
      "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0358]        \n",
      "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0358]        \n",
      "Epoch 553: 100%|██████████| 1/1 [00:00<00:00, 19.63it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0358]\n",
      "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0358]        \n",
      "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0358]        \n",
      "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0358]        \n",
      "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0358]        \n",
      "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0358]        \n",
      "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0358]        \n",
      "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0358]        \n",
      "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0358]        \n",
      "Epoch 569: 100%|██████████| 1/1 [00:00<00:00, 37.71it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0358]\n",
      "Epoch 569: 100%|██████████| 1/1 [00:00<00:00, 21.66it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.519, valid_loss=0.0358]\n",
      "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0358]        \n",
      "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0358]\n",
      "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.0358]        \n",
      "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0358]        \n",
      "Epoch 576: 100%|██████████| 1/1 [00:00<00:00, 36.35it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0358]\n",
      "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0358]        \n",
      "Epoch 578: 100%|██████████| 1/1 [00:00<00:00, 27.45it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0358]\n",
      "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0358]        \n",
      "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0358]        \n",
      "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0358]        \n",
      "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0358]        \n",
      "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0358]        \n",
      "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0358]        \n",
      "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0358]        \n",
      "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0358]        \n",
      "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0358]        \n",
      "Epoch 596: 100%|██████████| 1/1 [00:00<00:00, 35.82it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0358]\n",
      "Epoch 598: 100%|██████████| 1/1 [00:00<00:00, 35.03it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0358]\n",
      "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 21.70it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0358]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 47.01it/s]\u001b[A\n",
      "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0359]        \n",
      "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0359]        \n",
      "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0359]        \n",
      "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0359]        \n",
      "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0359]        \n",
      "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0359]        \n",
      "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0359]        \n",
      "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0359]        \n",
      "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0359]        \n",
      "Epoch 616: 100%|██████████| 1/1 [00:00<00:00, 32.57it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0359]\n",
      "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0359]        \n",
      "Epoch 618: 100%|██████████| 1/1 [00:00<00:00, 36.38it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0359]\n",
      "Epoch 620: 100%|██████████| 1/1 [00:00<00:00, 37.12it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0359]\n",
      "Epoch 622:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0359]        \n",
      "Epoch 622: 100%|██████████| 1/1 [00:00<00:00, 25.92it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0359]\n",
      "Epoch 624: 100%|██████████| 1/1 [00:00<00:00, 36.72it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0359]\n",
      "Epoch 626: 100%|██████████| 1/1 [00:00<00:00, 29.12it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0359]\n",
      "Epoch 628: 100%|██████████| 1/1 [00:00<00:00, 33.08it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0359]\n",
      "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0359]        \n",
      "Epoch 632: 100%|██████████| 1/1 [00:00<00:00, 44.29it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0359]\n",
      "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0359]        \n",
      "Epoch 634: 100%|██████████| 1/1 [00:00<00:00, 29.56it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0359]\n",
      "Epoch 636: 100%|██████████| 1/1 [00:00<00:00, 43.65it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0359]\n",
      "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0359]        \n",
      "Epoch 641: 100%|██████████| 1/1 [00:00<00:00, 44.62it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0359]\n",
      "Epoch 643: 100%|██████████| 1/1 [00:00<00:00, 44.04it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0359]\n",
      "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.0359]        \n",
      "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0359]        \n",
      "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0359]        \n",
      "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0359]        \n",
      "Epoch 654: 100%|██████████| 1/1 [00:00<00:00, 42.32it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0359]\n",
      "Epoch 657:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0359]        \n",
      "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0359]        \n",
      "Epoch 661: 100%|██████████| 1/1 [00:00<00:00, 42.16it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0359]\n",
      "Epoch 663: 100%|██████████| 1/1 [00:00<00:00, 33.62it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0359]\n",
      "Epoch 665: 100%|██████████| 1/1 [00:00<00:00, 22.10it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0359]\n",
      "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0359]        \n",
      "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0359]\n",
      "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0359]        \n",
      "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0359]        \n",
      "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0359]        \n",
      "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0359]        \n",
      "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0359]        \n",
      "Epoch 677: 100%|██████████| 1/1 [00:00<00:00, 26.78it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0359]\n",
      "Epoch 677: 100%|██████████| 1/1 [00:00<00:00, 17.35it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0359]\n",
      "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0359]        \n",
      "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0359]        \n",
      "Epoch 684: 100%|██████████| 1/1 [00:00<00:00, 39.85it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0359]\n",
      "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0359]        \n",
      "Epoch 688: 100%|██████████| 1/1 [00:00<00:00, 40.19it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0359]\n",
      "Epoch 690: 100%|██████████| 1/1 [00:00<00:00, 29.80it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0359]\n",
      "Epoch 692: 100%|██████████| 1/1 [00:00<00:00, 41.27it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0359]\n",
      "Epoch 694: 100%|██████████| 1/1 [00:00<00:00, 30.28it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0359]\n",
      "Epoch 696: 100%|██████████| 1/1 [00:00<00:00, 21.99it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0359]\n",
      "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0359]        \n",
      "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0359]\n",
      "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0359]        \n",
      "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 20.82it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0359]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 54.42it/s]\u001b[A\n",
      "Epoch 700: 100%|██████████| 1/1 [00:00<00:00, 38.06it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0332]\n",
      "Epoch 702: 100%|██████████| 1/1 [00:00<00:00, 28.34it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0332]\n",
      "Epoch 704: 100%|██████████| 1/1 [00:00<00:00, 28.71it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0332]\n",
      "Epoch 706: 100%|██████████| 1/1 [00:00<00:00, 28.28it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0332]\n",
      "Epoch 708: 100%|██████████| 1/1 [00:00<00:00, 40.63it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0332]\n",
      "Epoch 710: 100%|██████████| 1/1 [00:00<00:00, 21.25it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0332]\n",
      "Epoch 710: 100%|██████████| 1/1 [00:00<00:00, 20.20it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0332]\n",
      "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0332]        \n",
      "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0332]        \n",
      "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0332]        \n",
      "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0332]        \n",
      "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0332]        \n",
      "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0332]        \n",
      "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0332]        \n",
      "Epoch 725: 100%|██████████| 1/1 [00:00<00:00, 39.74it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0332]\n",
      "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0332]        \n",
      "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0332]        \n",
      "Epoch 729: 100%|██████████| 1/1 [00:00<00:00, 32.59it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0332]\n",
      "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0332]        \n",
      "Epoch 731: 100%|██████████| 1/1 [00:00<00:00, 29.15it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0332]\n",
      "Epoch 733: 100%|██████████| 1/1 [00:00<00:00, 30.39it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0332]\n",
      "Epoch 735: 100%|██████████| 1/1 [00:00<00:00, 28.01it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0332]\n",
      "Epoch 737: 100%|██████████| 1/1 [00:00<00:00, 32.75it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0332]\n",
      "Epoch 739: 100%|██████████| 1/1 [00:00<00:00, 30.93it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0332]\n",
      "Epoch 739: 100%|██████████| 1/1 [00:00<00:00, 20.62it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.491, valid_loss=0.0332]\n",
      "Epoch 739: 100%|██████████| 1/1 [00:00<00:00, 19.79it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0332]\n",
      "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0332]        \n",
      "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0332]        \n",
      "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0332]        \n",
      "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0332]        \n",
      "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0332]        \n",
      "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0332]        \n",
      "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0332]        \n",
      "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0332]        \n",
      "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0332]        \n",
      "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0332]        \n",
      "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0332]        \n",
      "Epoch 762: 100%|██████████| 1/1 [00:00<00:00, 35.57it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0332]\n",
      "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0332]        \n",
      "Epoch 766: 100%|██████████| 1/1 [00:00<00:00, 34.72it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0332]\n",
      "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0332]        \n",
      "Epoch 770: 100%|██████████| 1/1 [00:00<00:00, 38.44it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0332]\n",
      "Epoch 772: 100%|██████████| 1/1 [00:00<00:00, 28.52it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0332]\n",
      "Epoch 774: 100%|██████████| 1/1 [00:00<00:00, 36.00it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0332]\n",
      "Epoch 774: 100%|██████████| 1/1 [00:00<00:00, 20.88it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0332]\n",
      "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0332]        \n",
      "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0332]        \n",
      "Epoch 779:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0332]        \n",
      "Epoch 781:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0332]        \n",
      "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0332]        \n",
      "Epoch 783: 100%|██████████| 1/1 [00:00<00:00, 37.17it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0332]\n",
      "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0332]        \n",
      "Epoch 785: 100%|██████████| 1/1 [00:00<00:00, 28.94it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0332]\n",
      "Epoch 787: 100%|██████████| 1/1 [00:00<00:00, 39.08it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.0332]\n",
      "Epoch 787: 100%|██████████| 1/1 [00:00<00:00, 21.60it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.0332]\n",
      "Epoch 789: 100%|██████████| 1/1 [00:00<00:00, 28.21it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.0332]\n",
      "Epoch 791: 100%|██████████| 1/1 [00:00<00:00, 41.39it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.0332]\n",
      "Epoch 791: 100%|██████████| 1/1 [00:00<00:00, 22.47it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0332]\n",
      "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0332]        \n",
      "Epoch 793: 100%|██████████| 1/1 [00:00<00:00, 19.94it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.0332]\n",
      "Epoch 794:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.0332]        \n",
      "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.475, train_loss_epoch=0.475, valid_loss=0.0332]        \n",
      "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.474, train_loss_epoch=0.474, valid_loss=0.0332]        \n",
      "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 23.45it/s, v_num=0, train_loss_step=0.474, train_loss_epoch=0.474, valid_loss=0.0332]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=10234)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 46.33it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=10234)\u001b[0m \n",
      "Epoch 801: 100%|██████████| 1/1 [00:00<00:00, 21.57it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473, valid_loss=0.0355]\n",
      "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473, valid_loss=0.0355]        \n",
      "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.0355]        \n",
      "Epoch 806:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.0355]        \n",
      "Epoch 808:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471, valid_loss=0.0355]        \n",
      "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471, valid_loss=0.0355]        \n",
      "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=0.0355]        \n",
      "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=0.0355]        \n",
      "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=0.0355]        \n",
      "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.0355]        \n",
      "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.0355]        \n",
      "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.0355]        \n",
      "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.0355]        \n",
      "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.0355]        \n",
      "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.0355]        \n",
      "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.468, valid_loss=0.0355]        \n",
      "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.0355]        \n",
      "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.468, valid_loss=0.0355]        \n",
      "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=0.0355]        \n",
      "Epoch 836: 100%|██████████| 1/1 [00:00<00:00, 38.40it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=0.0355]\n",
      "Epoch 838: 100%|██████████| 1/1 [00:00<00:00, 31.74it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=0.0355]\n",
      "Epoch 840: 100%|██████████| 1/1 [00:00<00:00, 44.01it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=0.0355]\n",
      "Epoch 842: 100%|██████████| 1/1 [00:00<00:00, 28.18it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=0.0355]\n",
      "Epoch 844: 100%|██████████| 1/1 [00:00<00:00, 34.37it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=0.0355]\n",
      "Epoch 844: 100%|██████████| 1/1 [00:00<00:00, 21.61it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.467, valid_loss=0.0355]\n",
      "Epoch 844: 100%|██████████| 1/1 [00:00<00:00, 20.38it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=0.0355]\n",
      "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=0.0355]        \n",
      "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=0.0355]        \n",
      "Epoch 849:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.465, valid_loss=0.0355]        \n",
      "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=0.0355]        \n",
      "Epoch 853:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=0.0355]        \n",
      "Epoch 854: 100%|██████████| 1/1 [00:00<00:00, 18.27it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.465, valid_loss=0.0355]\n",
      "Epoch 854: 100%|██████████| 1/1 [00:00<00:00, 17.58it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=0.0355]\n",
      "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=0.0355]        \n",
      "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=0.0355]        \n",
      "Epoch 858: 100%|██████████| 1/1 [00:00<00:00, 28.12it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=0.0355]\n",
      "Epoch 858: 100%|██████████| 1/1 [00:00<00:00, 18.00it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=0.0355]\n",
      "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=0.0355]        \n",
      "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.0355]        \n",
      "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=0.0355]        \n",
      "Epoch 865: 100%|██████████| 1/1 [00:00<00:00, 38.58it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=0.0355]\n",
      "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.0355]        \n",
      "Epoch 867: 100%|██████████| 1/1 [00:00<00:00, 29.77it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.0355]\n",
      "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.0355]        \n",
      "Epoch 869: 100%|██████████| 1/1 [00:00<00:00, 27.61it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.0355]\n",
      "Epoch 871: 100%|██████████| 1/1 [00:00<00:00, 26.87it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.0355]\n",
      "Epoch 873: 100%|██████████| 1/1 [00:00<00:00, 27.85it/s, v_num=0, train_loss_step=0.461, train_loss_epoch=0.461, valid_loss=0.0355]\n",
      "Epoch 875: 100%|██████████| 1/1 [00:00<00:00, 28.53it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0355]\n",
      "Epoch 877: 100%|██████████| 1/1 [00:00<00:00, 30.40it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0355]\n",
      "Epoch 879: 100%|██████████| 1/1 [00:00<00:00, 38.96it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471, valid_loss=0.0355]\n",
      "Epoch 881: 100%|██████████| 1/1 [00:00<00:00, 35.69it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.0355]\n",
      "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0355]        \n",
      "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0355]        \n",
      "Epoch 887: 100%|██████████| 1/1 [00:00<00:00, 18.50it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0355]\n",
      "Epoch 888:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0355]        \n",
      "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0355]        \n",
      "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0355]        \n",
      "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0355]        \n",
      "Epoch 896:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0355]        \n",
      "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0355]        \n",
      "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 19.87it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.492, valid_loss=0.0355]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=10234)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 39.48it/s]\u001b[A\n",
      "Epoch 901: 100%|██████████| 1/1 [00:00<00:00, 38.32it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0411]\n",
      "Epoch 901: 100%|██████████| 1/1 [00:00<00:00, 22.41it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0411]\n",
      "Epoch 901: 100%|██████████| 1/1 [00:00<00:00, 21.51it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0411]\n",
      "Epoch 902:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0411]        \n",
      "Epoch 903: 100%|██████████| 1/1 [00:00<00:00, 19.32it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0411]\n",
      "Epoch 904:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0411]        \n",
      "Epoch 905: 100%|██████████| 1/1 [00:00<00:00, 34.22it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0411]\n",
      "Epoch 905: 100%|██████████| 1/1 [00:00<00:00, 20.53it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.488, valid_loss=0.0411]\n",
      "Epoch 905: 100%|██████████| 1/1 [00:00<00:00, 20.24it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0411]\n",
      "Epoch 906:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0411]        \n",
      "Epoch 908:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0411]        \n",
      "Epoch 910:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0411]        \n",
      "Epoch 912:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0411]        \n",
      "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0411]        \n",
      "Epoch 916:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0411]        \n",
      "Epoch 918:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0411]        \n",
      "Epoch 920:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0411]        \n",
      "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0411]        \n",
      "Epoch 924:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0411]        \n",
      "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0411]        \n",
      "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0411]        \n",
      "Epoch 930:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0411]        \n",
      "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0411]        \n",
      "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0411]        \n",
      "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0411]        \n",
      "Epoch 938: 100%|██████████| 1/1 [00:00<00:00, 42.58it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0411]\n",
      "Epoch 940: 100%|██████████| 1/1 [00:00<00:00, 29.91it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0411]\n",
      "Epoch 942: 100%|██████████| 1/1 [00:00<00:00, 32.47it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0411]\n",
      "Epoch 944: 100%|██████████| 1/1 [00:00<00:00, 42.81it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0411]\n",
      "Epoch 946: 100%|██████████| 1/1 [00:00<00:00, 23.18it/s, v_num=0, train_loss_step=0.475, train_loss_epoch=0.477, valid_loss=0.0411]\n",
      "Epoch 946: 100%|██████████| 1/1 [00:00<00:00, 21.54it/s, v_num=0, train_loss_step=0.475, train_loss_epoch=0.475, valid_loss=0.0411]\n",
      "Epoch 947:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.475, train_loss_epoch=0.475, valid_loss=0.0411]        \n",
      "Epoch 948:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473, valid_loss=0.0411]        \n",
      "Epoch 948: 100%|██████████| 1/1 [00:00<00:00, 19.69it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473, valid_loss=0.0411]\n",
      "Epoch 950: 100%|██████████| 1/1 [00:00<00:00, 42.09it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.0411]\n",
      "Epoch 952:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0411]        \n",
      "Epoch 953:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0411]\n",
      "Epoch 955:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.0411]        \n",
      "Epoch 956: 100%|██████████| 1/1 [00:00<00:00, 18.88it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0411]\n",
      "Epoch 957:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.0411]        \n",
      "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0411]        \n",
      "Epoch 961:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.0411]        \n",
      "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.474, train_loss_epoch=0.474, valid_loss=0.0411]        \n",
      "Epoch 965:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.474, train_loss_epoch=0.474, valid_loss=0.0411]        \n",
      "Epoch 967:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471, valid_loss=0.0411]        \n",
      "Epoch 969:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.0411]        \n",
      "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=0.0411]        \n",
      "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.465, valid_loss=0.0411]        \n",
      "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=0.0411]        \n",
      "Epoch 977:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=0.0411]        \n",
      "Epoch 979:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.465, valid_loss=0.0411]        \n",
      "Epoch 979: 100%|██████████| 1/1 [00:00<00:00, 34.14it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.465, valid_loss=0.0411]\n",
      "Epoch 981:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=0.0411]        \n",
      "Epoch 981: 100%|██████████| 1/1 [00:00<00:00, 31.05it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=0.0411]\n",
      "Epoch 983: 100%|██████████| 1/1 [00:00<00:00, 44.47it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=0.0411]\n",
      "Epoch 985: 100%|██████████| 1/1 [00:00<00:00, 30.37it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0411]\n",
      "Epoch 987: 100%|██████████| 1/1 [00:00<00:00, 22.54it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.465, valid_loss=0.0411]\n",
      "Epoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.465, valid_loss=0.0411]        \n",
      "Epoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.0411]        \n",
      "Epoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=0.0411]        \n",
      "Epoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=0.0411]        \n",
      "Epoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=0.0411]        \n",
      "Epoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.0411]        \n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 23.10it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.464, valid_loss=0.0411]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 50.24it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=10234)\u001b[0m \n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 13.07it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.0413]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=10234)\u001b[0m `Trainer.fit` stopped: `max_steps=1000` reached.\n",
      "\u001b[36m(_train_tune pid=10624)\u001b[0m /home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=10624)\u001b[0m Seed set to 4\n",
      "\u001b[36m(_train_tune pid=10624)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=10624)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=10624)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=10624)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(_train_tune pid=10624)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_train_tune pid=10624)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=10624)\u001b[0m   | Name            | Type          | Params | Mode \n",
      "\u001b[36m(_train_tune pid=10624)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=10624)\u001b[0m 0 | loss            | WMAPE         | 0      | train\n",
      "\u001b[36m(_train_tune pid=10624)\u001b[0m 1 | padder          | ConstantPad1d | 0      | train\n",
      "\u001b[36m(_train_tune pid=10624)\u001b[0m 2 | scaler          | TemporalNorm  | 0      | train\n",
      "\u001b[36m(_train_tune pid=10624)\u001b[0m 3 | hist_encoder    | LSTM          | 10.6 K | train\n",
      "\u001b[36m(_train_tune pid=10624)\u001b[0m 4 | context_adapter | Linear        | 19.6 K | train\n",
      "\u001b[36m(_train_tune pid=10624)\u001b[0m 5 | mlp_decoder     | MLP           | 449    | train\n",
      "\u001b[36m(_train_tune pid=10624)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=10624)\u001b[0m 30.7 K    Trainable params\n",
      "\u001b[36m(_train_tune pid=10624)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=10624)\u001b[0m 30.7 K    Total params\n",
      "\u001b[36m(_train_tune pid=10624)\u001b[0m 0.123     Total estimated model params size (MB)\n",
      "\u001b[36m(_train_tune pid=10624)\u001b[0m 11        Modules in train mode\n",
      "\u001b[36m(_train_tune pid=10624)\u001b[0m 0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Sanity Checking DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  4.13it/s]\n",
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997]        \n",
      "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.996, train_loss_epoch=0.996]        \n",
      "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.990, train_loss_epoch=0.990]         \n",
      "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.980, train_loss_epoch=0.980]         \n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00, 81.68it/s, v_num=0, train_loss_step=0.960, train_loss_epoch=0.960] \n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00, 73.34it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=0.960]\n",
      "Epoch 33: 100%|██████████| 1/1 [00:00<00:00, 69.22it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=0.950]\n",
      "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=0.950]        \n",
      "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.904, train_loss_epoch=0.904]        \n",
      "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.836, train_loss_epoch=0.836]         \n",
      "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.803, train_loss_epoch=0.803]         \n",
      "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.758, train_loss_epoch=0.758]         \n",
      "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.748, train_loss_epoch=0.748]         \n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00, 99.70it/s, v_num=0, train_loss_step=0.715, train_loss_epoch=0.715] \n",
      "Epoch 77: 100%|██████████| 1/1 [00:00<00:00, 83.93it/s, v_num=0, train_loss_step=0.703, train_loss_epoch=0.703]\n",
      "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.703, train_loss_epoch=0.703]        \n",
      "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.729, train_loss_epoch=0.729]         \n",
      "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.710, train_loss_epoch=0.710]        \n",
      "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.715, train_loss_epoch=0.715]        \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 74.40it/s, v_num=0, train_loss_step=0.669, train_loss_epoch=0.715]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 122.15it/s]\u001b[A\n",
      "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.676, train_loss_epoch=0.676, valid_loss=0.137]        \n",
      "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.687, train_loss_epoch=0.687, valid_loss=0.137]         \n",
      "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.671, train_loss_epoch=0.671, valid_loss=0.137]         \n",
      "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.701, train_loss_epoch=0.701, valid_loss=0.137]         \n",
      "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.595, train_loss_epoch=0.595, valid_loss=0.137]        \n",
      "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.706, train_loss_epoch=0.706, valid_loss=0.137]        \n",
      "Epoch 145: 100%|██████████| 1/1 [00:00<00:00, 77.86it/s, v_num=0, train_loss_step=0.682, train_loss_epoch=0.682, valid_loss=0.137]\n",
      "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.682, train_loss_epoch=0.682, valid_loss=0.137]        \n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00, 103.43it/s, v_num=0, train_loss_step=0.703, train_loss_epoch=0.703, valid_loss=0.137]\n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00, 88.09it/s, v_num=0, train_loss_step=0.589, train_loss_epoch=0.703, valid_loss=0.137] \n",
      "Epoch 153: 100%|██████████| 1/1 [00:00<00:00, 81.54it/s, v_num=0, train_loss_step=0.589, train_loss_epoch=0.589, valid_loss=0.137]\n",
      "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.589, train_loss_epoch=0.589, valid_loss=0.137]        \n",
      "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.690, train_loss_epoch=0.690, valid_loss=0.137]        \n",
      "Epoch 165: 100%|██████████| 1/1 [00:00<00:00, 80.36it/s, v_num=0, train_loss_step=0.692, train_loss_epoch=0.692, valid_loss=0.137]\n",
      "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.692, train_loss_epoch=0.692, valid_loss=0.137]        \n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00, 92.81it/s, v_num=0, train_loss_step=0.700, train_loss_epoch=0.700, valid_loss=0.137] \n",
      "Epoch 173: 100%|██████████| 1/1 [00:00<00:00, 79.39it/s, v_num=0, train_loss_step=0.616, train_loss_epoch=0.616, valid_loss=0.137]\n",
      "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.616, train_loss_epoch=0.616, valid_loss=0.137]        \n",
      "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.711, train_loss_epoch=0.711, valid_loss=0.137]        \n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00, 77.73it/s, v_num=0, train_loss_step=0.617, train_loss_epoch=0.711, valid_loss=0.137]\n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00, 73.91it/s, v_num=0, train_loss_step=0.617, train_loss_epoch=0.617, valid_loss=0.137]\n",
      "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.617, train_loss_epoch=0.617, valid_loss=0.137]        \n",
      "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.630, train_loss_epoch=0.630, valid_loss=0.137]        \n",
      "Epoch 187: 100%|██████████| 1/1 [00:00<00:00, 51.69it/s, v_num=0, train_loss_step=0.641, train_loss_epoch=0.641, valid_loss=0.137]\n",
      "Epoch 194: 100%|██████████| 1/1 [00:00<00:00, 61.62it/s, v_num=0, train_loss_step=0.703, train_loss_epoch=0.703, valid_loss=0.137] \n",
      "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.703, train_loss_epoch=0.703, valid_loss=0.137]        \n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 61.90it/s, v_num=0, train_loss_step=0.690, train_loss_epoch=0.572, valid_loss=0.137]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 73.65it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=10624)\u001b[0m \n",
      "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.691, train_loss_epoch=0.691, valid_loss=0.0464]        \n",
      "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.699, train_loss_epoch=0.699, valid_loss=0.0464]        \n",
      "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.619, train_loss_epoch=0.619, valid_loss=0.0464]        \n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00, 100.66it/s, v_num=0, train_loss_step=0.619, train_loss_epoch=0.619, valid_loss=0.0464]\n",
      "Epoch 218: 100%|██████████| 1/1 [00:00<00:00, 84.72it/s, v_num=0, train_loss_step=0.705, train_loss_epoch=0.705, valid_loss=0.0464] \n",
      "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.705, train_loss_epoch=0.705, valid_loss=0.0464]        \n",
      "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.581, train_loss_epoch=0.581, valid_loss=0.0464]         \n",
      "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569, valid_loss=0.0464]         \n",
      "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.701, train_loss_epoch=0.701, valid_loss=0.0464]         \n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00, 78.32it/s, v_num=0, train_loss_step=0.683, train_loss_epoch=0.701, valid_loss=0.0464]\n",
      "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.683, train_loss_epoch=0.683, valid_loss=0.0464]        \n",
      "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573, valid_loss=0.0464]        \n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00, 94.07it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573, valid_loss=0.0464]\n",
      "Epoch 247: 100%|██████████| 1/1 [00:00<00:00, 76.97it/s, v_num=0, train_loss_step=0.699, train_loss_epoch=0.699, valid_loss=0.0464]\n",
      "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.699, train_loss_epoch=0.699, valid_loss=0.0464]        \n",
      "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.644, train_loss_epoch=0.644, valid_loss=0.0464]         \n",
      "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.694, train_loss_epoch=0.694, valid_loss=0.0464]        \n",
      "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567, valid_loss=0.0464]        \n",
      "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567, valid_loss=0.0464]         \n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00, 96.76it/s, v_num=0, train_loss_step=0.649, train_loss_epoch=0.649, valid_loss=0.0464] \n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00, 81.93it/s, v_num=0, train_loss_step=0.588, train_loss_epoch=0.588, valid_loss=0.0464]\n",
      "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.588, train_loss_epoch=0.588, valid_loss=0.0464]        \n",
      "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.686, train_loss_epoch=0.686, valid_loss=0.0464]         \n",
      "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=0.0464]         \n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 77.29it/s, v_num=0, train_loss_step=0.709, train_loss_epoch=0.713, valid_loss=0.0464]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 129.33it/s]\u001b[A\n",
      "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.695, train_loss_epoch=0.695, valid_loss=0.0684]         \n",
      "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.688, train_loss_epoch=0.688, valid_loss=0.0684]         \n",
      "Epoch 318: 100%|██████████| 1/1 [00:00<00:00, 93.39it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.547, valid_loss=0.0684] \n",
      "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0684]        \n",
      "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0684]\n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00, 79.40it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0684] \n",
      "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0684]        \n",
      "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.659, train_loss_epoch=0.659, valid_loss=0.0684]         \n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00, 90.75it/s, v_num=0, train_loss_step=0.625, train_loss_epoch=0.625, valid_loss=0.0684] \n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00, 77.89it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0684]\n",
      "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0684]        \n",
      "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.692, train_loss_epoch=0.692, valid_loss=0.0684]        \n",
      "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.644, train_loss_epoch=0.644, valid_loss=0.0684]         \n",
      "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.693, train_loss_epoch=0.693, valid_loss=0.0684]         \n",
      "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.691, train_loss_epoch=0.691, valid_loss=0.0684]         \n",
      "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.649, train_loss_epoch=0.649, valid_loss=0.0684]         \n",
      "Epoch 386: 100%|██████████| 1/1 [00:00<00:00, 68.10it/s, v_num=0, train_loss_step=0.629, train_loss_epoch=0.629, valid_loss=0.0684] \n",
      "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.629, train_loss_epoch=0.629, valid_loss=0.0684]        \n",
      "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.687, train_loss_epoch=0.687, valid_loss=0.0684]         \n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 68.78it/s, v_num=0, train_loss_step=0.692, train_loss_epoch=0.684, valid_loss=0.0684] \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 93.66it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=10624)\u001b[0m \n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 27.00it/s, v_num=0, train_loss_step=0.692, train_loss_epoch=0.684, valid_loss=0.0433]\n",
      "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.692, train_loss_epoch=0.692, valid_loss=0.0433]        \n",
      "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.692, train_loss_epoch=0.692, valid_loss=0.0433]\n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00, 80.75it/s, v_num=0, train_loss_step=0.687, train_loss_epoch=0.687, valid_loss=0.0433] \n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00, 71.60it/s, v_num=0, train_loss_step=0.680, train_loss_epoch=0.687, valid_loss=0.0433]\n",
      "Epoch 407: 100%|██████████| 1/1 [00:00<00:00, 64.58it/s, v_num=0, train_loss_step=0.680, train_loss_epoch=0.680, valid_loss=0.0433]\n",
      "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.680, train_loss_epoch=0.680, valid_loss=0.0433]        \n",
      "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.0433]         \n",
      "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.684, train_loss_epoch=0.684, valid_loss=0.0433]        \n",
      "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.653, train_loss_epoch=0.653, valid_loss=0.0433]        \n",
      "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.672, train_loss_epoch=0.672, valid_loss=0.0433]        \n",
      "Epoch 434: 100%|██████████| 1/1 [00:00<00:00,  4.13it/s, v_num=0, train_loss_step=0.670, train_loss_epoch=0.670, valid_loss=0.0433]\n",
      "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.670, train_loss_epoch=0.670, valid_loss=0.0433]        \n",
      "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.0433]         \n",
      "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.609, train_loss_epoch=0.609, valid_loss=0.0433]        \n",
      "Epoch 455: 100%|██████████| 1/1 [00:00<00:00, 78.84it/s, v_num=0, train_loss_step=0.674, train_loss_epoch=0.544, valid_loss=0.0433] \n",
      "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.674, train_loss_epoch=0.674, valid_loss=0.0433]        \n",
      "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.659, train_loss_epoch=0.659, valid_loss=0.0433]         \n",
      "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.669, train_loss_epoch=0.669, valid_loss=0.0433]         \n",
      "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.642, train_loss_epoch=0.642, valid_loss=0.0433]        \n",
      "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.668, train_loss_epoch=0.668, valid_loss=0.0433]        \n",
      "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.622, train_loss_epoch=0.622, valid_loss=0.0433]         \n",
      "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.653, train_loss_epoch=0.653, valid_loss=0.0433]        \n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 76.31it/s, v_num=0, train_loss_step=0.666, train_loss_epoch=0.660, valid_loss=0.0433]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 125.66it/s]\u001b[A\n",
      "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0422]        \n",
      "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0422]         \n",
      "Epoch 510: 100%|██████████| 1/1 [00:00<00:00, 98.97it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0422]\n",
      "Epoch 510: 100%|██████████| 1/1 [00:00<00:00, 81.16it/s, v_num=0, train_loss_step=0.631, train_loss_epoch=0.631, valid_loss=0.0422]\n",
      "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.631, train_loss_epoch=0.631, valid_loss=0.0422]        \n",
      "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0422]         \n",
      "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0422]         \n",
      "Epoch 525: 100%|██████████| 1/1 [00:00<00:00, 93.81it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0422]\n",
      "Epoch 525: 100%|██████████| 1/1 [00:00<00:00, 79.59it/s, v_num=0, train_loss_step=0.651, train_loss_epoch=0.651, valid_loss=0.0422]\n",
      "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.651, train_loss_epoch=0.651, valid_loss=0.0422]        \n",
      "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.652, train_loss_epoch=0.652, valid_loss=0.0422]         \n",
      "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.657, train_loss_epoch=0.657, valid_loss=0.0422]         \n",
      "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.575, train_loss_epoch=0.575, valid_loss=0.0422]         \n",
      "Epoch 546: 100%|██████████| 1/1 [00:00<00:00, 101.69it/s, v_num=0, train_loss_step=0.575, train_loss_epoch=0.575, valid_loss=0.0422]\n",
      "Epoch 546: 100%|██████████| 1/1 [00:00<00:00, 83.74it/s, v_num=0, train_loss_step=0.651, train_loss_epoch=0.651, valid_loss=0.0422] \n",
      "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.651, train_loss_epoch=0.651, valid_loss=0.0422]        \n",
      "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.656, train_loss_epoch=0.656, valid_loss=0.0422]         \n",
      "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.609, train_loss_epoch=0.609, valid_loss=0.0422]         \n",
      "Epoch 569: 100%|██████████| 1/1 [00:00<00:00, 101.59it/s, v_num=0, train_loss_step=0.631, train_loss_epoch=0.631, valid_loss=0.0422]\n",
      "Epoch 569: 100%|██████████| 1/1 [00:00<00:00, 81.87it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=0.0422] \n",
      "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=0.0422]        \n",
      "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.610, train_loss_epoch=0.610, valid_loss=0.0422]         \n",
      "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.630, train_loss_epoch=0.630, valid_loss=0.0422]         \n",
      "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.624, train_loss_epoch=0.624, valid_loss=0.0422]        \n",
      "Epoch 589: 100%|██████████| 1/1 [00:00<00:00, 82.28it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.624, valid_loss=0.0422]\n",
      "Epoch 589: 100%|██████████| 1/1 [00:00<00:00, 78.45it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0422]\n",
      "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0422]        \n",
      "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.631, train_loss_epoch=0.631, valid_loss=0.0422]         \n",
      "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 83.88it/s, v_num=0, train_loss_step=0.596, train_loss_epoch=0.646, valid_loss=0.0422]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 129.34it/s]\u001b[A\n",
      "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0426]         \n",
      "Epoch 610: 100%|██████████| 1/1 [00:00<00:00, 103.58it/s, v_num=0, train_loss_step=0.641, train_loss_epoch=0.641, valid_loss=0.0426]\n",
      "Epoch 610: 100%|██████████| 1/1 [00:00<00:00, 83.69it/s, v_num=0, train_loss_step=0.619, train_loss_epoch=0.619, valid_loss=0.0426] \n",
      "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.619, train_loss_epoch=0.619, valid_loss=0.0426]        \n",
      "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.621, train_loss_epoch=0.621, valid_loss=0.0426]         \n",
      "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563, valid_loss=0.0426]         \n",
      "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0426]         \n",
      "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.619, train_loss_epoch=0.619, valid_loss=0.0426]         \n",
      "Epoch 648: 100%|██████████| 1/1 [00:00<00:00, 69.66it/s, v_num=0, train_loss_step=0.611, train_loss_epoch=0.611, valid_loss=0.0426]\n",
      "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.611, train_loss_epoch=0.611, valid_loss=0.0426]        \n",
      "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.604, train_loss_epoch=0.604, valid_loss=0.0426]         \n",
      "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0426]        \n",
      "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.630, train_loss_epoch=0.630, valid_loss=0.0426]         \n",
      "Epoch 677: 100%|██████████| 1/1 [00:00<00:00, 87.04it/s, v_num=0, train_loss_step=0.604, train_loss_epoch=0.604, valid_loss=0.0426] \n",
      "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.604, train_loss_epoch=0.604, valid_loss=0.0426]        \n",
      "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.577, train_loss_epoch=0.577, valid_loss=0.0426]         \n",
      "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.662, train_loss_epoch=0.662, valid_loss=0.0426]        \n",
      "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.604, train_loss_epoch=0.604, valid_loss=0.0426]         \n",
      "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 109.20it/s, v_num=0, train_loss_step=0.604, train_loss_epoch=0.604, valid_loss=0.0426]\n",
      "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 90.45it/s, v_num=0, train_loss_step=0.670, train_loss_epoch=0.604, valid_loss=0.0426] \n",
      "\u001b[36m(_train_tune pid=10624)\u001b[0m \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=10624)\u001b[0m \n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=10624)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 122.24it/s]\u001b[A\n",
      "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.589, train_loss_epoch=0.589, valid_loss=0.0997]         \n",
      "Epoch 713: 100%|██████████| 1/1 [00:00<00:00, 95.80it/s, v_num=0, train_loss_step=0.659, train_loss_epoch=0.659, valid_loss=0.0997] \n",
      "Epoch 713: 100%|██████████| 1/1 [00:00<00:00, 78.46it/s, v_num=0, train_loss_step=0.665, train_loss_epoch=0.665, valid_loss=0.0997]\n",
      "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.665, train_loss_epoch=0.665, valid_loss=0.0997]        \n",
      "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=0.0997]         \n",
      "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574, valid_loss=0.0997]         \n",
      "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.634, train_loss_epoch=0.634, valid_loss=0.0997]        \n",
      "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.661, train_loss_epoch=0.661, valid_loss=0.0997]         \n",
      "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0997]         \n",
      "Epoch 752: 100%|██████████| 1/1 [00:00<00:00, 88.03it/s, v_num=0, train_loss_step=0.570, train_loss_epoch=0.570, valid_loss=0.0997] \n",
      "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.570, train_loss_epoch=0.570, valid_loss=0.0997]        \n",
      "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.644, train_loss_epoch=0.644, valid_loss=0.0997]         \n",
      "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.656, train_loss_epoch=0.656, valid_loss=0.0997]         \n",
      "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.636, train_loss_epoch=0.636, valid_loss=0.0997]        \n",
      "Epoch 782: 100%|██████████| 1/1 [00:00<00:00, 84.27it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=0.0997] \n",
      "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=0.0997]        \n",
      "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0997]        \n",
      "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.631, train_loss_epoch=0.631, valid_loss=0.0997]        \n",
      "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 87.07it/s, v_num=0, train_loss_step=0.606, train_loss_epoch=0.552, valid_loss=0.0997] \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 103.44it/s]\u001b[A\n",
      "Epoch 801: 100%|██████████| 1/1 [00:00<00:00, 78.72it/s, v_num=0, train_loss_step=0.610, train_loss_epoch=0.610, valid_loss=0.0428]\n",
      "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.610, train_loss_epoch=0.610, valid_loss=0.0428]        \n",
      "Epoch 808: 100%|██████████| 1/1 [00:00<00:00, 81.08it/s, v_num=0, train_loss_step=0.640, train_loss_epoch=0.640, valid_loss=0.0428] \n",
      "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.640, train_loss_epoch=0.640, valid_loss=0.0428]        \n",
      "Epoch 816: 100%|██████████| 1/1 [00:00<00:00, 72.16it/s, v_num=0, train_loss_step=0.603, train_loss_epoch=0.594, valid_loss=0.0428] \n",
      "Epoch 816: 100%|██████████| 1/1 [00:00<00:00, 68.71it/s, v_num=0, train_loss_step=0.603, train_loss_epoch=0.603, valid_loss=0.0428]\n",
      "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.603, train_loss_epoch=0.603, valid_loss=0.0428]        \n",
      "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0428]         \n",
      "Epoch 831:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.624, train_loss_epoch=0.624, valid_loss=0.0428]         \n",
      "Epoch 831: 100%|██████████| 1/1 [00:00<00:00, 106.35it/s, v_num=0, train_loss_step=0.624, train_loss_epoch=0.624, valid_loss=0.0428]\n",
      "Epoch 831: 100%|██████████| 1/1 [00:00<00:00, 90.13it/s, v_num=0, train_loss_step=0.631, train_loss_epoch=0.624, valid_loss=0.0428] \n",
      "Epoch 831:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.631, train_loss_epoch=0.631, valid_loss=0.0428]        \n",
      "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.631, train_loss_epoch=0.631, valid_loss=0.0428]\n",
      "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0428]         \n",
      "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.607, train_loss_epoch=0.607, valid_loss=0.0428]         \n",
      "Epoch 853:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.610, train_loss_epoch=0.610, valid_loss=0.0428]         \n",
      "Epoch 860:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.0428]         \n",
      "Epoch 868:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.632, train_loss_epoch=0.632, valid_loss=0.0428]         \n",
      "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0428]         \n",
      "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.0428]         \n",
      "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.617, train_loss_epoch=0.617, valid_loss=0.0428]         \n",
      "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0428]        \n",
      "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 91.38it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.515, valid_loss=0.0428] \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 132.59it/s]\u001b[A\n",
      "Epoch 903: 100%|██████████| 1/1 [00:00<00:00, 78.85it/s, v_num=0, train_loss_step=0.611, train_loss_epoch=0.611, valid_loss=0.0414] \n",
      "Epoch 903: 100%|██████████| 1/1 [00:00<00:00, 71.44it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.0414]\n",
      "Epoch 904:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.0414]        \n",
      "Epoch 911:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.610, train_loss_epoch=0.610, valid_loss=0.0414]         \n",
      "Epoch 918: 100%|██████████| 1/1 [00:00<00:00, 71.79it/s, v_num=0, train_loss_step=0.975, train_loss_epoch=0.549, valid_loss=0.0414] \n",
      "Epoch 918: 100%|██████████| 1/1 [00:00<00:00, 68.85it/s, v_num=0, train_loss_step=0.975, train_loss_epoch=0.975, valid_loss=0.0414]\n",
      "Epoch 919:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.975, train_loss_epoch=0.975, valid_loss=0.0414]        \n",
      "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.578, train_loss_epoch=0.578, valid_loss=0.0414]         \n",
      "Epoch 926: 100%|██████████| 1/1 [00:00<00:00, 94.65it/s, v_num=0, train_loss_step=0.578, train_loss_epoch=0.578, valid_loss=0.0414]\n",
      "Epoch 926: 100%|██████████| 1/1 [00:00<00:00, 78.23it/s, v_num=0, train_loss_step=0.663, train_loss_epoch=0.663, valid_loss=0.0414]\n",
      "Epoch 927:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.663, train_loss_epoch=0.663, valid_loss=0.0414]        \n",
      "Epoch 934: 100%|██████████| 1/1 [00:00<00:00, 86.64it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0414] \n",
      "Epoch 934: 100%|██████████| 1/1 [00:00<00:00, 77.32it/s, v_num=0, train_loss_step=0.669, train_loss_epoch=0.539, valid_loss=0.0414]\n",
      "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.669, train_loss_epoch=0.669, valid_loss=0.0414]        \n",
      "Epoch 935:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.669, train_loss_epoch=0.669, valid_loss=0.0414]\n",
      "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.681, train_loss_epoch=0.681, valid_loss=0.0414]         \n",
      "Epoch 948:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.602, train_loss_epoch=0.602, valid_loss=0.0414]         \n",
      "Epoch 956:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.608, train_loss_epoch=0.608, valid_loss=0.0414]         \n",
      "Epoch 962: 100%|██████████| 1/1 [00:00<00:00, 77.80it/s, v_num=0, train_loss_step=0.685, train_loss_epoch=0.677, valid_loss=0.0414]\n",
      "Epoch 962: 100%|██████████| 1/1 [00:00<00:00, 73.82it/s, v_num=0, train_loss_step=0.685, train_loss_epoch=0.685, valid_loss=0.0414]\n",
      "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.685, train_loss_epoch=0.685, valid_loss=0.0414]        \n",
      "Epoch 970:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.687, train_loss_epoch=0.687, valid_loss=0.0414]         \n",
      "Epoch 978:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.600, train_loss_epoch=0.600, valid_loss=0.0414]         \n",
      "Epoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.664, train_loss_epoch=0.664, valid_loss=0.0414]         \n",
      "Epoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.653, train_loss_epoch=0.653, valid_loss=0.0414]         \n",
      "Epoch 992: 100%|██████████| 1/1 [00:00<00:00, 88.97it/s, v_num=0, train_loss_step=0.653, train_loss_epoch=0.653, valid_loss=0.0414]\n",
      "Epoch 992: 100%|██████████| 1/1 [00:00<00:00, 76.60it/s, v_num=0, train_loss_step=0.651, train_loss_epoch=0.651, valid_loss=0.0414]\n",
      "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.651, train_loss_epoch=0.651, valid_loss=0.0414]        \n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 88.88it/s, v_num=0, train_loss_step=0.624, train_loss_epoch=0.591, valid_loss=0.0414] \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=10624)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 138.11it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=10624)\u001b[0m `Trainer.fit` stopped: `max_steps=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=10624)\u001b[0m \n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 34.39it/s, v_num=0, train_loss_step=0.624, train_loss_epoch=0.624, valid_loss=0.042] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=10766)\u001b[0m /home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=10766)\u001b[0m Seed set to 11\n",
      "\u001b[36m(_train_tune pid=10766)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=10766)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=10766)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=10766)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(_train_tune pid=10766)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_train_tune pid=10766)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=10766)\u001b[0m   | Name            | Type          | Params | Mode \n",
      "\u001b[36m(_train_tune pid=10766)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=10766)\u001b[0m 0 | loss            | WMAPE         | 0      | train\n",
      "\u001b[36m(_train_tune pid=10766)\u001b[0m 1 | padder          | ConstantPad1d | 0      | train\n",
      "\u001b[36m(_train_tune pid=10766)\u001b[0m 2 | scaler          | TemporalNorm  | 0      | train\n",
      "\u001b[36m(_train_tune pid=10766)\u001b[0m 3 | hist_encoder    | LSTM          | 363 K  | train\n",
      "\u001b[36m(_train_tune pid=10766)\u001b[0m 4 | context_adapter | Linear        | 115 K  | train\n",
      "\u001b[36m(_train_tune pid=10766)\u001b[0m 5 | mlp_decoder     | MLP           | 897    | train\n",
      "\u001b[36m(_train_tune pid=10766)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=10766)\u001b[0m 480 K     Trainable params\n",
      "\u001b[36m(_train_tune pid=10766)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=10766)\u001b[0m 480 K     Total params\n",
      "\u001b[36m(_train_tune pid=10766)\u001b[0m 1.922     Total estimated model params size (MB)\n",
      "\u001b[36m(_train_tune pid=10766)\u001b[0m 11        Modules in train mode\n",
      "\u001b[36m(_train_tune pid=10766)\u001b[0m 0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Sanity Checking DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  2.69it/s]\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]        \n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 47.88it/s, v_num=0, train_loss_step=0.985, train_loss_epoch=0.985]\n",
      "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.961, train_loss_epoch=0.961]        \n",
      "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.936, train_loss_epoch=0.936]        \n",
      "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.881, train_loss_epoch=0.881]        \n",
      "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.827, train_loss_epoch=0.827]        \n",
      "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.953, train_loss_epoch=0.953]        \n",
      "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.900, train_loss_epoch=0.900]        \n",
      "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.828, train_loss_epoch=0.828]        \n",
      "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993]        \n",
      "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.703, train_loss_epoch=0.703]        \n",
      "Epoch 43: 100%|██████████| 1/1 [00:00<00:00, 35.03it/s, v_num=0, train_loss_step=0.693, train_loss_epoch=0.693]\n",
      "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.693, train_loss_epoch=0.693]        \n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00, 41.74it/s, v_num=0, train_loss_step=0.861, train_loss_epoch=0.638]\n",
      "Epoch 47: 100%|██████████| 1/1 [00:00<00:00, 39.89it/s, v_num=0, train_loss_step=0.861, train_loss_epoch=0.861]\n",
      "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.861, train_loss_epoch=0.861]        \n",
      "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525]        \n",
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00, 43.32it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525]\n",
      "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.673, train_loss_epoch=0.673]        \n",
      "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.622, train_loss_epoch=0.622]        \n",
      "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994]        \n",
      "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.643, train_loss_epoch=0.643]        \n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00, 48.50it/s, v_num=0, train_loss_step=0.703, train_loss_epoch=0.703]\n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00, 42.25it/s, v_num=0, train_loss_step=0.726, train_loss_epoch=0.703]\n",
      "Epoch 70: 100%|██████████| 1/1 [00:00<00:00, 41.19it/s, v_num=0, train_loss_step=0.726, train_loss_epoch=0.726]\n",
      "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.726, train_loss_epoch=0.726]        \n",
      "Epoch 74: 100%|██████████| 1/1 [00:00<00:00, 42.28it/s, v_num=0, train_loss_step=0.855, train_loss_epoch=0.855]\n",
      "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.855, train_loss_epoch=0.855]        \n",
      "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.783, train_loss_epoch=0.783]        \n",
      "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.615, train_loss_epoch=0.615]        \n",
      "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.602, train_loss_epoch=0.602]        \n",
      "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.602, train_loss_epoch=0.602]\n",
      "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.961, train_loss_epoch=0.961]        \n",
      "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.603, train_loss_epoch=0.603]        \n",
      "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565]        \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 40.54it/s, v_num=0, train_loss_step=0.658, train_loss_epoch=0.633]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=10766)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 19.82it/s]\u001b[A\n",
      "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.612, train_loss_epoch=0.612, valid_loss=0.0743]        \n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00, 36.20it/s, v_num=0, train_loss_step=0.679, train_loss_epoch=0.612, valid_loss=0.0743]\n",
      "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.679, train_loss_epoch=0.679, valid_loss=0.0743]        \n",
      "Epoch 106: 100%|██████████| 1/1 [00:00<00:00, 40.45it/s, v_num=0, train_loss_step=0.641, train_loss_epoch=0.641, valid_loss=0.0743]\n",
      "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.641, train_loss_epoch=0.641, valid_loss=0.0743]        \n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00, 50.27it/s, v_num=0, train_loss_step=0.658, train_loss_epoch=0.658, valid_loss=0.0743]\n",
      "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.687, train_loss_epoch=0.687, valid_loss=0.0743]        \n",
      "Epoch 114: 100%|██████████| 1/1 [00:00<00:00, 47.84it/s, v_num=0, train_loss_step=0.687, train_loss_epoch=0.687, valid_loss=0.0743]\n",
      "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.0743]        \n",
      "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.664, train_loss_epoch=0.664, valid_loss=0.0743]        \n",
      "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.804, train_loss_epoch=0.804, valid_loss=0.0743]        \n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00, 49.92it/s, v_num=0, train_loss_step=0.737, train_loss_epoch=0.737, valid_loss=0.0743]\n",
      "Epoch 129: 100%|██████████| 1/1 [00:00<00:00, 41.61it/s, v_num=0, train_loss_step=0.740, train_loss_epoch=0.740, valid_loss=0.0743]\n",
      "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.740, train_loss_epoch=0.740, valid_loss=0.0743]        \n",
      "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0743]        \n",
      "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.612, train_loss_epoch=0.612, valid_loss=0.0743]        \n",
      "Epoch 140: 100%|██████████| 1/1 [00:00<00:00, 42.20it/s, v_num=0, train_loss_step=0.870, train_loss_epoch=0.870, valid_loss=0.0743]\n",
      "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.870, train_loss_epoch=0.870, valid_loss=0.0743]        \n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00, 48.63it/s, v_num=0, train_loss_step=0.739, train_loss_epoch=0.739, valid_loss=0.0743]\n",
      "Epoch 144: 100%|██████████| 1/1 [00:00<00:00, 41.53it/s, v_num=0, train_loss_step=0.732, train_loss_epoch=0.732, valid_loss=0.0743]\n",
      "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.732, train_loss_epoch=0.732, valid_loss=0.0743]        \n",
      "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.653, train_loss_epoch=0.653, valid_loss=0.0743]        \n",
      "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.805, train_loss_epoch=0.805, valid_loss=0.0743]        \n",
      "Epoch 155: 100%|██████████| 1/1 [00:00<00:00, 33.67it/s, v_num=0, train_loss_step=0.650, train_loss_epoch=0.650, valid_loss=0.0743]\n",
      "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.650, train_loss_epoch=0.650, valid_loss=0.0743]        \n",
      "Epoch 159: 100%|██████████| 1/1 [00:00<00:00, 40.72it/s, v_num=0, train_loss_step=0.742, train_loss_epoch=0.742, valid_loss=0.0743]\n",
      "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.742, train_loss_epoch=0.742, valid_loss=0.0743]        \n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00, 52.50it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0743]\n",
      "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.620, train_loss_epoch=0.620, valid_loss=0.0743]        \n",
      "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.638, train_loss_epoch=0.638, valid_loss=0.0743]        \n",
      "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.943, train_loss_epoch=0.943, valid_loss=0.0743]        \n",
      "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.678, train_loss_epoch=0.678, valid_loss=0.0743]        \n",
      "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.412, train_loss_epoch=0.412, valid_loss=0.0743]        \n",
      "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0743]        \n",
      "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.612, train_loss_epoch=0.612, valid_loss=0.0743]        \n",
      "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.716, train_loss_epoch=0.716, valid_loss=0.0743]        \n",
      "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.686, train_loss_epoch=0.686, valid_loss=0.0743]        \n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00, 34.28it/s, v_num=0, train_loss_step=0.686, train_loss_epoch=0.686, valid_loss=0.0743]\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 33.71it/s, v_num=0, train_loss_step=0.848, train_loss_epoch=0.673, valid_loss=0.0743]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=10766)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 20.26it/s]\u001b[A\n",
      "Epoch 201: 100%|██████████| 1/1 [00:00<00:00, 31.39it/s, v_num=0, train_loss_step=0.634, train_loss_epoch=0.634, valid_loss=0.0782]\n",
      "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.634, train_loss_epoch=0.634, valid_loss=0.0782]        \n",
      "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.680, train_loss_epoch=0.680, valid_loss=0.0782]        \n",
      "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.727, train_loss_epoch=0.727, valid_loss=0.0782]        \n",
      "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.823, train_loss_epoch=0.823, valid_loss=0.0782]        \n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00, 47.77it/s, v_num=0, train_loss_step=0.644, train_loss_epoch=0.644, valid_loss=0.0782]\n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00, 33.83it/s, v_num=0, train_loss_step=0.739, train_loss_epoch=0.644, valid_loss=0.0782]\n",
      "Epoch 215: 100%|██████████| 1/1 [00:00<00:00, 32.59it/s, v_num=0, train_loss_step=0.739, train_loss_epoch=0.739, valid_loss=0.0782]\n",
      "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.739, train_loss_epoch=0.739, valid_loss=0.0782]        \n",
      "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.746, train_loss_epoch=0.746, valid_loss=0.0782]        \n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00, 46.17it/s, v_num=0, train_loss_step=0.746, train_loss_epoch=0.746, valid_loss=0.0782]\n",
      "Epoch 219: 100%|██████████| 1/1 [00:00<00:00, 40.73it/s, v_num=0, train_loss_step=0.792, train_loss_epoch=0.746, valid_loss=0.0782]\n",
      "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.792, train_loss_epoch=0.792, valid_loss=0.0782]        \n",
      "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.678, train_loss_epoch=0.678, valid_loss=0.0782]        \n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00, 42.02it/s, v_num=0, train_loss_step=0.617, train_loss_epoch=0.671, valid_loss=0.0782]\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00, 41.07it/s, v_num=0, train_loss_step=0.617, train_loss_epoch=0.617, valid_loss=0.0782]\n",
      "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.617, train_loss_epoch=0.617, valid_loss=0.0782]        \n",
      "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.628, train_loss_epoch=0.628, valid_loss=0.0782]        \n",
      "Epoch 231: 100%|██████████| 1/1 [00:00<00:00, 46.47it/s, v_num=0, train_loss_step=0.628, train_loss_epoch=0.628, valid_loss=0.0782]\n",
      "Epoch 231: 100%|██████████| 1/1 [00:00<00:00, 40.46it/s, v_num=0, train_loss_step=0.748, train_loss_epoch=0.748, valid_loss=0.0782]\n",
      "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.748, train_loss_epoch=0.748, valid_loss=0.0782]        \n",
      "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.761, train_loss_epoch=0.761, valid_loss=0.0782]        \n",
      "Epoch 238: 100%|██████████| 1/1 [00:00<00:00, 40.14it/s, v_num=0, train_loss_step=0.759, train_loss_epoch=0.759, valid_loss=0.0782]\n",
      "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.759, train_loss_epoch=0.759, valid_loss=0.0782]        \n",
      "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.734, train_loss_epoch=0.734, valid_loss=0.0782]        \n",
      "Epoch 245: 100%|██████████| 1/1 [00:00<00:00, 39.12it/s, v_num=0, train_loss_step=0.620, train_loss_epoch=0.620, valid_loss=0.0782]\n",
      "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.620, train_loss_epoch=0.620, valid_loss=0.0782]        \n",
      "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.621, train_loss_epoch=0.621, valid_loss=0.0782]        \n",
      "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.575, train_loss_epoch=0.575, valid_loss=0.0782]        \n",
      "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.891, train_loss_epoch=0.891, valid_loss=0.0782]        \n",
      "Epoch 257: 100%|██████████| 1/1 [00:00<00:00, 50.06it/s, v_num=0, train_loss_step=0.891, train_loss_epoch=0.891, valid_loss=0.0782]\n",
      "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.862, train_loss_epoch=0.862, valid_loss=0.0782]        \n",
      "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.642, train_loss_epoch=0.642, valid_loss=0.0782]        \n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00, 33.11it/s, v_num=0, train_loss_step=0.758, train_loss_epoch=0.758, valid_loss=0.0782]\n",
      "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.758, train_loss_epoch=0.758, valid_loss=0.0782]        \n",
      "Epoch 268: 100%|██████████| 1/1 [00:00<00:00, 39.68it/s, v_num=0, train_loss_step=0.625, train_loss_epoch=0.625, valid_loss=0.0782]\n",
      "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.625, train_loss_epoch=0.625, valid_loss=0.0782]        \n",
      "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.681, train_loss_epoch=0.681, valid_loss=0.0782]        \n",
      "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.625, train_loss_epoch=0.625, valid_loss=0.0782]        \n",
      "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.697, train_loss_epoch=0.697, valid_loss=0.0782]        \n",
      "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.838, train_loss_epoch=0.838, valid_loss=0.0782]        \n",
      "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.757, train_loss_epoch=0.757, valid_loss=0.0782]        \n",
      "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.625, train_loss_epoch=0.625, valid_loss=0.0782]        \n",
      "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.668, train_loss_epoch=0.668, valid_loss=0.0782]        \n",
      "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.572, valid_loss=0.0782]        \n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 41.90it/s, v_num=0, train_loss_step=0.589, train_loss_epoch=0.588, valid_loss=0.0782]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 21.04it/s]\u001b[A\n",
      "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.589, train_loss_epoch=0.589, valid_loss=0.0578]        \n",
      "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.882, train_loss_epoch=0.882, valid_loss=0.0578]        \n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00, 48.37it/s, v_num=0, train_loss_step=0.882, train_loss_epoch=0.882, valid_loss=0.0578]\n",
      "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.656, train_loss_epoch=0.656, valid_loss=0.0578]        \n",
      "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.660, train_loss_epoch=0.660, valid_loss=0.0578]        \n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00, 52.36it/s, v_num=0, train_loss_step=0.640, train_loss_epoch=0.640, valid_loss=0.0578]\n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00, 36.12it/s, v_num=0, train_loss_step=0.884, train_loss_epoch=0.640, valid_loss=0.0578]\n",
      "Epoch 314: 100%|██████████| 1/1 [00:00<00:00, 34.54it/s, v_num=0, train_loss_step=0.884, train_loss_epoch=0.884, valid_loss=0.0578]\n",
      "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.884, train_loss_epoch=0.884, valid_loss=0.0578]        \n",
      "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.383, train_loss_epoch=0.383, valid_loss=0.0578]        \n",
      "Epoch 318: 100%|██████████| 1/1 [00:00<00:00, 41.61it/s, v_num=0, train_loss_step=0.657, train_loss_epoch=0.657, valid_loss=0.0578]\n",
      "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.657, train_loss_epoch=0.657, valid_loss=0.0578]        \n",
      "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.726, train_loss_epoch=0.726, valid_loss=0.0578]        \n",
      "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.432, train_loss_epoch=0.432, valid_loss=0.0578]        \n",
      "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.862, train_loss_epoch=0.862, valid_loss=0.0578]        \n",
      "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.648, train_loss_epoch=0.648, valid_loss=0.0578]        \n",
      "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.826, train_loss_epoch=0.826, valid_loss=0.0578]        \n",
      "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.672, train_loss_epoch=0.672, valid_loss=0.0578]        \n",
      "Epoch 343: 100%|██████████| 1/1 [00:00<00:00, 46.04it/s, v_num=0, train_loss_step=0.944, train_loss_epoch=0.944, valid_loss=0.0578]\n",
      "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.613, train_loss_epoch=0.613, valid_loss=0.0578]        \n",
      "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.839, train_loss_epoch=0.839, valid_loss=0.0578]        \n",
      "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.664, train_loss_epoch=0.664, valid_loss=0.0578]        \n",
      "Epoch 358: 100%|██████████| 1/1 [00:00<00:00, 38.86it/s, v_num=0, train_loss_step=0.714, train_loss_epoch=0.714, valid_loss=0.0578]\n",
      "Epoch 358: 100%|██████████| 1/1 [00:00<00:00, 37.51it/s, v_num=0, train_loss_step=0.600, train_loss_epoch=0.600, valid_loss=0.0578]\n",
      "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.600, train_loss_epoch=0.600, valid_loss=0.0578]        \n",
      "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.785, train_loss_epoch=0.785, valid_loss=0.0578]        \n",
      "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.860, train_loss_epoch=0.860, valid_loss=0.0578]        \n",
      "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.668, train_loss_epoch=0.668, valid_loss=0.0578]        \n",
      "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.598, train_loss_epoch=0.598, valid_loss=0.0578]        \n",
      "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.634, train_loss_epoch=0.634, valid_loss=0.0578]        \n",
      "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0578]        \n",
      "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.693, train_loss_epoch=0.693, valid_loss=0.0578]        \n",
      "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.775, train_loss_epoch=0.775, valid_loss=0.0578]        \n",
      "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.606, train_loss_epoch=0.606, valid_loss=0.0578]        \n",
      "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.711, train_loss_epoch=0.711, valid_loss=0.0578]        \n",
      "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.649, train_loss_epoch=0.649, valid_loss=0.0578]        \n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 40.09it/s, v_num=0, train_loss_step=0.650, train_loss_epoch=0.912, valid_loss=0.0578]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=10766)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 10.03it/s]\u001b[A\n",
      "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.711, train_loss_epoch=0.711, valid_loss=0.120]         \n",
      "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.878, train_loss_epoch=0.878, valid_loss=0.120]        \n",
      "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.812, train_loss_epoch=0.812, valid_loss=0.120]        \n",
      "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.649, train_loss_epoch=0.649, valid_loss=0.120]        \n",
      "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.606, train_loss_epoch=0.606, valid_loss=0.120]        \n",
      "Epoch 419: 100%|██████████| 1/1 [00:00<00:00, 45.79it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563, valid_loss=0.120]\n",
      "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.639, train_loss_epoch=0.639, valid_loss=0.120]        \n",
      "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.846, train_loss_epoch=0.846, valid_loss=0.120]        \n",
      "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.607, train_loss_epoch=0.607, valid_loss=0.120]        \n",
      "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.599, train_loss_epoch=0.599, valid_loss=0.120]        \n",
      "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.726, train_loss_epoch=0.726, valid_loss=0.120]        \n",
      "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.639, train_loss_epoch=0.639, valid_loss=0.120]        \n",
      "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.736, train_loss_epoch=0.736, valid_loss=0.120]        \n",
      "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.590, train_loss_epoch=0.590, valid_loss=0.120]        \n",
      "Epoch 450: 100%|██████████| 1/1 [00:00<00:00, 36.96it/s, v_num=0, train_loss_step=0.821, train_loss_epoch=0.821, valid_loss=0.120]\n",
      "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.821, train_loss_epoch=0.821, valid_loss=0.120]        \n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00, 38.02it/s, v_num=0, train_loss_step=0.650, train_loss_epoch=0.650, valid_loss=0.120]\n",
      "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.620, train_loss_epoch=0.620, valid_loss=0.120]        \n",
      "Epoch 461: 100%|██████████| 1/1 [00:00<00:00, 42.10it/s, v_num=0, train_loss_step=0.881, train_loss_epoch=0.881, valid_loss=0.120]\n",
      "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.881, train_loss_epoch=0.881, valid_loss=0.120]        \n",
      "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.721, train_loss_epoch=0.721, valid_loss=0.120]        \n",
      "Epoch 468: 100%|██████████| 1/1 [00:00<00:00, 46.82it/s, v_num=0, train_loss_step=0.601, train_loss_epoch=0.601, valid_loss=0.120]\n",
      "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.120]        \n",
      "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.120]        \n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00, 41.41it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.120]\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00, 37.06it/s, v_num=0, train_loss_step=0.794, train_loss_epoch=0.496, valid_loss=0.120]\n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00, 36.19it/s, v_num=0, train_loss_step=0.794, train_loss_epoch=0.794, valid_loss=0.120]\n",
      "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.794, train_loss_epoch=0.794, valid_loss=0.120]        \n",
      "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.839, train_loss_epoch=0.839, valid_loss=0.120]        \n",
      "Epoch 482: 100%|██████████| 1/1 [00:00<00:00, 45.93it/s, v_num=0, train_loss_step=0.747, train_loss_epoch=0.747, valid_loss=0.120]\n",
      "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.685, train_loss_epoch=0.685, valid_loss=0.120]        \n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00, 45.76it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582, valid_loss=0.120]\n",
      "Epoch 489: 100%|██████████| 1/1 [00:00<00:00, 32.66it/s, v_num=0, train_loss_step=0.624, train_loss_epoch=0.624, valid_loss=0.120]\n",
      "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.624, train_loss_epoch=0.624, valid_loss=0.120]        \n",
      "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.598, train_loss_epoch=0.598, valid_loss=0.120]        \n",
      "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=0.120]        \n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 40.89it/s, v_num=0, train_loss_step=0.450, train_loss_epoch=0.665, valid_loss=0.120]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=10766)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 21.34it/s]\u001b[A\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 12.24it/s, v_num=0, train_loss_step=0.450, train_loss_epoch=0.450, valid_loss=0.0637]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=10766)\u001b[0m `Trainer.fit` stopped: `max_steps=500` reached.\n",
      "\u001b[36m(_train_tune pid=10911)\u001b[0m /home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=10911)\u001b[0m Seed set to 6\n",
      "\u001b[36m(_train_tune pid=10911)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=10911)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=10911)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=10911)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(_train_tune pid=10911)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=10911)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=10911)\u001b[0m   | Name            | Type          | Params | Mode \n",
      "\u001b[36m(_train_tune pid=10911)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=10911)\u001b[0m 0 | loss            | WMAPE         | 0      | train\n",
      "\u001b[36m(_train_tune pid=10911)\u001b[0m 1 | padder          | ConstantPad1d | 0      | train\n",
      "\u001b[36m(_train_tune pid=10911)\u001b[0m 2 | scaler          | TemporalNorm  | 0      | train\n",
      "\u001b[36m(_train_tune pid=10911)\u001b[0m 3 | hist_encoder    | LSTM          | 31.0 K | train\n",
      "\u001b[36m(_train_tune pid=10911)\u001b[0m 4 | context_adapter | Linear        | 39.3 K | train\n",
      "\u001b[36m(_train_tune pid=10911)\u001b[0m 5 | mlp_decoder     | MLP           | 6.1 K  | train\n",
      "\u001b[36m(_train_tune pid=10911)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=10911)\u001b[0m 76.4 K    Trainable params\n",
      "\u001b[36m(_train_tune pid=10911)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=10911)\u001b[0m 76.4 K    Total params\n",
      "\u001b[36m(_train_tune pid=10911)\u001b[0m 0.306     Total estimated model params size (MB)\n",
      "\u001b[36m(_train_tune pid=10911)\u001b[0m 11        Modules in train mode\n",
      "\u001b[36m(_train_tune pid=10911)\u001b[0m 0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.925, train_loss_epoch=0.925]        \n",
      "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.972, train_loss_epoch=0.972]         \n",
      "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.790, train_loss_epoch=0.790]        \n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00, 97.30it/s, v_num=0, train_loss_step=0.663, train_loss_epoch=0.663] \n",
      "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.835, train_loss_epoch=0.835]        \n",
      "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.617, train_loss_epoch=0.617]         \n",
      "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.751, train_loss_epoch=0.751]        \n",
      "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.793, train_loss_epoch=0.793]        \n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00, 52.16it/s, v_num=0, train_loss_step=0.673, train_loss_epoch=0.673]\n",
      "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.673, train_loss_epoch=0.673]        \n",
      "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.904, train_loss_epoch=0.904]        \n",
      "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]        \n",
      "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120]        \n",
      "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.650, train_loss_epoch=0.650]         \n",
      "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.824, train_loss_epoch=0.824]         \n",
      "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.824, train_loss_epoch=0.824]\n",
      "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.694, train_loss_epoch=0.694]         \n",
      "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.584, train_loss_epoch=0.584]         \n",
      "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.716, train_loss_epoch=0.716]         \n",
      "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.780, train_loss_epoch=0.780]        \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 65.91it/s, v_num=0, train_loss_step=0.697, train_loss_epoch=0.780]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 47.26it/s]\u001b[A\n",
      "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.871, train_loss_epoch=0.871, valid_loss=0.100]        \n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00, 60.01it/s, v_num=0, train_loss_step=0.871, train_loss_epoch=0.871, valid_loss=0.100]\n",
      "Epoch 102: 100%|██████████| 1/1 [00:00<00:00, 50.78it/s, v_num=0, train_loss_step=0.586, train_loss_epoch=0.586, valid_loss=0.100]\n",
      "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.586, train_loss_epoch=0.586, valid_loss=0.100]        \n",
      "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.741, train_loss_epoch=0.741, valid_loss=0.100]        \n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00, 105.43it/s, v_num=0, train_loss_step=0.791, train_loss_epoch=0.791, valid_loss=0.100]\n",
      "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.614, train_loss_epoch=0.614, valid_loss=0.100]         \n",
      "Epoch 122: 100%|██████████| 1/1 [00:00<00:00, 94.16it/s, v_num=0, train_loss_step=0.614, train_loss_epoch=0.614, valid_loss=0.100]\n",
      "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.770, train_loss_epoch=0.770, valid_loss=0.100]        \n",
      "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.613, train_loss_epoch=0.613, valid_loss=0.100]         \n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00, 67.84it/s, v_num=0, train_loss_step=0.613, train_loss_epoch=0.613, valid_loss=0.100]\n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00, 59.52it/s, v_num=0, train_loss_step=0.752, train_loss_epoch=0.613, valid_loss=0.100]\n",
      "Epoch 135: 100%|██████████| 1/1 [00:00<00:00, 57.21it/s, v_num=0, train_loss_step=0.752, train_loss_epoch=0.752, valid_loss=0.100]\n",
      "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.752, train_loss_epoch=0.752, valid_loss=0.100]        \n",
      "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.750, train_loss_epoch=0.750, valid_loss=0.100]         \n",
      "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.817, train_loss_epoch=0.817, valid_loss=0.100]         \n",
      "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.100]        \n",
      "Epoch 155: 100%|██████████| 1/1 [00:00<00:00, 56.22it/s, v_num=0, train_loss_step=0.651, train_loss_epoch=0.537, valid_loss=0.100]\n",
      "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.651, train_loss_epoch=0.651, valid_loss=0.100]        \n",
      "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.776, train_loss_epoch=0.776, valid_loss=0.100]         \n",
      "Epoch 162: 100%|██████████| 1/1 [00:00<00:00, 90.27it/s, v_num=0, train_loss_step=0.776, train_loss_epoch=0.776, valid_loss=0.100]\n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00, 96.57it/s, v_num=0, train_loss_step=0.625, train_loss_epoch=0.625, valid_loss=0.100] \n",
      "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.770, train_loss_epoch=0.770, valid_loss=0.100]         \n",
      "Epoch 176: 100%|██████████| 1/1 [00:00<00:00, 101.07it/s, v_num=0, train_loss_step=0.770, train_loss_epoch=0.770, valid_loss=0.100]\n",
      "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.669, train_loss_epoch=0.669, valid_loss=0.100]         \n",
      "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.918, train_loss_epoch=0.918, valid_loss=0.100]        \n",
      "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.647, train_loss_epoch=0.647, valid_loss=0.100]         \n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 67.27it/s, v_num=0, train_loss_step=0.824, train_loss_epoch=0.653, valid_loss=0.100]\n",
      "\u001b[36m(_train_tune pid=10911)\u001b[0m \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=10911)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 47.12it/s]\u001b[A\n",
      "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.465, valid_loss=0.118]         \n",
      "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.643, train_loss_epoch=0.643, valid_loss=0.118]         \n",
      "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.793, train_loss_epoch=0.793, valid_loss=0.118]         \n",
      "Epoch 222: 100%|██████████| 1/1 [00:00<00:00, 91.95it/s, v_num=0, train_loss_step=0.645, train_loss_epoch=0.645, valid_loss=0.118] \n",
      "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.833, train_loss_epoch=0.833, valid_loss=0.118]        \n",
      "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.598, train_loss_epoch=0.598, valid_loss=0.118]         \n",
      "Epoch 234: 100%|██████████| 1/1 [00:00<00:00, 90.51it/s, v_num=0, train_loss_step=0.598, train_loss_epoch=0.598, valid_loss=0.118]\n",
      "Epoch 240: 100%|██████████| 1/1 [00:00<00:00, 69.79it/s, v_num=0, train_loss_step=0.640, train_loss_epoch=0.725, valid_loss=0.118]\n",
      "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.640, train_loss_epoch=0.640, valid_loss=0.118]        \n",
      "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.689, train_loss_epoch=0.689, valid_loss=0.118]        \n",
      "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.733, train_loss_epoch=0.733, valid_loss=0.118]        \n",
      "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.631, train_loss_epoch=0.631, valid_loss=0.118]         \n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00, 61.25it/s, v_num=0, train_loss_step=0.961, train_loss_epoch=0.904, valid_loss=0.118]\n",
      "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.961, train_loss_epoch=0.961, valid_loss=0.118]        \n",
      "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.961, train_loss_epoch=0.961, valid_loss=0.118]\n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00, 93.83it/s, v_num=0, train_loss_step=0.754, train_loss_epoch=0.754, valid_loss=0.118]\n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00, 70.93it/s, v_num=0, train_loss_step=0.651, train_loss_epoch=0.754, valid_loss=0.118]\n",
      "Epoch 270: 100%|██████████| 1/1 [00:00<00:00, 66.34it/s, v_num=0, train_loss_step=0.651, train_loss_epoch=0.651, valid_loss=0.118]\n",
      "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.651, train_loss_epoch=0.651, valid_loss=0.118]        \n",
      "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.668, train_loss_epoch=0.668, valid_loss=0.118]        \n",
      "Epoch 282: 100%|██████████| 1/1 [00:00<00:00, 62.85it/s, v_num=0, train_loss_step=0.635, train_loss_epoch=0.635, valid_loss=0.118]\n",
      "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.635, train_loss_epoch=0.635, valid_loss=0.118]        \n",
      "Epoch 288: 100%|██████████| 1/1 [00:00<00:00, 61.03it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.118]\n",
      "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.118]        \n",
      "Epoch 294: 100%|██████████| 1/1 [00:00<00:00, 79.74it/s, v_num=0, train_loss_step=0.587, train_loss_epoch=0.587, valid_loss=0.118]\n",
      "Epoch 294: 100%|██████████| 1/1 [00:00<00:00, 63.82it/s, v_num=0, train_loss_step=0.695, train_loss_epoch=0.695, valid_loss=0.118]\n",
      "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.695, train_loss_epoch=0.695, valid_loss=0.118]        \n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 80.03it/s, v_num=0, train_loss_step=0.714, train_loss_epoch=0.957, valid_loss=0.118] \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.19it/s]\u001b[A\n",
      "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.714, train_loss_epoch=0.714, valid_loss=0.168]        \n",
      "Epoch 306: 100%|██████████| 1/1 [00:00<00:00, 94.75it/s, v_num=0, train_loss_step=0.680, train_loss_epoch=0.680, valid_loss=0.168] \n",
      "Epoch 306: 100%|██████████| 1/1 [00:00<00:00, 71.43it/s, v_num=0, train_loss_step=0.937, train_loss_epoch=0.937, valid_loss=0.168]\n",
      "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.937, train_loss_epoch=0.937, valid_loss=0.168]        \n",
      "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.719, train_loss_epoch=0.719, valid_loss=0.168]        \n",
      "Epoch 318: 100%|██████████| 1/1 [00:00<00:00, 51.61it/s, v_num=0, train_loss_step=0.686, train_loss_epoch=0.686, valid_loss=0.168]\n",
      "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.686, train_loss_epoch=0.686, valid_loss=0.168]        \n",
      "Epoch 324: 100%|██████████| 1/1 [00:00<00:00, 49.77it/s, v_num=0, train_loss_step=0.652, train_loss_epoch=0.652, valid_loss=0.168]\n",
      "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.652, train_loss_epoch=0.652, valid_loss=0.168]        \n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 50.08it/s, v_num=0, train_loss_step=0.409, train_loss_epoch=0.409, valid_loss=0.168]\n",
      "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.409, train_loss_epoch=0.409, valid_loss=0.168]        \n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00, 65.43it/s, v_num=0, train_loss_step=0.454, train_loss_epoch=0.454, valid_loss=0.168]\n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00, 56.56it/s, v_num=0, train_loss_step=0.861, train_loss_epoch=0.454, valid_loss=0.168]\n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00, 53.76it/s, v_num=0, train_loss_step=0.861, train_loss_epoch=0.861, valid_loss=0.168]\n",
      "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.861, train_loss_epoch=0.861, valid_loss=0.168]        \n",
      "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.724, train_loss_epoch=0.724, valid_loss=0.168]         \n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00, 89.76it/s, v_num=0, train_loss_step=0.724, train_loss_epoch=0.724, valid_loss=0.168]\n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00, 71.29it/s, v_num=0, train_loss_step=0.708, train_loss_epoch=0.724, valid_loss=0.168]\n",
      "Epoch 342: 100%|██████████| 1/1 [00:00<00:00, 67.09it/s, v_num=0, train_loss_step=0.708, train_loss_epoch=0.708, valid_loss=0.168]\n",
      "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.708, train_loss_epoch=0.708, valid_loss=0.168]        \n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00, 105.86it/s, v_num=0, train_loss_step=0.809, train_loss_epoch=0.809, valid_loss=0.168]\n",
      "Epoch 349: 100%|██████████| 1/1 [00:00<00:00, 77.90it/s, v_num=0, train_loss_step=0.698, train_loss_epoch=0.809, valid_loss=0.168] \n",
      "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.698, train_loss_epoch=0.698, valid_loss=0.168]        \n",
      "Epoch 356: 100%|██████████| 1/1 [00:00<00:00, 90.79it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.168] \n",
      "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.637, train_loss_epoch=0.637, valid_loss=0.168]         \n",
      "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.620, train_loss_epoch=0.620, valid_loss=0.168]        \n",
      "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.807, train_loss_epoch=0.807, valid_loss=0.168]         \n",
      "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.599, train_loss_epoch=0.599, valid_loss=0.168]        \n",
      "Epoch 384: 100%|██████████| 1/1 [00:00<00:00, 52.90it/s, v_num=0, train_loss_step=0.659, train_loss_epoch=0.659, valid_loss=0.168]\n",
      "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.659, train_loss_epoch=0.659, valid_loss=0.168]        \n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00, 91.72it/s, v_num=0, train_loss_step=0.753, train_loss_epoch=0.753, valid_loss=0.168]\n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00, 72.68it/s, v_num=0, train_loss_step=0.653, train_loss_epoch=0.753, valid_loss=0.168]\n",
      "Epoch 391: 100%|██████████| 1/1 [00:00<00:00, 69.63it/s, v_num=0, train_loss_step=0.653, train_loss_epoch=0.653, valid_loss=0.168]\n",
      "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.653, train_loss_epoch=0.653, valid_loss=0.168]        \n",
      "Epoch 398: 100%|██████████| 1/1 [00:00<00:00, 66.54it/s, v_num=0, train_loss_step=0.851, train_loss_epoch=0.851, valid_loss=0.168] \n",
      "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.851, train_loss_epoch=0.851, valid_loss=0.168]        \n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 72.07it/s, v_num=0, train_loss_step=0.655, train_loss_epoch=0.851, valid_loss=0.168]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 48.86it/s]\u001b[A\n",
      "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.644, train_loss_epoch=0.644, valid_loss=0.119]        \n",
      "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.676, train_loss_epoch=0.676, valid_loss=0.119]        \n",
      "Epoch 414: 100%|██████████| 1/1 [00:00<00:00, 67.44it/s, v_num=0, train_loss_step=0.627, train_loss_epoch=0.627, valid_loss=0.119] \n",
      "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.627, train_loss_epoch=0.627, valid_loss=0.119]        \n",
      "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.617, train_loss_epoch=0.617, valid_loss=0.119]        \n",
      "Epoch 424: 100%|██████████| 1/1 [00:00<00:00, 70.49it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.683, valid_loss=0.119] \n",
      "Epoch 424: 100%|██████████| 1/1 [00:00<00:00, 66.89it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=0.119]\n",
      "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=0.119]        \n",
      "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.779, train_loss_epoch=0.779, valid_loss=0.119]         \n",
      "Epoch 431: 100%|██████████| 1/1 [00:00<00:00, 101.99it/s, v_num=0, train_loss_step=0.779, train_loss_epoch=0.779, valid_loss=0.119]\n",
      "Epoch 431: 100%|██████████| 1/1 [00:00<00:00, 77.47it/s, v_num=0, train_loss_step=0.627, train_loss_epoch=0.779, valid_loss=0.119] \n",
      "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.627, train_loss_epoch=0.627, valid_loss=0.119]        \n",
      "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.657, train_loss_epoch=0.657, valid_loss=0.119]        \n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00, 78.34it/s, v_num=0, train_loss_step=0.709, train_loss_epoch=0.665, valid_loss=0.119] \n",
      "Epoch 437: 100%|██████████| 1/1 [00:00<00:00, 74.38it/s, v_num=0, train_loss_step=0.709, train_loss_epoch=0.709, valid_loss=0.119]\n",
      "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.709, train_loss_epoch=0.709, valid_loss=0.119]        \n",
      "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.652, train_loss_epoch=0.652, valid_loss=0.119]        \n",
      "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.691, train_loss_epoch=0.691, valid_loss=0.119]         \n",
      "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.619, train_loss_epoch=0.619, valid_loss=0.119]         \n",
      "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.655, train_loss_epoch=0.655, valid_loss=0.119]        \n",
      "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.668, train_loss_epoch=0.668, valid_loss=0.119]         \n",
      "Epoch 473: 100%|██████████| 1/1 [00:00<00:00, 49.07it/s, v_num=0, train_loss_step=0.810, train_loss_epoch=0.810, valid_loss=0.119]\n",
      "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.810, train_loss_epoch=0.810, valid_loss=0.119]        \n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00, 73.23it/s, v_num=0, train_loss_step=0.689, train_loss_epoch=0.689, valid_loss=0.119]\n",
      "Epoch 485: 100%|██████████| 1/1 [00:00<00:00, 59.43it/s, v_num=0, train_loss_step=0.639, train_loss_epoch=0.639, valid_loss=0.119] \n",
      "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.639, train_loss_epoch=0.639, valid_loss=0.119]        \n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00, 104.94it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582, valid_loss=0.119]\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00, 77.75it/s, v_num=0, train_loss_step=0.913, train_loss_epoch=0.582, valid_loss=0.119] \n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00, 74.46it/s, v_num=0, train_loss_step=0.913, train_loss_epoch=0.913, valid_loss=0.119]\n",
      "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.913, train_loss_epoch=0.913, valid_loss=0.119]        \n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00, 46.22it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.119] \n",
      "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.119]        \n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 63.80it/s, v_num=0, train_loss_step=0.799, train_loss_epoch=0.544, valid_loss=0.119]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 54.88it/s]\u001b[A\n",
      "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.879, train_loss_epoch=0.879, valid_loss=0.101]         \n",
      "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.721, train_loss_epoch=0.721, valid_loss=0.101]        \n",
      "Epoch 509: 100%|██████████| 1/1 [00:00<00:00, 82.60it/s, v_num=0, train_loss_step=0.721, train_loss_epoch=0.721, valid_loss=0.101]\n",
      "Epoch 509: 100%|██████████| 1/1 [00:00<00:00, 67.89it/s, v_num=0, train_loss_step=0.760, train_loss_epoch=0.721, valid_loss=0.101]\n",
      "Epoch 509: 100%|██████████| 1/1 [00:00<00:00, 64.96it/s, v_num=0, train_loss_step=0.760, train_loss_epoch=0.760, valid_loss=0.101]\n",
      "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.760, train_loss_epoch=0.760, valid_loss=0.101]        \n",
      "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.678, train_loss_epoch=0.678, valid_loss=0.101]         \n",
      "Epoch 516: 100%|██████████| 1/1 [00:00<00:00, 89.33it/s, v_num=0, train_loss_step=0.678, train_loss_epoch=0.678, valid_loss=0.101]\n",
      "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.846, train_loss_epoch=0.846, valid_loss=0.101]         \n",
      "Epoch 529: 100%|██████████| 1/1 [00:00<00:00, 73.26it/s, v_num=0, train_loss_step=0.822, train_loss_epoch=0.822, valid_loss=0.101] \n",
      "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.822, train_loss_epoch=0.822, valid_loss=0.101]        \n",
      "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.856, train_loss_epoch=0.856, valid_loss=0.101]         \n",
      "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.770, train_loss_epoch=0.770, valid_loss=0.101]         \n",
      "Epoch 547: 100%|██████████| 1/1 [00:00<00:00, 47.50it/s, v_num=0, train_loss_step=0.872, train_loss_epoch=0.620, valid_loss=0.101]\n",
      "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.872, train_loss_epoch=0.872, valid_loss=0.101]        \n",
      "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.605, train_loss_epoch=0.605, valid_loss=0.101]         \n",
      "Epoch 558: 100%|██████████| 1/1 [00:00<00:00, 36.89it/s, v_num=0, train_loss_step=0.830, train_loss_epoch=0.830, valid_loss=0.101] \n",
      "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.830, train_loss_epoch=0.830, valid_loss=0.101]        \n",
      "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.672, train_loss_epoch=0.672, valid_loss=0.101]         \n",
      "Epoch 570: 100%|██████████| 1/1 [00:00<00:00, 106.18it/s, v_num=0, train_loss_step=0.737, train_loss_epoch=0.737, valid_loss=0.101]\n",
      "Epoch 576: 100%|██████████| 1/1 [00:00<00:00, 68.30it/s, v_num=0, train_loss_step=0.646, train_loss_epoch=0.646, valid_loss=0.101] \n",
      "Epoch 576: 100%|██████████| 1/1 [00:00<00:00, 59.04it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.646, valid_loss=0.101]\n",
      "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.101]        \n",
      "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.101]\n",
      "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571, valid_loss=0.101]        \n",
      "Epoch 588: 100%|██████████| 1/1 [00:00<00:00, 96.43it/s, v_num=0, train_loss_step=0.659, train_loss_epoch=0.659, valid_loss=0.101] \n",
      "Epoch 588: 100%|██████████| 1/1 [00:00<00:00, 69.38it/s, v_num=0, train_loss_step=0.649, train_loss_epoch=0.649, valid_loss=0.101]\n",
      "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.649, train_loss_epoch=0.649, valid_loss=0.101]        \n",
      "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.594, train_loss_epoch=0.594, valid_loss=0.101]         \n",
      "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 46.42it/s, v_num=0, train_loss_step=0.647, train_loss_epoch=0.602, valid_loss=0.101]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=10911)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 42.31it/s]\u001b[A\n",
      "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.620, train_loss_epoch=0.620, valid_loss=0.0499]        \n",
      "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.779, train_loss_epoch=0.779, valid_loss=0.0499]        \n",
      "Epoch 609: 100%|██████████| 1/1 [00:00<00:00, 50.25it/s, v_num=0, train_loss_step=0.605, train_loss_epoch=0.779, valid_loss=0.0499]\n",
      "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.605, train_loss_epoch=0.605, valid_loss=0.0499]        \n",
      "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.615, train_loss_epoch=0.615, valid_loss=0.0499]        \n",
      "Epoch 622:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.608, train_loss_epoch=0.608, valid_loss=0.0499]         \n",
      "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.614, train_loss_epoch=0.614, valid_loss=0.0499]        \n",
      "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.818, train_loss_epoch=0.818, valid_loss=0.0499]         \n",
      "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.666, train_loss_epoch=0.666, valid_loss=0.0499]         \n",
      "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.953, train_loss_epoch=0.953, valid_loss=0.0499]        \n",
      "Epoch 651: 100%|██████████| 1/1 [00:00<00:00, 84.96it/s, v_num=0, train_loss_step=0.622, train_loss_epoch=0.622, valid_loss=0.0499] \n",
      "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.775, train_loss_epoch=0.775, valid_loss=0.0499]         \n",
      "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.601, train_loss_epoch=0.601, valid_loss=0.0499]         \n",
      "Epoch 671: 100%|██████████| 1/1 [00:00<00:00, 90.16it/s, v_num=0, train_loss_step=0.784, train_loss_epoch=0.784, valid_loss=0.0499] \n",
      "Epoch 671: 100%|██████████| 1/1 [00:00<00:00, 69.06it/s, v_num=0, train_loss_step=0.709, train_loss_epoch=0.709, valid_loss=0.0499]\n",
      "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.709, train_loss_epoch=0.709, valid_loss=0.0499]        \n",
      "Epoch 677: 100%|██████████| 1/1 [00:00<00:00, 52.11it/s, v_num=0, train_loss_step=0.587, train_loss_epoch=0.587, valid_loss=0.0499]\n",
      "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.587, train_loss_epoch=0.587, valid_loss=0.0499]        \n",
      "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.0499]         \n",
      "Epoch 690: 100%|██████████| 1/1 [00:00<00:00, 97.87it/s, v_num=0, train_loss_step=0.682, train_loss_epoch=0.682, valid_loss=0.0499] \n",
      "Epoch 690: 100%|██████████| 1/1 [00:00<00:00, 74.39it/s, v_num=0, train_loss_step=0.788, train_loss_epoch=0.682, valid_loss=0.0499]\n",
      "Epoch 690: 100%|██████████| 1/1 [00:00<00:00, 71.17it/s, v_num=0, train_loss_step=0.788, train_loss_epoch=0.788, valid_loss=0.0499]\n",
      "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.788, train_loss_epoch=0.788, valid_loss=0.0499]        \n",
      "Epoch 697: 100%|██████████| 1/1 [00:00<00:00, 69.05it/s, v_num=0, train_loss_step=0.598, train_loss_epoch=0.598, valid_loss=0.0499] \n",
      "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.598, train_loss_epoch=0.598, valid_loss=0.0499]        \n",
      "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 71.23it/s, v_num=0, train_loss_step=0.652, train_loss_epoch=0.853, valid_loss=0.0499]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 39.61it/s]\u001b[A\n",
      "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.603, train_loss_epoch=0.603, valid_loss=0.0496]        \n",
      "Epoch 701: 100%|██████████| 1/1 [00:00<00:00, 62.06it/s, v_num=0, train_loss_step=0.859, train_loss_epoch=0.603, valid_loss=0.0496]\n",
      "Epoch 701: 100%|██████████| 1/1 [00:00<00:00, 57.38it/s, v_num=0, train_loss_step=0.859, train_loss_epoch=0.859, valid_loss=0.0496]\n",
      "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.859, train_loss_epoch=0.859, valid_loss=0.0496]        \n",
      "Epoch 708: 100%|██████████| 1/1 [00:00<00:00, 74.91it/s, v_num=0, train_loss_step=0.729, train_loss_epoch=0.729, valid_loss=0.0496] \n",
      "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.729, train_loss_epoch=0.729, valid_loss=0.0496]        \n",
      "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.654, train_loss_epoch=0.654, valid_loss=0.0496]         \n",
      "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.619, train_loss_epoch=0.619, valid_loss=0.0496]         \n",
      "Epoch 728: 100%|██████████| 1/1 [00:00<00:00, 79.18it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0496] \n",
      "Epoch 735: 100%|██████████| 1/1 [00:00<00:00, 92.26it/s, v_num=0, train_loss_step=0.636, train_loss_epoch=0.636, valid_loss=0.0496] \n",
      "Epoch 735: 100%|██████████| 1/1 [00:00<00:00, 73.99it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=0.636, valid_loss=0.0496]\n",
      "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=0.914, valid_loss=0.0496]        \n",
      "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.955, train_loss_epoch=0.955, valid_loss=0.0496]        \n",
      "Epoch 738: 100%|██████████| 1/1 [00:00<00:00, 43.55it/s, v_num=0, train_loss_step=0.955, train_loss_epoch=0.955, valid_loss=0.0496]\n",
      "Epoch 738: 100%|██████████| 1/1 [00:00<00:00, 35.37it/s, v_num=0, train_loss_step=0.878, train_loss_epoch=0.878, valid_loss=0.0496]\n",
      "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.711, train_loss_epoch=0.711, valid_loss=0.0496]         \n",
      "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.817, train_loss_epoch=0.817, valid_loss=0.0496]        \n",
      "Epoch 750: 100%|██████████| 1/1 [00:00<00:00, 91.38it/s, v_num=0, train_loss_step=0.817, train_loss_epoch=0.817, valid_loss=0.0496]\n",
      "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.607, train_loss_epoch=0.607, valid_loss=0.0496]         \n",
      "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.628, train_loss_epoch=0.628, valid_loss=0.0496]        \n",
      "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.874, train_loss_epoch=0.874, valid_loss=0.0496]        \n",
      "Epoch 768: 100%|██████████| 1/1 [00:00<00:00, 83.11it/s, v_num=0, train_loss_step=0.874, train_loss_epoch=0.874, valid_loss=0.0496]\n",
      "Epoch 768: 100%|██████████| 1/1 [00:00<00:00, 65.74it/s, v_num=0, train_loss_step=0.653, train_loss_epoch=0.653, valid_loss=0.0496]\n",
      "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.653, train_loss_epoch=0.653, valid_loss=0.0496]        \n",
      "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.931, train_loss_epoch=0.931, valid_loss=0.0496]        \n",
      "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.672, train_loss_epoch=0.672, valid_loss=0.0496]         \n",
      "Epoch 785: 100%|██████████| 1/1 [00:00<00:00, 80.77it/s, v_num=0, train_loss_step=0.599, train_loss_epoch=0.599, valid_loss=0.0496]\n",
      "Epoch 785: 100%|██████████| 1/1 [00:00<00:00, 64.25it/s, v_num=0, train_loss_step=0.718, train_loss_epoch=0.718, valid_loss=0.0496]\n",
      "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.718, train_loss_epoch=0.718, valid_loss=0.0496]        \n",
      "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0496]         \n",
      "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.613, train_loss_epoch=0.613, valid_loss=0.0496]         \n",
      "Epoch 798: 100%|██████████| 1/1 [00:00<00:00, 95.89it/s, v_num=0, train_loss_step=0.613, train_loss_epoch=0.613, valid_loss=0.0496]\n",
      "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 70.43it/s, v_num=0, train_loss_step=0.606, train_loss_epoch=0.732, valid_loss=0.0496]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 52.29it/s]\u001b[A\n",
      "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.867, train_loss_epoch=0.867, valid_loss=0.0508]        \n",
      "Epoch 801: 100%|██████████| 1/1 [00:00<00:00, 39.67it/s, v_num=0, train_loss_step=0.596, train_loss_epoch=0.596, valid_loss=0.0508]\n",
      "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.596, train_loss_epoch=0.596, valid_loss=0.0508]        \n",
      "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.584, train_loss_epoch=0.584, valid_loss=0.0508]        \n",
      "Epoch 807: 100%|██████████| 1/1 [00:00<00:00, 74.62it/s, v_num=0, train_loss_step=0.584, train_loss_epoch=0.584, valid_loss=0.0508]\n",
      "Epoch 807: 100%|██████████| 1/1 [00:00<00:00, 59.61it/s, v_num=0, train_loss_step=0.854, train_loss_epoch=0.854, valid_loss=0.0508]\n",
      "Epoch 808:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.854, train_loss_epoch=0.854, valid_loss=0.0508]        \n",
      "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.642, train_loss_epoch=0.642, valid_loss=0.0508]        \n",
      "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.695, train_loss_epoch=0.695, valid_loss=0.0508]        \n",
      "Epoch 827:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.627, train_loss_epoch=0.627, valid_loss=0.0508]         \n",
      "Epoch 833:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.587, train_loss_epoch=0.587, valid_loss=0.0508]        \n",
      "Epoch 839: 100%|██████████| 1/1 [00:00<00:00, 94.37it/s, v_num=0, train_loss_step=0.656, train_loss_epoch=0.656, valid_loss=0.0508] \n",
      "Epoch 839: 100%|██████████| 1/1 [00:00<00:00, 73.98it/s, v_num=0, train_loss_step=0.658, train_loss_epoch=0.656, valid_loss=0.0508]\n",
      "Epoch 839: 100%|██████████| 1/1 [00:00<00:00, 68.82it/s, v_num=0, train_loss_step=0.658, train_loss_epoch=0.658, valid_loss=0.0508]\n",
      "Epoch 840:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.658, train_loss_epoch=0.658, valid_loss=0.0508]        \n",
      "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.784, train_loss_epoch=0.784, valid_loss=0.0508]        \n",
      "Epoch 852: 100%|██████████| 1/1 [00:00<00:00, 100.84it/s, v_num=0, train_loss_step=0.639, train_loss_epoch=0.639, valid_loss=0.0508]\n",
      "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.702, train_loss_epoch=0.702, valid_loss=0.0508]         \n",
      "Epoch 865: 100%|██████████| 1/1 [00:00<00:00, 94.71it/s, v_num=0, train_loss_step=0.621, train_loss_epoch=0.621, valid_loss=0.0508] \n",
      "Epoch 865: 100%|██████████| 1/1 [00:00<00:00, 69.97it/s, v_num=0, train_loss_step=0.834, train_loss_epoch=0.834, valid_loss=0.0508]\n",
      "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.834, train_loss_epoch=0.834, valid_loss=0.0508]        \n",
      "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.987, train_loss_epoch=0.987, valid_loss=0.0508]         \n",
      "Epoch 878: 100%|██████████| 1/1 [00:00<00:00, 96.84it/s, v_num=0, train_loss_step=0.813, train_loss_epoch=0.813, valid_loss=0.0508] \n",
      "Epoch 878: 100%|██████████| 1/1 [00:00<00:00, 70.30it/s, v_num=0, train_loss_step=0.615, train_loss_epoch=0.615, valid_loss=0.0508]\n",
      "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.615, train_loss_epoch=0.615, valid_loss=0.0508]        \n",
      "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.689, train_loss_epoch=0.689, valid_loss=0.0508]        \n",
      "Epoch 891: 100%|██████████| 1/1 [00:00<00:00, 96.82it/s, v_num=0, train_loss_step=0.604, train_loss_epoch=0.604, valid_loss=0.0508] \n",
      "Epoch 891: 100%|██████████| 1/1 [00:00<00:00, 70.73it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0508]\n",
      "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0508]        \n",
      "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.664, train_loss_epoch=0.664, valid_loss=0.0508]         \n",
      "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 73.97it/s, v_num=0, train_loss_step=0.362, train_loss_epoch=0.925, valid_loss=0.0508]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 49.09it/s]\u001b[A\n",
      "Epoch 902: 100%|██████████| 1/1 [00:00<00:00, 65.41it/s, v_num=0, train_loss_step=0.679, train_loss_epoch=0.679, valid_loss=0.0852]\n",
      "Epoch 903:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.679, train_loss_epoch=0.679, valid_loss=0.0852]        \n",
      "Epoch 909:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.612, train_loss_epoch=0.612, valid_loss=0.0852]         \n",
      "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.388, train_loss_epoch=0.388, valid_loss=0.0852]         \n",
      "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.764, train_loss_epoch=0.764, valid_loss=0.0852]         \n",
      "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.790, train_loss_epoch=0.790, valid_loss=0.0852]        \n",
      "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.655, train_loss_epoch=0.655, valid_loss=0.0852]        \n",
      "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.662, train_loss_epoch=0.662, valid_loss=0.0852]        \n",
      "Epoch 946: 100%|██████████| 1/1 [00:00<00:00, 78.34it/s, v_num=0, train_loss_step=0.620, train_loss_epoch=0.618, valid_loss=0.0852] \n",
      "Epoch 947:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.620, train_loss_epoch=0.620, valid_loss=0.0852]        \n",
      "Epoch 953:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.358, train_loss_epoch=0.358, valid_loss=0.0852]         \n",
      "Epoch 958: 100%|██████████| 1/1 [00:00<00:00, 45.27it/s, v_num=0, train_loss_step=0.581, train_loss_epoch=0.621, valid_loss=0.0852]\n",
      "Epoch 958: 100%|██████████| 1/1 [00:00<00:00, 43.54it/s, v_num=0, train_loss_step=0.581, train_loss_epoch=0.581, valid_loss=0.0852]\n",
      "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.581, train_loss_epoch=0.581, valid_loss=0.0852]        \n",
      "Epoch 964: 100%|██████████| 1/1 [00:00<00:00, 57.06it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574, valid_loss=0.0852]\n",
      "Epoch 965:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574, valid_loss=0.0852]        \n",
      "Epoch 970:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.949, train_loss_epoch=0.949, valid_loss=0.0852]        \n",
      "Epoch 976: 100%|██████████| 1/1 [00:00<00:00, 80.34it/s, v_num=0, train_loss_step=0.922, train_loss_epoch=0.922, valid_loss=0.0852]\n",
      "Epoch 976: 100%|██████████| 1/1 [00:00<00:00, 63.88it/s, v_num=0, train_loss_step=0.645, train_loss_epoch=0.645, valid_loss=0.0852]\n",
      "Epoch 977:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.645, train_loss_epoch=0.645, valid_loss=0.0852]        \n",
      "Epoch 982: 100%|██████████| 1/1 [00:00<00:00, 71.43it/s, v_num=0, train_loss_step=0.907, train_loss_epoch=0.907, valid_loss=0.0852]\n",
      "\u001b[36m(_train_tune pid=10911)\u001b[0m  v_num=0, train_loss_step=0.793, train_loss_epoch=0.907, valid_loss=0.0852]\n",
      "Epoch 982: 100%|██████████| 1/1 [00:00<00:00, 66.77it/s, v_num=0, train_loss_step=0.793, train_loss_epoch=0.793, valid_loss=0.0852]\n",
      "Epoch 983:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.793, train_loss_epoch=0.793, valid_loss=0.0852]        \n",
      "Epoch 988: 100%|██████████| 1/1 [00:00<00:00, 58.57it/s, v_num=0, train_loss_step=0.834, train_loss_epoch=0.877, valid_loss=0.0852]\n",
      "Epoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.834, train_loss_epoch=0.834, valid_loss=0.0852]        \n",
      "Epoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.834, train_loss_epoch=0.834, valid_loss=0.0852]\n",
      "Epoch 993: 100%|██████████| 1/1 [00:00<00:00, 51.76it/s, v_num=0, train_loss_step=0.856, train_loss_epoch=0.522, valid_loss=0.0852]\n",
      "Epoch 993: 100%|██████████| 1/1 [00:00<00:00, 47.19it/s, v_num=0, train_loss_step=0.856, train_loss_epoch=0.856, valid_loss=0.0852]\n",
      "Epoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.856, train_loss_epoch=0.856, valid_loss=0.0852]        \n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 79.02it/s, v_num=0, train_loss_step=0.599, train_loss_epoch=0.549, valid_loss=0.0852] \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=10911)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 53.66it/s]\u001b[A\n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 23.21it/s, v_num=0, train_loss_step=0.599, train_loss_epoch=0.599, valid_loss=0.0536]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=10911)\u001b[0m `Trainer.fit` stopped: `max_steps=1000` reached.\n",
      "\u001b[36m(_train_tune pid=11056)\u001b[0m /home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=11056)\u001b[0m Seed set to 4\n",
      "\u001b[36m(_train_tune pid=11056)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=11056)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=11056)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=11056)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(_train_tune pid=11056)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=11056)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=11056)\u001b[0m   | Name            | Type          | Params | Mode \n",
      "\u001b[36m(_train_tune pid=11056)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=11056)\u001b[0m 0 | loss            | WMAPE         | 0      | train\n",
      "\u001b[36m(_train_tune pid=11056)\u001b[0m 1 | padder          | ConstantPad1d | 0      | train\n",
      "\u001b[36m(_train_tune pid=11056)\u001b[0m 2 | scaler          | TemporalNorm  | 0      | train\n",
      "\u001b[36m(_train_tune pid=11056)\u001b[0m 3 | hist_encoder    | LSTM          | 484 K  | train\n",
      "\u001b[36m(_train_tune pid=11056)\u001b[0m 4 | context_adapter | Linear        | 77.4 K | train\n",
      "\u001b[36m(_train_tune pid=11056)\u001b[0m 5 | mlp_decoder     | MLP           | 449    | train\n",
      "\u001b[36m(_train_tune pid=11056)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=11056)\u001b[0m 561 K     Trainable params\n",
      "\u001b[36m(_train_tune pid=11056)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=11056)\u001b[0m 561 K     Total params\n",
      "\u001b[36m(_train_tune pid=11056)\u001b[0m 2.247     Total estimated model params size (MB)\n",
      "\u001b[36m(_train_tune pid=11056)\u001b[0m 11        Modules in train mode\n",
      "\u001b[36m(_train_tune pid=11056)\u001b[0m 0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]        \n",
      "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]        \n",
      "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.983, train_loss_epoch=0.983]       \n",
      "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00, 26.25it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.985]\n",
      "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992]        \n",
      "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.987, train_loss_epoch=0.987]        \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 29.55it/s, v_num=0, train_loss_step=0.962, train_loss_epoch=0.962]\n",
      "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.962, train_loss_epoch=0.962]        \n",
      "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997]        \n",
      "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988]        \n",
      "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988]\n",
      "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.971, train_loss_epoch=0.971]        \n",
      "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.907, train_loss_epoch=0.907]        \n",
      "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.797, train_loss_epoch=0.797]        \n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00, 30.33it/s, v_num=0, train_loss_step=0.658, train_loss_epoch=0.658]\n",
      "Epoch 36: 100%|██████████| 1/1 [00:00<00:00, 27.36it/s, v_num=0, train_loss_step=0.746, train_loss_epoch=0.746]\n",
      "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.746, train_loss_epoch=0.746]        \n",
      "Epoch 39: 100%|██████████| 1/1 [00:00<00:00, 28.13it/s, v_num=0, train_loss_step=0.605, train_loss_epoch=0.941]\n",
      "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.605, train_loss_epoch=0.605]        \n",
      "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.963, train_loss_epoch=0.963]        \n",
      "Epoch 45: 100%|██████████| 1/1 [00:00<00:00, 36.79it/s, v_num=0, train_loss_step=0.580, train_loss_epoch=0.580]\n",
      "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.587, train_loss_epoch=0.587]        \n",
      "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.976, train_loss_epoch=0.976]        \n",
      "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.906, train_loss_epoch=0.906]        \n",
      "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.866, train_loss_epoch=0.866]        \n",
      "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.969, train_loss_epoch=0.969]        \n",
      "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.858, train_loss_epoch=0.858]        \n",
      "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.810, train_loss_epoch=0.810]        \n",
      "Epoch 65: 100%|██████████| 1/1 [00:00<00:00, 23.21it/s, v_num=0, train_loss_step=0.819, train_loss_epoch=0.819]\n",
      "Epoch 67: 100%|██████████| 1/1 [00:00<00:00, 23.70it/s, v_num=0, train_loss_step=0.795, train_loss_epoch=0.795]\n",
      "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.844, train_loss_epoch=0.844]        \n",
      "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.787, train_loss_epoch=0.787]        \n",
      "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.808, train_loss_epoch=0.808]        \n",
      "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.724, train_loss_epoch=0.724]        \n",
      "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.987, train_loss_epoch=0.987]        \n",
      "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.824, train_loss_epoch=0.824]        \n",
      "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.777, train_loss_epoch=0.777]        \n",
      "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.755, train_loss_epoch=0.755]        \n",
      "Epoch 90: 100%|██████████| 1/1 [00:00<00:00, 32.39it/s, v_num=0, train_loss_step=0.730, train_loss_epoch=0.730]\n",
      "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.730, train_loss_epoch=0.730]        \n",
      "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.752, train_loss_epoch=0.752]        \n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00, 37.35it/s, v_num=0, train_loss_step=0.679, train_loss_epoch=0.679]\n",
      "Epoch 96: 100%|██████████| 1/1 [00:00<00:00, 32.59it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070]\n",
      "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070]        \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 33.68it/s, v_num=0, train_loss_step=0.749, train_loss_epoch=0.652]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=11056)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 13.06it/s]\u001b[A\n",
      "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.749, train_loss_epoch=0.749, valid_loss=0.236]       \n",
      "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.681, train_loss_epoch=0.681, valid_loss=0.236]        \n",
      "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.757, train_loss_epoch=0.757, valid_loss=0.236]        \n",
      "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.236]        \n",
      "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.830, train_loss_epoch=0.830, valid_loss=0.236]        \n",
      "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.886, train_loss_epoch=0.886, valid_loss=0.236]        \n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00, 22.96it/s, v_num=0, train_loss_step=0.757, train_loss_epoch=0.886, valid_loss=0.236]\n",
      "Epoch 110: 100%|██████████| 1/1 [00:00<00:00, 22.46it/s, v_num=0, train_loss_step=0.757, train_loss_epoch=0.757, valid_loss=0.236]\n",
      "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.757, train_loss_epoch=0.757, valid_loss=0.236]        \n",
      "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.632, train_loss_epoch=0.632, valid_loss=0.236]        \n",
      "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.653, train_loss_epoch=0.653, valid_loss=0.236]        \n",
      "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.696, train_loss_epoch=0.696, valid_loss=0.236]        \n",
      "Epoch 118: 100%|██████████| 1/1 [00:00<00:00, 23.42it/s, v_num=0, train_loss_step=0.696, train_loss_epoch=0.696, valid_loss=0.236]\n",
      "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.600, train_loss_epoch=0.600, valid_loss=0.236]        \n",
      "Epoch 121: 100%|██████████| 1/1 [00:00<00:00, 34.88it/s, v_num=0, train_loss_step=0.600, train_loss_epoch=0.600, valid_loss=0.236]\n",
      "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.688, train_loss_epoch=0.688, valid_loss=0.236]        \n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00, 30.21it/s, v_num=0, train_loss_step=0.683, train_loss_epoch=0.683, valid_loss=0.236]\n",
      "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.683, train_loss_epoch=0.683, valid_loss=0.236]        \n",
      "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.236]        \n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00, 31.89it/s, v_num=0, train_loss_step=0.845, train_loss_epoch=0.845, valid_loss=0.236]\n",
      "Epoch 130: 100%|██████████| 1/1 [00:00<00:00, 24.65it/s, v_num=0, train_loss_step=0.603, train_loss_epoch=0.603, valid_loss=0.236]\n",
      "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.603, train_loss_epoch=0.603, valid_loss=0.236]        \n",
      "Epoch 133: 100%|██████████| 1/1 [00:00<00:00, 31.74it/s, v_num=0, train_loss_step=0.710, train_loss_epoch=0.710, valid_loss=0.236]\n",
      "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.710, train_loss_epoch=0.710, valid_loss=0.236]        \n",
      "Epoch 136: 100%|██████████| 1/1 [00:00<00:00, 34.34it/s, v_num=0, train_loss_step=0.690, train_loss_epoch=0.690, valid_loss=0.236]\n",
      "Epoch 136: 100%|██████████| 1/1 [00:00<00:00, 30.26it/s, v_num=0, train_loss_step=0.734, train_loss_epoch=0.734, valid_loss=0.236]\n",
      "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.734, train_loss_epoch=0.734, valid_loss=0.236]        \n",
      "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.961, train_loss_epoch=0.961, valid_loss=0.236]        \n",
      "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.698, train_loss_epoch=0.698, valid_loss=0.236]        \n",
      "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.762, train_loss_epoch=0.762, valid_loss=0.236]        \n",
      "Epoch 145: 100%|██████████| 1/1 [00:00<00:00, 28.49it/s, v_num=0, train_loss_step=0.651, train_loss_epoch=0.651, valid_loss=0.236]\n",
      "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.651, train_loss_epoch=0.651, valid_loss=0.236]        \n",
      "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.639, train_loss_epoch=0.639, valid_loss=0.236]        \n",
      "Epoch 150: 100%|██████████| 1/1 [00:00<00:00, 24.37it/s, v_num=0, train_loss_step=0.725, train_loss_epoch=0.725, valid_loss=0.236]\n",
      "Epoch 152: 100%|██████████| 1/1 [00:00<00:00, 25.17it/s, v_num=0, train_loss_step=0.889, train_loss_epoch=0.889, valid_loss=0.236]\n",
      "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.985, train_loss_epoch=0.985, valid_loss=0.236]        \n",
      "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.591, train_loss_epoch=0.591, valid_loss=0.236]        \n",
      "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.700, train_loss_epoch=0.700, valid_loss=0.236]        \n",
      "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.881, train_loss_epoch=0.881, valid_loss=0.236]        \n",
      "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.595, train_loss_epoch=0.595, valid_loss=0.236]        \n",
      "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.641, train_loss_epoch=0.641, valid_loss=0.236]        \n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00, 26.36it/s, v_num=0, train_loss_step=0.658, train_loss_epoch=0.677, valid_loss=0.236]\n",
      "Epoch 171: 100%|██████████| 1/1 [00:00<00:00, 25.84it/s, v_num=0, train_loss_step=0.658, train_loss_epoch=0.658, valid_loss=0.236]\n",
      "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.658, train_loss_epoch=0.658, valid_loss=0.236]        \n",
      "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.796, train_loss_epoch=0.796, valid_loss=0.236]        \n",
      "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.236]        \n",
      "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.877, train_loss_epoch=0.877, valid_loss=0.236]        \n",
      "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.703, train_loss_epoch=0.703, valid_loss=0.236]        \n",
      "Epoch 183: 100%|██████████| 1/1 [00:00<00:00, 26.74it/s, v_num=0, train_loss_step=0.690, train_loss_epoch=0.755, valid_loss=0.236]\n",
      "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.690, train_loss_epoch=0.690, valid_loss=0.236]        \n",
      "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.661, train_loss_epoch=0.661, valid_loss=0.236]        \n",
      "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.907, train_loss_epoch=0.907, valid_loss=0.236]        \n",
      "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.671, train_loss_epoch=0.671, valid_loss=0.236]        \n",
      "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.795, train_loss_epoch=0.795, valid_loss=0.236]        \n",
      "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.736, train_loss_epoch=0.736, valid_loss=0.236]        \n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 28.21it/s, v_num=0, train_loss_step=0.692, train_loss_epoch=0.565, valid_loss=0.236]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=11056)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 14.28it/s]\u001b[A\n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00, 37.68it/s, v_num=0, train_loss_step=0.692, train_loss_epoch=0.692, valid_loss=0.127]\n",
      "Epoch 200: 100%|██████████| 1/1 [00:00<00:00, 33.32it/s, v_num=0, train_loss_step=0.900, train_loss_epoch=0.900, valid_loss=0.127]\n",
      "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.900, train_loss_epoch=0.900, valid_loss=0.127]        \n",
      "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.625, train_loss_epoch=0.625, valid_loss=0.127]        \n",
      "Epoch 205: 100%|██████████| 1/1 [00:00<00:00, 22.89it/s, v_num=0, train_loss_step=0.663, train_loss_epoch=0.663, valid_loss=0.127]\n",
      "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.624, train_loss_epoch=0.624, valid_loss=0.127]        \n",
      "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471, valid_loss=0.127]        \n",
      "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.688, train_loss_epoch=0.688, valid_loss=0.127]        \n",
      "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.127]        \n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00, 36.38it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.127]\n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00, 32.93it/s, v_num=0, train_loss_step=0.761, train_loss_epoch=1.020, valid_loss=0.127]\n",
      "Epoch 217: 100%|██████████| 1/1 [00:00<00:00, 32.27it/s, v_num=0, train_loss_step=0.761, train_loss_epoch=0.761, valid_loss=0.127]\n",
      "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.761, train_loss_epoch=0.761, valid_loss=0.127]        \n",
      "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.583, train_loss_epoch=0.583, valid_loss=0.127]        \n",
      "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.808, train_loss_epoch=0.808, valid_loss=0.127]        \n",
      "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.583, train_loss_epoch=0.583, valid_loss=0.127]        \n",
      "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.742, train_loss_epoch=0.742, valid_loss=0.127]        \n",
      "Epoch 230: 100%|██████████| 1/1 [00:00<00:00, 23.19it/s, v_num=0, train_loss_step=0.632, train_loss_epoch=0.632, valid_loss=0.127]\n",
      "Epoch 232: 100%|██████████| 1/1 [00:00<00:00, 23.29it/s, v_num=0, train_loss_step=0.652, train_loss_epoch=0.652, valid_loss=0.127]\n",
      "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=0.950, valid_loss=0.127]        \n",
      "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.794, train_loss_epoch=0.794, valid_loss=0.127]        \n",
      "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.742, train_loss_epoch=0.742, valid_loss=0.127]        \n",
      "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.789, train_loss_epoch=0.789, valid_loss=0.127]        \n",
      "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.616, train_loss_epoch=0.616, valid_loss=0.127]        \n",
      "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.614, train_loss_epoch=0.614, valid_loss=0.127]        \n",
      "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.599, train_loss_epoch=0.599, valid_loss=0.127]        \n",
      "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.646, train_loss_epoch=0.646, valid_loss=0.127]        \n",
      "Epoch 251: 100%|██████████| 1/1 [00:00<00:00, 23.85it/s, v_num=0, train_loss_step=0.596, train_loss_epoch=0.596, valid_loss=0.127]\n",
      "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.596, train_loss_epoch=0.596, valid_loss=0.127]        \n",
      "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.657, train_loss_epoch=0.657, valid_loss=0.127]        \n",
      "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.835, train_loss_epoch=0.835, valid_loss=0.127]        \n",
      "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.689, train_loss_epoch=0.689, valid_loss=0.127]        \n",
      "Epoch 260: 100%|██████████| 1/1 [00:00<00:00, 36.63it/s, v_num=0, train_loss_step=0.689, train_loss_epoch=0.689, valid_loss=0.127]\n",
      "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.894, train_loss_epoch=0.894, valid_loss=0.127]        \n",
      "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.654, train_loss_epoch=0.654, valid_loss=0.127]        \n",
      "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.926, train_loss_epoch=0.926, valid_loss=0.127]        \n",
      "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.830, train_loss_epoch=0.830, valid_loss=0.127]        \n",
      "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.639, train_loss_epoch=0.639, valid_loss=0.127]        \n",
      "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.677, train_loss_epoch=0.677, valid_loss=0.127]        \n",
      "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.623, train_loss_epoch=0.623, valid_loss=0.127]        \n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00, 36.92it/s, v_num=0, train_loss_step=0.770, train_loss_epoch=0.770, valid_loss=0.127]\n",
      "Epoch 283: 100%|██████████| 1/1 [00:00<00:00, 33.35it/s, v_num=0, train_loss_step=0.687, train_loss_epoch=0.770, valid_loss=0.127]\n",
      "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.687, train_loss_epoch=0.687, valid_loss=0.127]        \n",
      "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.687, train_loss_epoch=0.687, valid_loss=0.127]\n",
      "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.649, train_loss_epoch=0.649, valid_loss=0.127]        \n",
      "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.902, train_loss_epoch=0.902, valid_loss=0.127]        \n",
      "Epoch 291: 100%|██████████| 1/1 [00:00<00:00, 26.46it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.127]\n",
      "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.665, train_loss_epoch=0.665, valid_loss=0.127]        \n",
      "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.595, train_loss_epoch=0.595, valid_loss=0.127]        \n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00, 32.29it/s, v_num=0, train_loss_step=0.595, train_loss_epoch=0.595, valid_loss=0.127]\n",
      "Epoch 296: 100%|██████████| 1/1 [00:00<00:00, 31.08it/s, v_num=0, train_loss_step=0.685, train_loss_epoch=0.685, valid_loss=0.127]\n",
      "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.685, train_loss_epoch=0.685, valid_loss=0.127]        \n",
      "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.675, train_loss_epoch=0.675, valid_loss=0.127]        \n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 26.92it/s, v_num=0, train_loss_step=0.802, train_loss_epoch=0.675, valid_loss=0.127]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=11056)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  9.27it/s]\u001b[A\n",
      "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.790, train_loss_epoch=0.790, valid_loss=0.0447]        \n",
      "Epoch 303: 100%|██████████| 1/1 [00:00<00:00, 18.65it/s, v_num=0, train_loss_step=0.762, train_loss_epoch=0.762, valid_loss=0.0447]\n",
      "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.762, train_loss_epoch=0.762, valid_loss=0.0447]        \n",
      "Epoch 306: 100%|██████████| 1/1 [00:00<00:00, 28.92it/s, v_num=0, train_loss_step=0.741, train_loss_epoch=0.741, valid_loss=0.0447]\n",
      "Epoch 306: 100%|██████████| 1/1 [00:00<00:00, 24.94it/s, v_num=0, train_loss_step=0.720, train_loss_epoch=0.720, valid_loss=0.0447]\n",
      "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.720, train_loss_epoch=0.720, valid_loss=0.0447]        \n",
      "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.705, train_loss_epoch=0.705, valid_loss=0.0447]        \n",
      "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.716, train_loss_epoch=0.716, valid_loss=0.0447]        \n",
      "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.715, train_loss_epoch=0.715, valid_loss=0.0447]        \n",
      "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=0.0447]        \n",
      "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.624, train_loss_epoch=0.624, valid_loss=0.0447]        \n",
      "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.675, train_loss_epoch=0.675, valid_loss=0.0447]        \n",
      "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562, valid_loss=0.0447]        \n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00, 22.88it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=0.0447]\n",
      "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=0.0447]        \n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00, 31.68it/s, v_num=0, train_loss_step=0.626, train_loss_epoch=0.626, valid_loss=0.0447]\n",
      "Epoch 326: 100%|██████████| 1/1 [00:00<00:00, 30.47it/s, v_num=0, train_loss_step=0.828, train_loss_epoch=0.828, valid_loss=0.0447]\n",
      "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.828, train_loss_epoch=0.828, valid_loss=0.0447]        \n",
      "Epoch 329: 100%|██████████| 1/1 [00:00<00:00, 27.72it/s, v_num=0, train_loss_step=0.644, train_loss_epoch=0.644, valid_loss=0.0447]\n",
      "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.818, train_loss_epoch=0.818, valid_loss=0.0447]        \n",
      "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.684, train_loss_epoch=0.684, valid_loss=0.0447]        \n",
      "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.642, train_loss_epoch=0.642, valid_loss=0.0447]        \n",
      "Epoch 340: 100%|██████████| 1/1 [00:00<00:00, 31.47it/s, v_num=0, train_loss_step=0.829, train_loss_epoch=0.829, valid_loss=0.0447]\n",
      "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.829, train_loss_epoch=0.829, valid_loss=0.0447]        \n",
      "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.811, train_loss_epoch=0.811, valid_loss=0.0447]        \n",
      "Epoch 343: 100%|██████████| 1/1 [00:00<00:00, 36.17it/s, v_num=0, train_loss_step=0.811, train_loss_epoch=0.811, valid_loss=0.0447]\n",
      "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.669, train_loss_epoch=0.669, valid_loss=0.0447]        \n",
      "Epoch 346: 100%|██████████| 1/1 [00:00<00:00, 35.78it/s, v_num=0, train_loss_step=0.669, train_loss_epoch=0.669, valid_loss=0.0447]\n",
      "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.614, train_loss_epoch=0.614, valid_loss=0.0447]        \n",
      "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.738, train_loss_epoch=0.738, valid_loss=0.0447]        \n",
      "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.610, train_loss_epoch=0.610, valid_loss=0.0447]        \n",
      "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.733, train_loss_epoch=0.733, valid_loss=0.0447]        \n",
      "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.636, train_loss_epoch=0.636, valid_loss=0.0447]        \n",
      "Epoch 362: 100%|██████████| 1/1 [00:00<00:00, 29.13it/s, v_num=0, train_loss_step=0.715, train_loss_epoch=0.715, valid_loss=0.0447]\n",
      "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.638, train_loss_epoch=0.638, valid_loss=0.0447]        \n",
      "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.742, train_loss_epoch=0.742, valid_loss=0.0447]        \n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00, 23.19it/s, v_num=0, train_loss_step=0.689, train_loss_epoch=0.689, valid_loss=0.0447]\n",
      "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.689, train_loss_epoch=0.689, valid_loss=0.0447]        \n",
      "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.578, train_loss_epoch=0.578, valid_loss=0.0447]        \n",
      "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.578, train_loss_epoch=0.578, valid_loss=0.0447]\n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00, 25.79it/s, v_num=0, train_loss_step=0.702, train_loss_epoch=0.702, valid_loss=0.0447]\n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00, 23.94it/s, v_num=0, train_loss_step=0.779, train_loss_epoch=0.702, valid_loss=0.0447]\n",
      "Epoch 375: 100%|██████████| 1/1 [00:00<00:00, 23.54it/s, v_num=0, train_loss_step=0.779, train_loss_epoch=0.779, valid_loss=0.0447]\n",
      "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.779, train_loss_epoch=0.779, valid_loss=0.0447]        \n",
      "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.629, train_loss_epoch=0.629, valid_loss=0.0447]        \n",
      "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=0.0447]        \n",
      "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.670, train_loss_epoch=0.670, valid_loss=0.0447]        \n",
      "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0447]        \n",
      "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.780, train_loss_epoch=0.780, valid_loss=0.0447]        \n",
      "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.621, train_loss_epoch=0.621, valid_loss=0.0447]        \n",
      "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=0.0447]        \n",
      "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0447]        \n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 28.46it/s, v_num=0, train_loss_step=0.632, train_loss_epoch=0.746, valid_loss=0.0447]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=11056)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 14.25it/s]\u001b[A\n",
      "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.632, train_loss_epoch=0.632, valid_loss=0.0413]        \n",
      "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.615, train_loss_epoch=0.615, valid_loss=0.0413]        \n",
      "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.622, train_loss_epoch=0.622, valid_loss=0.0413]        \n",
      "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.931, train_loss_epoch=0.931, valid_loss=0.0413]        \n",
      "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.757, train_loss_epoch=0.757, valid_loss=0.0413]        \n",
      "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.875, train_loss_epoch=0.875, valid_loss=0.0413]        \n",
      "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.670, train_loss_epoch=0.670, valid_loss=0.0413]        \n",
      "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.666, train_loss_epoch=0.666, valid_loss=0.0413]        \n",
      "Epoch 418: 100%|██████████| 1/1 [00:00<00:00, 30.72it/s, v_num=0, train_loss_step=0.666, train_loss_epoch=0.666, valid_loss=0.0413]\n",
      "Epoch 420: 100%|██████████| 1/1 [00:00<00:00, 24.73it/s, v_num=0, train_loss_step=0.846, train_loss_epoch=0.846, valid_loss=0.0413]\n",
      "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.846, train_loss_epoch=0.846, valid_loss=0.0413]        \n",
      "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.679, train_loss_epoch=0.679, valid_loss=0.0413]        \n",
      "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.902, train_loss_epoch=0.902, valid_loss=0.0413]        \n",
      "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.662, train_loss_epoch=0.662, valid_loss=0.0413]        \n",
      "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.656, train_loss_epoch=0.656, valid_loss=0.0413]        \n",
      "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562, valid_loss=0.0413]        \n",
      "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.611, train_loss_epoch=0.611, valid_loss=0.0413]        \n",
      "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.802, train_loss_epoch=0.802, valid_loss=0.0413]        \n",
      "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0413]        \n",
      "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.812, train_loss_epoch=0.812, valid_loss=0.0413]        \n",
      "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.687, train_loss_epoch=0.687, valid_loss=0.0413]        \n",
      "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.625, train_loss_epoch=0.625, valid_loss=0.0413]        \n",
      "Epoch 451: 100%|██████████| 1/1 [00:00<00:00, 27.32it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561, valid_loss=0.0413]\n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00, 36.25it/s, v_num=0, train_loss_step=0.685, train_loss_epoch=0.685, valid_loss=0.0413]\n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00, 31.10it/s, v_num=0, train_loss_step=0.870, train_loss_epoch=0.870, valid_loss=0.0413]\n",
      "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.870, train_loss_epoch=0.870, valid_loss=0.0413]        \n",
      "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.785, train_loss_epoch=0.785, valid_loss=0.0413]        \n",
      "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.960, train_loss_epoch=0.960, valid_loss=0.0413]        \n",
      "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.653, train_loss_epoch=0.653, valid_loss=0.0413]        \n",
      "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.716, train_loss_epoch=0.716, valid_loss=0.0413]        \n",
      "Epoch 468: 100%|██████████| 1/1 [00:00<00:00, 25.48it/s, v_num=0, train_loss_step=0.664, train_loss_epoch=0.664, valid_loss=0.0413]\n",
      "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.688, train_loss_epoch=0.688, valid_loss=0.0413]        \n",
      "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.599, train_loss_epoch=0.599, valid_loss=0.0413]        \n",
      "Epoch 474: 100%|██████████| 1/1 [00:00<00:00, 36.11it/s, v_num=0, train_loss_step=0.599, train_loss_epoch=0.599, valid_loss=0.0413]\n",
      "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.719, train_loss_epoch=0.719, valid_loss=0.0413]        \n",
      "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297, valid_loss=0.0413]        \n",
      "Epoch 480: 100%|██████████| 1/1 [00:00<00:00, 31.24it/s, v_num=0, train_loss_step=0.698, train_loss_epoch=0.698, valid_loss=0.0413]\n",
      "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.698, train_loss_epoch=0.698, valid_loss=0.0413]        \n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00, 35.61it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=0.0413]\n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00, 32.47it/s, v_num=0, train_loss_step=0.751, train_loss_epoch=0.341, valid_loss=0.0413]\n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00, 31.85it/s, v_num=0, train_loss_step=0.751, train_loss_epoch=0.751, valid_loss=0.0413]\n",
      "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.751, train_loss_epoch=0.751, valid_loss=0.0413]        \n",
      "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.678, train_loss_epoch=0.678, valid_loss=0.0413]        \n",
      "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.777, train_loss_epoch=0.777, valid_loss=0.0413]        \n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00, 35.93it/s, v_num=0, train_loss_step=0.653, train_loss_epoch=0.653, valid_loss=0.0413]\n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00, 32.16it/s, v_num=0, train_loss_step=0.659, train_loss_epoch=0.659, valid_loss=0.0413]\n",
      "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.659, train_loss_epoch=0.659, valid_loss=0.0413]        \n",
      "Epoch 495: 100%|██████████| 1/1 [00:00<00:00, 36.24it/s, v_num=0, train_loss_step=0.737, train_loss_epoch=0.737, valid_loss=0.0413]\n",
      "Epoch 495: 100%|██████████| 1/1 [00:00<00:00, 32.55it/s, v_num=0, train_loss_step=0.819, train_loss_epoch=0.819, valid_loss=0.0413]\n",
      "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.819, train_loss_epoch=0.819, valid_loss=0.0413]        \n",
      "Epoch 498: 100%|██████████| 1/1 [00:00<00:00, 33.88it/s, v_num=0, train_loss_step=0.738, train_loss_epoch=0.738, valid_loss=0.0413]\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 31.58it/s, v_num=0, train_loss_step=0.688, train_loss_epoch=0.632, valid_loss=0.0413]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=11056)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 13.90it/s]\u001b[A\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  8.68it/s, v_num=0, train_loss_step=0.688, train_loss_epoch=0.688, valid_loss=0.0871]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=11056)\u001b[0m `Trainer.fit` stopped: `max_steps=500` reached.\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m /home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m Seed set to 3\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m   | Name            | Type          | Params | Mode \n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m 0 | loss            | WMAPE         | 0      | train\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m 1 | padder          | ConstantPad1d | 0      | train\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m 2 | scaler          | TemporalNorm  | 0      | train\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m 3 | hist_encoder    | LSTM          | 162 K  | train\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m 4 | context_adapter | Linear        | 773 K  | train\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m 5 | mlp_decoder     | MLP           | 13.3 K | train\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m 949 K     Trainable params\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m 949 K     Total params\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m 3.798     Total estimated model params size (MB)\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m 11        Modules in train mode\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m 0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.40, train_loss_epoch=11.40]        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-22 08:46:34,829\tERROR tune_controller.py:1331 -- Trial task failed for trial _train_tune_eaea9_00026\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/_private/worker.py\", line 2755, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/_private/worker.py\", line 906, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=11344, ip=172.23.111.25, actor_id=f1bd1c4b300b5b8d4ea8388b01000000, repr=_train_tune)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/air/_internal/util.py\", line 107, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 250, in _trainable_func\n",
      "    output = fn()\n",
      "             ^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/tune/trainable/util.py\", line 130, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/neuralforecast/common/_base_auto.py\", line 214, in _train_tune\n",
      "    _ = self._fit_model(\n",
      "        ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/neuralforecast/common/_base_auto.py\", line 362, in _fit_model\n",
      "    model = model.fit(\n",
      "            ^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/neuralforecast/common/_base_recurrent.py\", line 537, in fit\n",
      "    return self._fit(\n",
      "           ^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/neuralforecast/common/_base_model.py\", line 370, in _fit\n",
      "    trainer.fit(model, datamodule=datamodule)\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 539, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 575, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 982, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 1026, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py\", line 216, in run\n",
      "    self.advance()\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py\", line 455, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 150, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 320, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 192, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 270, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 171, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/core/module.py\", line 1302, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py\", line 154, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py\", line 239, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py\", line 123, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 137, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 487, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 91, in _use_grad\n",
      "    ret = func(self, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/torch/optim/adam.py\", line 202, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py\", line 109, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 146, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 131, in closure\n",
      "    step_output = self._step_fn()\n",
      "                  ^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 319, in _training_step\n",
      "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 323, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py\", line 391, in training_step\n",
      "    return self.lightning_module.training_step(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/neuralforecast/common/_base_recurrent.py\", line 350, in training_step\n",
      "    raise Exception(\"Loss is NaN, training stopped.\")\n",
      "Exception: Loss is NaN, training stopped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.70, train_loss_epoch=15.70]        \n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m Model Parameters \"alias\":                     None\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m \"batch_size\":                32\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m \"callbacks\":                 [<ray.tune.integration.pytorch_lightning.TuneReportCallback object at 0x7f06d0bf6250>, <pytorch_lightning.callbacks.progress.tqdm_progress.TQDMProgressBar object at 0x7f06c809d590>, <pytorch_lightning.callbacks.model_summary.ModelSummary object at 0x7f06c809d550>]\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m \"context_size\":              50\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m \"dataloader_kwargs\":         None\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m \"decoder_hidden_size\":       256\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m \"decoder_layers\":            2\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m \"drop_last_loader\":          False\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m \"early_stop_patience_steps\": -1\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m \"encoder_bias\":              True\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m \"encoder_dropout\":           0.0\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m \"encoder_hidden_size\":       200\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m \"encoder_n_layers\":          1\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m \"futr_exog_list\":            None\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m \"h\":                         77\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m \"hist_exog_list\":            None\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m \"inference_input_size\":      -77\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m \"input_size\":                4928\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m \"learning_rate\":             0.082237505198662\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m \"loss\":                      WMAPE()\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m \"lr_scheduler\":              None\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m \"lr_scheduler_kwargs\":       None\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m \"max_steps\":                 1000\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m \"num_lr_decays\":             -1\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m \"num_workers_loader\":        0\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m \"optimizer\":                 None\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m \"optimizer_kwargs\":          None\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m \"random_seed\":               3\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m \"scaler_type\":               robust\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m \"stat_exog_list\":            None\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m \"val_check_steps\":           100\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m \"valid_batch_size\":          None\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m \"valid_loss\":                WMAPE()\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m insample_y tensor(0, device='cuda:0')\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m outsample_y tensor(0, device='cuda:0')\n",
      "\u001b[36m(_train_tune pid=11344)\u001b[0m output tensor(250404, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=11433)\u001b[0m /home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m Seed set to 7\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=11433)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m   | Name            | Type          | Params | Mode \n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m 0 | loss            | WMAPE         | 0      | train\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m 1 | padder          | ConstantPad1d | 0      | train\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m 2 | scaler          | TemporalNorm  | 0      | train\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m 3 | hist_encoder    | LSTM          | 805 K  | train\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m 4 | context_adapter | Linear        | 773 K  | train\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m 5 | mlp_decoder     | MLP           | 13.3 K | train\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m 1.6 M     Trainable params\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m 1.6 M     Total params\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m 6.371     Total estimated model params size (MB)\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m 11        Modules in train mode\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m 0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.680, train_loss_epoch=3.680]        \n",
      "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.570, train_loss_epoch=3.570]        \n",
      "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.840, train_loss_epoch=5.840]        \n",
      "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=107.0, train_loss_epoch=107.0]        \n",
      "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.40, train_loss_epoch=11.40]        \n",
      "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.660, train_loss_epoch=3.660]        \n",
      "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.200, train_loss_epoch=4.200]        \n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m Model Parameters \"alias\":                     None\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m \"batch_size\":                32\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m \"callbacks\":                 [<ray.tune.integration.pytorch_lightning.TuneReportCallback object at 0x7fed22ba3510>, <pytorch_lightning.callbacks.progress.tqdm_progress.TQDMProgressBar object at 0x7fed202417d0>, <pytorch_lightning.callbacks.model_summary.ModelSummary object at 0x7fed202415d0>]\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m \"context_size\":              50\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m \"dataloader_kwargs\":         None\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m \"decoder_hidden_size\":       256\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m \"decoder_layers\":            2\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m \"drop_last_loader\":          False\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m \"early_stop_patience_steps\": -1\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m \"encoder_bias\":              True\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m \"encoder_dropout\":           0.0\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m \"encoder_hidden_size\":       200\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m \"encoder_n_layers\":          3\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m \"futr_exog_list\":            None\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m \"h\":                         77\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m \"hist_exog_list\":            None\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m \"inference_input_size\":      -77\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m \"input_size\":                1232\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m \"learning_rate\":             0.056633939367020616\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m \"loss\":                      WMAPE()\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m \"lr_scheduler\":              None\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m \"lr_scheduler_kwargs\":       None\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m \"max_steps\":                 1000\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m \"num_lr_decays\":             -1\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m \"num_workers_loader\":        0\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m \"optimizer\":                 None\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m \"optimizer_kwargs\":          None\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m \"random_seed\":               7\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m \"scaler_type\":               robust\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m \"stat_exog_list\":            None\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m \"val_check_steps\":           100\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m \"valid_batch_size\":          None\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m \"valid_loss\":                WMAPE()\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m insample_y tensor(0, device='cuda:0')\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m outsample_y tensor(0, device='cuda:0')\n",
      "\u001b[36m(_train_tune pid=11433)\u001b[0m output tensor(189728, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-22 08:46:43,120\tERROR tune_controller.py:1331 -- Trial task failed for trial _train_tune_eaea9_00027\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/_private/worker.py\", line 2755, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/_private/worker.py\", line 906, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=11433, ip=172.23.111.25, actor_id=52b53a5a1ca973ebd55508f701000000, repr=_train_tune)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/air/_internal/util.py\", line 107, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 250, in _trainable_func\n",
      "    output = fn()\n",
      "             ^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/tune/trainable/util.py\", line 130, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/neuralforecast/common/_base_auto.py\", line 214, in _train_tune\n",
      "    _ = self._fit_model(\n",
      "        ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/neuralforecast/common/_base_auto.py\", line 362, in _fit_model\n",
      "    model = model.fit(\n",
      "            ^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/neuralforecast/common/_base_recurrent.py\", line 537, in fit\n",
      "    return self._fit(\n",
      "           ^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/neuralforecast/common/_base_model.py\", line 370, in _fit\n",
      "    trainer.fit(model, datamodule=datamodule)\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 539, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 47, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 575, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 982, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 1026, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py\", line 216, in run\n",
      "    self.advance()\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py\", line 455, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 150, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 320, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 192, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 270, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 171, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/core/module.py\", line 1302, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py\", line 154, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py\", line 239, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py\", line 123, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/torch/optim/lr_scheduler.py\", line 137, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 487, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 91, in _use_grad\n",
      "    ret = func(self, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/torch/optim/adam.py\", line 202, in step\n",
      "    loss = closure()\n",
      "           ^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision.py\", line 109, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 146, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 131, in closure\n",
      "    step_output = self._step_fn()\n",
      "                  ^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py\", line 319, in _training_step\n",
      "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 323, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py\", line 391, in training_step\n",
      "    return self.lightning_module.training_step(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/neuralforecast/common/_base_recurrent.py\", line 350, in training_step\n",
      "    raise Exception(\"Loss is NaN, training stopped.\")\n",
      "Exception: Loss is NaN, training stopped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.200, train_loss_epoch=4.200]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=11527)\u001b[0m /home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=11527)\u001b[0m Seed set to 18\n",
      "\u001b[36m(_train_tune pid=11527)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=11527)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=11527)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=11527)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(_train_tune pid=11527)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=11527)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=11527)\u001b[0m   | Name            | Type          | Params | Mode \n",
      "\u001b[36m(_train_tune pid=11527)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=11527)\u001b[0m 0 | loss            | WMAPE         | 0      | train\n",
      "\u001b[36m(_train_tune pid=11527)\u001b[0m 1 | padder          | ConstantPad1d | 0      | train\n",
      "\u001b[36m(_train_tune pid=11527)\u001b[0m 2 | scaler          | TemporalNorm  | 0      | train\n",
      "\u001b[36m(_train_tune pid=11527)\u001b[0m 3 | hist_encoder    | LSTM          | 162 K  | train\n",
      "\u001b[36m(_train_tune pid=11527)\u001b[0m 4 | context_adapter | Linear        | 77.4 K | train\n",
      "\u001b[36m(_train_tune pid=11527)\u001b[0m 5 | mlp_decoder     | MLP           | 897    | train\n",
      "\u001b[36m(_train_tune pid=11527)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=11527)\u001b[0m 240 K     Trainable params\n",
      "\u001b[36m(_train_tune pid=11527)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=11527)\u001b[0m 240 K     Total params\n",
      "\u001b[36m(_train_tune pid=11527)\u001b[0m 0.963     Total estimated model params size (MB)\n",
      "\u001b[36m(_train_tune pid=11527)\u001b[0m 11        Modules in train mode\n",
      "\u001b[36m(_train_tune pid=11527)\u001b[0m 0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]        \n",
      "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]        \n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  9.67it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]\n",
      "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999]        \n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]\n",
      "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995]        \n",
      "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.993, train_loss_epoch=0.993]       \n",
      "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.989, train_loss_epoch=0.989]        \n",
      "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988]        \n",
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984]        \n",
      "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.979, train_loss_epoch=0.979]        \n",
      "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.974, train_loss_epoch=0.974]        \n",
      "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.962, train_loss_epoch=0.962]        \n",
      "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.954, train_loss_epoch=0.954]        \n",
      "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.935, train_loss_epoch=0.935]        \n",
      "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.913, train_loss_epoch=0.913]        \n",
      "Epoch 22: 100%|██████████| 1/1 [00:00<00:00, 14.11it/s, v_num=0, train_loss_step=0.900, train_loss_epoch=0.900]\n",
      "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.900, train_loss_epoch=0.900]        \n",
      "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.890, train_loss_epoch=0.890]        \n",
      "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.902, train_loss_epoch=0.902]        \n",
      "Epoch 25: 100%|██████████| 1/1 [00:00<00:00, 14.32it/s, v_num=0, train_loss_step=0.921, train_loss_epoch=0.921]\n",
      "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.921, train_loss_epoch=0.921]        \n",
      "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.863, train_loss_epoch=0.863]        \n",
      "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.869, train_loss_epoch=0.869]        \n",
      "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.830, train_loss_epoch=0.830]        \n",
      "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.838, train_loss_epoch=0.838]        \n",
      "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.829, train_loss_epoch=0.829]        \n",
      "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.806, train_loss_epoch=0.806]        \n",
      "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.806, train_loss_epoch=0.806]        \n",
      "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.824, train_loss_epoch=0.824]        \n",
      "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.796, train_loss_epoch=0.796]        \n",
      "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.796, train_loss_epoch=0.796]        \n",
      "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.774, train_loss_epoch=0.774]        \n",
      "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.752, train_loss_epoch=0.752]        \n",
      "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.746, train_loss_epoch=0.746]        \n",
      "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.754, train_loss_epoch=0.754]        \n",
      "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.768, train_loss_epoch=0.768]        \n",
      "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.744, train_loss_epoch=0.744]        \n",
      "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.724, train_loss_epoch=0.724]        \n",
      "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.724, train_loss_epoch=0.724]        \n",
      "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.718, train_loss_epoch=0.718]        \n",
      "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.714, train_loss_epoch=0.714]        \n",
      "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.730, train_loss_epoch=0.730]        \n",
      "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.696, train_loss_epoch=0.696]        \n",
      "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.692, train_loss_epoch=0.692]        \n",
      "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.708, train_loss_epoch=0.708]        \n",
      "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.670, train_loss_epoch=0.670]        \n",
      "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.669, train_loss_epoch=0.669]        \n",
      "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.662, train_loss_epoch=0.662]        \n",
      "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.655, train_loss_epoch=0.655]        \n",
      "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.626, train_loss_epoch=0.626]        \n",
      "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.748, train_loss_epoch=0.748]        \n",
      "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.638, train_loss_epoch=0.638]        \n",
      "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.643, train_loss_epoch=0.643]        \n",
      "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.607, train_loss_epoch=0.607]        \n",
      "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.737, train_loss_epoch=0.737]        \n",
      "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.680, train_loss_epoch=0.680]        \n",
      "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.604, train_loss_epoch=0.604]        \n",
      "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.726, train_loss_epoch=0.726]        \n",
      "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.730, train_loss_epoch=0.730]        \n",
      "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.636, train_loss_epoch=0.636]        \n",
      "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.690, train_loss_epoch=0.690]        \n",
      "Epoch 76: 100%|██████████| 1/1 [00:00<00:00, 12.28it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582]\n",
      "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582]        \n",
      "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.724, train_loss_epoch=0.724]        \n",
      "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565]        \n",
      "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.698, train_loss_epoch=0.698]        \n",
      "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.713, train_loss_epoch=0.713]        \n",
      "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.579, train_loss_epoch=0.579]        \n",
      "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.711, train_loss_epoch=0.711]        \n",
      "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.584, train_loss_epoch=0.584]        \n",
      "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.586, train_loss_epoch=0.586]        \n",
      "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.635, train_loss_epoch=0.635]        \n",
      "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.714, train_loss_epoch=0.714]        \n",
      "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563]        \n",
      "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.726, train_loss_epoch=0.726]        \n",
      "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.736, train_loss_epoch=0.736]        \n",
      "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.719, train_loss_epoch=0.719]        \n",
      "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.709, train_loss_epoch=0.709]        \n",
      "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.684, train_loss_epoch=0.684]        \n",
      "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.693, train_loss_epoch=0.693]        \n",
      "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.702, train_loss_epoch=0.702]        \n",
      "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.669, train_loss_epoch=0.669]        \n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 11.94it/s, v_num=0, train_loss_step=0.710, train_loss_epoch=0.669]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=11527)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 22.75it/s]\u001b[A\n",
      "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.679, train_loss_epoch=0.679, valid_loss=0.138]        \n",
      "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.700, train_loss_epoch=0.700, valid_loss=0.138]        \n",
      "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.672, train_loss_epoch=0.672, valid_loss=0.138]        \n",
      "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.679, train_loss_epoch=0.679, valid_loss=0.138]        \n",
      "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.696, train_loss_epoch=0.696, valid_loss=0.138]        \n",
      "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.697, train_loss_epoch=0.697, valid_loss=0.138]        \n",
      "Epoch 107: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s, v_num=0, train_loss_step=0.697, train_loss_epoch=0.697, valid_loss=0.138]\n",
      "Epoch 107: 100%|██████████| 1/1 [00:00<00:00, 11.56it/s, v_num=0, train_loss_step=0.629, train_loss_epoch=0.629, valid_loss=0.138]\n",
      "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.629, train_loss_epoch=0.629, valid_loss=0.138]        \n",
      "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.629, train_loss_epoch=0.629, valid_loss=0.138]\n",
      "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.695, train_loss_epoch=0.695, valid_loss=0.138]        \n",
      "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.687, train_loss_epoch=0.687, valid_loss=0.138]        \n",
      "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.619, train_loss_epoch=0.619, valid_loss=0.138]        \n",
      "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.601, train_loss_epoch=0.601, valid_loss=0.138]        \n",
      "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.713, train_loss_epoch=0.713, valid_loss=0.138]        \n",
      "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.581, train_loss_epoch=0.581, valid_loss=0.138]        \n",
      "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.705, train_loss_epoch=0.705, valid_loss=0.138]        \n",
      "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.591, train_loss_epoch=0.591, valid_loss=0.138]        \n",
      "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.727, train_loss_epoch=0.727, valid_loss=0.138]        \n",
      "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.715, train_loss_epoch=0.715, valid_loss=0.138]        \n",
      "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.710, train_loss_epoch=0.710, valid_loss=0.138]        \n",
      "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.707, train_loss_epoch=0.707, valid_loss=0.138]        \n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00, 14.68it/s, v_num=0, train_loss_step=0.700, train_loss_epoch=0.700, valid_loss=0.138]\n",
      "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.700, train_loss_epoch=0.700, valid_loss=0.138]        \n",
      "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.623, train_loss_epoch=0.623, valid_loss=0.138]        \n",
      "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.699, train_loss_epoch=0.699, valid_loss=0.138]        \n",
      "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.710, train_loss_epoch=0.710, valid_loss=0.138]        \n",
      "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.705, train_loss_epoch=0.705, valid_loss=0.138]        \n",
      "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.626, train_loss_epoch=0.626, valid_loss=0.138]        \n",
      "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.701, train_loss_epoch=0.701, valid_loss=0.138]        \n",
      "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.684, train_loss_epoch=0.684, valid_loss=0.138]        \n",
      "Epoch 134: 100%|██████████| 1/1 [00:00<00:00, 15.85it/s, v_num=0, train_loss_step=0.684, train_loss_epoch=0.684, valid_loss=0.138]\n",
      "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.662, train_loss_epoch=0.662, valid_loss=0.138]        \n",
      "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.683, train_loss_epoch=0.683, valid_loss=0.138]        \n",
      "Epoch 137: 100%|██████████| 1/1 [00:00<00:00, 15.76it/s, v_num=0, train_loss_step=0.683, train_loss_epoch=0.683, valid_loss=0.138]\n",
      "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.645, train_loss_epoch=0.645, valid_loss=0.138]        \n",
      "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.588, train_loss_epoch=0.588, valid_loss=0.138]        \n",
      "Epoch 141: 100%|██████████| 1/1 [00:00<00:00, 12.83it/s, v_num=0, train_loss_step=0.645, train_loss_epoch=0.645, valid_loss=0.138]\n",
      "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.682, train_loss_epoch=0.682, valid_loss=0.138]        \n",
      "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.719, train_loss_epoch=0.719, valid_loss=0.138]        \n",
      "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.698, train_loss_epoch=0.698, valid_loss=0.138]        \n",
      "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.593, train_loss_epoch=0.593, valid_loss=0.138]        \n",
      "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.709, train_loss_epoch=0.709, valid_loss=0.138]        \n",
      "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.591, train_loss_epoch=0.591, valid_loss=0.138]        \n",
      "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.592, train_loss_epoch=0.592, valid_loss=0.138]        \n",
      "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.588, train_loss_epoch=0.588, valid_loss=0.138]        \n",
      "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=0.138]        \n",
      "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.717, train_loss_epoch=0.717, valid_loss=0.138]        \n",
      "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.707, train_loss_epoch=0.707, valid_loss=0.138]        \n",
      "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.670, train_loss_epoch=0.670, valid_loss=0.138]        \n",
      "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.703, train_loss_epoch=0.703, valid_loss=0.138]        \n",
      "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.592, train_loss_epoch=0.592, valid_loss=0.138]        \n",
      "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.626, train_loss_epoch=0.626, valid_loss=0.138]        \n",
      "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.713, train_loss_epoch=0.713, valid_loss=0.138]        \n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00, 14.34it/s, v_num=0, train_loss_step=0.713, train_loss_epoch=0.713, valid_loss=0.138]\n",
      "Epoch 163: 100%|██████████| 1/1 [00:00<00:00, 14.01it/s, v_num=0, train_loss_step=0.704, train_loss_epoch=0.704, valid_loss=0.138]\n",
      "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.704, train_loss_epoch=0.704, valid_loss=0.138]        \n",
      "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.138]        \n",
      "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573, valid_loss=0.138]        \n",
      "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.673, train_loss_epoch=0.673, valid_loss=0.138]        \n",
      "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.719, train_loss_epoch=0.719, valid_loss=0.138]        \n",
      "Epoch 169: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=0, train_loss_step=0.708, train_loss_epoch=0.708, valid_loss=0.138]\n",
      "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.708, train_loss_epoch=0.708, valid_loss=0.138]        \n",
      "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568, valid_loss=0.138]        \n",
      "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.702, train_loss_epoch=0.702, valid_loss=0.138]        \n",
      "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.138]        \n",
      "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=0.138]        \n",
      "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.713, train_loss_epoch=0.713, valid_loss=0.138]        \n",
      "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.707, train_loss_epoch=0.707, valid_loss=0.138]        \n",
      "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.138]        \n",
      "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.711, train_loss_epoch=0.711, valid_loss=0.138]        \n",
      "Epoch 180: 100%|██████████| 1/1 [00:00<00:00, 15.36it/s, v_num=0, train_loss_step=0.709, train_loss_epoch=0.709, valid_loss=0.138]\n",
      "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.709, train_loss_epoch=0.709, valid_loss=0.138]        \n",
      "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.706, train_loss_epoch=0.706, valid_loss=0.138]        \n",
      "Epoch 182: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=0, train_loss_step=0.689, train_loss_epoch=0.689, valid_loss=0.138]\n",
      "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.689, train_loss_epoch=0.689, valid_loss=0.138]        \n",
      "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.658, train_loss_epoch=0.658, valid_loss=0.138]        \n",
      "Epoch 185: 100%|██████████| 1/1 [00:00<00:00, 12.49it/s, v_num=0, train_loss_step=0.674, train_loss_epoch=0.674, valid_loss=0.138]\n",
      "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.674, train_loss_epoch=0.674, valid_loss=0.138]        \n",
      "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.659, train_loss_epoch=0.659, valid_loss=0.138]        \n",
      "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.580, train_loss_epoch=0.580, valid_loss=0.138]        \n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00, 11.67it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582, valid_loss=0.138]\n",
      "Epoch 189: 100%|██████████| 1/1 [00:00<00:00, 11.26it/s, v_num=0, train_loss_step=0.706, train_loss_epoch=0.706, valid_loss=0.138]\n",
      "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.706, train_loss_epoch=0.706, valid_loss=0.138]        \n",
      "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.707, train_loss_epoch=0.707, valid_loss=0.138]        \n",
      "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.723, train_loss_epoch=0.723, valid_loss=0.138]        \n",
      "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.700, train_loss_epoch=0.700, valid_loss=0.138]        \n",
      "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.701, train_loss_epoch=0.701, valid_loss=0.138]        \n",
      "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.585, train_loss_epoch=0.585, valid_loss=0.138]        \n",
      "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.706, train_loss_epoch=0.706, valid_loss=0.138]        \n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 11.96it/s, v_num=0, train_loss_step=0.702, train_loss_epoch=0.706, valid_loss=0.138]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=11527)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 25.26it/s]\u001b[A\n",
      "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.693, train_loss_epoch=0.693, valid_loss=0.0441]        \n",
      "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568, valid_loss=0.0441]        \n",
      "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.701, train_loss_epoch=0.701, valid_loss=0.0441]        \n",
      "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.566, train_loss_epoch=0.566, valid_loss=0.0441]        \n",
      "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.661, train_loss_epoch=0.661, valid_loss=0.0441]        \n",
      "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0441]        \n",
      "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.618, train_loss_epoch=0.618, valid_loss=0.0441]        \n",
      "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.703, train_loss_epoch=0.703, valid_loss=0.0441]        \n",
      "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0441]        \n",
      "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.705, train_loss_epoch=0.705, valid_loss=0.0441]        \n",
      "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.566, train_loss_epoch=0.566, valid_loss=0.0441]        \n",
      "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.705, train_loss_epoch=0.705, valid_loss=0.0441]        \n",
      "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.683, train_loss_epoch=0.683, valid_loss=0.0441]        \n",
      "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.661, train_loss_epoch=0.661, valid_loss=0.0441]        \n",
      "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.0441]        \n",
      "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.575, train_loss_epoch=0.575, valid_loss=0.0441]        \n",
      "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.704, train_loss_epoch=0.704, valid_loss=0.0441]        \n",
      "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.700, train_loss_epoch=0.700, valid_loss=0.0441]        \n",
      "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.702, train_loss_epoch=0.702, valid_loss=0.0441]        \n",
      "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.644, train_loss_epoch=0.644, valid_loss=0.0441]        \n",
      "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=0.0441]        \n",
      "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0441]        \n",
      "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=0.0441]        \n",
      "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0441]        \n",
      "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=0.0441]        \n",
      "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.701, train_loss_epoch=0.701, valid_loss=0.0441]        \n",
      "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.702, train_loss_epoch=0.702, valid_loss=0.0441]        \n",
      "Epoch 237: 100%|██████████| 1/1 [00:00<00:00, 11.25it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.703, valid_loss=0.0441]\n",
      "Epoch 237: 100%|██████████| 1/1 [00:00<00:00, 11.15it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=0.0441]\n",
      "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=0.0441]        \n",
      "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.700, train_loss_epoch=0.700, valid_loss=0.0441]        \n",
      "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.659, train_loss_epoch=0.659, valid_loss=0.0441]        \n",
      "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.611, train_loss_epoch=0.611, valid_loss=0.0441]        \n",
      "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.700, train_loss_epoch=0.700, valid_loss=0.0441]        \n",
      "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.604, train_loss_epoch=0.604, valid_loss=0.0441]        \n",
      "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.692, train_loss_epoch=0.692, valid_loss=0.0441]        \n",
      "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.706, train_loss_epoch=0.706, valid_loss=0.0441]        \n",
      "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.666, train_loss_epoch=0.666, valid_loss=0.0441]        \n",
      "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.695, train_loss_epoch=0.695, valid_loss=0.0441]        \n",
      "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.575, train_loss_epoch=0.575, valid_loss=0.0441]        \n",
      "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.646, train_loss_epoch=0.646, valid_loss=0.0441]        \n",
      "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.664, train_loss_epoch=0.664, valid_loss=0.0441]        \n",
      "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.704, train_loss_epoch=0.704, valid_loss=0.0441]        \n",
      "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.575, train_loss_epoch=0.575, valid_loss=0.0441]        \n",
      "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.655, train_loss_epoch=0.655, valid_loss=0.0441]        \n",
      "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.695, train_loss_epoch=0.695, valid_loss=0.0441]        \n",
      "Epoch 259: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.695, valid_loss=0.0441]\n",
      "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574, valid_loss=0.0441]        \n",
      "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.674, train_loss_epoch=0.674, valid_loss=0.0441]        \n",
      "Epoch 261: 100%|██████████| 1/1 [00:00<00:00, 16.01it/s, v_num=0, train_loss_step=0.674, train_loss_epoch=0.674, valid_loss=0.0441]\n",
      "Epoch 261: 100%|██████████| 1/1 [00:00<00:00, 15.32it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=0.0441]\n",
      "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=0.0441]        \n",
      "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.699, train_loss_epoch=0.699, valid_loss=0.0441]        \n",
      "Epoch 264: 100%|██████████| 1/1 [00:00<00:00, 14.26it/s, v_num=0, train_loss_step=0.691, train_loss_epoch=0.691, valid_loss=0.0441]\n",
      "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.691, train_loss_epoch=0.691, valid_loss=0.0441]        \n",
      "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.654, train_loss_epoch=0.654, valid_loss=0.0441]        \n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00, 15.40it/s, v_num=0, train_loss_step=0.695, train_loss_epoch=0.695, valid_loss=0.0441]\n",
      "Epoch 267: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=0, train_loss_step=0.697, train_loss_epoch=0.697, valid_loss=0.0441]\n",
      "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.697, train_loss_epoch=0.697, valid_loss=0.0441]        \n",
      "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.699, train_loss_epoch=0.699, valid_loss=0.0441]        \n",
      "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.694, train_loss_epoch=0.694, valid_loss=0.0441]        \n",
      "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.648, train_loss_epoch=0.648, valid_loss=0.0441]        \n",
      "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.700, train_loss_epoch=0.700, valid_loss=0.0441]        \n",
      "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.697, train_loss_epoch=0.697, valid_loss=0.0441]        \n",
      "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.650, train_loss_epoch=0.650, valid_loss=0.0441]        \n",
      "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.690, train_loss_epoch=0.690, valid_loss=0.0441]        \n",
      "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.0441]        \n",
      "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0441]        \n",
      "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0441]        \n",
      "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.614, train_loss_epoch=0.614, valid_loss=0.0441]        \n",
      "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.691, train_loss_epoch=0.691, valid_loss=0.0441]        \n",
      "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.599, train_loss_epoch=0.599, valid_loss=0.0441]        \n",
      "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.698, train_loss_epoch=0.698, valid_loss=0.0441]        \n",
      "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.694, train_loss_epoch=0.694, valid_loss=0.0441]        \n",
      "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.686, train_loss_epoch=0.686, valid_loss=0.0441]        \n",
      "Epoch 289: 100%|██████████| 1/1 [00:00<00:00, 12.71it/s, v_num=0, train_loss_step=0.594, train_loss_epoch=0.594, valid_loss=0.0441]\n",
      "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.594, train_loss_epoch=0.594, valid_loss=0.0441]        \n",
      "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.669, train_loss_epoch=0.669, valid_loss=0.0441]        \n",
      "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.614, train_loss_epoch=0.614, valid_loss=0.0441]        \n",
      "Epoch 293: 100%|██████████| 1/1 [00:00<00:00, 13.06it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.700, valid_loss=0.0441]\n",
      "Epoch 293: 100%|██████████| 1/1 [00:00<00:00, 12.94it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0441]\n",
      "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0441]        \n",
      "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0441]\n",
      "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=0.0441]        \n",
      "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.689, train_loss_epoch=0.689, valid_loss=0.0441]        \n",
      "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.652, train_loss_epoch=0.652, valid_loss=0.0441]        \n",
      "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.0441]        \n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 13.97it/s, v_num=0, train_loss_step=0.691, train_loss_epoch=0.554, valid_loss=0.0441]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 23.62it/s]\u001b[A\n",
      "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.691, train_loss_epoch=0.691, valid_loss=0.0551]        \n",
      "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.663, train_loss_epoch=0.663, valid_loss=0.0551]        \n",
      "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.683, train_loss_epoch=0.683, valid_loss=0.0551]        \n",
      "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.637, train_loss_epoch=0.637, valid_loss=0.0551]        \n",
      "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.696, train_loss_epoch=0.696, valid_loss=0.0551]        \n",
      "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.627, train_loss_epoch=0.627, valid_loss=0.0551]        \n",
      "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.680, train_loss_epoch=0.680, valid_loss=0.0551]        \n",
      "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.594, train_loss_epoch=0.594, valid_loss=0.0551]        \n",
      "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.0551]        \n",
      "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0551]        \n",
      "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.636, train_loss_epoch=0.636, valid_loss=0.0551]        \n",
      "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.676, train_loss_epoch=0.676, valid_loss=0.0551]        \n",
      "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.566, train_loss_epoch=0.566, valid_loss=0.0551]        \n",
      "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.704, train_loss_epoch=0.704, valid_loss=0.0551]        \n",
      "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=0.0551]        \n",
      "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.597, train_loss_epoch=0.597, valid_loss=0.0551]        \n",
      "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.606, train_loss_epoch=0.606, valid_loss=0.0551]        \n",
      "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.702, train_loss_epoch=0.702, valid_loss=0.0551]        \n",
      "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.678, train_loss_epoch=0.678, valid_loss=0.0551]        \n",
      "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.655, train_loss_epoch=0.655, valid_loss=0.0551]        \n",
      "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.697, train_loss_epoch=0.697, valid_loss=0.0551]        \n",
      "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.576, train_loss_epoch=0.576, valid_loss=0.0551]        \n",
      "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.686, train_loss_epoch=0.686, valid_loss=0.0551]        \n",
      "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.696, train_loss_epoch=0.696, valid_loss=0.0551]        \n",
      "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0551]        \n",
      "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.696, train_loss_epoch=0.696, valid_loss=0.0551]        \n",
      "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.685, train_loss_epoch=0.685, valid_loss=0.0551]        \n",
      "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.700, train_loss_epoch=0.700, valid_loss=0.0551]        \n",
      "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.684, train_loss_epoch=0.684, valid_loss=0.0551]        \n",
      "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.644, train_loss_epoch=0.644, valid_loss=0.0551]        \n",
      "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.631, train_loss_epoch=0.631, valid_loss=0.0551]        \n",
      "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.630, train_loss_epoch=0.630, valid_loss=0.0551]        \n",
      "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567, valid_loss=0.0551]        \n",
      "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.692, train_loss_epoch=0.692, valid_loss=0.0551]        \n",
      "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.627, train_loss_epoch=0.627, valid_loss=0.0551]        \n",
      "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.0551]        \n",
      "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.686, train_loss_epoch=0.686, valid_loss=0.0551]        \n",
      "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574, valid_loss=0.0551]        \n",
      "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.618, train_loss_epoch=0.618, valid_loss=0.0551]        \n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00, 14.06it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0551]\n",
      "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0551]        \n",
      "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0551]        \n",
      "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.639, train_loss_epoch=0.639, valid_loss=0.0551]        \n",
      "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.679, train_loss_epoch=0.679, valid_loss=0.0551]        \n",
      "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.693, train_loss_epoch=0.693, valid_loss=0.0551]        \n",
      "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.583, train_loss_epoch=0.583, valid_loss=0.0551]        \n",
      "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.665, train_loss_epoch=0.665, valid_loss=0.0551]        \n",
      "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582, valid_loss=0.0551]        \n",
      "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.673, train_loss_epoch=0.673, valid_loss=0.0551]        \n",
      "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.700, train_loss_epoch=0.700, valid_loss=0.0551]        \n",
      "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.694, train_loss_epoch=0.694, valid_loss=0.0551]        \n",
      "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.0551]        \n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.0551]\n",
      "Epoch 369: 100%|██████████| 1/1 [00:00<00:00, 14.36it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0551]\n",
      "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0551]        \n",
      "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.663, train_loss_epoch=0.663, valid_loss=0.0551]        \n",
      "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.640, train_loss_epoch=0.640, valid_loss=0.0551]        \n",
      "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.696, train_loss_epoch=0.696, valid_loss=0.0551]        \n",
      "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.636, train_loss_epoch=0.636, valid_loss=0.0551]        \n",
      "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=0.0551]        \n",
      "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.692, train_loss_epoch=0.692, valid_loss=0.0551]        \n",
      "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561, valid_loss=0.0551]        \n",
      "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.689, train_loss_epoch=0.689, valid_loss=0.0551]        \n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00, 13.92it/s, v_num=0, train_loss_step=0.689, train_loss_epoch=0.689, valid_loss=0.0551]\n",
      "Epoch 380: 100%|██████████| 1/1 [00:00<00:00, 13.26it/s, v_num=0, train_loss_step=0.631, train_loss_epoch=0.631, valid_loss=0.0551]\n",
      "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.631, train_loss_epoch=0.631, valid_loss=0.0551]        \n",
      "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565, valid_loss=0.0551]        \n",
      "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.609, train_loss_epoch=0.609, valid_loss=0.0551]        \n",
      "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=0.0551]        \n",
      "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0551]        \n",
      "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.684, train_loss_epoch=0.684, valid_loss=0.0551]        \n",
      "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.690, train_loss_epoch=0.690, valid_loss=0.0551]        \n",
      "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.681, train_loss_epoch=0.681, valid_loss=0.0551]        \n",
      "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.0551]        \n",
      "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0551]        \n",
      "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0551]        \n",
      "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.697, train_loss_epoch=0.697, valid_loss=0.0551]        \n",
      "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.696, train_loss_epoch=0.696, valid_loss=0.0551]        \n",
      "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.640, train_loss_epoch=0.640, valid_loss=0.0551]        \n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.583, valid_loss=0.0551]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=11527)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 25.16it/s]\u001b[A\n",
      "Epoch 400: 100%|██████████| 1/1 [00:00<00:00, 14.57it/s, v_num=0, train_loss_step=0.684, train_loss_epoch=0.684, valid_loss=0.0631]\n",
      "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.684, train_loss_epoch=0.684, valid_loss=0.0631]        \n",
      "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.594, train_loss_epoch=0.594, valid_loss=0.0631]        \n",
      "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.686, train_loss_epoch=0.686, valid_loss=0.0631]        \n",
      "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.673, train_loss_epoch=0.673, valid_loss=0.0631]        \n",
      "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.691, train_loss_epoch=0.691, valid_loss=0.0631]        \n",
      "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.585, train_loss_epoch=0.585, valid_loss=0.0631]        \n",
      "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.0631]        \n",
      "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.678, train_loss_epoch=0.678, valid_loss=0.0631]        \n",
      "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.676, train_loss_epoch=0.676, valid_loss=0.0631]        \n",
      "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.675, train_loss_epoch=0.675, valid_loss=0.0631]        \n",
      "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0631]        \n",
      "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.674, train_loss_epoch=0.674, valid_loss=0.0631]        \n",
      "Epoch 416: 100%|██████████| 1/1 [00:00<00:00, 15.35it/s, v_num=0, train_loss_step=0.627, train_loss_epoch=0.627, valid_loss=0.0631]\n",
      "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.627, train_loss_epoch=0.627, valid_loss=0.0631]        \n",
      "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0631]        \n",
      "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.685, train_loss_epoch=0.685, valid_loss=0.0631]        \n",
      "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.631, train_loss_epoch=0.631, valid_loss=0.0631]        \n",
      "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0631]        \n",
      "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.622, train_loss_epoch=0.622, valid_loss=0.0631]        \n",
      "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=0.0631]        \n",
      "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0631]        \n",
      "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0631]        \n",
      "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.678, train_loss_epoch=0.678, valid_loss=0.0631]        \n",
      "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.695, train_loss_epoch=0.695, valid_loss=0.0631]        \n",
      "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.689, train_loss_epoch=0.689, valid_loss=0.0631]        \n",
      "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.688, train_loss_epoch=0.688, valid_loss=0.0631]        \n",
      "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0631]        \n",
      "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.593, train_loss_epoch=0.593, valid_loss=0.0631]        \n",
      "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0631]        \n",
      "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.683, train_loss_epoch=0.683, valid_loss=0.0631]        \n",
      "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.697, train_loss_epoch=0.697, valid_loss=0.0631]        \n",
      "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0631]        \n",
      "Epoch 440: 100%|██████████| 1/1 [00:00<00:00, 14.23it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.0631]\n",
      "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.0631]        \n",
      "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567, valid_loss=0.0631]        \n",
      "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.692, train_loss_epoch=0.692, valid_loss=0.0631]        \n",
      "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.668, train_loss_epoch=0.668, valid_loss=0.0631]        \n",
      "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.677, train_loss_epoch=0.677, valid_loss=0.0631]        \n",
      "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=0.0631]        \n",
      "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.669, train_loss_epoch=0.669, valid_loss=0.0631]        \n",
      "Epoch 450: 100%|██████████| 1/1 [00:00<00:00, 14.33it/s, v_num=0, train_loss_step=0.652, train_loss_epoch=0.652, valid_loss=0.0631]\n",
      "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.652, train_loss_epoch=0.652, valid_loss=0.0631]        \n",
      "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.620, train_loss_epoch=0.620, valid_loss=0.0631]        \n",
      "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.674, train_loss_epoch=0.674, valid_loss=0.0631]        \n",
      "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=0.0631]        \n",
      "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0631]        \n",
      "Epoch 457: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=0, train_loss_step=0.645, train_loss_epoch=0.645, valid_loss=0.0631]\n",
      "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.645, train_loss_epoch=0.645, valid_loss=0.0631]        \n",
      "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.696, train_loss_epoch=0.696, valid_loss=0.0631]        \n",
      "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.695, train_loss_epoch=0.695, valid_loss=0.0631]        \n",
      "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.626, train_loss_epoch=0.626, valid_loss=0.0631]        \n",
      "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.683, train_loss_epoch=0.683, valid_loss=0.0631]        \n",
      "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.683, train_loss_epoch=0.683, valid_loss=0.0631]        \n",
      "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.686, train_loss_epoch=0.686, valid_loss=0.0631]        \n",
      "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.686, train_loss_epoch=0.686, valid_loss=0.0631]        \n",
      "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.0631]        \n",
      "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.616, train_loss_epoch=0.616, valid_loss=0.0631]        \n",
      "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.688, train_loss_epoch=0.688, valid_loss=0.0631]        \n",
      "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.583, train_loss_epoch=0.583, valid_loss=0.0631]        \n",
      "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0631]        \n",
      "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.586, train_loss_epoch=0.586, valid_loss=0.0631]        \n",
      "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.688, train_loss_epoch=0.688, valid_loss=0.0631]        \n",
      "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.631, train_loss_epoch=0.631, valid_loss=0.0631]        \n",
      "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.689, train_loss_epoch=0.689, valid_loss=0.0631]        \n",
      "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.682, train_loss_epoch=0.682, valid_loss=0.0631]        \n",
      "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.609, train_loss_epoch=0.609, valid_loss=0.0631]        \n",
      "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.587, train_loss_epoch=0.587, valid_loss=0.0631]        \n",
      "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0631]        \n",
      "Epoch 484: 100%|██████████| 1/1 [00:00<00:00, 14.61it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0631]\n",
      "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0631]        \n",
      "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563, valid_loss=0.0631]        \n",
      "Epoch 487: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, v_num=0, train_loss_step=0.581, train_loss_epoch=0.620, valid_loss=0.0631]\n",
      "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.581, train_loss_epoch=0.581, valid_loss=0.0631]        \n",
      "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0631]        \n",
      "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.689, train_loss_epoch=0.689, valid_loss=0.0631]        \n",
      "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.0631]        \n",
      "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.661, train_loss_epoch=0.661, valid_loss=0.0631]        \n",
      "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.615, train_loss_epoch=0.615, valid_loss=0.0631]        \n",
      "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.650, train_loss_epoch=0.650, valid_loss=0.0631]        \n",
      "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0631]        \n",
      "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.684, train_loss_epoch=0.684, valid_loss=0.0631]        \n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 14.18it/s, v_num=0, train_loss_step=0.685, train_loss_epoch=0.684, valid_loss=0.0631]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 25.51it/s]\u001b[A\n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  8.21it/s, v_num=0, train_loss_step=0.685, train_loss_epoch=0.685, valid_loss=0.0387]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=11527)\u001b[0m `Trainer.fit` stopped: `max_steps=500` reached.\n",
      "\u001b[36m(_train_tune pid=11734)\u001b[0m /home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
      "\u001b[36m(_train_tune pid=11734)\u001b[0m Seed set to 18\n",
      "\u001b[36m(_train_tune pid=11734)\u001b[0m GPU available: True (cuda), used: True\n",
      "\u001b[36m(_train_tune pid=11734)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[36m(_train_tune pid=11734)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[36m(_train_tune pid=11734)\u001b[0m You are using a CUDA device ('NVIDIA GeForce RTX 3050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[36m(_train_tune pid=11734)\u001b[0m LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[36m(_train_tune pid=11734)\u001b[0m \n",
      "\u001b[36m(_train_tune pid=11734)\u001b[0m   | Name            | Type          | Params | Mode \n",
      "\u001b[36m(_train_tune pid=11734)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=11734)\u001b[0m 0 | loss            | WMAPE         | 0      | train\n",
      "\u001b[36m(_train_tune pid=11734)\u001b[0m 1 | padder          | ConstantPad1d | 0      | train\n",
      "\u001b[36m(_train_tune pid=11734)\u001b[0m 2 | scaler          | TemporalNorm  | 0      | train\n",
      "\u001b[36m(_train_tune pid=11734)\u001b[0m 3 | hist_encoder    | LSTM          | 202 K  | train\n",
      "\u001b[36m(_train_tune pid=11734)\u001b[0m 4 | context_adapter | Linear        | 388 K  | train\n",
      "\u001b[36m(_train_tune pid=11734)\u001b[0m 5 | mlp_decoder     | MLP           | 6.7 K  | train\n",
      "\u001b[36m(_train_tune pid=11734)\u001b[0m ----------------------------------------------------------\n",
      "\u001b[36m(_train_tune pid=11734)\u001b[0m 598 K     Trainable params\n",
      "\u001b[36m(_train_tune pid=11734)\u001b[0m 0         Non-trainable params\n",
      "\u001b[36m(_train_tune pid=11734)\u001b[0m 598 K     Total params\n",
      "\u001b[36m(_train_tune pid=11734)\u001b[0m 2.393     Total estimated model params size (MB)\n",
      "\u001b[36m(_train_tune pid=11734)\u001b[0m 11        Modules in train mode\n",
      "\u001b[36m(_train_tune pid=11734)\u001b[0m 0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]        \n",
      "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.977, train_loss_epoch=0.977]        \n",
      "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.831, train_loss_epoch=0.831]        \n",
      "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.751, train_loss_epoch=0.751]        \n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 42.63it/s, v_num=0, train_loss_step=0.751, train_loss_epoch=0.751]\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00, 30.83it/s, v_num=0, train_loss_step=0.855, train_loss_epoch=0.855]\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00, 21.55it/s, v_num=0, train_loss_step=0.920, train_loss_epoch=0.920]\n",
      "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.920, train_loss_epoch=0.920]        \n",
      "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.892, train_loss_epoch=0.892]        \n",
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.766, train_loss_epoch=0.766]        \n",
      "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.766, train_loss_epoch=0.766]\n",
      "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.697, train_loss_epoch=0.697]        \n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00, 19.94it/s, v_num=0, train_loss_step=0.668, train_loss_epoch=0.668]\n",
      "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.668, train_loss_epoch=0.668]        \n",
      "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.641, train_loss_epoch=0.641]        \n",
      "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.620, train_loss_epoch=0.620]        \n",
      "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.620, train_loss_epoch=0.620]\n",
      "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.598, train_loss_epoch=0.598]        \n",
      "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.590, train_loss_epoch=0.590]        \n",
      "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.602, train_loss_epoch=0.602]        \n",
      "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.592, train_loss_epoch=0.592]        \n",
      "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568]        \n",
      "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569]        \n",
      "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568]        \n",
      "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559]        \n",
      "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553]        \n",
      "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557]        \n",
      "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554]        \n",
      "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546]        \n",
      "Epoch 49: 100%|██████████| 1/1 [00:00<00:00, 34.00it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543]\n",
      "Epoch 51: 100%|██████████| 1/1 [00:00<00:00, 29.92it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552]\n",
      "Epoch 53: 100%|██████████| 1/1 [00:00<00:00, 32.30it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543]\n",
      "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544]        \n",
      "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543]        \n",
      "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539]        \n",
      "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537]        \n",
      "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532]        \n",
      "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526]        \n",
      "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523]        \n",
      "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522]        \n",
      "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521]        \n",
      "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510]        \n",
      "Epoch 76: 100%|██████████| 1/1 [00:00<00:00, 32.41it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516]\n",
      "Epoch 78: 100%|██████████| 1/1 [00:00<00:00, 31.20it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514]\n",
      "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550]        \n",
      "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533]        \n",
      "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513]        \n",
      "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511]        \n",
      "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539]        \n",
      "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557]        \n",
      "Epoch 93: 100%|██████████| 1/1 [00:00<00:00, 34.91it/s, v_num=0, train_loss_step=0.575, train_loss_epoch=0.575]\n",
      "Epoch 95: 100%|██████████| 1/1 [00:00<00:00, 31.48it/s, v_num=0, train_loss_step=0.590, train_loss_epoch=0.590]\n",
      "Epoch 97: 100%|██████████| 1/1 [00:00<00:00, 30.06it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564]\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 31.71it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548]\n",
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00, 20.27it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.548]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 44.88it/s]\u001b[A\n",
      "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0569]        \n",
      "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=0.0569]        \n",
      "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.0569]        \n",
      "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0569]        \n",
      "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0569]        \n",
      "Epoch 111: 100%|██████████| 1/1 [00:00<00:00, 32.52it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0569]\n",
      "Epoch 113: 100%|██████████| 1/1 [00:00<00:00, 34.62it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0569]\n",
      "Epoch 115: 100%|██████████| 1/1 [00:00<00:00, 22.56it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0569]\n",
      "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0569]        \n",
      "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0569]        \n",
      "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0569]        \n",
      "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0569]        \n",
      "Epoch 124: 100%|██████████| 1/1 [00:00<00:00, 30.69it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0569]\n",
      "Epoch 126: 100%|██████████| 1/1 [00:00<00:00, 29.73it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0569]\n",
      "Epoch 128: 100%|██████████| 1/1 [00:00<00:00, 26.65it/s, v_num=0, train_loss_step=0.581, train_loss_epoch=0.581, valid_loss=0.0569]\n",
      "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.566, train_loss_epoch=0.566, valid_loss=0.0569]        \n",
      "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.664, train_loss_epoch=0.664, valid_loss=0.0569]        \n",
      "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.722, train_loss_epoch=0.722, valid_loss=0.0569]        \n",
      "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.693, train_loss_epoch=0.693, valid_loss=0.0569]        \n",
      "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.696, train_loss_epoch=0.696, valid_loss=0.0569]        \n",
      "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.647, train_loss_epoch=0.647, valid_loss=0.0569]        \n",
      "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.610, train_loss_epoch=0.610, valid_loss=0.0569]        \n",
      "Epoch 145: 100%|██████████| 1/1 [00:00<00:00, 33.04it/s, v_num=0, train_loss_step=0.588, train_loss_epoch=0.588, valid_loss=0.0569]\n",
      "Epoch 147: 100%|██████████| 1/1 [00:00<00:00, 28.94it/s, v_num=0, train_loss_step=0.579, train_loss_epoch=0.579, valid_loss=0.0569]\n",
      "Epoch 149: 100%|██████████| 1/1 [00:00<00:00, 20.69it/s, v_num=0, train_loss_step=0.699, train_loss_epoch=0.699, valid_loss=0.0569]\n",
      "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.699, train_loss_epoch=0.699, valid_loss=0.0569]        \n",
      "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.706, train_loss_epoch=0.706, valid_loss=0.0569]        \n",
      "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.634, train_loss_epoch=0.634, valid_loss=0.0569]        \n",
      "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.613, train_loss_epoch=0.613, valid_loss=0.0569]        \n",
      "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.602, train_loss_epoch=0.602, valid_loss=0.0569]        \n",
      "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.585, train_loss_epoch=0.585, valid_loss=0.0569]        \n",
      "Epoch 162: 100%|██████████| 1/1 [00:00<00:00, 32.63it/s, v_num=0, train_loss_step=0.566, train_loss_epoch=0.566, valid_loss=0.0569]\n",
      "Epoch 164: 100%|██████████| 1/1 [00:00<00:00, 33.28it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=0.0569]\n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00, 31.05it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0569]\n",
      "Epoch 166: 100%|██████████| 1/1 [00:00<00:00, 20.79it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565, valid_loss=0.0569]\n",
      "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565, valid_loss=0.0569]        \n",
      "Epoch 168: 100%|██████████| 1/1 [00:00<00:00, 19.72it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=0.0569]\n",
      "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=0.0569]        \n",
      "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0569]        \n",
      "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=0.0569]        \n",
      "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=0.0569]        \n",
      "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0569]        \n",
      "Epoch 177: 100%|██████████| 1/1 [00:00<00:00, 29.50it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.0569]\n",
      "Epoch 179: 100%|██████████| 1/1 [00:00<00:00, 31.39it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0569]\n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00, 34.45it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0569]\n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00, 21.42it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.524, valid_loss=0.0569]\n",
      "Epoch 181: 100%|██████████| 1/1 [00:00<00:00, 20.88it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0569]\n",
      "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0569]        \n",
      "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=0.0569]        \n",
      "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0569]        \n",
      "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0569]        \n",
      "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=0.0569]        \n",
      "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=0.0569]        \n",
      "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0569]        \n",
      "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.0569]        \n",
      "Epoch 196: 100%|██████████| 1/1 [00:00<00:00, 28.36it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.0569]\n",
      "Epoch 198: 100%|██████████| 1/1 [00:00<00:00, 31.71it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0569]\n",
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 22.34it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.550, valid_loss=0.0569]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 38.35it/s]\u001b[A\n",
      "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=0.0996]        \n",
      "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.623, train_loss_epoch=0.623, valid_loss=0.0996]        \n",
      "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.589, train_loss_epoch=0.589, valid_loss=0.0996]        \n",
      "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.578, train_loss_epoch=0.578, valid_loss=0.0996]        \n",
      "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.620, train_loss_epoch=0.620, valid_loss=0.0996]        \n",
      "Epoch 208: 100%|██████████| 1/1 [00:00<00:00, 30.38it/s, v_num=0, train_loss_step=0.620, train_loss_epoch=0.620, valid_loss=0.0996]\n",
      "Epoch 210: 100%|██████████| 1/1 [00:00<00:00, 41.93it/s, v_num=0, train_loss_step=0.606, train_loss_epoch=0.606, valid_loss=0.0996]\n",
      "Epoch 212: 100%|██████████| 1/1 [00:00<00:00, 29.58it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571, valid_loss=0.0996]\n",
      "Epoch 212: 100%|██████████| 1/1 [00:00<00:00, 19.24it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0996]\n",
      "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0996]        \n",
      "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0996]        \n",
      "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0996]        \n",
      "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.576, train_loss_epoch=0.576, valid_loss=0.0996]        \n",
      "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.628, train_loss_epoch=0.628, valid_loss=0.0996]        \n",
      "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.629, train_loss_epoch=0.629, valid_loss=0.0996]        \n",
      "Epoch 223: 100%|██████████| 1/1 [00:00<00:00, 32.50it/s, v_num=0, train_loss_step=0.629, train_loss_epoch=0.629, valid_loss=0.0996]\n",
      "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.600, train_loss_epoch=0.600, valid_loss=0.0996]        \n",
      "Epoch 225: 100%|██████████| 1/1 [00:00<00:00, 28.35it/s, v_num=0, train_loss_step=0.600, train_loss_epoch=0.600, valid_loss=0.0996]\n",
      "Epoch 227: 100%|██████████| 1/1 [00:00<00:00, 31.61it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571, valid_loss=0.0996]\n",
      "Epoch 229: 100%|██████████| 1/1 [00:00<00:00, 31.50it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0996]\n",
      "Epoch 229: 100%|██████████| 1/1 [00:00<00:00, 20.74it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0996]\n",
      "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0996]        \n",
      "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.575, train_loss_epoch=0.575, valid_loss=0.0996]        \n",
      "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.0996]        \n",
      "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.0996]        \n",
      "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0996]        \n",
      "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.578, train_loss_epoch=0.578, valid_loss=0.0996]        \n",
      "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=0.0996]        \n",
      "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.721, train_loss_epoch=0.721, valid_loss=0.0996]        \n",
      "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.788, train_loss_epoch=0.788, valid_loss=0.0996]        \n",
      "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.900, train_loss_epoch=0.900, valid_loss=0.0996]        \n",
      "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.0996]        \n",
      "Epoch 252: 100%|██████████| 1/1 [00:00<00:00, 35.16it/s, v_num=0, train_loss_step=0.901, train_loss_epoch=0.901, valid_loss=0.0996]\n",
      "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.830, train_loss_epoch=0.830, valid_loss=0.0996]        \n",
      "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.705, train_loss_epoch=0.705, valid_loss=0.0996]        \n",
      "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.927, train_loss_epoch=0.927, valid_loss=0.0996]        \n",
      "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=0.0996]        \n",
      "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.955, train_loss_epoch=0.955, valid_loss=0.0996]        \n",
      "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.0996]        \n",
      "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.842, train_loss_epoch=0.842, valid_loss=0.0996]        \n",
      "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.817, train_loss_epoch=0.817, valid_loss=0.0996]        \n",
      "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.791, train_loss_epoch=0.791, valid_loss=0.0996]        \n",
      "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.759, train_loss_epoch=0.759, valid_loss=0.0996]        \n",
      "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.741, train_loss_epoch=0.741, valid_loss=0.0996]        \n",
      "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.722, train_loss_epoch=0.722, valid_loss=0.0996]        \n",
      "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.721, train_loss_epoch=0.721, valid_loss=0.0996]        \n",
      "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.737, train_loss_epoch=0.737, valid_loss=0.0996]        \n",
      "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.724, train_loss_epoch=0.724, valid_loss=0.0996]        \n",
      "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.746, train_loss_epoch=0.746, valid_loss=0.0996]        \n",
      "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.713, train_loss_epoch=0.713, valid_loss=0.0996]        \n",
      "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.780, train_loss_epoch=0.780, valid_loss=0.0996]        \n",
      "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.749, train_loss_epoch=0.749, valid_loss=0.0996]        \n",
      "Epoch 290: 100%|██████████| 1/1 [00:00<00:00, 34.16it/s, v_num=0, train_loss_step=0.749, train_loss_epoch=0.749, valid_loss=0.0996]\n",
      "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.699, train_loss_epoch=0.699, valid_loss=0.0996]        \n",
      "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.673, train_loss_epoch=0.673, valid_loss=0.0996]        \n",
      "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.629, train_loss_epoch=0.629, valid_loss=0.0996]        \n",
      "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.617, train_loss_epoch=0.617, valid_loss=0.0996]        \n",
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00, 21.69it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.610, valid_loss=0.0996]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=11734)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 36.58it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=11734)\u001b[0m \n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00, 40.29it/s, v_num=0, train_loss_step=0.586, train_loss_epoch=0.586, valid_loss=0.0381]\n",
      "Epoch 301: 100%|██████████| 1/1 [00:00<00:00, 23.01it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582, valid_loss=0.0381]\n",
      "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582, valid_loss=0.0381]        \n",
      "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0381]        \n",
      "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=0.0381]        \n",
      "Epoch 307: 100%|██████████| 1/1 [00:00<00:00, 16.81it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=0.0381]\n",
      "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=0.0381]        \n",
      "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.0381]        \n",
      "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=0.0381]        \n",
      "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=0.0381]        \n",
      "Epoch 315: 100%|██████████| 1/1 [00:00<00:00, 19.29it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.0381]\n",
      "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.0381]        \n",
      "Epoch 317: 100%|██████████| 1/1 [00:00<00:00, 19.42it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0381]\n",
      "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0381]        \n",
      "Epoch 319: 100%|██████████| 1/1 [00:00<00:00, 18.65it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.530, valid_loss=0.0381]\n",
      "Epoch 319: 100%|██████████| 1/1 [00:00<00:00, 18.20it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0381]\n",
      "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0381]        \n",
      "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0381]        \n",
      "Epoch 323: 100%|██████████| 1/1 [00:00<00:00, 19.98it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0381]\n",
      "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0381]        \n",
      "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0381]        \n",
      "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0381]        \n",
      "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0381]        \n",
      "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0381]        \n",
      "Epoch 333: 100%|██████████| 1/1 [00:00<00:00, 24.29it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.0381]\n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00, 22.02it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0381]\n",
      "Epoch 335: 100%|██████████| 1/1 [00:00<00:00, 21.27it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0381]\n",
      "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0381]        \n",
      "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=0.0381]        \n",
      "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0381]        \n",
      "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0381]        \n",
      "Epoch 343: 100%|██████████| 1/1 [00:00<00:00, 33.30it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0381]\n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00, 35.69it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0381]\n",
      "Epoch 345: 100%|██████████| 1/1 [00:00<00:00, 21.39it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0381]\n",
      "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0381]        \n",
      "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0381]        \n",
      "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0381]        \n",
      "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0381]        \n",
      "Epoch 353: 100%|██████████| 1/1 [00:00<00:00, 13.74it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0381]\n",
      "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0381]        \n",
      "Epoch 355: 100%|██████████| 1/1 [00:00<00:00, 27.17it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0381]\n",
      "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0381]        \n",
      "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0381]        \n",
      "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0381]        \n",
      "Epoch 362: 100%|██████████| 1/1 [00:00<00:00, 38.84it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=0.0381]\n",
      "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=0.0381]        \n",
      "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0381]        \n",
      "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0381]        \n",
      "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0381]        \n",
      "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0381]        \n",
      "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0381]        \n",
      "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0381]        \n",
      "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0381]        \n",
      "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471, valid_loss=0.0381]        \n",
      "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0381]        \n",
      "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471, valid_loss=0.0381]        \n",
      "Epoch 385: 100%|██████████| 1/1 [00:00<00:00, 16.80it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0381]\n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00, 40.29it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0381]\n",
      "Epoch 387: 100%|██████████| 1/1 [00:00<00:00, 23.09it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.0381]\n",
      "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.0381]        \n",
      "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0381]        \n",
      "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0381]        \n",
      "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0381]        \n",
      "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0381]        \n",
      "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0381]        \n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 27.25it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471, valid_loss=0.0381]\n",
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 19.62it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.471, valid_loss=0.0381]\n",
      "\u001b[36m(_train_tune pid=11734)\u001b[0m \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=11734)\u001b[0m \n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=11734)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 36.68it/s]\u001b[A\n",
      "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.465, valid_loss=0.044]         \n",
      "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.458, train_loss_epoch=0.458, valid_loss=0.044]        \n",
      "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.468, valid_loss=0.044]        \n",
      "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452, valid_loss=0.044]        \n",
      "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.461, train_loss_epoch=0.461, valid_loss=0.044]        \n",
      "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473, valid_loss=0.044]        \n",
      "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.044]        \n",
      "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=0.044]        \n",
      "Epoch 415: 100%|██████████| 1/1 [00:00<00:00, 28.77it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=0.044]\n",
      "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=0.044]        \n",
      "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.454, train_loss_epoch=0.454, valid_loss=0.044]        \n",
      "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.443, train_loss_epoch=0.443, valid_loss=0.044]        \n",
      "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.437, train_loss_epoch=0.437, valid_loss=0.044]        \n",
      "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.437, train_loss_epoch=0.437, valid_loss=0.044]        \n",
      "Epoch 425: 100%|██████████| 1/1 [00:00<00:00, 31.97it/s, v_num=0, train_loss_step=0.437, train_loss_epoch=0.437, valid_loss=0.044]\n",
      "Epoch 427: 100%|██████████| 1/1 [00:00<00:00, 29.35it/s, v_num=0, train_loss_step=0.439, train_loss_epoch=0.439, valid_loss=0.044]\n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00, 22.05it/s, v_num=0, train_loss_step=0.431, train_loss_epoch=0.439, valid_loss=0.044]\n",
      "Epoch 429: 100%|██████████| 1/1 [00:00<00:00, 21.21it/s, v_num=0, train_loss_step=0.431, train_loss_epoch=0.431, valid_loss=0.044]\n",
      "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.431, train_loss_epoch=0.431, valid_loss=0.044]        \n",
      "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.433, train_loss_epoch=0.433, valid_loss=0.044]        \n",
      "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.434, train_loss_epoch=0.434, valid_loss=0.044]        \n",
      "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.450, train_loss_epoch=0.450, valid_loss=0.044]        \n",
      "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=0.044]        \n",
      "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.044]        \n",
      "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=0.044]        \n",
      "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.457, train_loss_epoch=0.457, valid_loss=0.044]        \n",
      "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.448, valid_loss=0.044]        \n",
      "Epoch 444: 100%|██████████| 1/1 [00:00<00:00, 31.73it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.448, valid_loss=0.044]\n",
      "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.443, train_loss_epoch=0.443, valid_loss=0.044]        \n",
      "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.437, train_loss_epoch=0.437, valid_loss=0.044]        \n",
      "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.431, train_loss_epoch=0.431, valid_loss=0.044]        \n",
      "Epoch 452: 100%|██████████| 1/1 [00:00<00:00, 34.67it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=0.044]\n",
      "Epoch 454: 100%|██████████| 1/1 [00:00<00:00, 28.70it/s, v_num=0, train_loss_step=0.423, train_loss_epoch=0.423, valid_loss=0.044]\n",
      "Epoch 456: 100%|██████████| 1/1 [00:00<00:00, 28.67it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=0.044]\n",
      "Epoch 458: 100%|██████████| 1/1 [00:00<00:00, 28.19it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=0.044]\n",
      "Epoch 460: 100%|██████████| 1/1 [00:00<00:00, 27.57it/s, v_num=0, train_loss_step=0.440, train_loss_epoch=0.440, valid_loss=0.044]\n",
      "Epoch 462: 100%|██████████| 1/1 [00:00<00:00, 28.29it/s, v_num=0, train_loss_step=0.437, train_loss_epoch=0.437, valid_loss=0.044]\n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00, 26.92it/s, v_num=0, train_loss_step=0.430, train_loss_epoch=0.430, valid_loss=0.044]\n",
      "Epoch 464: 100%|██████████| 1/1 [00:00<00:00, 19.85it/s, v_num=0, train_loss_step=0.447, train_loss_epoch=0.430, valid_loss=0.044]\n",
      "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.447, train_loss_epoch=0.447, valid_loss=0.044]        \n",
      "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.437, train_loss_epoch=0.437, valid_loss=0.044]        \n",
      "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.433, train_loss_epoch=0.433, valid_loss=0.044]        \n",
      "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.432, train_loss_epoch=0.432, valid_loss=0.044]        \n",
      "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.438, train_loss_epoch=0.438, valid_loss=0.044]        \n",
      "Epoch 475: 100%|██████████| 1/1 [00:00<00:00, 34.02it/s, v_num=0, train_loss_step=0.428, train_loss_epoch=0.428, valid_loss=0.044]\n",
      "Epoch 477: 100%|██████████| 1/1 [00:00<00:00, 26.32it/s, v_num=0, train_loss_step=0.424, train_loss_epoch=0.424, valid_loss=0.044]\n",
      "Epoch 479: 100%|██████████| 1/1 [00:00<00:00, 27.73it/s, v_num=0, train_loss_step=0.422, train_loss_epoch=0.422, valid_loss=0.044]\n",
      "Epoch 481: 100%|██████████| 1/1 [00:00<00:00, 22.63it/s, v_num=0, train_loss_step=0.422, train_loss_epoch=0.418, valid_loss=0.044]\n",
      "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.422, train_loss_epoch=0.422, valid_loss=0.044]        \n",
      "Epoch 483: 100%|██████████| 1/1 [00:00<00:00, 20.02it/s, v_num=0, train_loss_step=0.421, train_loss_epoch=0.421, valid_loss=0.044]\n",
      "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.421, train_loss_epoch=0.421, valid_loss=0.044]        \n",
      "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.423, train_loss_epoch=0.423, valid_loss=0.044]        \n",
      "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.418, train_loss_epoch=0.418, valid_loss=0.044]        \n",
      "Epoch 490: 100%|██████████| 1/1 [00:00<00:00, 28.73it/s, v_num=0, train_loss_step=0.413, train_loss_epoch=0.413, valid_loss=0.044]\n",
      "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.415, valid_loss=0.044]        \n",
      "Epoch 492: 100%|██████████| 1/1 [00:00<00:00, 25.78it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.415, valid_loss=0.044]\n",
      "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.417, train_loss_epoch=0.417, valid_loss=0.044]        \n",
      "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.412, train_loss_epoch=0.412, valid_loss=0.044]        \n",
      "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.412, train_loss_epoch=0.412, valid_loss=0.044]        \n",
      "Epoch 499: 100%|██████████| 1/1 [00:00<00:00, 20.80it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.412, valid_loss=0.044]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 40.86it/s]\u001b[A\n",
      "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.415, valid_loss=0.0446]        \n",
      "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.449, train_loss_epoch=0.449, valid_loss=0.0446]        \n",
      "Epoch 504: 100%|██████████| 1/1 [00:00<00:00, 30.02it/s, v_num=0, train_loss_step=0.431, train_loss_epoch=0.431, valid_loss=0.0446]\n",
      "Epoch 506: 100%|██████████| 1/1 [00:00<00:00, 32.21it/s, v_num=0, train_loss_step=0.422, train_loss_epoch=0.422, valid_loss=0.0446]\n",
      "Epoch 506: 100%|██████████| 1/1 [00:00<00:00, 22.08it/s, v_num=0, train_loss_step=0.427, train_loss_epoch=0.422, valid_loss=0.0446]\n",
      "Epoch 506: 100%|██████████| 1/1 [00:00<00:00, 20.83it/s, v_num=0, train_loss_step=0.427, train_loss_epoch=0.427, valid_loss=0.0446]\n",
      "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.427, train_loss_epoch=0.427, valid_loss=0.0446]        \n",
      "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.416, valid_loss=0.0446]        \n",
      "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.415, valid_loss=0.0446]        \n",
      "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.412, train_loss_epoch=0.412, valid_loss=0.0446]        \n",
      "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.411, train_loss_epoch=0.411, valid_loss=0.0446]        \n",
      "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.409, train_loss_epoch=0.409, valid_loss=0.0446]        \n",
      "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.410, train_loss_epoch=0.410, valid_loss=0.0446]        \n",
      "Epoch 521: 100%|██████████| 1/1 [00:00<00:00, 40.27it/s, v_num=0, train_loss_step=0.413, train_loss_epoch=0.413, valid_loss=0.0446]\n",
      "Epoch 523: 100%|██████████| 1/1 [00:00<00:00, 28.10it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=0.0446]\n",
      "Epoch 523: 100%|██████████| 1/1 [00:00<00:00, 19.01it/s, v_num=0, train_loss_step=0.406, train_loss_epoch=0.406, valid_loss=0.0446]\n",
      "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.406, train_loss_epoch=0.406, valid_loss=0.0446]        \n",
      "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.412, train_loss_epoch=0.412, valid_loss=0.0446]        \n",
      "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.433, train_loss_epoch=0.433, valid_loss=0.0446]        \n",
      "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.432, train_loss_epoch=0.432, valid_loss=0.0446]        \n",
      "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.424, train_loss_epoch=0.424, valid_loss=0.0446]        \n",
      "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.415, valid_loss=0.0446]        \n",
      "Epoch 536: 100%|██████████| 1/1 [00:00<00:00, 34.61it/s, v_num=0, train_loss_step=0.410, train_loss_epoch=0.410, valid_loss=0.0446]\n",
      "Epoch 538: 100%|██████████| 1/1 [00:00<00:00, 21.13it/s, v_num=0, train_loss_step=0.409, train_loss_epoch=0.409, valid_loss=0.0446]\n",
      "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.409, train_loss_epoch=0.409, valid_loss=0.0446]        \n",
      "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.406, train_loss_epoch=0.406, valid_loss=0.0446]        \n",
      "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.403, train_loss_epoch=0.403, valid_loss=0.0446]        \n",
      "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.433, train_loss_epoch=0.433, valid_loss=0.0446]        \n",
      "Epoch 547: 100%|██████████| 1/1 [00:00<00:00, 40.10it/s, v_num=0, train_loss_step=0.418, train_loss_epoch=0.418, valid_loss=0.0446]\n",
      "Epoch 549: 100%|██████████| 1/1 [00:00<00:00, 29.94it/s, v_num=0, train_loss_step=0.417, train_loss_epoch=0.417, valid_loss=0.0446]\n",
      "Epoch 549: 100%|██████████| 1/1 [00:00<00:00, 20.83it/s, v_num=0, train_loss_step=0.413, train_loss_epoch=0.417, valid_loss=0.0446]\n",
      "Epoch 549: 100%|██████████| 1/1 [00:00<00:00, 18.91it/s, v_num=0, train_loss_step=0.413, train_loss_epoch=0.413, valid_loss=0.0446]\n",
      "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.413, train_loss_epoch=0.413, valid_loss=0.0446]        \n",
      "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.410, train_loss_epoch=0.410, valid_loss=0.0446]        \n",
      "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.403, train_loss_epoch=0.403, valid_loss=0.0446]        \n",
      "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.409, train_loss_epoch=0.409, valid_loss=0.0446]        \n",
      "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.408, train_loss_epoch=0.408, valid_loss=0.0446]        \n",
      "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.421, train_loss_epoch=0.421, valid_loss=0.0446]        \n",
      "Epoch 562: 100%|██████████| 1/1 [00:00<00:00, 42.57it/s, v_num=0, train_loss_step=0.407, train_loss_epoch=0.407, valid_loss=0.0446]\n",
      "Epoch 564: 100%|██████████| 1/1 [00:00<00:00, 30.51it/s, v_num=0, train_loss_step=0.406, train_loss_epoch=0.406, valid_loss=0.0446]\n",
      "Epoch 566: 100%|██████████| 1/1 [00:00<00:00, 29.76it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=0.0446]\n",
      "Epoch 568: 100%|██████████| 1/1 [00:00<00:00, 28.97it/s, v_num=0, train_loss_step=0.406, train_loss_epoch=0.406, valid_loss=0.0446]\n",
      "Epoch 570: 100%|██████████| 1/1 [00:00<00:00, 30.65it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=0.0446]\n",
      "Epoch 570: 100%|██████████| 1/1 [00:00<00:00, 20.31it/s, v_num=0, train_loss_step=0.399, train_loss_epoch=0.399, valid_loss=0.0446]\n",
      "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.399, train_loss_epoch=0.399, valid_loss=0.0446]        \n",
      "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.398, train_loss_epoch=0.398, valid_loss=0.0446]        \n",
      "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.399, train_loss_epoch=0.399, valid_loss=0.0446]        \n",
      "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.399, train_loss_epoch=0.399, valid_loss=0.0446]        \n",
      "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.399, train_loss_epoch=0.399, valid_loss=0.0446]        \n",
      "Epoch 579: 100%|██████████| 1/1 [00:00<00:00, 32.29it/s, v_num=0, train_loss_step=0.399, train_loss_epoch=0.399, valid_loss=0.0446]\n",
      "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.411, train_loss_epoch=0.411, valid_loss=0.0446]        \n",
      "Epoch 581: 100%|██████████| 1/1 [00:00<00:00, 28.72it/s, v_num=0, train_loss_step=0.411, train_loss_epoch=0.411, valid_loss=0.0446]\n",
      "Epoch 583: 100%|██████████| 1/1 [00:00<00:00, 21.12it/s, v_num=0, train_loss_step=0.428, train_loss_epoch=0.428, valid_loss=0.0446]\n",
      "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.428, train_loss_epoch=0.428, valid_loss=0.0446]        \n",
      "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=0.0446]        \n",
      "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452, valid_loss=0.0446]        \n",
      "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.446, train_loss_epoch=0.446, valid_loss=0.0446]        \n",
      "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.426, train_loss_epoch=0.426, valid_loss=0.0446]        \n",
      "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.429, train_loss_epoch=0.429, valid_loss=0.0446]        \n",
      "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.422, train_loss_epoch=0.422, valid_loss=0.0446]        \n",
      "Epoch 596: 100%|██████████| 1/1 [00:00<00:00, 33.61it/s, v_num=0, train_loss_step=0.422, train_loss_epoch=0.422, valid_loss=0.0446]\n",
      "Epoch 598: 100%|██████████| 1/1 [00:00<00:00, 28.47it/s, v_num=0, train_loss_step=0.411, train_loss_epoch=0.411, valid_loss=0.0446]\n",
      "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 23.40it/s, v_num=0, train_loss_step=0.410, train_loss_epoch=0.410, valid_loss=0.0446]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 40.06it/s]\u001b[A\n",
      "Epoch 599: 100%|██████████| 1/1 [00:00<00:00, 11.17it/s, v_num=0, train_loss_step=0.410, train_loss_epoch=0.410, valid_loss=0.040] \n",
      "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.410, train_loss_epoch=0.410, valid_loss=0.040]        \n",
      "Epoch 601: 100%|██████████| 1/1 [00:00<00:00, 19.18it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=0.040]\n",
      "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=0.040]        \n",
      "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.403, train_loss_epoch=0.403, valid_loss=0.040]        \n",
      "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.403, train_loss_epoch=0.403, valid_loss=0.040]        \n",
      "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.401, train_loss_epoch=0.401, valid_loss=0.040]        \n",
      "Epoch 608: 100%|██████████| 1/1 [00:00<00:00, 36.21it/s, v_num=0, train_loss_step=0.401, train_loss_epoch=0.401, valid_loss=0.040]\n",
      "Epoch 610: 100%|██████████| 1/1 [00:00<00:00, 31.42it/s, v_num=0, train_loss_step=0.397, train_loss_epoch=0.397, valid_loss=0.040]\n",
      "Epoch 612: 100%|██████████| 1/1 [00:00<00:00, 31.33it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396, valid_loss=0.040]\n",
      "Epoch 612: 100%|██████████| 1/1 [00:00<00:00, 20.43it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=0.040]\n",
      "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=0.040]        \n",
      "Epoch 614: 100%|██████████| 1/1 [00:00<00:00, 19.93it/s, v_num=0, train_loss_step=0.398, train_loss_epoch=0.398, valid_loss=0.040]\n",
      "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.468, valid_loss=0.040]        \n",
      "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=0.040]        \n",
      "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.443, train_loss_epoch=0.443, valid_loss=0.040]        \n",
      "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=0.040]        \n",
      "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.418, train_loss_epoch=0.418, valid_loss=0.040]        \n",
      "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.420, train_loss_epoch=0.420, valid_loss=0.040]        \n",
      "Epoch 629: 100%|██████████| 1/1 [00:00<00:00, 33.31it/s, v_num=0, train_loss_step=0.417, train_loss_epoch=0.417, valid_loss=0.040]\n",
      "Epoch 631: 100%|██████████| 1/1 [00:00<00:00, 28.75it/s, v_num=0, train_loss_step=0.411, train_loss_epoch=0.411, valid_loss=0.040]\n",
      "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.406, train_loss_epoch=0.406, valid_loss=0.040]        \n",
      "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.402, train_loss_epoch=0.402, valid_loss=0.040]        \n",
      "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.402, train_loss_epoch=0.402, valid_loss=0.040]        \n",
      "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=0.040]        \n",
      "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.421, train_loss_epoch=0.421, valid_loss=0.040]        \n",
      "Epoch 644: 100%|██████████| 1/1 [00:00<00:00, 38.02it/s, v_num=0, train_loss_step=0.428, train_loss_epoch=0.428, valid_loss=0.040]\n",
      "Epoch 646: 100%|██████████| 1/1 [00:00<00:00, 34.61it/s, v_num=0, train_loss_step=0.421, train_loss_epoch=0.421, valid_loss=0.040]\n",
      "Epoch 646: 100%|██████████| 1/1 [00:00<00:00, 21.98it/s, v_num=0, train_loss_step=0.401, train_loss_epoch=0.401, valid_loss=0.040]\n",
      "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.401, train_loss_epoch=0.401, valid_loss=0.040]        \n",
      "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.401, train_loss_epoch=0.401, valid_loss=0.040]        \n",
      "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.401, train_loss_epoch=0.401, valid_loss=0.040]        \n",
      "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396, valid_loss=0.040]        \n",
      "Epoch 655: 100%|██████████| 1/1 [00:00<00:00, 40.49it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396, valid_loss=0.040]\n",
      "Epoch 657: 100%|██████████| 1/1 [00:00<00:00, 26.36it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=0.040]\n",
      "Epoch 659: 100%|██████████| 1/1 [00:00<00:00, 28.95it/s, v_num=0, train_loss_step=0.393, train_loss_epoch=0.393, valid_loss=0.040]\n",
      "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.392, train_loss_epoch=0.392, valid_loss=0.040]        \n",
      "Epoch 661: 100%|██████████| 1/1 [00:00<00:00, 25.52it/s, v_num=0, train_loss_step=0.392, train_loss_epoch=0.392, valid_loss=0.040]\n",
      "Epoch 663: 100%|██████████| 1/1 [00:00<00:00, 30.24it/s, v_num=0, train_loss_step=0.393, train_loss_epoch=0.393, valid_loss=0.040]\n",
      "Epoch 663: 100%|██████████| 1/1 [00:00<00:00, 20.68it/s, v_num=0, train_loss_step=0.443, train_loss_epoch=0.443, valid_loss=0.040]\n",
      "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.443, train_loss_epoch=0.443, valid_loss=0.040]        \n",
      "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.040]        \n",
      "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.040]        \n",
      "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.040]        \n",
      "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.040]        \n",
      "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.040]        \n",
      "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.040]        \n",
      "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.465, valid_loss=0.040]        \n",
      "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=0.040]        \n",
      "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.456, train_loss_epoch=0.456, valid_loss=0.040]        \n",
      "Epoch 682: 100%|██████████| 1/1 [00:00<00:00, 28.99it/s, v_num=0, train_loss_step=0.456, train_loss_epoch=0.456, valid_loss=0.040]\n",
      "Epoch 684: 100%|██████████| 1/1 [00:00<00:00, 32.04it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452, valid_loss=0.040]\n",
      "Epoch 686: 100%|██████████| 1/1 [00:00<00:00, 29.92it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.448, valid_loss=0.040]\n",
      "Epoch 686: 100%|██████████| 1/1 [00:00<00:00, 20.27it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.448, valid_loss=0.040]\n",
      "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.448, valid_loss=0.040]        \n",
      "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=0.040]        \n",
      "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.442, train_loss_epoch=0.442, valid_loss=0.040]        \n",
      "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.441, train_loss_epoch=0.441, valid_loss=0.040]        \n",
      "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.439, train_loss_epoch=0.439, valid_loss=0.040]        \n",
      "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.438, train_loss_epoch=0.438, valid_loss=0.040]        \n",
      "Epoch 697: 100%|██████████| 1/1 [00:00<00:00, 29.56it/s, v_num=0, train_loss_step=0.438, train_loss_epoch=0.438, valid_loss=0.040]\n",
      "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 29.79it/s, v_num=0, train_loss_step=0.436, train_loss_epoch=0.436, valid_loss=0.040]\n",
      "Epoch 699: 100%|██████████| 1/1 [00:00<00:00, 21.12it/s, v_num=0, train_loss_step=0.435, train_loss_epoch=0.436, valid_loss=0.040]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 46.61it/s]\u001b[A\n",
      "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.434, train_loss_epoch=0.434, valid_loss=0.0455]        \n",
      "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.433, train_loss_epoch=0.433, valid_loss=0.0455]        \n",
      "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.432, train_loss_epoch=0.432, valid_loss=0.0455]        \n",
      "Epoch 705: 100%|██████████| 1/1 [00:00<00:00, 35.46it/s, v_num=0, train_loss_step=0.432, train_loss_epoch=0.432, valid_loss=0.0455]\n",
      "Epoch 707: 100%|██████████| 1/1 [00:00<00:00, 29.36it/s, v_num=0, train_loss_step=0.430, train_loss_epoch=0.430, valid_loss=0.0455]\n",
      "Epoch 709: 100%|██████████| 1/1 [00:00<00:00, 22.39it/s, v_num=0, train_loss_step=0.429, train_loss_epoch=0.429, valid_loss=0.0455]\n",
      "Epoch 709: 100%|██████████| 1/1 [00:00<00:00, 21.28it/s, v_num=0, train_loss_step=0.429, train_loss_epoch=0.429, valid_loss=0.0455]\n",
      "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.429, train_loss_epoch=0.429, valid_loss=0.0455]        \n",
      "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.427, train_loss_epoch=0.427, valid_loss=0.0455]        \n",
      "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.426, train_loss_epoch=0.426, valid_loss=0.0455]        \n",
      "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=0.0455]        \n",
      "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.424, train_loss_epoch=0.424, valid_loss=0.0455]        \n",
      "Epoch 718: 100%|██████████| 1/1 [00:00<00:00, 39.00it/s, v_num=0, train_loss_step=0.424, train_loss_epoch=0.424, valid_loss=0.0455]\n",
      "Epoch 720: 100%|██████████| 1/1 [00:00<00:00, 31.08it/s, v_num=0, train_loss_step=0.423, train_loss_epoch=0.423, valid_loss=0.0455]\n",
      "Epoch 722: 100%|██████████| 1/1 [00:00<00:00, 22.11it/s, v_num=0, train_loss_step=0.423, train_loss_epoch=0.422, valid_loss=0.0455]\n",
      "Epoch 722: 100%|██████████| 1/1 [00:00<00:00, 21.47it/s, v_num=0, train_loss_step=0.423, train_loss_epoch=0.423, valid_loss=0.0455]\n",
      "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.423, train_loss_epoch=0.423, valid_loss=0.0455]        \n",
      "Epoch 724: 100%|██████████| 1/1 [00:00<00:00, 19.04it/s, v_num=0, train_loss_step=0.432, train_loss_epoch=0.432, valid_loss=0.0455]\n",
      "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.432, train_loss_epoch=0.432, valid_loss=0.0455]        \n",
      "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.437, train_loss_epoch=0.437, valid_loss=0.0455]        \n",
      "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.421, train_loss_epoch=0.421, valid_loss=0.0455]        \n",
      "Epoch 731: 100%|██████████| 1/1 [00:00<00:00, 36.45it/s, v_num=0, train_loss_step=0.428, train_loss_epoch=0.428, valid_loss=0.0455]\n",
      "Epoch 733: 100%|██████████| 1/1 [00:00<00:00, 38.22it/s, v_num=0, train_loss_step=0.419, train_loss_epoch=0.419, valid_loss=0.0455]\n",
      "Epoch 733: 100%|██████████| 1/1 [00:00<00:00, 23.00it/s, v_num=0, train_loss_step=0.423, train_loss_epoch=0.423, valid_loss=0.0455]\n",
      "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.423, train_loss_epoch=0.423, valid_loss=0.0455]        \n",
      "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.426, train_loss_epoch=0.426, valid_loss=0.0455]        \n",
      "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.418, train_loss_epoch=0.418, valid_loss=0.0455]        \n",
      "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.423, train_loss_epoch=0.423, valid_loss=0.0455]        \n",
      "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.416, valid_loss=0.0455]        \n",
      "Epoch 744: 100%|██████████| 1/1 [00:00<00:00, 38.03it/s, v_num=0, train_loss_step=0.414, train_loss_epoch=0.414, valid_loss=0.0455]\n",
      "Epoch 746: 100%|██████████| 1/1 [00:00<00:00, 36.55it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.416, valid_loss=0.0455]\n",
      "Epoch 748: 100%|██████████| 1/1 [00:00<00:00, 31.39it/s, v_num=0, train_loss_step=0.428, train_loss_epoch=0.428, valid_loss=0.0455]\n",
      "Epoch 750: 100%|██████████| 1/1 [00:00<00:00, 21.26it/s, v_num=0, train_loss_step=0.414, train_loss_epoch=0.434, valid_loss=0.0455]\n",
      "Epoch 750: 100%|██████████| 1/1 [00:00<00:00, 19.60it/s, v_num=0, train_loss_step=0.414, train_loss_epoch=0.414, valid_loss=0.0455]\n",
      "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.414, train_loss_epoch=0.414, valid_loss=0.0455]        \n",
      "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.424, train_loss_epoch=0.424, valid_loss=0.0455]        \n",
      "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=0.0455]        \n",
      "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.412, train_loss_epoch=0.412, valid_loss=0.0455]        \n",
      "Epoch 759: 100%|██████████| 1/1 [00:00<00:00, 40.93it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.416, valid_loss=0.0455]\n",
      "Epoch 761: 100%|██████████| 1/1 [00:00<00:00, 20.98it/s, v_num=0, train_loss_step=0.413, train_loss_epoch=0.413, valid_loss=0.0455]\n",
      "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.413, train_loss_epoch=0.413, valid_loss=0.0455]        \n",
      "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.412, train_loss_epoch=0.412, valid_loss=0.0455]        \n",
      "Epoch 766:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.409, train_loss_epoch=0.409, valid_loss=0.0455]        \n",
      "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.409, train_loss_epoch=0.409, valid_loss=0.0455]        \n",
      "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.415, valid_loss=0.0455]        \n",
      "Epoch 770: 100%|██████████| 1/1 [00:00<00:00, 30.67it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.415, valid_loss=0.0455]\n",
      "Epoch 772: 100%|██████████| 1/1 [00:00<00:00, 31.83it/s, v_num=0, train_loss_step=0.440, train_loss_epoch=0.440, valid_loss=0.0455]\n",
      "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.434, train_loss_epoch=0.434, valid_loss=0.0455]        \n",
      "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.421, train_loss_epoch=0.421, valid_loss=0.0455]        \n",
      "Epoch 779:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.415, valid_loss=0.0455]        \n",
      "Epoch 781:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.421, train_loss_epoch=0.421, valid_loss=0.0455]        \n",
      "Epoch 783: 100%|██████████| 1/1 [00:00<00:00, 34.58it/s, v_num=0, train_loss_step=0.413, train_loss_epoch=0.413, valid_loss=0.0455]\n",
      "Epoch 785: 100%|██████████| 1/1 [00:00<00:00, 31.18it/s, v_num=0, train_loss_step=0.418, train_loss_epoch=0.418, valid_loss=0.0455]\n",
      "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.408, train_loss_epoch=0.408, valid_loss=0.0455]        \n",
      "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=0.0455]        \n",
      "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.408, train_loss_epoch=0.408, valid_loss=0.0455]        \n",
      "Epoch 794:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.414, train_loss_epoch=0.414, valid_loss=0.0455]        \n",
      "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.443, train_loss_epoch=0.443, valid_loss=0.0455]        \n",
      "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.424, train_loss_epoch=0.424, valid_loss=0.0455]        \n",
      "Epoch 799: 100%|██████████| 1/1 [00:00<00:00, 23.14it/s, v_num=0, train_loss_step=0.424, train_loss_epoch=0.424, valid_loss=0.0455]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 42.32it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=11734)\u001b[0m \n",
      "Epoch 801: 100%|██████████| 1/1 [00:00<00:00, 30.18it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.415, valid_loss=0.0417]\n",
      "Epoch 801: 100%|██████████| 1/1 [00:00<00:00, 20.58it/s, v_num=0, train_loss_step=0.408, train_loss_epoch=0.408, valid_loss=0.0417]\n",
      "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.408, train_loss_epoch=0.408, valid_loss=0.0417]        \n",
      "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.417, train_loss_epoch=0.417, valid_loss=0.0417]        \n",
      "Epoch 806:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.408, train_loss_epoch=0.408, valid_loss=0.0417]        \n",
      "Epoch 808: 100%|██████████| 1/1 [00:00<00:00, 37.98it/s, v_num=0, train_loss_step=0.410, train_loss_epoch=0.410, valid_loss=0.0417]\n",
      "Epoch 811:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.403, train_loss_epoch=0.403, valid_loss=0.0417]        \n",
      "Epoch 812: 100%|██████████| 1/1 [00:00<00:00, 23.91it/s, v_num=0, train_loss_step=0.404, train_loss_epoch=0.404, valid_loss=0.0417]\n",
      "Epoch 812: 100%|██████████| 1/1 [00:00<00:00, 17.21it/s, v_num=0, train_loss_step=0.402, train_loss_epoch=0.404, valid_loss=0.0417]\n",
      "Epoch 812: 100%|██████████| 1/1 [00:00<00:00, 16.37it/s, v_num=0, train_loss_step=0.402, train_loss_epoch=0.402, valid_loss=0.0417]\n",
      "Epoch 813:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.402, train_loss_epoch=0.402, valid_loss=0.0417]        \n",
      "Epoch 815:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.401, train_loss_epoch=0.401, valid_loss=0.0417]        \n",
      "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.412, train_loss_epoch=0.412, valid_loss=0.0417]        \n",
      "Epoch 817: 100%|██████████| 1/1 [00:00<00:00, 31.58it/s, v_num=0, train_loss_step=0.412, train_loss_epoch=0.412, valid_loss=0.0417]\n",
      "Epoch 819: 100%|██████████| 1/1 [00:00<00:00, 29.34it/s, v_num=0, train_loss_step=0.438, train_loss_epoch=0.438, valid_loss=0.0417]\n",
      "Epoch 821: 100%|██████████| 1/1 [00:00<00:00, 22.36it/s, v_num=0, train_loss_step=0.419, train_loss_epoch=0.404, valid_loss=0.0417]\n",
      "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.419, train_loss_epoch=0.419, valid_loss=0.0417]        \n",
      "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.402, train_loss_epoch=0.402, valid_loss=0.0417]        \n",
      "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.414, train_loss_epoch=0.414, valid_loss=0.0417]        \n",
      "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.402, train_loss_epoch=0.402, valid_loss=0.0417]        \n",
      "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.402, train_loss_epoch=0.402, valid_loss=0.0417]        \n",
      "Epoch 832: 100%|██████████| 1/1 [00:00<00:00, 36.02it/s, v_num=0, train_loss_step=0.397, train_loss_epoch=0.397, valid_loss=0.0417]\n",
      "Epoch 834: 100%|██████████| 1/1 [00:00<00:00, 32.85it/s, v_num=0, train_loss_step=0.418, train_loss_epoch=0.418, valid_loss=0.0417]\n",
      "Epoch 834: 100%|██████████| 1/1 [00:00<00:00, 21.36it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.415, valid_loss=0.0417]\n",
      "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.415, valid_loss=0.0417]        \n",
      "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.408, train_loss_epoch=0.408, valid_loss=0.0417]        \n",
      "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=0.0417]        \n",
      "Epoch 841: 100%|██████████| 1/1 [00:00<00:00, 40.48it/s, v_num=0, train_loss_step=0.398, train_loss_epoch=0.398, valid_loss=0.0417]\n",
      "Epoch 843: 100%|██████████| 1/1 [00:00<00:00, 36.99it/s, v_num=0, train_loss_step=0.400, train_loss_epoch=0.400, valid_loss=0.0417]\n",
      "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=0.0417]        \n",
      "Epoch 848:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.406, train_loss_epoch=0.406, valid_loss=0.0417]        \n",
      "Epoch 850:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.399, train_loss_epoch=0.399, valid_loss=0.0417]        \n",
      "Epoch 852: 100%|██████████| 1/1 [00:00<00:00, 40.82it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=0.0417]\n",
      "Epoch 854: 100%|██████████| 1/1 [00:00<00:00, 21.04it/s, v_num=0, train_loss_step=0.430, train_loss_epoch=0.399, valid_loss=0.0417]\n",
      "Epoch 854: 100%|██████████| 1/1 [00:00<00:00, 19.57it/s, v_num=0, train_loss_step=0.430, train_loss_epoch=0.430, valid_loss=0.0417]\n",
      "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.430, train_loss_epoch=0.430, valid_loss=0.0417]        \n",
      "Epoch 856: 100%|██████████| 1/1 [00:00<00:00, 18.56it/s, v_num=0, train_loss_step=0.419, train_loss_epoch=0.419, valid_loss=0.0417]\n",
      "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.419, train_loss_epoch=0.419, valid_loss=0.0417]        \n",
      "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.420, train_loss_epoch=0.420, valid_loss=0.0417]        \n",
      "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.411, train_loss_epoch=0.411, valid_loss=0.0417]        \n",
      "Epoch 863: 100%|██████████| 1/1 [00:00<00:00, 35.44it/s, v_num=0, train_loss_step=0.397, train_loss_epoch=0.397, valid_loss=0.0417]\n",
      "Epoch 865: 100%|██████████| 1/1 [00:00<00:00, 37.10it/s, v_num=0, train_loss_step=0.406, train_loss_epoch=0.406, valid_loss=0.0417]\n",
      "Epoch 868:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.401, train_loss_epoch=0.401, valid_loss=0.0417]        \n",
      "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396, valid_loss=0.0417]        \n",
      "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.392, train_loss_epoch=0.392, valid_loss=0.0417]        \n",
      "Epoch 874: 100%|██████████| 1/1 [00:00<00:00, 41.30it/s, v_num=0, train_loss_step=0.392, train_loss_epoch=0.392, valid_loss=0.0417]\n",
      "Epoch 877:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.399, train_loss_epoch=0.399, valid_loss=0.0417]        \n",
      "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.388, train_loss_epoch=0.388, valid_loss=0.0417]        \n",
      "Epoch 881:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.418, train_loss_epoch=0.418, valid_loss=0.0417]        \n",
      "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.391, train_loss_epoch=0.391, valid_loss=0.0417]        \n",
      "Epoch 884: 100%|██████████| 1/1 [00:00<00:00, 25.31it/s, v_num=0, train_loss_step=0.401, train_loss_epoch=0.401, valid_loss=0.0417]\n",
      "Epoch 886: 100%|██████████| 1/1 [00:00<00:00, 21.42it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.389, valid_loss=0.0417]\n",
      "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.389, valid_loss=0.0417]        \n",
      "Epoch 888: 100%|██████████| 1/1 [00:00<00:00, 17.20it/s, v_num=0, train_loss_step=0.393, train_loss_epoch=0.393, valid_loss=0.0417]\n",
      "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.393, train_loss_epoch=0.393, valid_loss=0.0417]        \n",
      "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.448, valid_loss=0.0417]        \n",
      "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.429, train_loss_epoch=0.429, valid_loss=0.0417]        \n",
      "Epoch 893: 100%|██████████| 1/1 [00:00<00:00, 37.17it/s, v_num=0, train_loss_step=0.429, train_loss_epoch=0.429, valid_loss=0.0417]\n",
      "Epoch 895: 100%|██████████| 1/1 [00:00<00:00, 31.98it/s, v_num=0, train_loss_step=0.419, train_loss_epoch=0.419, valid_loss=0.0417]\n",
      "Epoch 895: 100%|██████████| 1/1 [00:00<00:00, 21.73it/s, v_num=0, train_loss_step=0.430, train_loss_epoch=0.419, valid_loss=0.0417]\n",
      "Epoch 895: 100%|██████████| 1/1 [00:00<00:00, 21.01it/s, v_num=0, train_loss_step=0.430, train_loss_epoch=0.430, valid_loss=0.0417]\n",
      "Epoch 896:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.430, train_loss_epoch=0.430, valid_loss=0.0417]        \n",
      "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.420, train_loss_epoch=0.420, valid_loss=0.0417]        \n",
      "Epoch 899: 100%|██████████| 1/1 [00:00<00:00, 22.70it/s, v_num=0, train_loss_step=0.407, train_loss_epoch=0.417, valid_loss=0.0417]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=11734)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 44.01it/s]\u001b[A\n",
      "Epoch 901:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.406, train_loss_epoch=0.406, valid_loss=0.0429]        \n",
      "Epoch 901: 100%|██████████| 1/1 [00:00<00:00, 31.15it/s, v_num=0, train_loss_step=0.406, train_loss_epoch=0.406, valid_loss=0.0429]\n",
      "Epoch 903: 100%|██████████| 1/1 [00:00<00:00, 31.24it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=0.0429]\n",
      "Epoch 905: 100%|██████████| 1/1 [00:00<00:00, 28.14it/s, v_num=0, train_loss_step=0.400, train_loss_epoch=0.400, valid_loss=0.0429]\n",
      "Epoch 908:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.397, train_loss_epoch=0.397, valid_loss=0.0429]        \n",
      "Epoch 910:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.390, train_loss_epoch=0.390, valid_loss=0.0429]        \n",
      "Epoch 912:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.392, train_loss_epoch=0.392, valid_loss=0.0429]        \n",
      "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=0.0429]        \n",
      "Epoch 916: 100%|██████████| 1/1 [00:00<00:00, 33.83it/s, v_num=0, train_loss_step=0.397, train_loss_epoch=0.397, valid_loss=0.0429]\n",
      "Epoch 918: 100%|██████████| 1/1 [00:00<00:00, 30.28it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=0.0429]\n",
      "Epoch 920: 100%|██████████| 1/1 [00:00<00:00, 22.01it/s, v_num=0, train_loss_step=0.397, train_loss_epoch=0.397, valid_loss=0.0429]\n",
      "Epoch 921:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.397, train_loss_epoch=0.397, valid_loss=0.0429]        \n",
      "Epoch 923:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396, valid_loss=0.0429]        \n",
      "Epoch 925:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.398, train_loss_epoch=0.398, valid_loss=0.0429]        \n",
      "Epoch 927:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.387, train_loss_epoch=0.387, valid_loss=0.0429]        \n",
      "Epoch 929: 100%|██████████| 1/1 [00:00<00:00, 30.65it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.389, valid_loss=0.0429]\n",
      "Epoch 931: 100%|██████████| 1/1 [00:00<00:00, 27.23it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=0.0429]\n",
      "Epoch 933: 100%|██████████| 1/1 [00:00<00:00, 21.84it/s, v_num=0, train_loss_step=0.408, train_loss_epoch=0.408, valid_loss=0.0429]\n",
      "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.408, train_loss_epoch=0.408, valid_loss=0.0429]        \n",
      "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.392, train_loss_epoch=0.392, valid_loss=0.0429]        \n",
      "Epoch 938:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.388, train_loss_epoch=0.388, valid_loss=0.0429]        \n",
      "Epoch 938: 100%|██████████| 1/1 [00:00<00:00, 29.45it/s, v_num=0, train_loss_step=0.388, train_loss_epoch=0.388, valid_loss=0.0429]\n",
      "Epoch 940: 100%|██████████| 1/1 [00:00<00:00, 28.20it/s, v_num=0, train_loss_step=0.394, train_loss_epoch=0.394, valid_loss=0.0429]\n",
      "Epoch 943:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.378, valid_loss=0.0429]        \n",
      "Epoch 944: 100%|██████████| 1/1 [00:00<00:00, 19.75it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379, valid_loss=0.0429]\n",
      "Epoch 945:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379, valid_loss=0.0429]        \n",
      "Epoch 947:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.376, train_loss_epoch=0.376, valid_loss=0.0429]        \n",
      "Epoch 949:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.375, train_loss_epoch=0.375, valid_loss=0.0429]        \n",
      "Epoch 951:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.370, train_loss_epoch=0.370, valid_loss=0.0429]        \n",
      "Epoch 953:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379, valid_loss=0.0429]        \n",
      "Epoch 955:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.370, train_loss_epoch=0.370, valid_loss=0.0429]        \n",
      "Epoch 957:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.368, train_loss_epoch=0.368, valid_loss=0.0429]        \n",
      "Epoch 957: 100%|██████████| 1/1 [00:00<00:00, 37.16it/s, v_num=0, train_loss_step=0.368, train_loss_epoch=0.368, valid_loss=0.0429]\n",
      "Epoch 959: 100%|██████████| 1/1 [00:00<00:00, 35.46it/s, v_num=0, train_loss_step=0.367, train_loss_epoch=0.367, valid_loss=0.0429]\n",
      "Epoch 959: 100%|██████████| 1/1 [00:00<00:00, 22.52it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=0.0429]\n",
      "Epoch 960:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=0.0429]        \n",
      "Epoch 962:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.394, train_loss_epoch=0.394, valid_loss=0.0429]        \n",
      "Epoch 964: 100%|██████████| 1/1 [00:00<00:00, 33.37it/s, v_num=0, train_loss_step=0.381, train_loss_epoch=0.381, valid_loss=0.0429]\n",
      "Epoch 966: 100%|██████████| 1/1 [00:00<00:00, 28.46it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365, valid_loss=0.0429]\n",
      "Epoch 968: 100%|██████████| 1/1 [00:00<00:00, 21.28it/s, v_num=0, train_loss_step=0.382, train_loss_epoch=0.382, valid_loss=0.0429]\n",
      "Epoch 969:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.382, train_loss_epoch=0.382, valid_loss=0.0429]        \n",
      "Epoch 970: 100%|██████████| 1/1 [00:00<00:00, 19.42it/s, v_num=0, train_loss_step=0.364, train_loss_epoch=0.364, valid_loss=0.0429]\n",
      "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.364, train_loss_epoch=0.364, valid_loss=0.0429]        \n",
      "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.376, train_loss_epoch=0.376, valid_loss=0.0429]        \n",
      "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363, valid_loss=0.0429]        \n",
      "Epoch 977:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.372, valid_loss=0.0429]        \n",
      "Epoch 979:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.376, train_loss_epoch=0.376, valid_loss=0.0429]        \n",
      "Epoch 981: 100%|██████████| 1/1 [00:00<00:00, 31.64it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361, valid_loss=0.0429]\n",
      "Epoch 983: 100%|██████████| 1/1 [00:00<00:00, 29.71it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.372, valid_loss=0.0429]\n",
      "Epoch 986:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=0.0429]        \n",
      "Epoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.370, train_loss_epoch=0.370, valid_loss=0.0429]        \n",
      "Epoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=0.0429]        \n",
      "Epoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.358, train_loss_epoch=0.358, valid_loss=0.0429]        \n",
      "Epoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.373, train_loss_epoch=0.373, valid_loss=0.0429]        \n",
      "Epoch 994: 100%|██████████| 1/1 [00:00<00:00, 29.53it/s, v_num=0, train_loss_step=0.373, train_loss_epoch=0.373, valid_loss=0.0429]\n",
      "Epoch 996: 100%|██████████| 1/1 [00:00<00:00, 29.67it/s, v_num=0, train_loss_step=0.362, train_loss_epoch=0.362, valid_loss=0.0429]\n",
      "Epoch 998: 100%|██████████| 1/1 [00:00<00:00, 40.86it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=0.0429]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=11734)\u001b[0m `Trainer.fit` stopped: `max_steps=1000` reached.\n",
      "2024-12-22 08:48:25,665\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/felip/ray_results/_train_tune_2024-12-22_08-14-41' in 0.0109s.\n",
      "2024-12-22 08:48:25,669\tERROR tune.py:1037 -- Trials did not complete: [_train_tune_eaea9_00020, _train_tune_eaea9_00026, _train_tune_eaea9_00027]\n",
      "Seed set to 19\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 21.47it/s, v_num=0, train_loss_step=0.364, train_loss_epoch=0.359, valid_loss=0.0429]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 37.30it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=11734)\u001b[0m \n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00, 10.46it/s, v_num=0, train_loss_step=0.364, train_loss_epoch=0.364, valid_loss=0.0419]\n",
      "Epoch 999: 100%|██████████| 1/1 [00:00<00:00,  9.93it/s, v_num=0, train_loss_step=0.364, train_loss_epoch=0.364, valid_loss=0.0419]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type          | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | loss            | WMAPE         | 0      | eval \n",
      "1 | padder          | ConstantPad1d | 0      | train\n",
      "2 | scaler          | TemporalNorm  | 0      | train\n",
      "3 | hist_encoder    | LSTM          | 363 K  | train\n",
      "4 | context_adapter | Linear        | 231 K  | train\n",
      "5 | mlp_decoder     | MLP           | 769    | train\n",
      "----------------------------------------------------------\n",
      "596 K     Trainable params\n",
      "0         Non-trainable params\n",
      "596 K     Total params\n",
      "2.385     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "1         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45561e783b7b43f5ba69dcc6feacd917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3bbf289e5994f8d938c5a1e8a3746be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "904a54aef9dc443baac6fee2b0db5f94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d39594601de949699e0dc9405a5c25fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db6d084b70974040a23bb2b7699936db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3834f474326b4a3688fd701e731d8139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e34005c0cb44a1a00fe8f8d89aede8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d135dd667d14fdd860e2de8091d386a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "623b91fa31bc4ea5a0c92f464937b1da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c6cd965bf064c7a8f334bcb41c51aa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f269f5f6ee24602ab8292e929a55418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "692c77e759634768a68ec6c9921bba0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1000` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40fdee3ad07046d7ba53362603a2a759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.023405799364705722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/neuralforecast/core.py:214: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model.fit(train, val_size=30)\n",
    "\n",
    "p = model.predict().reset_index()\n",
    "p = p.merge(valid[[\"ds\", \"unique_id\", \"y\"]], on=[\"ds\", \"unique_id\"], how=\"left\")\n",
    "print(wmape(p[\"y\"], p[\"AutoLSTM\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1333.33x750 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(1280 / 96, 720 / 96))\n",
    "fig.tight_layout(pad=7.0)\n",
    "for ax_i, unique_id in enumerate([\"ABEV3\", \"BBAS3\"]):\n",
    "    plot_df = pd.concat(\n",
    "        [\n",
    "            train.loc[train[\"unique_id\"] == unique_id].tail(30),\n",
    "            p.loc[p[\"unique_id\"] == unique_id],\n",
    "        ]\n",
    "    ).set_index(\"ds\")\n",
    "    plot_df[[\"y\", \"AutoLSTM\"]].plot(ax=ax[ax_i], linewidth=2, title=unique_id)\n",
    "\n",
    "    ax[ax_i].grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neuralforecast_lstm.joblib']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model, \"neuralforecast_lstm.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos obter as melhores configurações do Tuning\n",
    "\n",
    "best_config = models[0].results.get_best_result().metrics[\"config\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O resultado da busca deve ser algo como em:\n",
    "\n",
    "{'h': 90,\n",
    " 'encoder_hidden_size': 100,\n",
    " 'encoder_n_layers': 3,\n",
    " 'context_size': 5,\n",
    " 'decoder_hidden_size': 128,\n",
    " 'learning_rate': 0.0015887770515036423,\n",
    " 'max_steps': 500,\n",
    " 'batch_size': 32,\n",
    " 'loss': WMAPE(),\n",
    " 'check_val_every_n_epoch': 100,\n",
    " 'random_seed': 13,\n",
    " 'input_size': 5760}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_config = {\n",
    "    \"h\": 77,\n",
    "    \"encoder_hidden_size\": 300,\n",
    "    \"encoder_n_layers\": 1,\n",
    "    \"context_size\": 10,\n",
    "    \"decoder_hidden_size\": 64,\n",
    "    \"learning_rate\": 0.008279309926218455,\n",
    "    \"max_steps\": 10_000,\n",
    "    \"batch_size\": 32,\n",
    "    \"loss\": WMAPE(),\n",
    "    \"check_val_every_n_epoch\": 100,  # 'val_check_steps': 100,\n",
    "    \"random_seed\": 19,\n",
    "    \"input_size\": 4928,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 19\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type          | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | loss            | WMAPE         | 0      | train\n",
      "1 | padder          | ConstantPad1d | 0      | train\n",
      "2 | scaler          | TemporalNorm  | 0      | train\n",
      "3 | hist_encoder    | LSTM          | 363 K  | train\n",
      "4 | context_adapter | Linear        | 231 K  | train\n",
      "5 | mlp_decoder     | MLP           | 769    | train\n",
      "----------------------------------------------------------\n",
      "596 K     Trainable params\n",
      "0         Non-trainable params\n",
      "596 K     Total params\n",
      "2.385     Total estimated model params size (MB)\n",
      "11        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "819eeffcc8f04158afe300714f3fad9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b319e1c950b44a66861f2e2a73b4108c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32ed0a44899747c4b270901dd6ff2c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d704805db8849e7b6e8757c054915f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8b51e248b5c46d0a7c2e028396f4a93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63996a5e44e34cc7ad9dcac176dd8647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "996a952d7486490b9cdef8dc139b7e1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3694769a9c30476e8255e774e6d13e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa02b063c47b47ec974967d2b74007a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa8c7d538791494586d0158f3012c9e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c6895c289fb4fd9b7cd9063bc78f5a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93b921c922de4ea8a316e3639d6e2c6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b81962f33b4466b94c014fee1219d1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10adc1a63cfa4fb2be80306b57363fcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e32af5681a44d1c859dc1c3317fec8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55f0e323ba6e483faa0dace0f655fb46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57871d4f2f314cd6aa79bc126f637a97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b80eacf2a8f413881b2e6027dd55a46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3826cf14ce3d47dcb20ee8078cb83c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "842cdce6b64c4a7ab922f6e364225caf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fce6b32e38c45f9b349ee812adfe683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1a2d50e2e80492181512cd22444088d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f87af09eeb542b9844fde1a1140bb51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f2f83bbcd62415e840b5ca2ea1366a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53da779a9db9493c93b98b31ee8c283d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be37a5e45c414e2b8ca2db54a49b1cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76038b0111b6427eaf2b9ef004eac3d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7226e7f08b8241e08e8b96f2bbe19aba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18d53833238a49fa98fb470c8313b8b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4e5d39f7e5e495084f55654cdb13040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58942ea6c7ab4122a13270a0f18545ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a0dca8e77504bd2b7ce271b55cd1775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe0d2970a1a4dcdab67387c9433096e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf0d7dc3d4224187a882656751fb030b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb4f7e1bcec7439da76d865b2463e551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13feedcfa0884266ae43e71d2f63d392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6e3d278183e40c89c64bcc1ce78c3ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9574e5bff12245ad805cb55f80e01e5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a741be2f607d4e7f8c5c9b3d3acbab81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a8265236dfe407b8ed06472f9f38fd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "605b2fbb7df04725b80c541f66199d11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d0fdab6a85b4662917d49005d88a687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d99fca3e75644f578788494d3a2d95d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea539ee99b944d428a5c31b6852dbb9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "626fea5fc7af434f8b1d472aee13fbc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfa41567360c4e10b0b143e60eaebcfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a89566b7fd4761b80e439b58bd9b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d44a955167fd4d61b24efcf270e62059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51aee8a0a7f549bf9ea4d60a84bd251d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "474f33ce86c7490abd4c3af8a678a7d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1bcc7af0cfd4ba980a2e03ccb2c809b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f1085d9aa6d45318638bc8ab0d6d1d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a00b51bae07430486a0b3ca1bfc5239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dec0de45d3944afa595c816e8939625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25fb8f347ad5439f95c396a89c9d500e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ef39f5c1a974319adc5110fa3befdaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2bfd26401fa46168e1ebaaad717d553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48c87dc74939469abe6a379604b6cf7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b36f693f7ca340868a425bf958ff2bac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d91ff205a07445728c320d227a154e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9346d28587784626840be2b05020e4ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b1896b07864894aaac5527bddf712f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a6e8bfc6617447ab1d1e1c6e8907614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d44bfc14046a403390422704c826015e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e74ba4e95aa642209cd7a1cd12a3f9af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14b7c2253a3a4347b8a1961739c7c6c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89895ce51f5e4d78869deac52ee06889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "458303b38aa544ea8d4303f26d2aed19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ba4bc5b072544ccb9e94f945150460f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b8a8246981c47cd8bde33d30771e119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7213fe4cf8c54765a9f061fb61258aee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f366b6b7b2494654b9f0da19efa4ad26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d54b9c83b1347e4b1e65b00b885386d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfa7198971434f26b25baf30b65a5e74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00e8708742514a03921e5df86d049abf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "529835d9cfae4f4a82862588767f056f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f5da254bd5483aa1ffe9d37d8800ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a18d5663d1f7437f83c43bae7dfea99c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e90d147dfd44d3c9120df1cf00ab3b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49aeb4932c3c4ee69174d84b60737719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7429214722194a22b070527c32281045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5a3a10ce09b42f886be9489b89ca0ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0387a578aa0e4a60a2200472d1d3fe7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7736ac5c038c47488f0291fc72797724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad60a08656214af6aeb0bbd32767cdb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea3d2ddf5d2048a3993cc30f76992e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c3ad432629d45cea6ee8e4b65bc51fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe453d366af4493be6dcd913be07c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "910771fcb5f54f28ac5e7771b7090eae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f3e8d34fbfb41c39d7ef68d262f25ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa1246fb70984ec7aa85400e88eb072d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8aa0f508523451db68959e83a77689b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86f88d62fe6645fda1a9c292007810ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86b834d6a1d54abc8138a414b0495120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b640b0485c6c4c898be5daf060f75173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be988b9eeb9a4b8abeb73b0886332c8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "242d8cf3e6ca46249e66b8855e71bd73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d38c319ed20648a2b7ae4beecd917540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9900bc43eab7444aa4608122ea4fed3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30c2a2e22740472796f0ec926b79209c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a608c1b5d154f17b177222ac1328be5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d01e54196b444ba9acbf3d57f79c4eae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=10000` reached.\n"
     ]
    }
   ],
   "source": [
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import LSTM\n",
    "\n",
    "models = [\n",
    "    LSTM(\n",
    "        scaler_type=\"robust\",\n",
    "        #            futr_exog_list=['onpromotion', 'weekday_0',\n",
    "        #    'weekday_1', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5',\n",
    "        #    'weekday_6', 'dcoilwtico'],\n",
    "        **best_config,\n",
    "    )\n",
    "]\n",
    "\n",
    "model = NeuralForecast(models=models, freq=\"D\")\n",
    "model.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neuralforecast_lstm_v6_10_000_epochs.joblib']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model, \"neuralforecast_lstm_v6_10_000_epochs.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bfe659b4ab94b52a91ba63c1ae81e8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.020077799093674208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felip/Documents/tech-challenge-4/.venv/lib/python3.11/site-packages/neuralforecast/core.py:214: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "p = model.predict().reset_index()\n",
    "p = p.merge(valid[[\"ds\", \"unique_id\", \"y\"]], on=[\"ds\", \"unique_id\"], how=\"left\")\n",
    "print(wmape(p[\"y\"], p[\"LSTM\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1333.33x750 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(1280 / 96, 720 / 96))\n",
    "fig.tight_layout(pad=7.0)\n",
    "for ax_i, unique_id in enumerate([\"ABEV3\", \"BBAS3\"]):\n",
    "    plot_df = pd.concat(\n",
    "        [\n",
    "            train.loc[train[\"unique_id\"] == unique_id].tail(30),\n",
    "            p.loc[p[\"unique_id\"] == unique_id],\n",
    "        ]\n",
    "    ).set_index(\"ds\")\n",
    "    plot_df[[\"y\", \"LSTM\"]].plot(ax=ax[ax_i], linewidth=2, title=unique_id)\n",
    "\n",
    "    ax[ax_i].grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid[\"dcoilwtico\"] = train[\"dcoilwtico\"].iloc[-1]\n",
    "\n",
    "p = model.predict(futr_df=valid).reset_index()\n",
    "p = p.merge(valid[[\"ds\", \"unique_id\", \"y\"]], on=[\"ds\", \"unique_id\"], how=\"left\")\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(1280 / 96, 720 / 96))\n",
    "fig.tight_layout(pad=7.0)\n",
    "for ax_i, unique_id in enumerate([\"MEATS\", \"PERSONAL CARE\"]):\n",
    "    plot_df = pd.concat(\n",
    "        [\n",
    "            train.loc[train[\"unique_id\"] == unique_id].tail(30),\n",
    "            p.loc[p[\"unique_id\"] == unique_id],\n",
    "        ]\n",
    "    ).set_index(\"ds\")  # Concatenate the train and forecast dataframes\n",
    "    plot_df[[\"y\", \"LSTM\"]].plot(ax=ax[ax_i], linewidth=2, title=unique_id)\n",
    "\n",
    "    ax[ax_i].grid()\n",
    "\n",
    "print(wmape(p[\"y\"], p[\"LSTM\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline com SeasonalNaive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import SeasonalNaive\n",
    "\n",
    "model = StatsForecast(models=[SeasonalNaive(season_length=7)], freq=\"D\", n_jobs=-1)\n",
    "model.fit(train)\n",
    "\n",
    "forecast_df = model.predict(h=h, level=[90])\n",
    "forecast_df = forecast_df.reset_index().merge(valid, on=[\"ds\", \"unique_id\"], how=\"left\")\n",
    "wmape_ = wmape(forecast_df[\"y\"], forecast_df[\"SeasonalNaive\"])\n",
    "print(f\"WMAPE: {wmape_:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referência\n",
    "\n",
    "https://mariofilho.com/como-prever-series-temporais-com-lstm-em-python/#como-instalar-a-neuralforecast-com-e-sem-suporte-a-gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outra opção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import LSTM\n",
    "from neuralforecast.losses.pytorch import DistributionLoss\n",
    "from neuralforecast.utils import AirPassengersPanel, AirPassengersStatic\n",
    "\n",
    "Y_train_df = AirPassengersPanel[\n",
    "    AirPassengersPanel.ds < AirPassengersPanel[\"ds\"].values[-12]\n",
    "]  # 132 train\n",
    "Y_test_df = AirPassengersPanel[\n",
    "    AirPassengersPanel.ds >= AirPassengersPanel[\"ds\"].values[-12]\n",
    "].reset_index(drop=True)  # 12 test\n",
    "\n",
    "nf = NeuralForecast(\n",
    "    models=[\n",
    "        LSTM(\n",
    "            h=12,\n",
    "            input_size=-1,\n",
    "            loss=DistributionLoss(distribution=\"Normal\", level=[80, 90]),\n",
    "            scaler_type=\"robust\",\n",
    "            encoder_n_layers=2,\n",
    "            encoder_hidden_size=128,\n",
    "            context_size=10,\n",
    "            decoder_hidden_size=128,\n",
    "            decoder_layers=2,\n",
    "            max_steps=200,\n",
    "            futr_exog_list=[\"y_[lag12]\"],\n",
    "            stat_exog_list=[\"airline1\"],\n",
    "        )\n",
    "    ],\n",
    "    freq=\"M\",\n",
    ")\n",
    "nf.fit(df=Y_train_df, static_df=AirPassengersStatic)\n",
    "Y_hat_df = nf.predict(futr_df=Y_test_df)\n",
    "\n",
    "Y_hat_df = Y_hat_df.reset_index(drop=False).drop(columns=[\"unique_id\", \"ds\"])\n",
    "plot_df = pd.concat([Y_test_df, Y_hat_df], axis=1)\n",
    "plot_df = pd.concat([Y_train_df, plot_df])\n",
    "\n",
    "plot_df = plot_df[plot_df.unique_id == \"Airline1\"].drop(\"unique_id\", axis=1)\n",
    "plt.plot(plot_df[\"ds\"], plot_df[\"y\"], c=\"black\", label=\"True\")\n",
    "plt.plot(plot_df[\"ds\"], plot_df[\"LSTM\"], c=\"purple\", label=\"mean\")\n",
    "plt.plot(plot_df[\"ds\"], plot_df[\"LSTM-median\"], c=\"blue\", label=\"median\")\n",
    "plt.fill_between(\n",
    "    x=plot_df[\"ds\"][-12:],\n",
    "    y1=plot_df[\"LSTM-lo-90\"][-12:].values,\n",
    "    y2=plot_df[\"LSTM-hi-90\"][-12:].values,\n",
    "    alpha=0.4,\n",
    "    label=\"level 90\",\n",
    ")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
